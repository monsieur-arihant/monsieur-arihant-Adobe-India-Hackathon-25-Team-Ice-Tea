# PDF Heading Detection System

## Overview

This project is an AI-powered system that automatically detects and classifies different heading levels (TITLE, H1, H2, H3) and regular text from PDF documents. Built using machine learning with RandomForest classifier, it analyzes font properties, positioning, and text patterns to accurately categorize content structure.

## Features

üîç **Smart Heading Detection**: Automatically identifies titles, headings (H1, H2, H3), and regular text  
ü§ñ **Machine Learning Powered**: Uses RandomForest classifier trained on academic papers  
üéØ **Adaptive Font Analysis**: Works with PDFs of different font sizes and styles  
üßπ **Advanced Filtering**: Removes watermarks, table of contents, and junk symbols  
üìÑ **Text Merging**: Combines text spans that belong to the same sentence/paragraph  
üîÑ **Batch Processing**: Process multiple PDFs automatically  
üìä **JSON Output**: Clean, structured output for easy integration  
üê≥ **Docker Ready**: Containerized for easy deployment and reproducibility  

## Technology Stack

- **Python 3.9+**: Core programming language
- **PyMuPDF (fitz)**: PDF text extraction and analysis
- **scikit-learn**: Machine learning (RandomForest classifier)
- **pandas**: Data manipulation and analysis
- **numpy**: Numerical computations
- **Docker**: Containerization for deployment

## Project Structure

```
pdf-heading-detector/
‚îú‚îÄ‚îÄ Dockerfile           # Docker container configuration
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îú‚îÄ‚îÄ main.py             # Main application code
‚îú‚îÄ‚îÄ README.md           # This file
‚îú‚îÄ‚îÄ input/              # Place your PDF files here
‚îÇ   ‚îú‚îÄ‚îÄ document1.pdf
‚îÇ   ‚îî‚îÄ‚îÄ document2.pdf
‚îî‚îÄ‚îÄ output/             # JSON results appear here
    ‚îú‚îÄ‚îÄ document1_labels.json
    ‚îî‚îÄ‚îÄ document2_labels.json
```

## Algorithm Overview

### 1. **PDF Text Extraction**
- Extracts text with font properties (size, style, position)
- Merges text spans on the same line for better accuracy
- Filters out watermarks, headers, footers, and margins

### 2. **Feature Engineering**
- **Font Size**: Relative to document's average font size
- **Font Style**: Bold detection for emphasis
- **Position**: X, Y coordinates for layout analysis
- **Text Properties**: Length, uppercase ratio, patterns
- **Context**: Page position, document structure

### 3. **Smart Filtering**
- **Watermark Detection**: Removes translucent or margin text
- **TOC Filtering**: Excludes table of contents entries
- **Symbol Cleanup**: Filters junk symbols, page numbers, dots
- **Pattern Recognition**: Identifies numbered sections (1.1, 1.1.1)

### 4. **Machine Learning Classification**
- **Training Data**: Academic papers from arXiv
- **Model**: RandomForest with 100 estimators
- **Features**: Font size, position, formatting, text properties
- **Labels**: TITLE, H1, H2, H3, P (paragraph)

### 5. **Post-Processing**
- **Single Title Rule**: Ensures only one TITLE per document
- **Hierarchy Validation**: Maintains logical heading structure
- **Quality Assurance**: Validates predictions against patterns

## Installation & Usage

### Method 1: Docker (Recommended)

#### Prerequisites
- Docker installed on your system
- PDF files to process

#### Quick Start

1. **Setup directories:**
```bash
mkdir -p input output
```

2. **Add your PDF files:**
```bash
cp your_document.pdf input/
```

3. **Build the Docker image:**
```bash
docker build -t pdf-heading-detector .
```

4. **Run the container:**

**For Linux/Mac:**
```bash
docker run --rm -v $(pwd)/input:/app/input:ro -v $(pwd)/output:/app/output:rw pdf-heading-detector
```

**For Windows PowerShell:**
```bash
docker run --rm -v ${PWD}/input:/app/input:ro -v ${PWD}/output:/app/output:rw pdf-heading-detector
```

**For Windows Command Prompt:**
```bash
docker run --rm -v %cd%/input:/app/input:ro -v %cd%/output:/app/output:rw pdf-heading-detector
```

5. **Check results:**
```bash
ls output/
```

#### One-Line Build and Run
```bash
# Linux/Mac
docker build -t pdf-detector . && docker run --rm -v $(pwd)/input:/app/input:ro -v $(pwd)/output:/app/output:rw pdf-detector

# Windows PowerShell  
docker build -t pdf-detector . && docker run --rm -v ${PWD}/input:/app/input:ro -v ${PWD}/output:/app/output:rw pdf-detector
```

### Method 2: Local Python Installation

#### Prerequisites
- Python 3.9 or higher
- pip package manager

#### Installation
```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
python main.py
```

## Output Format

The system generates JSON files for each processed PDF with a hierarchical structure:

```json
{
  "title": "Machine Learning in Document Processing: A Comprehensive Review",
  "outline": [
    {
      "page": 1,
      "text": "Abstract",
      "label": "H1"
    },
    {
      "page": 1,
      "text": "This paper presents a comprehensive review of machine learning techniques...",
      "label": "P"
    },
    {
      "page": 2,
      "text": "1. Introduction",
      "label": "H1"
    },
    {
      "page": 2,
      "text": "1.1 Background and Motivation",
      "label": "H2"
    },
    {
      "page": 2,
      "text": "1.1.1 Recent Advances",
      "label": "H3"
    },
    {
      "page": 2,
      "text": "Machine learning has revolutionized document processing...",
      "label": "P"
    },
    {
      "page": 3,
      "text": "2. Methodology",
      "label": "H1"
    },
    {
      "page": 3,
      "text": "2.1 Data Collection",
      "label": "H2"
    }
  ]
}
```

### Structure Explanation

- **title**: The main document title (extracted from TITLE label)
- **outline**: Hierarchical structure containing all other content:
  - **page**: Page number where the text appears
  - **text**: The actual text content
  - **label**: Classification (H1, H2, H3, P)

### Label Definitions

- **title** (top level): Main document title
- **H1**: Primary headings (chapters, major sections)
- **H2**: Secondary headings (subsections)  
- **H3**: Tertiary headings (sub-subsections)
- **P**: Regular paragraph text

*Note: The title appears at the top level, while all other content is organized hierarchically in the outline.*

## Docker Command Explanation

```bash
docker run --rm -v $(pwd)/input:/app/input:ro -v $(pwd)/output:/app/output:rw pdf-heading-detector
```

**Parameters:**
- `--rm`: Automatically remove container when it exits
- `-v $(pwd)/input:/app/input:ro`: Mount local `input/` folder as read-only
- `-v $(pwd)/output:/app/output:rw`: Mount local `output/` folder as read-write
- `pdf-heading-detector`: The Docker image name

## Configuration

### File Size Limits
- Maximum PDF size: 48MB
- Larger files are automatically skipped with warning

### Supported PDF Types
- Text-based PDFs (not scanned images)
- Academic papers, reports, documents
- Multi-page documents
- Various font sizes and styles

## Troubleshooting

### Common Issues

**No output files generated:**
- Verify PDF files are in the `input/` directory
- Ensure PDFs are text-based (not scanned images)
- Check that PDFs are not corrupted or password-protected
- View container logs: `docker logs <container_id>`

**Permission issues:**
- Ensure the `output/` directory has write permissions
- On Linux/Mac: `chmod 755 output/`
- On Windows: Check folder permissions

**Large files skipped:**
- Files over 48MB are automatically skipped
- Compress PDFs or split large documents
- Check file size: `ls -lh input/`

**Poor classification accuracy:**
- Works best with structured documents (papers, reports)
- May struggle with highly formatted or artistic layouts
- Ensure PDFs have consistent formatting

### Debug Mode

For development and debugging:

```bash
# Interactive container access
docker run -it --rm -v $(pwd):/app pdf-heading-detector bash

# Check logs
docker run --rm -v $(pwd)/input:/app/input:ro -v $(pwd)/output:/app/output:rw pdf-heading-detector 2>&1
```

## Performance

- **Processing Speed**: ~100-500 pages per minute (depends on complexity)
- **Memory Usage**: ~200-500MB per PDF
- **Accuracy**: 85-95% on structured academic documents
- **Model Size**: ~50MB trained model

## Model Training

The system automatically trains on sample academic papers from arXiv:
- Attention mechanism papers
- BERT and transformer research
- Computer vision papers
- Deep learning reviews

### Training Features
- Font size relative to document average
- Text position (x, y coordinates)
- Bold formatting detection
- Uppercase text ratio
- Text length analysis
- Page positioning

## API Integration

The hierarchical JSON output format makes it easy to integrate with other systems:

```python
import json

# Load results
with open('output/document_labels.json', 'r') as f:
    data = json.load(f)

# Access title
print(f"Document Title: {data['title']}")

# Process outline
for item in data['outline']:
    if item['label'] in ['H1', 'H2', 'H3']:
        indent = "  " * (int(item['label'][1]) - 1)  # Create indentation
        print(f"{indent}Page {item['page']}: {item['text']}")
    elif item['label'] == 'P':
        print(f"    Content: {item['text'][:100]}...")  # First 100 chars
```

Example Output:
```
Document Title: Machine Learning in Document Processing: A Comprehensive Review
Page 2: 1. Introduction
  Page 2: 1.1 Background and Motivation
    Page 2: 1.1.1 Recent Advances
    Content: Machine learning has revolutionized document processing...
Page 3: 2. Methodology
  Page 3: 2.1 Data Collection
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test with various PDF types
5. Submit a pull request

## License

This project is developed for Adobe Hackathon 2025 (Round 1A).

## Limitations

- Works best with structured, text-based PDFs
- May struggle with highly artistic or non-standard layouts
- Requires PDFs with extractable text (not scanned images)
- Optimized for English text documents
- Performance varies with document complexity

## Future Enhancements

- Support for scanned PDFs (OCR integration)
- Multi-language support
- Web interface for easier usage
- Real-time processing API
- Enhanced formatting detection
- Table and figure caption recognition

---

**Built with ‚ù§Ô∏è for Adobe Hackathon 2025**