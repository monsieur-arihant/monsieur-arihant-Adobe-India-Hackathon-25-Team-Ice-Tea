filename,page,text,font_size,font_name,bold,x0,y0,uppercase_ratio,length,label
sample_1.pdf,1,Skip to main content,11.0,Charis SIL Regular,False,33.0,40.681739807128906,0.05,20,H3
sample_1.pdf,1,[image],11.0,Charis SIL Regular,False,33.0,53.881744384765625,0.0,7,H3
sample_1.pdf,1,We gratefully acknowledge support from,11.0,Charis SIL Regular,False,33.0,78.08174133300781,0.02631578947368421,38,H3
sample_1.pdf,1,"the Simons Foundation,",11.0,Charis SIL Regular,False,33.0,91.28173828125,0.09090909090909091,22,H3
sample_1.pdf,1,member institutions,11.0,Charis SIL Regular,False,151.72802734375,91.28173828125,0.0,19,H3
sample_1.pdf,1,", and all contributors.",11.0,Charis SIL Regular,False,249.53564453125,91.28173828125,0.0,23,H3
sample_1.pdf,1,Donate,11.0,Charis SIL Regular,False,33.0,104.48174285888672,0.16666666666666666,6,H3
sample_1.pdf,1,[image],11.0,Charis SIL Regular,False,33.0,128.68173217773438,0.0,7,H3
sample_1.pdf,1,Help,11.0,Charis SIL Regular,False,33.0,152.88172912597656,0.25,4,H3
sample_1.pdf,1,Advanced Search,11.0,Charis SIL Regular,False,66.31689453125,152.88172912597656,0.13333333333333333,15,H3
sample_1.pdf,1,All fields Title Author Abstract Comments Journal reference ACM,11.0,Charis SIL Regular,False,33.0,177.08172607421875,0.14285714285714285,63,H3
sample_1.pdf,1,classification MSC classification Report number arXiv identifier DOI,11.0,Charis SIL Regular,False,33.0,190.28172302246094,0.11764705882352941,68,H3
sample_1.pdf,1,ORCID arXiv author ID Help pages Full text,11.0,Charis SIL Regular,False,33.0,203.48171997070312,0.23809523809523808,42,H3
sample_1.pdf,1,Search,11.0,Charis SIL Regular,False,33.0,216.6817169189453,0.16666666666666666,6,H3
sample_1.pdf,1,Login,11.0,Charis SIL Regular,False,33.0,229.8817138671875,0.2,5,H3
sample_1.pdf,1,Not Found,22.0,Charis SIL Bold,True,33.0,267.6819763183594,0.2222222222222222,9,TITLE
sample_1.pdf,1,[image],11.0,Charis SIL Regular,False,33.0,325.3617248535156,0.0,7,H3
sample_1.pdf,1,The requested URL was not found on the server. If you entered the,11.0,Charis SIL Regular,False,33.0,362.7617492675781,0.07692307692307693,65,H3
sample_1.pdf,1,URL manually please check your spelling and try again.,11.0,Charis SIL Regular,False,33.0,375.9617614746094,0.05555555555555555,54,H3
sample_1.pdf,1,"If the error persists, please contact arXiv support at",11.0,Charis SIL Regular,False,33.0,400.1617736816406,0.037037037037037035,54,H3
sample_1.pdf,1,help@arxiv.org,11.0,Charis SIL Regular,False,286.11279296875,400.1617736816406,0.0,14,H3
sample_1.pdf,1,About,11.0,Charis SIL Regular,False,63.0,435.3617858886719,0.2,5,H3
sample_1.pdf,1,Help,11.0,Charis SIL Regular,False,63.0,448.5617980957031,0.25,4,H3
sample_1.pdf,2,Contact,11.0,Charis SIL Regular,False,63.0,333.6817626953125,0.14285714285714285,7,H3
sample_1.pdf,3,Subscribe,11.0,Charis SIL Regular,False,63.0,333.6817626953125,0.1111111111111111,9,H3
sample_1.pdf,3,Copyright,11.0,Charis SIL Regular,False,63.0,357.8817138671875,0.1111111111111111,9,H3
sample_1.pdf,3,Privacy Policy,11.0,Charis SIL Regular,False,63.0,371.0816650390625,0.14285714285714285,14,H3
sample_1.pdf,3,Web Accessibility Assistance,11.0,Charis SIL Regular,False,63.0,395.2816162109375,0.10714285714285714,28,H3
sample_1.pdf,3,arXiv Operational Status,11.0,Charis SIL Regular,False,63.0,419.4815673828125,0.125,24,H3
sample_1.pdf,4,Get status notifications via,11.0,Charis SIL Regular,False,63.0,541.181640625,0.03571428571428571,28,H3
sample_1.pdf,5,email,11.0,Charis SIL Regular,False,63.0,333.681640625,0.0,5,H3
sample_1.pdf,6,slack,11.0,Charis SIL Regular,False,63.0,376.96484375,0.0,5,H3
sample_2.pdf,1,Deep contextualized word representations,14.346199989318848,NimbusRomNo9L-Medi,False,170.60400390625,66.2960205078125,0.025,40,TITLE
sample_2.pdf,1,Matthew E. Peters,11.9552001953125,NimbusRomNo9L-Medi,False,126.07500457763672,92.57213592529297,0.17647058823529413,17,H3
sample_2.pdf,1,", Mark Neumann",11.9552001953125,NimbusRomNo9L-Medi,False,224.70999145507812,92.57213592529297,0.14285714285714285,14,H3
sample_2.pdf,1,", Mohit Iyyer",11.9552001953125,NimbusRomNo9L-Medi,False,316.9729919433594,92.57213592529297,0.15384615384615385,13,H3
sample_2.pdf,1,", Matt Gardner",11.9552001953125,NimbusRomNo9L-Medi,False,388.5179748535156,92.57213592529297,0.14285714285714285,14,H3
sample_2.pdf,1,"matthewp,markn,mohiti,mattg",11.9552001953125,NimbusMonL-Regu,False,160.3909912109375,106.01722717285156,0.0,27,H3
sample_2.pdf,1,@allenai.org,11.9552001953125,NimbusMonL-Regu,False,360.0419921875,106.01722717285156,0.0,12,H3
sample_2.pdf,1,Christopher Clark,11.9552001953125,NimbusRomNo9L-Medi,False,160.72499084472656,135.18817138671875,0.11764705882352941,17,H3
sample_2.pdf,1,", Kenton Lee",11.9552001953125,NimbusRomNo9L-Medi,False,260.7619934082031,135.18817138671875,0.16666666666666666,12,H3
sample_2.pdf,1,", Luke Zettlemoyer",11.9552001953125,NimbusRomNo9L-Medi,False,330.6139831542969,135.18817138671875,0.1111111111111111,18,H3
sample_2.pdf,1,"csquared,kentonl,lsz",11.9552001953125,NimbusMonL-Regu,False,162.48300170898438,148.6332550048828,0.0,20,H3
sample_2.pdf,1,@cs.washington.edu,11.9552001953125,NimbusMonL-Regu,False,311.9219970703125,148.6332550048828,0.0,18,H3
sample_2.pdf,1,Allen Institute for Artiﬁcial Intelligence,11.9552001953125,NimbusRomNo9L-Regu,False,205.27499389648438,177.2503204345703,0.09523809523809523,42,H3
sample_2.pdf,1,"Paul G. Allen School of Computer Science & Engineering, University of Washington",11.9552001953125,NimbusRomNo9L-Regu,False,97.23199462890625,191.1983184814453,0.1125,80,H3
sample_2.pdf,1,Abstract,11.9552001953125,NimbusRomNo9L-Medi,False,158.8909912109375,224.32415771484375,0.125,8,H3
sample_2.pdf,1,We introduce a new type of,9.962599754333496,NimbusRomNo9L-Regu,False,89.00798797607422,248.6024932861328,0.038461538461538464,26,H3
sample_2.pdf,1,deep contextual-,9.962599754333496,NimbusRomNo9L-ReguItal,False,202.99009704589844,248.426025390625,0.0,16,H3
sample_2.pdf,1,ized,9.962599754333496,NimbusRomNo9L-ReguItal,False,89.00799560546875,260.38104248046875,0.0,4,H3
sample_2.pdf,1,word representation that models both (1),9.962599754333496,NimbusRomNo9L-Regu,False,105.0577392578125,260.5574951171875,0.0,40,H3
sample_2.pdf,1,"complex characteristics of word use (e.g., syn-",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,272.51251220703125,0.0,47,H3
sample_2.pdf,1,"tax and semantics), and (2) how these uses",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,284.467529296875,0.0,42,H3
sample_2.pdf,1,"vary across linguistic contexts (i.e., to model",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,296.42254638671875,0.0,47,H3
sample_2.pdf,1,polysemy). Our word vectors are learned func-,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,308.3785400390625,0.022222222222222223,45,H3
sample_2.pdf,1,tions of the internal states of a deep bidirec-,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,320.33355712890625,0.0,47,H3
sample_2.pdf,1,"tional language model (biLM), which is pre-",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,332.2885437011719,0.046511627906976744,43,H3
sample_2.pdf,1,trained on a large text corpus. We show that,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,344.2435302734375,0.022727272727272728,44,H3
sample_2.pdf,1,these representations can be easily added to,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,356.1985168457031,0.0,44,H3
sample_2.pdf,1,existing models and signiﬁcantly improve the,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,368.15350341796875,0.0,44,H3
sample_2.pdf,1,state of the art across six challenging NLP,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,380.1094970703125,0.06976744186046512,43,H3
sample_2.pdf,1,"problems, including question answering, tex-",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,392.0644836425781,0.0,44,H3
sample_2.pdf,1,tual entailment and sentiment analysis.,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,404.01947021484375,0.0,39,H3
sample_2.pdf,1,also present an analysis showing that exposing,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,415.9744567871094,0.0,46,H3
sample_2.pdf,1,the deep internals of the pre-trained network is,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,427.929443359375,0.0,48,H3
sample_2.pdf,1,"crucial, allowing downstream models to mix",9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,439.8844299316406,0.0,42,H3
sample_2.pdf,1,different types of semi-supervision signals.,9.962599754333496,NimbusRomNo9L-Regu,False,89.00799560546875,451.8404235839844,0.0,44,H3
sample_2.pdf,1,Introduction,11.9552001953125,NimbusRomNo9L-Medi,False,89.93280029296875,474.8701171875,0.08333333333333333,12,H3
sample_2.pdf,1,Pre-trained word representations (,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,497.0935974121094,0.029411764705882353,34,H3
sample_2.pdf,1,Mikolov et al.,10.909099578857422,NimbusRomNo9L-Regu,False,224.0292205810547,497.0935974121094,0.07142857142857142,14,H3
sample_2.pdf,1,2013,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,510.6426086425781,0.0,4,H3
sample_2.pdf,1,Pennington et al.,10.909099578857422,NimbusRomNo9L-Regu,False,96.85093688964844,510.6426086425781,0.058823529411764705,17,H3
sample_2.pdf,1,2014,10.909099578857422,NimbusRomNo9L-Regu,False,179.04010009765625,510.6426086425781,0.0,4,H3
sample_2.pdf,1,) are a key compo-,10.909099578857422,NimbusRomNo9L-Regu,False,204.62191772460938,510.6426086425781,0.0,18,H3
sample_2.pdf,1,nent in many neural language understanding mod-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,524.191650390625,0.0,47,H3
sample_2.pdf,1,els.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,537.7406616210938,0.0,4,H3
sample_2.pdf,1,"However, learning high quality representa-",10.909099578857422,NimbusRomNo9L-Regu,False,95.88002014160156,537.7406616210938,0.023809523809523808,42,H3
sample_2.pdf,1,tions can be challenging.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,551.2896728515625,0.0,25,H3
sample_2.pdf,1,They should ideally,10.909099578857422,NimbusRomNo9L-Regu,False,198.78555297851562,551.2896728515625,0.05263157894736842,19,H3
sample_2.pdf,1,model both (1) complex characteristics of word,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,564.8396606445312,0.0,46,H3
sample_2.pdf,1,"use (e.g., syntax and semantics), and (2) how these",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,578.388671875,0.0,51,H3
sample_2.pdf,1,"uses vary across linguistic contexts (i.e., to model",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,591.9376220703125,0.0,52,H3
sample_2.pdf,1,"polysemy). In this paper, we introduce a new type",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,605.4866333007812,0.02040816326530612,49,H3
sample_2.pdf,1,deep contextualized,10.909099578857422,NimbusRomNo9L-ReguItal,False,81.0872802734375,618.8424072265625,0.0,19,H3
sample_2.pdf,1,word representation that,10.909099578857422,NimbusRomNo9L-Regu,False,174.6108856201172,619.03564453125,0.0,24,H3
sample_2.pdf,1,"directly addresses both challenges, can be easily",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,632.5856323242188,0.0,49,H3
sample_2.pdf,1,"integrated into existing models, and signiﬁcantly",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,646.1346435546875,0.0,49,H3
sample_2.pdf,1,improves the state of the art in every considered,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,659.6836547851562,0.0,49,H3
sample_2.pdf,1,case across a range of challenging language un-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,673.232666015625,0.0,47,H3
sample_2.pdf,1,derstanding problems.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,686.7816162109375,0.0,21,H3
sample_2.pdf,1,Our representations differ from traditional word,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,700.49560546875,0.020833333333333332,48,H3
sample_2.pdf,1,type embeddings in that each token is assigned a,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,714.0446166992188,0.0,48,H3
sample_2.pdf,1,representation that is a function of the entire input,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,727.5936279296875,0.0,53,H3
sample_2.pdf,1,sentence. We use vectors derived from a bidirec-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,741.1436157226562,0.020833333333333332,48,H3
sample_2.pdf,1,tional LSTM that is trained with a coupled lan-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,754.692626953125,0.0851063829787234,47,H3
sample_2.pdf,1,guage model (LM) objective on a large text cor-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,225.22659301757812,0.0425531914893617,47,H3
sample_2.pdf,1,"pus. For this reason, we call them ELMo (Em-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,238.77560424804688,0.11363636363636363,44,H3
sample_2.pdf,1,beddings from Language Models) representations.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,252.32461547851562,0.0425531914893617,47,H3
sample_2.pdf,1,Unlike previous approaches for learning contextu-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,265.8736267089844,0.02040816326530612,49,H3
sample_2.pdf,1,alized word vectors (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,279.4226379394531,0.0,21,H3
sample_2.pdf,1,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,401.1705627441406,279.4226379394531,0.07692307692307693,13,H3
sample_2.pdf,1,2017,10.909099578857422,NimbusRomNo9L-Regu,False,456.0759582519531,279.4226379394531,0.0,4,H3
sample_2.pdf,1,McCann,10.909099578857422,NimbusRomNo9L-Regu,False,484.4505615234375,279.4226379394531,0.3333333333333333,6,H3
sample_2.pdf,1,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,292.9726257324219,0.0,6,H3
sample_2.pdf,1,2017,10.909099578857422,NimbusRomNo9L-Regu,False,332.563232421875,292.9726257324219,0.0,4,H3
sample_2.pdf,1,"), ELMo representations are deep, in",10.909099578857422,NimbusRomNo9L-Regu,False,358.46148681640625,292.9726257324219,0.08333333333333333,36,H3
sample_2.pdf,1,the sense that they are a function of all of the in-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,306.5216369628906,0.0,52,H3
sample_2.pdf,1,"ternal layers of the biLM. More speciﬁcally, we",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,320.0706481933594,0.06382978723404255,47,H3
sample_2.pdf,1,learn a linear combination of the vectors stacked,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,333.6196594238281,0.0,49,H3
sample_2.pdf,1,"above each input word for each end task, which",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,347.1686706542969,0.0,46,H3
sample_2.pdf,1,markedly improves performance over just using,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,360.7186584472656,0.0,45,H3
sample_2.pdf,1,the top LSTM layer.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,374.2676696777344,0.21052631578947367,19,H3
sample_2.pdf,1,Combining the internal states in this manner al-,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,388.3406677246094,0.020833333333333332,48,H3
sample_2.pdf,1,lows for very rich word representations. Using in-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,401.8896789550781,0.02,50,H3
sample_2.pdf,1,"trinsic evaluations, we show that the higher-level",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,415.4386901855469,0.0,50,H3
sample_2.pdf,1,LSTM states capture context-dependent aspects,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,428.9877014160156,0.08888888888888889,45,H3
sample_2.pdf,1,"of word meaning (e.g., they can be used with-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,442.5376892089844,0.0,45,H3
sample_2.pdf,1,out modiﬁcation to perform well on supervised,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,456.0867004394531,0.0,45,H3
sample_2.pdf,1,word sense disambiguation tasks) while lower-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,469.6357116699219,0.0,45,H3
sample_2.pdf,1,"level states model aspects of syntax (e.g., they can",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,483.1847229003906,0.0,52,H3
sample_2.pdf,1,be used to do part-of-speech tagging). Simultane-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,496.7337341308594,0.02040816326530612,49,H3
sample_2.pdf,1,ously exposing all of these signals is highly bene-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,510.2827453613281,0.0,51,H3
sample_2.pdf,1,"ﬁcial, allowing the learned models select the types",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,523.832763671875,0.0,51,H3
sample_2.pdf,1,of semi-supervision that are most useful for each,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,537.3817749023438,0.0,49,H3
sample_2.pdf,1,end task.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,550.9307861328125,0.0,9,H3
sample_2.pdf,1,Extensive experiments demonstrate that ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,565.0037841796875,0.09302325581395349,43,H3
sample_2.pdf,1,representations work extremely well in practice.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,578.5527954101562,0.0,48,H3
sample_2.pdf,1,We ﬁrst show that they can be easily added to,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,592.101806640625,0.022222222222222223,45,H3
sample_2.pdf,1,existing models for six diverse and challenging,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,605.6517944335938,0.0,47,H3
sample_2.pdf,1,"language understanding problems, including tex-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,619.2008056640625,0.0,47,H3
sample_2.pdf,1,"tual entailment, question answering and sentiment",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,632.749755859375,0.0,49,H3
sample_2.pdf,1,analysis. The addition of ELMo representations,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,646.2987670898438,0.08695652173913043,46,H3
sample_2.pdf,1,alone signiﬁcantly improves the state of the art,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,659.8477783203125,0.0,48,H3
sample_2.pdf,1,"in every case, including up to 20% relative error",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,673.3977661132812,0.0,49,H3
sample_2.pdf,1,reductions. For tasks where direct comparisons,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,686.94677734375,0.021739130434782608,46,H3
sample_2.pdf,1,"are possible, ELMo outperforms CoVe (",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,700.4957275390625,0.13513513513513514,37,H3
sample_2.pdf,1,McCann,10.909099578857422,NimbusRomNo9L-Regu,False,487.97430419921875,700.4957275390625,0.3333333333333333,6,H3
sample_2.pdf,1,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,714.0447387695312,0.0,6,H3
sample_2.pdf,1,2017,10.909099578857422,NimbusRomNo9L-Regu,False,331.69049072265625,714.0447387695312,0.0,4,H3
sample_2.pdf,1,"), which computes contextualized rep-",10.909099578857422,NimbusRomNo9L-Regu,False,356.7268981933594,714.0447387695312,0.0,37,H3
sample_2.pdf,1,resentations using a neural machine translation en-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.59375,0.0,51,H3
sample_2.pdf,1,coder.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,741.1437377929688,0.0,6,H3
sample_2.pdf,1,"Finally, an analysis of both ELMo and",10.909099578857422,NimbusRomNo9L-Regu,False,343.84326171875,741.1437377929688,0.10810810810810811,37,H3
sample_2.pdf,1,CoVe reveals that deep representations outperform,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,754.6927490234375,0.04081632653061224,49,H3
sample_2.pdf,1,arXiv:1802.05365v2  [cs.CL]  22 Mar 2018,20.0,Times-Roman,False,10.940000534057617,259.92999267578125,0.1,40,TITLE
sample_2.pdf,2,those derived from just the top layer of an LSTM.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,65.49368286132812,0.08163265306122448,49,H3
sample_2.pdf,2,Our trained models and code are publicly avail-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,79.04367065429688,0.02127659574468085,47,H3
sample_2.pdf,2,"able, and we expect that ELMo will provide simi-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,92.59268188476562,0.0625,48,H3
sample_2.pdf,2,lar gains for many other NLP problems.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,106.14169311523438,0.07894736842105263,38,H3
sample_2.pdf,2,Related work,11.9552001953125,NimbusRomNo9L-Medi,False,89.93280029296875,133.5272216796875,0.08333333333333333,12,H3
sample_2.pdf,2,Due to their ability to capture syntactic and se-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,158.57870483398438,0.02040816326530612,49,H3
sample_2.pdf,2,mantic information of words from large scale un-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,172.12771606445312,0.0,48,H3
sample_2.pdf,2,"labeled text, pretrained word vectors (",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,185.67672729492188,0.0,39,H3
sample_2.pdf,2,Turian et al.,10.909099578857422,NimbusRomNo9L-Regu,False,235.7674560546875,185.67672729492188,0.07692307692307693,13,H3
sample_2.pdf,2,2010,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,199.22573852539062,0.0,4,H3
sample_2.pdf,2,Mikolov et al.,10.909099578857422,NimbusRomNo9L-Regu,False,96.85093688964844,199.22573852539062,0.07142857142857142,14,H3
sample_2.pdf,2,2013,10.909099578857422,NimbusRomNo9L-Regu,False,172.1455535888672,199.22573852539062,0.0,4,H3
sample_2.pdf,2,Pennington et al.,10.909099578857422,NimbusRomNo9L-Regu,False,202.58192443847656,199.22573852539062,0.058823529411764705,17,H3
sample_2.pdf,2,2014,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,212.77572631835938,0.0,4,H3
sample_2.pdf,2,) are a standard component of most state-of-,10.909099578857422,NimbusRomNo9L-Regu,False,93.81820678710938,212.77572631835938,0.0,44,H3
sample_2.pdf,2,"the-art NLP architectures, including for question",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,226.32473754882812,0.061224489795918366,49,H3
sample_2.pdf,2,answering (,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,239.87374877929688,0.0,11,H3
sample_2.pdf,2,Liu et al.,10.909099578857422,NimbusRomNo9L-Regu,False,125.32369232177734,239.87374877929688,0.1,10,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,171.40374755859375,239.87374877929688,0.0,4,H3
sample_2.pdf,2,"), textual entailment",10.909099578857422,NimbusRomNo9L-Regu,False,198.07647705078125,239.87374877929688,0.0,21,H3
sample_2.pdf,2,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,75.63272857666016,253.42276000976562,0.09090909090909091,11,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,130.81097412109375,253.42276000976562,0.0,4,H3
sample_2.pdf,2,) and semantic role labeling,10.909099578857422,NimbusRomNo9L-Regu,False,158.1055145263672,253.42276000976562,0.0,28,H3
sample_2.pdf,2,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,75.63272857666016,266.9717712402344,0.1111111111111111,9,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,116.53095245361328,266.9717712402344,0.0,4,H3
sample_2.pdf,2,"). However, these approaches for",10.909099578857422,NimbusRomNo9L-Regu,False,141.84005737304688,266.9717712402344,0.03125,32,H3
sample_2.pdf,2,learning word vectors only allow a single context-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,280.5217590332031,0.0,50,H3
sample_2.pdf,2,independent representation for each word.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,294.0707702636719,0.0,41,H3
sample_2.pdf,2,Previously proposed methods overcome some,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,308.9257507324219,0.024390243902439025,41,H3
sample_2.pdf,2,of the shortcomings of traditional word vectors,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,322.4747619628906,0.0,47,H3
sample_2.pdf,2,by either enriching them with subword informa-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,336.0237731933594,0.0,46,H3
sample_2.pdf,2,"tion (e.g.,",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,349.5727844238281,0.0,11,H3
sample_2.pdf,2,Wieting et al.,10.909099578857422,NimbusRomNo9L-Regu,False,113.90184783935547,349.5727844238281,0.07142857142857142,14,H3
sample_2.pdf,2,2016,10.909099578857422,NimbusRomNo9L-Regu,False,181.10189819335938,349.5727844238281,0.0,4,H3
sample_2.pdf,2,Bojanowski et al.,10.909099578857422,NimbusRomNo9L-Regu,False,208.76734924316406,349.5727844238281,0.058823529411764705,17,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,363.1217956542969,0.0,4,H3
sample_2.pdf,2,) or learning separate vectors for each word,10.909099578857422,NimbusRomNo9L-Regu,False,93.81820678710938,363.1217956542969,0.0,44,H3
sample_2.pdf,2,"sense (e.g.,",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,376.6717834472656,0.0,12,H3
sample_2.pdf,2,Neelakantan et al.,10.909099578857422,NimbusRomNo9L-Regu,False,130.75640869140625,376.6717834472656,0.05555555555555555,18,H3
sample_2.pdf,2,2014,10.909099578857422,NimbusRomNo9L-Regu,False,214.9201202392578,376.6717834472656,0.0,4,H3
sample_2.pdf,2,). Our ap-,10.909099578857422,NimbusRomNo9L-Regu,False,240.94920349121094,376.6717834472656,0.1,10,H3
sample_2.pdf,2,proach also beneﬁts from subword units through,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,390.2207946777344,0.0,46,H3
sample_2.pdf,2,"the use of character convolutions, and we seam-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,403.7698059082031,0.0,47,H3
sample_2.pdf,2,lessly incorporate multi-sense information into,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,417.3188171386719,0.0,47,H3
sample_2.pdf,2,downstream tasks without explicitly training to,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,430.8678283691406,0.0,47,H3
sample_2.pdf,2,predict predeﬁned sense classes.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,444.4178161621094,0.0,32,H3
sample_2.pdf,2,Other,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,459.2718200683594,0.2,5,H3
sample_2.pdf,2,recent,10.909099578857422,NimbusRomNo9L-Regu,False,117.18539428710938,459.2718200683594,0.0,6,H3
sample_2.pdf,2,work,10.909099578857422,NimbusRomNo9L-Regu,False,153.27268981933594,459.2718200683594,0.0,4,H3
sample_2.pdf,2,has,10.909099578857422,NimbusRomNo9L-Regu,False,185.00726318359375,459.2718200683594,0.0,3,H3
sample_2.pdf,2,also,10.909099578857422,NimbusRomNo9L-Regu,False,208.98545837402344,459.2718200683594,0.0,4,H3
sample_2.pdf,2,focused,10.909099578857422,NimbusRomNo9L-Regu,False,235.9963836669922,459.2718200683594,0.0,7,H3
sample_2.pdf,2,learning,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,472.8218078613281,0.0,8,H3
sample_2.pdf,2,context-dependent,10.909099578857422,NimbusRomNo9L-Regu,False,124.4073257446289,472.8218078613281,0.0,17,H3
sample_2.pdf,2,representations.,10.909099578857422,NimbusRomNo9L-Regu,False,221.49827575683594,472.8218078613281,0.0,16,H3
sample_2.pdf,2,context2vec,10.909099578857422,NimbusMonL-Regu,False,72.0,485.81231689453125,0.0,11,H3
sample_2.pdf,2,Melamud et al.,10.909099578857422,NimbusRomNo9L-Regu,False,152.7217254638672,486.3708190917969,0.07142857142857142,14,H3
sample_2.pdf,2,2016,10.909099578857422,NimbusRomNo9L-Regu,False,225.92178344726562,486.3708190917969,0.0,4,H3
sample_2.pdf,2,) uses a,10.909099578857422,NimbusRomNo9L-Regu,False,252.8236083984375,486.3708190917969,0.0,8,H3
sample_2.pdf,2,bidirectional Long Short Term Memory (LSTM;,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,499.9198303222656,0.18604651162790697,43,H3
sample_2.pdf,2,Hochreiter and Schmidhuber,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,513.4688720703125,0.07692307692307693,26,H3
sample_2.pdf,2,1997,10.909099578857422,NimbusRomNo9L-Regu,False,200.9019012451172,513.4688720703125,0.0,4,H3
sample_2.pdf,2,) to encode the,10.909099578857422,NimbusRomNo9L-Regu,False,225.52371215820312,513.4688720703125,0.0,15,H3
sample_2.pdf,2,context around a pivot word. Other approaches,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,527.0178833007812,0.022222222222222223,45,H3
sample_2.pdf,2,for learning contextual embeddings include the,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,540.56787109375,0.0,46,H3
sample_2.pdf,2,pivot word itself in the representation and are,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,554.1168823242188,0.0,47,H3
sample_2.pdf,2,computed with the encoder of either a supervised,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,567.6658935546875,0.0,48,H3
sample_2.pdf,2,neural machine translation (MT) system (CoVe;,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,581.2149047851562,0.08888888888888889,45,H3
sample_2.pdf,2,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,594.763916015625,0.15384615384615385,13,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,142.24371337890625,594.763916015625,0.0,4,H3
sample_2.pdf,2,) or an unsupervised lan-,10.909099578857422,NimbusRomNo9L-Regu,False,169.78916931152344,594.763916015625,0.0,25,H3
sample_2.pdf,2,guage model (,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,608.3139038085938,0.0,13,H3
sample_2.pdf,2,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,136.4291534423828,608.3139038085938,0.07692307692307693,13,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,191.7601318359375,608.3139038085938,0.0,4,H3
sample_2.pdf,2,). Both of these,10.909099578857422,NimbusRomNo9L-Regu,False,217.30921936035156,608.3139038085938,0.0625,16,H3
sample_2.pdf,2,"approaches beneﬁt from large datasets, although",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,621.8629150390625,0.0,47,H3
sample_2.pdf,2,the MT approach is limited by the size of parallel,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,635.411865234375,0.04,50,H3
sample_2.pdf,2,"corpora. In this paper, we take full advantage of",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,648.9608764648438,0.02040816326530612,49,H3
sample_2.pdf,2,"access to plentiful monolingual data, and train",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,662.5098876953125,0.0,47,H3
sample_2.pdf,2,our biLM on a corpus with approximately 30,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,676.0598754882812,0.047619047619047616,42,H3
sample_2.pdf,2,million sentences (,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,689.60888671875,0.0,19,H3
sample_2.pdf,2,Chelba et al.,10.909099578857422,NimbusRomNo9L-Regu,False,156.51280212402344,689.60888671875,0.07692307692307693,13,H3
sample_2.pdf,2,2014,10.909099578857422,NimbusRomNo9L-Regu,False,216.1746826171875,689.60888671875,0.0,4,H3
sample_2.pdf,2,). We also,10.909099578857422,NimbusRomNo9L-Regu,False,241.7674102783203,689.60888671875,0.1,10,H3
sample_2.pdf,2,generalize these approaches to deep contextual,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,703.1578369140625,0.0,46,H3
sample_2.pdf,2,"representations, which we show work well across",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,716.7068481445312,0.0,47,H3
sample_2.pdf,2,a broad range of diverse NLP tasks.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,730.255859375,0.08571428571428572,35,H3
sample_2.pdf,2,http://allennlp.org/elmo,8.966400146484375,NimbusMonL-Regu,False,88.13899993896484,755.7069091796875,0.0,24,P
sample_2.pdf,2,Previous work has also shown that different lay-,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,65.49368286132812,0.020833333333333332,48,H3
sample_2.pdf,2,ers of deep biRNNs encode different types of in-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,79.04367065429688,0.0625,48,H3
sample_2.pdf,2,formation.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,92.59268188476562,0.0,10,H3
sample_2.pdf,2,"For example, introducing multi-task",10.909099578857422,NimbusRomNo9L-Regu,False,362.1159973144531,92.59268188476562,0.02857142857142857,35,H3
sample_2.pdf,2,"syntactic supervision (e.g., part-of-speech tags) at",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,106.14169311523438,0.0,52,H3
sample_2.pdf,2,the lower levels of a deep LSTM can improve,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,119.69070434570312,0.09302325581395349,43,H3
sample_2.pdf,2,overall performance of higher level tasks such as,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,133.23971557617188,0.0,49,H3
sample_2.pdf,2,dependency parsing (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,146.78970336914062,0.0,20,H3
sample_2.pdf,2,Hashimoto et al.,10.909099578857422,NimbusRomNo9L-Regu,False,403.9524230957031,146.78970336914062,0.0625,16,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,482.0178527832031,146.78970336914062,0.0,4,H3
sample_2.pdf,2,) or,10.909099578857422,NimbusRomNo9L-Regu,False,508.33062744140625,146.78970336914062,0.0,4,H3
sample_2.pdf,2,CCG super tagging (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,160.33871459960938,0.15789473684210525,19,H3
sample_2.pdf,2,Søgaard and Goldberg,10.909099578857422,NimbusRomNo9L-Regu,False,395.93426513671875,160.33871459960938,0.1,20,H3
sample_2.pdf,2,2016,10.909099578857422,NimbusRomNo9L-Regu,False,495.2834777832031,160.33871459960938,0.0,4,H3
sample_2.pdf,2,In an RNN-based encoder-decoder machine trans-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,173.88772583007812,0.08695652173913043,46,H3
sample_2.pdf,2,"lation system,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,187.43673706054688,0.0,14,H3
sample_2.pdf,2,Belinkov et al.,10.909099578857422,NimbusRomNo9L-Regu,False,368.5196533203125,187.43673706054688,0.06666666666666667,15,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,443.9560241699219,187.43673706054688,0.0,4,H3
sample_2.pdf,2,) showed that,10.909099578857422,NimbusRomNo9L-Regu,False,465.7742614746094,187.43673706054688,0.0,13,H3
sample_2.pdf,2,the representations learned at the ﬁrst layer in a 2-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,200.98574829101562,0.0,53,H3
sample_2.pdf,2,layer LSTM encoder are better at predicting POS,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,214.53475952148438,0.14893617021276595,47,H3
sample_2.pdf,2,"tags then second layer. Finally, the top layer of an",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,228.08474731445312,0.019230769230769232,52,H3
sample_2.pdf,2,LSTM for encoding word context (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,241.63375854492188,0.125,32,H3
sample_2.pdf,2,Melamud et al.,10.909099578857422,NimbusRomNo9L-Regu,False,458.0833740234375,241.63375854492188,0.07142857142857142,14,H3
sample_2.pdf,2,2016,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,255.18276977539062,0.0,4,H3
sample_2.pdf,2,) has been shown to learn representations of,10.909099578857422,NimbusRomNo9L-Regu,False,329.09423828125,255.18276977539062,0.0,44,H3
sample_2.pdf,2,word sense. We show that similar signals are also,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,268.7317810058594,0.02040816326530612,49,H3
sample_2.pdf,2,induced by the modiﬁed language model objective,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,282.2807922363281,0.0,47,H3
sample_2.pdf,2,"of our ELMo representations, and it can be very",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,295.8307800292969,0.06382978723404255,47,H3
sample_2.pdf,2,beneﬁcial to learn models for downstream tasks,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,309.3797912597656,0.0,46,H3
sample_2.pdf,2,that mix these different types of semi-supervision.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,322.9288024902344,0.0,51,H3
sample_2.pdf,2,Dai and Le,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,339.31781005859375,0.2,10,H3
sample_2.pdf,2,2015,10.909099578857422,NimbusRomNo9L-Regu,False,380.0832214355469,339.31781005859375,0.0,4,H3
sample_2.pdf,2,) and,10.909099578857422,NimbusRomNo9L-Regu,False,401.9014587402344,339.31781005859375,0.0,5,H3
sample_2.pdf,2,Ramachandran et al.,10.909099578857422,NimbusRomNo9L-Regu,False,426.3814697265625,339.31781005859375,0.05263157894736842,19,H3
sample_2.pdf,2,2017,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087219238281,352.8677978515625,0.0,4,H3
sample_2.pdf,2,) pretrain encoder-decoder pairs using lan-,10.909099578857422,NimbusRomNo9L-Regu,False,332.7269592285156,352.8677978515625,0.0,43,H3
sample_2.pdf,2,guage models and sequence autoencoders and then,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,366.41680908203125,0.0,47,H3
sample_2.pdf,2,ﬁne tune with task speciﬁc supervision. In con-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,379.9658203125,0.02127659574468085,47,H3
sample_2.pdf,2,"trast, after pretraining the biLM with unlabeled",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,393.51483154296875,0.041666666666666664,48,H3
sample_2.pdf,2,"data, we ﬁx the weights and add additional task-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,407.0638427734375,0.0,48,H3
sample_2.pdf,2,"speciﬁc model capacity, allowing us to leverage",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,420.61383056640625,0.0,47,H3
sample_2.pdf,2,"large, rich and universal biLM representations for",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,434.162841796875,0.04,50,H3
sample_2.pdf,2,cases where downstream training data size dictates,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,447.71185302734375,0.0,50,H3
sample_2.pdf,2,a smaller supervised model.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,461.2608642578125,0.0,27,H3
sample_2.pdf,2,ELMo: Embeddings from Language,11.9552001953125,NimbusRomNo9L-Medi,False,325.20880126953125,493.9623718261719,0.16666666666666666,30,H3
sample_2.pdf,2,Models,11.9552001953125,NimbusRomNo9L-Medi,False,325.2080078125,507.90936279296875,0.16666666666666666,6,H3
sample_2.pdf,2,Unlike most widely used word embeddings (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,536.763916015625,0.024390243902439025,41,H3
sample_2.pdf,2,Pen-,10.909099578857422,NimbusRomNo9L-Regu,False,505.5488586425781,536.763916015625,0.25,4,H3
sample_2.pdf,2,nington et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,550.3128662109375,0.0,14,H3
sample_2.pdf,2,2014,10.909099578857422,NimbusRomNo9L-Regu,False,368.0287170410156,550.3128662109375,0.0,4,H3
sample_2.pdf,2,"), ELMo word representations",10.909099578857422,NimbusRomNo9L-Regu,False,392.94512939453125,550.3128662109375,0.10714285714285714,28,H3
sample_2.pdf,2,"are functions of the entire input sentence, as de-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,563.8619384765625,0.0,50,H3
sample_2.pdf,2,scribed in this section. They are computed on top,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,577.410888671875,0.02040816326530612,49,H3
sample_2.pdf,2,of two-layer biLMs with character convolutions,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,590.9598999023438,0.043478260869565216,46,H3
sample_2.pdf,2,(Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,604.5098876953125,0.2,5,H3
sample_2.pdf,2,3.1,10.909099578857422,NimbusRomNo9L-Regu,False,329.3887023925781,604.5098876953125,0.0,3,H3
sample_2.pdf,2,"), as a linear function of the internal net-",10.909099578857422,NimbusRomNo9L-Regu,False,346.156005859375,604.5098876953125,0.0,44,H3
sample_2.pdf,2,work states (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,618.0588989257812,0.058823529411764705,17,H3
sample_2.pdf,2,3.2,10.909099578857422,NimbusRomNo9L-Regu,False,382.2432861328125,618.0588989257812,0.0,3,H3
sample_2.pdf,2,). This setup allows us to do,10.909099578857422,NimbusRomNo9L-Regu,False,399.03240966796875,618.0588989257812,0.034482758620689655,29,H3
sample_2.pdf,2,"semi-supervised learning, where the biLM is pre-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,631.60791015625,0.041666666666666664,48,H3
sample_2.pdf,2,trained at a large scale (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,645.1569213867188,0.03333333333333333,30,H3
sample_2.pdf,2,3.4,10.909099578857422,NimbusRomNo9L-Regu,False,429.93780517578125,645.1569213867188,0.0,3,H3
sample_2.pdf,2,) and easily incor-,10.909099578857422,NimbusRomNo9L-Regu,False,446.399658203125,645.1569213867188,0.0,19,H3
sample_2.pdf,2,porated into a wide range of existing neural NLP,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,658.7059326171875,0.0625,48,H3
sample_2.pdf,2,architectures (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,672.2559204101562,0.05263157894736842,19,H3
sample_2.pdf,2,3.3,10.909099578857422,NimbusRomNo9L-Regu,False,387.8504638671875,672.2559204101562,0.0,3,H3
sample_2.pdf,2,3.1,10.909099578857422,NimbusRomNo9L-Medi,False,307.2760009765625,704.3792724609375,0.0,3,H3
sample_2.pdf,2,Bidirectional language models,10.909099578857422,NimbusRomNo9L-Medi,False,331.82147216796875,704.3792724609375,0.034482758620689655,29,H3
sample_2.pdf,2,Given a sequence of,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.5939331054688,0.05263157894736842,19,H3
sample_2.pdf,2,"tokens,",10.909099578857422,NimbusRomNo9L-Regu,False,411.86090087890625,727.5939331054688,0.0,7,H3
sample_2.pdf,2,", t",10.909099578857422,CMMI10,False,465.1969909667969,727.3414306640625,0.0,3,H3
sample_2.pdf,2,", ..., t",10.909099578857422,CMMI10,False,478.71697998046875,727.3414306640625,0.0,8,H3
sample_2.pdf,2,", a",10.909099578857422,NimbusRomNo9L-Regu,False,513.7549438476562,727.5939331054688,0.0,3,H3
sample_2.pdf,2,forward language model computes the probability,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,741.1429443359375,0.0,47,H3
sample_2.pdf,2,of the sequence by modeling the probability of to-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,754.6929321289062,0.0,50,H3
sample_2.pdf,3,ken,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,65.49368286132812,0.0,3,H3
sample_2.pdf,3,given the history,10.909099578857422,NimbusRomNo9L-Regu,False,98.71746826171875,65.49368286132812,0.0,17,H3
sample_2.pdf,3,", ..., t",10.909099578857422,CMMI10,False,190.69200134277344,65.24122619628906,0.0,8,H3
sample_2.pdf,3,", t",10.909099578857422,CMMI10,False,96.69200134277344,101.69325256347656,0.0,3,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,110.21200561523438,101.69325256347656,0.0,11,H3
sample_2.pdf,3,) =,10.909099578857422,CMR10,False,146.46200561523438,101.69325256347656,0.0,3,H3
sample_2.pdf,3,", t",10.909099578857422,CMMI10,False,219.06297302246094,101.69325256347656,0.0,3,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,232.5829620361328,101.69325256347656,0.0,11,H3
sample_2.pdf,3,Recent state-of-the-art neural language models,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,137.38070678710938,0.021739130434782608,46,H3
sample_2.pdf,3,J´ozefowicz et al.,10.909099578857422,NimbusRomNo9L-Regu,False,75.63269805908203,150.87570190429688,0.05555555555555555,18,H3
sample_2.pdf,3,2016,10.909099578857422,NimbusRomNo9L-Regu,False,152.45423889160156,150.93069458007812,0.0,4,H3
sample_2.pdf,3,Melis et al.,10.909099578857422,NimbusRomNo9L-Regu,False,180.71969604492188,150.93069458007812,0.08333333333333333,12,H3
sample_2.pdf,3,2017,10.909099578857422,NimbusRomNo9L-Regu,False,237.01068115234375,150.93069458007812,0.0,4,H3
sample_2.pdf,3,Mer-,10.909099578857422,NimbusRomNo9L-Regu,False,265.2652282714844,150.93069458007812,0.25,4,H3
sample_2.pdf,3,ity et al.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,164.47970581054688,0.0,10,H3
sample_2.pdf,3,2017,10.909099578857422,NimbusRomNo9L-Regu,False,109.48363494873047,164.47970581054688,0.0,4,H3
sample_2.pdf,3,) compute a context-independent to-,10.909099578857422,NimbusRomNo9L-Regu,False,133.6800079345703,164.47970581054688,0.0,35,H3
sample_2.pdf,3,ken representation,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,178.02871704101562,0.0,18,H3
sample_2.pdf,3,(via token embeddings or,10.909099578857422,NimbusRomNo9L-Regu,False,179.3329620361328,178.02877807617188,0.0,24,H3
sample_2.pdf,3,a CNN over characters) then pass it through,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996185302734,191.57778930664062,0.06976744186046512,43,H3
sample_2.pdf,3,lay-,10.909099578857422,NimbusRomNo9L-Regu,False,270.9170837402344,191.57778930664062,0.0,4,H3
sample_2.pdf,3,ers of forward LSTMs. At each position,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,205.12680053710938,0.13157894736842105,38,H3
sample_2.pdf,3,", each",10.909099578857422,NimbusRomNo9L-Regu,False,263.7650146484375,205.12680053710938,0.0,6,H3
sample_2.pdf,3,LSTM layer outputs a context-dependent repre-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,218.67678833007812,0.08888888888888889,45,H3
sample_2.pdf,3,sentation,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,233.61276245117188,0.0,9,H3
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,124.43502044677734,238.978271484375,0.0,3,P
sample_2.pdf,3,where,10.909099578857422,NimbusRomNo9L-Regu,False,141.80801391601562,233.61282348632812,0.0,5,H3
sample_2.pdf,3,= 1,10.909099578857422,CMR10,False,175.0875701904297,233.36036682128906,0.0,3,H3
sample_2.pdf,3,", . . . , L",10.909099578857422,CMMI10,False,195.71002197265625,233.36036682128906,0.09090909090909091,11,H3
sample_2.pdf,3,. The top layer,10.909099578857422,NimbusRomNo9L-Regu,False,227.3760223388672,233.61282348632812,0.06666666666666667,15,H3
sample_2.pdf,3,"LSTM output,",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,251.05783081054688,0.3333333333333333,12,H3
sample_2.pdf,3,"k,L",7.970099925994873,CMMI8,False,150.67901611328125,256.42333984375,0.3333333333333333,3,P
sample_2.pdf,3,", is used to predict the next",10.909099578857422,NimbusRomNo9L-Regu,False,165.9180145263672,251.05789184570312,0.0,29,H3
sample_2.pdf,3,token,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,264.6069030761719,0.0,5,H3
sample_2.pdf,3,with a Softmax layer.,10.909099578857422,NimbusRomNo9L-Regu,False,118.23445129394531,264.6069030761719,0.047619047619047616,21,H3
sample_2.pdf,3,"A backward LM is similar to a forward LM, ex-",10.909099578857422,NimbusRomNo9L-Regu,False,82.90901947021484,278.6878967285156,0.1111111111111111,45,H3
sample_2.pdf,3,"cept it runs over the sequence in reverse, predict-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,292.2378845214844,0.0,51,H3
sample_2.pdf,3,ing the previous token given the future context:,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,305.7868957519531,0.0,48,H3
sample_2.pdf,3,", t",10.909099578857422,CMMI10,False,90.40301513671875,341.62042236328125,0.0,3,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,103.92301940917969,341.62042236328125,0.0,11,H3
sample_2.pdf,3,) =,10.909099578857422,CMR10,False,140.17300415039062,341.62042236328125,0.0,3,H3
sample_2.pdf,3,", t",10.909099578857422,CMMI10,False,223.9820098876953,341.6204528808594,0.0,3,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,248.70999145507812,341.6204528808594,0.0,11,H3
sample_2.pdf,3,It can be implemented in an analogous way to a,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,377.30792236328125,0.021739130434782608,46,H3
sample_2.pdf,3,"forward LM, with each backward LSTM layer",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,390.85693359375,0.14634146341463414,41,H3
sample_2.pdf,3,in a,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,404.40692138671875,0.0,4,H3
sample_2.pdf,3,layer deep model producing representations,10.909099578857422,NimbusRomNo9L-Regu,False,97.7761001586914,404.40692138671875,0.0,42,H3
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,82.90900421142578,424.7083435058594,0.0,3,P
sample_2.pdf,3,given,10.909099578857422,NimbusRomNo9L-Regu,False,121.03646850585938,419.3428649902344,0.0,5,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,175.12901306152344,419.09039306640625,0.0,11,H3
sample_2.pdf,3,A biLM combines both a forward and backward,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,433.4238586425781,0.06976744186046512,43,H3
sample_2.pdf,3,LM. Our formulation jointly maximizes the log,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,446.9728698730469,0.06666666666666667,45,H3
sample_2.pdf,3,likelihood of the forward and backward directions:,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,460.5218811035156,0.0,50,H3
sample_2.pdf,3,( log,10.909099578857422,CMR10,False,89.57599639892578,494.1474304199219,0.0,5,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,149.29400634765625,494.1474304199219,0.0,11,H3
sample_2.pdf,3,LSTM,7.970099925994873,CMMI8,False,226.56227111816406,496.4443664550781,1.0,4,P
sample_2.pdf,3,+ log,10.909099578857422,CMR10,False,86.52899169921875,524.0324096679688,0.0,5,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,160.50198364257812,524.033447265625,0.0,11,H3
sample_2.pdf,3,LSTM,7.970099925994873,CMMI8,False,229.8982696533203,526.3303833007812,1.0,4,P
sample_2.pdf,3,) ),10.909099578857422,CMR10,False,275.7959899902344,524.033447265625,0.0,3,H3
sample_2.pdf,3,We tie the parameters for both the token represen-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,549.3409423828125,0.02,50,H3
sample_2.pdf,3,tation (,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,562.8909301757812,0.0,8,H3
sample_2.pdf,3,) and Softmax layer (,10.909099578857422,NimbusRomNo9L-Regu,False,116.9169692993164,562.8909301757812,0.047619047619047616,21,H3
sample_2.pdf,3,) in the forward,10.909099578857422,NimbusRomNo9L-Regu,False,222.3469696044922,562.8909301757812,0.0,16,H3
sample_2.pdf,3,and backward direction while maintaining sepa-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,576.43994140625,0.0,46,H3
sample_2.pdf,3,rate parameters for the LSTMs in each direction.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,589.9889526367188,0.08333333333333333,48,H3
sample_2.pdf,3,"Overall, this formulation is similar to the approach",10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,603.5379638671875,0.019230769230769232,52,H3
sample_2.pdf,3,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,81.08724975585938,617.0869140625,0.07692307692307693,13,H3
sample_2.pdf,3,2017,10.909099578857422,NimbusRomNo9L-Regu,False,142.34185791015625,617.0869140625,0.0,4,H3
sample_2.pdf,3,"), with the exception that we",10.909099578857422,NimbusRomNo9L-Regu,False,164.1600341796875,617.0869140625,0.0,29,H3
sample_2.pdf,3,share some weights between directions instead of,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,630.636962890625,0.0,48,H3
sample_2.pdf,3,using completely independent parameters. In the,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,644.1859130859375,0.02127659574468085,47,H3
sample_2.pdf,3,"next section, we depart from previous work by in-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,657.7349243164062,0.0,49,H3
sample_2.pdf,3,troducing a new approach for learning word rep-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,671.283935546875,0.0,47,H3
sample_2.pdf,3,resentations that are a linear combination of the,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,684.8328857421875,0.0,49,H3
sample_2.pdf,3,biLM layers.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,698.3829345703125,0.16666666666666666,12,H3
sample_2.pdf,3,3.2,10.909099578857422,NimbusRomNo9L-Medi,False,71.99996948242188,722.5112915039062,0.0,3,H3
sample_2.pdf,3,ELMo,10.909099578857422,NimbusRomNo9L-Medi,False,96.54544830322266,722.5112915039062,0.75,4,H3
sample_2.pdf,3,ELMo is a task speciﬁc combination of the in-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,741.1439208984375,0.06666666666666667,45,H3
sample_2.pdf,3,termediate layer representations in the biLM. For,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,754.6929321289062,0.061224489795918366,49,H3
sample_2.pdf,3,each token,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,65.49392700195312,0.0,10,H3
sample_2.pdf,3,", a",10.909099578857422,NimbusRomNo9L-Regu,False,367.5049743652344,65.49392700195312,0.0,3,H3
sample_2.pdf,3,-layer biLM computes a set of,10.909099578857422,NimbusRomNo9L-Regu,False,389.7539978027344,65.49392700195312,0.06896551724137931,29,H3
sample_2.pdf,3,+ 1,10.909099578857422,CMR10,False,320.15911865234375,78.79145812988281,0.0,3,H3
sample_2.pdf,3,representations,10.909099578857422,NimbusRomNo9L-Regu,False,338.9426574707031,79.04391479492188,0.0,15,H3
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,400.3730163574219,110.1153564453125,0.0,3,P
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,431.3700256347656,110.1153564453125,0.0,3,P
sample_2.pdf,3,= 1,10.909099578857422,CMR10,False,459.5875549316406,105.04243469238281,0.0,3,H3
sample_2.pdf,3,", . . . , L",10.909099578857422,CMMI10,False,480.21002197265625,105.04243469238281,0.09090909090909091,11,H3
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,369.72503662109375,128.3763427734375,0.0,3,P
sample_2.pdf,3,= 0,10.909099578857422,CMR10,False,397.9435729980469,123.30342102050781,0.0,3,H3
sample_2.pdf,3,", . . . , L",10.909099578857422,CMMI10,False,418.5650329589844,123.30342102050781,0.09090909090909091,11,H3
sample_2.pdf,3,where,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,149.59884643554688,0.0,5,H3
sample_2.pdf,3,is the token layer and,10.909099578857422,NimbusRomNo9L-Regu,False,369.3380126953125,149.59890747070312,0.0,22,H3
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,491.614013671875,154.96441650390625,0.0,3,P
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,321.2149963378906,172.41046142578125,0.0,3,P
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,352.2120056152344,172.41046142578125,0.0,3,P
sample_2.pdf,3,", for each biLSTM layer.",10.909099578857422,NimbusRomNo9L-Regu,False,370.48101806640625,167.04397583007812,0.16666666666666666,24,H3
sample_2.pdf,3,"For inclusion in a downstream model, ELMo",10.909099578857422,NimbusRomNo9L-Regu,False,318.1850280761719,180.71200561523438,0.0975609756097561,41,H3
sample_2.pdf,3,collapses all layers in,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,194.26101684570312,0.0,23,H3
sample_2.pdf,3,"into a single vector,",10.909099578857422,NimbusRomNo9L-Regu,False,424.5910339355469,194.26101684570312,0.0,21,H3
sample_2.pdf,3,ELMo,10.909099578857422,CMBX10,False,307.2760314941406,207.5585479736328,0.75,4,H3
sample_2.pdf,3,"In the simplest case,",10.909099578857422,NimbusRomNo9L-Regu,False,430.75439453125,207.81100463867188,0.047619047619047616,21,H3
sample_2.pdf,3,"ELMo just selects the top layer,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,221.36001586914062,0.09375,32,H3
sample_2.pdf,3,) =,10.909099578857422,CMR10,False,479.15802001953125,221.10755920410156,0.0,3,H3
sample_2.pdf,3,"k,L",7.970099925994873,CMMI8,False,507.5770263671875,226.72552490234375,0.3333333333333333,3,P
sample_2.pdf,3,as in TagLM (,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,234.90908813476562,0.23076923076923078,13,H3
sample_2.pdf,3,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,370.7669982910156,234.90908813476562,0.07692307692307693,13,H3
sample_2.pdf,3,2017,10.909099578857422,NimbusRomNo9L-Regu,False,425.1923828125,234.90908813476562,0.0,4,H3
sample_2.pdf,3,) and CoVe (,10.909099578857422,NimbusRomNo9L-Regu,False,450.2833557128906,234.90908813476562,0.16666666666666666,12,H3
sample_2.pdf,3,Mc-,10.909099578857422,NimbusRomNo9L-Regu,False,507.37066650390625,234.90908813476562,0.3333333333333333,3,H3
sample_2.pdf,3,Cann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,248.45809936523438,0.09090909090909091,11,H3
sample_2.pdf,3,2017,10.909099578857422,NimbusRomNo9L-Regu,False,357.35968017578125,248.45809936523438,0.0,4,H3
sample_2.pdf,3,"). More generally, we compute a",10.909099578857422,NimbusRomNo9L-Regu,False,382.1015625,248.45809936523438,0.03225806451612903,31,H3
sample_2.pdf,3,task speciﬁc weighting of all biLM layers:,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,262.0071105957031,0.047619047619047616,42,H3
sample_2.pdf,3,ELMo,10.909099578857422,CMBX10,False,307.27606201171875,296.60162353515625,0.75,4,H3
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,341.24505615234375,294.39453125,0.0,4,P
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,412.0430908203125,294.39453125,0.0,4,P
sample_2.pdf,3,) =,10.909099578857422,CMR10,False,428.63409423828125,296.60162353515625,0.0,3,H3
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,453.67608642578125,294.39453125,0.0,4,P
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,494.7751159667969,294.39447021484375,0.0,4,P
sample_2.pdf,3,"k,j",7.970099925994873,CMMI8,False,518.3370971679688,301.6744384765625,0.0,3,P
sample_2.pdf,3,(1),10.909099578857422,NimbusRomNo9L-Regu,False,512.8231201171875,321.0179748535156,0.0,3,H3
sample_2.pdf,3,In (,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,334.5679626464844,0.25,4,H3
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,343.99810791015625,332.6534118652344,0.0,4,P
sample_2.pdf,3,are softmax-normalized weights and,10.909099578857422,NimbusRomNo9L-Regu,False,364.110107421875,334.5679626464844,0.0,34,H3
sample_2.pdf,3,the scalar parameter,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,348.1169738769531,0.0,20,H3
sample_2.pdf,3,task,7.970099925994873,CMMI8,False,402.7251281738281,346.2024230957031,0.0,4,P
sample_2.pdf,3,allows the task model to,10.909099578857422,NimbusRomNo9L-Regu,False,421.5871276855469,348.1169738769531,0.0,24,H3
sample_2.pdf,3,scale the entire ELMo vector.,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,361.6659851074219,0.10344827586206896,29,H3
sample_2.pdf,3,is of practical im-,10.909099578857422,NimbusRomNo9L-Regu,False,444.9370422363281,361.6659851074219,0.0,19,H3
sample_2.pdf,3,portance to aid the optimization process (see sup-,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,375.2149963378906,0.0,50,H3
sample_2.pdf,3,plemental material for details). Considering that,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,388.7640075683594,0.02040816326530612,49,H3
sample_2.pdf,3,the activations of each biLM layer have a different,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,402.3139953613281,0.0392156862745098,51,H3
sample_2.pdf,3,"distribution, in some cases it also helped to apply",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,415.8630065917969,0.0,51,H3
sample_2.pdf,3,layer normalization (,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,429.4120178222656,0.0,21,H3
sample_2.pdf,3,Ba et al.,10.909099578857422,NimbusRomNo9L-Regu,False,398.34515380859375,429.4120178222656,0.1111111111111111,9,H3
sample_2.pdf,3,2016,10.909099578857422,NimbusRomNo9L-Regu,False,436.7014465332031,429.4120178222656,0.0,4,H3
sample_2.pdf,3,) to each biLM,10.909099578857422,NimbusRomNo9L-Regu,False,461.0396728515625,429.4120178222656,0.14285714285714285,14,H3
sample_2.pdf,3,layer before weighting.,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,442.9610290527344,0.0,23,H3
sample_2.pdf,3,3.3,10.909099578857422,NimbusRomNo9L-Medi,False,307.276123046875,465.6584167480469,0.0,3,H3
sample_2.pdf,3,Using biLMs for supervised NLP tasks,10.909099578857422,NimbusRomNo9L-Medi,False,331.82159423828125,465.6584167480469,0.16666666666666666,36,H3
sample_2.pdf,3,Given a pre-trained biLM and a supervised archi-,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,483.4710388183594,0.0625,48,H3
sample_2.pdf,3,"tecture for a target NLP task, it is a simple process",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,497.0200500488281,0.05660377358490566,53,H3
sample_2.pdf,3,to use the biLM to improve the task model. We,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,510.5690612792969,0.06666666666666667,45,H3
sample_2.pdf,3,simply run the biLM and record all of the layer,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,524.1190795898438,0.0425531914893617,47,H3
sample_2.pdf,3,"representations for each word. Then, we let the",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,537.6680908203125,0.02127659574468085,47,H3
sample_2.pdf,3,end task model learn a linear combination of these,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,551.2171020507812,0.0,50,H3
sample_2.pdf,3,"representations, as described below.",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,564.76611328125,0.0,36,H3
sample_2.pdf,3,First consider the lowest layers of the super-,10.909099578857422,NimbusRomNo9L-Regu,False,318.18511962890625,578.43408203125,0.021739130434782608,46,H3
sample_2.pdf,3,vised model without the biLM. Most supervised,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,591.9830932617188,0.06666666666666667,45,H3
sample_2.pdf,3,NLP models share a common architecture at the,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,605.5330810546875,0.06666666666666667,45,H3
sample_2.pdf,3,"lowest layers, allowing us to add ELMo in a",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,619.0820922851562,0.06976744186046512,43,H3
sample_2.pdf,3,"consistent, uniﬁed manner.",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,632.631103515625,0.0,26,H3
sample_2.pdf,3,Given a sequence,10.909099578857422,NimbusRomNo9L-Regu,False,443.1271057128906,632.631103515625,0.0625,16,H3
sample_2.pdf,3,of tokens,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,646.1801147460938,0.0,9,H3
sample_2.pdf,3,", . . . , t",10.909099578857422,CMMI10,False,367.4731140136719,645.9276123046875,0.0,11,H3
sample_2.pdf,3,", it is standard to form a",10.909099578857422,NimbusRomNo9L-Regu,False,407.96612548828125,646.1801147460938,0.0,26,H3
sample_2.pdf,3,context-independent token representation,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,659.7291259765625,0.0,40,H3
sample_2.pdf,3,for,10.909099578857422,NimbusRomNo9L-Regu,False,507.36859130859375,659.7291259765625,0.0,3,H3
sample_2.pdf,3,each token position using pre-trained word em-,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,673.2791137695312,0.0,46,H3
sample_2.pdf,3,beddings and optionally character-based represen-,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,686.828125,0.0,49,H3
sample_2.pdf,3,"tations. Then, the model forms a context-sensitive",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,700.3770751953125,0.02,50,H3
sample_2.pdf,3,representation,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,713.9260864257812,0.0,14,H3
sample_2.pdf,3,", typically using either bidirec-",10.909099578857422,NimbusRomNo9L-Regu,False,385.3061218261719,713.9260864257812,0.0,33,H3
sample_2.pdf,3,"tional RNNs, CNNs, or feed forward networks.",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,727.47509765625,0.13636363636363635,44,H3
sample_2.pdf,3,"To add ELMo to the supervised model, we",10.909099578857422,NimbusRomNo9L-Regu,False,318.18511962890625,741.14306640625,0.10256410256410256,39,H3
sample_2.pdf,3,ﬁrst freeze the weights of the biLM and then,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,754.693115234375,0.045454545454545456,44,H3
sample_2.pdf,4,concatenate the ELMo vector,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,65.49368286132812,0.1111111111111111,27,H3
sample_2.pdf,4,ELMo,10.909099578857422,CMBX10,False,209.1492462158203,65.24122619628906,0.75,4,H3
sample_2.pdf,4,task,7.970099925994873,CMMI8,False,248.697998046875,63.208126068115234,0.0,4,P
sample_2.pdf,4,with,10.909099578857422,NimbusRomNo9L-Regu,False,270.87200927734375,65.49368286132812,0.0,4,H3
sample_2.pdf,4,and pass the ELMo enhanced representation,10.909099578857422,NimbusRomNo9L-Regu,False,83.02848052978516,79.04367065429688,0.07317073170731707,41,H3
sample_2.pdf,4,ELMo,10.909099578857422,CMBX10,False,89.80374908447266,92.34022521972656,0.75,4,H3
sample_2.pdf,4,task,7.970099925994873,CMMI8,False,125.58901977539062,90.30712890625,0.0,4,P
sample_2.pdf,4,into the task RNN. For some,10.909099578857422,NimbusRomNo9L-Regu,False,145.2137451171875,92.59268188476562,0.14814814814814814,27,H3
sample_2.pdf,4,"tasks (e.g., SNLI, SQuAD), we observe further",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,106.14169311523438,0.17777777777777778,45,H3
sample_2.pdf,4,improvements by also including ELMo at the out-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,119.69070434570312,0.06382978723404255,47,H3
sample_2.pdf,4,put of the task RNN by introducing another set,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,133.23971557617188,0.06521739130434782,46,H3
sample_2.pdf,4,of output speciﬁc linear weights and replacing,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,146.78970336914062,0.0,46,H3
sample_2.pdf,4,with,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,160.33865356445312,0.0,4,H3
sample_2.pdf,4,ELMo,10.909099578857422,CMBX10,False,113.95974731445312,160.08619689941406,0.75,4,H3
sample_2.pdf,4,task,7.970099925994873,CMMI8,False,149.74502563476562,158.0531005859375,0.0,4,P
sample_2.pdf,4,. As the remainder of the,10.909099578857422,NimbusRomNo9L-Regu,False,169.3670196533203,160.33865356445312,0.04,25,H3
sample_2.pdf,4,"supervised model remains unchanged, these addi-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,173.88766479492188,0.0,47,H3
sample_2.pdf,4,tions can happen within the context of more com-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,187.43667602539062,0.0,48,H3
sample_2.pdf,4,"plex neural models. For example, see the SNLI",10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,200.98568725585938,0.1111111111111111,45,H3
sample_2.pdf,4,experiments in Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,214.53567504882812,0.05263157894736842,19,H3
sample_2.pdf,4,where a bi-attention layer,10.909099578857422,NimbusRomNo9L-Regu,False,170.05104064941406,214.53567504882812,0.0,26,H3
sample_2.pdf,4,"follows the biLSTMs, or the coreference resolu-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,228.08468627929688,0.0851063829787234,47,H3
sample_2.pdf,4,tion experiments where a clustering model is lay-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,241.63369750976562,0.0,49,H3
sample_2.pdf,4,ered on top of the biLSTMs.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0000228881836,255.18270874023438,0.14814814814814814,27,H3
sample_2.pdf,4,"Finally, we found it beneﬁcial to add a moder-",10.909099578857422,NimbusRomNo9L-Regu,False,82.90902709960938,270.4137268066406,0.021739130434782608,46,H3
sample_2.pdf,4,ate amount of dropout to ELMo (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,283.9627380371094,0.0967741935483871,31,H3
sample_2.pdf,4,Srivastava et al.,10.909099578857422,NimbusRomNo9L-Regu,False,218.7601318359375,283.9627380371094,0.058823529411764705,17,H3
sample_2.pdf,4,2014,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,297.5117492675781,0.0,4,H3
sample_2.pdf,4,) and in some cases to regularize the ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,93.8182373046875,297.5117492675781,0.07142857142857142,42,H3
sample_2.pdf,4,weights by adding,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,311.0607604980469,0.0,17,H3
sample_2.pdf,4,to the loss. This im-,10.909099578857422,NimbusRomNo9L-Regu,False,194.26803588867188,311.0608215332031,0.047619047619047616,21,H3
sample_2.pdf,4,poses an inductive bias on the ELMo weights to,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003814697266,324.6098327636719,0.06521739130434782,46,H3
sample_2.pdf,4,stay close to an average of all biLM layers.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003814697266,338.1598205566406,0.045454545454545456,44,H3
sample_2.pdf,4,3.4,10.909099578857422,NimbusRomNo9L-Medi,False,72.00003814697266,366.2691955566406,0.0,3,H3
sample_2.pdf,4,Pre-trained bidirectional language model,10.909099578857422,NimbusRomNo9L-Medi,False,96.54551696777344,366.2691955566406,0.025,40,H3
sample_2.pdf,4,architecture,10.909099578857422,NimbusRomNo9L-Medi,False,96.54503631591797,379.8182067871094,0.0,12,H3
sample_2.pdf,4,The pre-trained biLMs in this paper are similar to,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003814697266,400.7318115234375,0.06,50,H3
sample_2.pdf,4,the architectures in,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003814697266,414.28179931640625,0.0,20,H3
sample_2.pdf,4,J´ozefowicz et al.,10.909099578857422,NimbusRomNo9L-Regu,False,157.7237548828125,414.226806640625,0.05555555555555555,18,H3
sample_2.pdf,4,2016,10.909099578857422,NimbusRomNo9L-Regu,False,244.9813995361328,414.28179931640625,0.0,4,H3
sample_2.pdf,4,) and,10.909099578857422,NimbusRomNo9L-Regu,False,266.7995910644531,414.28179931640625,0.0,5,H3
sample_2.pdf,4,Kim et al.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,427.830810546875,0.1,10,H3
sample_2.pdf,4,2015,10.909099578857422,NimbusRomNo9L-Regu,False,126.42554473876953,427.830810546875,0.0,4,H3
sample_2.pdf,4,"), but modiﬁed to support joint",10.909099578857422,NimbusRomNo9L-Regu,False,148.2437286376953,427.830810546875,0.0,31,H3
sample_2.pdf,4,training of both directions and add a residual con-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,441.37982177734375,0.0,51,H3
sample_2.pdf,4,nection between LSTM layers. We focus on large,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,454.9288330078125,0.10869565217391304,46,H3
sample_2.pdf,4,"scale biLMs in this work, as",10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,468.47784423828125,0.07142857142857142,28,H3
sample_2.pdf,4,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,200.7165069580078,468.47784423828125,0.07692307692307693,13,H3
sample_2.pdf,4,2017,10.909099578857422,NimbusRomNo9L-Regu,False,264.8183898925781,468.47784423828125,0.0,4,H3
sample_2.pdf,4,highlighted the importance of using biLMs over,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,482.02783203125,0.043478260869565216,46,H3
sample_2.pdf,4,forward-only LMs and large scale training.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,495.57684326171875,0.047619047619047616,42,H3
sample_2.pdf,4,To balance overall language model perplexity,10.909099578857422,NimbusRomNo9L-Regu,False,82.90902709960938,510.8068542480469,0.022727272727272728,44,H3
sample_2.pdf,4,with model size and computational requirements,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,524.3558959960938,0.0,46,H3
sample_2.pdf,4,for downstream tasks while maintaining a purely,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,537.9058837890625,0.0,47,H3
sample_2.pdf,4,"character-based input representation, we halved all",10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,551.4548950195312,0.0,51,H3
sample_2.pdf,4,embedding and hidden dimensions from the single,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,565.00390625,0.0,47,H3
sample_2.pdf,4,best model,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,578.5529174804688,0.0,10,H3
sample_2.pdf,4,CNN-BIG-LSTM,10.909099578857422,NimbusMonL-Regu,False,120.03280639648438,577.994384765625,0.8333333333333334,12,H3
sample_2.pdf,4,J´ozefowicz et al.,10.909099578857422,NimbusRomNo9L-Regu,False,213.435302734375,578.4989013671875,0.05555555555555555,18,H3
sample_2.pdf,4,2016,10.909099578857422,NimbusRomNo9L-Regu,False,75.63275909423828,592.1019287109375,0.0,4,H3
sample_2.pdf,4,). The ﬁnal model uses,10.909099578857422,NimbusRomNo9L-Regu,False,97.45096588134766,592.1019287109375,0.045454545454545456,22,H3
sample_2.pdf,4,= 2,10.909099578857422,CMR10,False,209.2291259765625,591.8494262695312,0.0,3,H3
sample_2.pdf,4,biLSTM lay-,10.909099578857422,NimbusRomNo9L-Regu,False,229.90676879882812,592.1019287109375,0.36363636363636365,11,H3
sample_2.pdf,4,ers with 4096 units and 512 dimension projections,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,605.6519165039062,0.0,49,H3
sample_2.pdf,4,and a residual connection from the ﬁrst to second,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,619.200927734375,0.0,49,H3
sample_2.pdf,4,layer. The context insensitive type representation,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,632.7498779296875,0.02,50,H3
sample_2.pdf,4,uses 2048 character n-gram convolutional ﬁlters,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,646.2988891601562,0.0,47,H3
sample_2.pdf,4,followed by two highway layers (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,659.847900390625,0.0,32,H3
sample_2.pdf,4,Srivastava et al.,10.909099578857422,NimbusRomNo9L-Regu,False,218.98924255371094,659.847900390625,0.058823529411764705,17,H3
sample_2.pdf,4,2015,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,673.3978881835938,0.0,4,H3
sample_2.pdf,4,) and a linear projection down to a 512 repre-,10.909099578857422,NimbusRomNo9L-Regu,False,93.8182373046875,673.3978881835938,0.0,46,H3
sample_2.pdf,4,"sentation. As a result, the biLM provides three lay-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,686.9468994140625,0.057692307692307696,52,H3
sample_2.pdf,4,"ers of representations for each input token, includ-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,700.495849609375,0.0,52,H3
sample_2.pdf,4,ing those outside the training set due to the purely,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,714.0448608398438,0.0,52,H3
sample_2.pdf,4,"character input. In contrast, traditional word em-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,727.5938720703125,0.02,50,H3
sample_2.pdf,4,bedding methods only provide one layer of repre-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,741.1438598632812,0.0,48,H3
sample_2.pdf,4,sentation for tokens in a ﬁxed vocabulary.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,754.69287109375,0.0,42,H3
sample_2.pdf,4,After training for 10 epochs on the 1B Word,10.909099578857422,NimbusRomNo9L-Regu,False,318.1850280761719,65.49386596679688,0.06976744186046512,43,H3
sample_2.pdf,4,Benchmark (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,79.04287719726562,0.09090909090909091,11,H3
sample_2.pdf,4,Chelba et al.,10.909099578857422,NimbusRomNo9L-Regu,False,364.1996765136719,79.04287719726562,0.07692307692307693,13,H3
sample_2.pdf,4,2014,10.909099578857422,NimbusRomNo9L-Regu,False,422.30145263671875,79.04287719726562,0.0,4,H3
sample_2.pdf,4,"), the average for-",10.909099578857422,NimbusRomNo9L-Regu,False,447.11968994140625,79.04287719726562,0.0,19,H3
sample_2.pdf,4,"ward and backward perplexities is 39.7, compared",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,92.59286499023438,0.0,48,H3
sample_2.pdf,4,to 30.0 for the forward,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,106.14187622070312,0.0,23,H3
sample_2.pdf,4,CNN-BIG-LSTM,10.909099578857422,NimbusMonL-Regu,False,407.9124450683594,105.5833740234375,0.8333333333333334,12,H3
sample_2.pdf,4,. Gener-,10.909099578857422,NimbusRomNo9L-Regu,False,489.6040344238281,106.14187622070312,0.125,8,H3
sample_2.pdf,4,"ally, we found the forward and backward perplex-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,119.69088745117188,0.0,48,H3
sample_2.pdf,4,"ities to be approximately equal, with the backward",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,133.23989868164062,0.0,50,H3
sample_2.pdf,4,value slightly lower.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,146.78890991210938,0.0,21,H3
sample_2.pdf,4,"Once pretrained, the biLM can compute repre-",10.909099578857422,NimbusRomNo9L-Regu,False,318.1850280761719,160.54489135742188,0.06818181818181818,44,H3
sample_2.pdf,4,"sentations for any task. In some cases, ﬁne tuning",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,174.09487915039062,0.02,50,H3
sample_2.pdf,4,the biLM on domain speciﬁc data leads to signiﬁ-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,187.64389038085938,0.041666666666666664,48,H3
sample_2.pdf,4,cant drops in perplexity and an increase in down-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,201.19290161132812,0.0,49,H3
sample_2.pdf,4,stream task performance. This can be seen as a,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,214.74191284179688,0.021739130434782608,46,H3
sample_2.pdf,4,"type of domain transfer for the biLM. As a result,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,228.29092407226562,0.06,50,H3
sample_2.pdf,4,in most cases we used a ﬁne-tuned biLM in the,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,241.83993530273438,0.044444444444444446,45,H3
sample_2.pdf,4,downstream task. See supplemental material for,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,255.38992309570312,0.021739130434782608,46,H3
sample_2.pdf,4,details.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,268.9389343261719,0.0,8,H3
sample_2.pdf,4,Evaluation,11.9552001953125,NimbusRomNo9L-Medi,False,325.2088317871094,292.5184326171875,0.1,10,H3
sample_2.pdf,4,Table,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,314.8459167480469,0.2,5,H3
sample_2.pdf,4,shows the performance of ELMo across a,10.909099578857422,NimbusRomNo9L-Regu,False,339.6651306152344,314.8459167480469,0.07894736842105263,38,H3
sample_2.pdf,4,diverse set of six benchmark NLP tasks. In every,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,328.3949279785156,0.08333333333333333,48,H3
sample_2.pdf,4,"task considered, simply adding ELMo establishes",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,341.9439392089844,0.06382978723404255,47,H3
sample_2.pdf,4,"a new state-of-the-art result, with relative error re-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,355.4929504394531,0.0,54,H3
sample_2.pdf,4,ductions ranging from 6 - 20% over strong base,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,369.0429382324219,0.0,46,H3
sample_2.pdf,4,models. This is a very general result across a di-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,382.5919494628906,0.02,50,H3
sample_2.pdf,4,verse set model architectures and language under-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,396.1409606933594,0.0,49,H3
sample_2.pdf,4,standing tasks. In the remainder of this section we,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,409.6899719238281,0.0196078431372549,51,H3
sample_2.pdf,4,provide high-level sketches of the individual task,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,423.2389831542969,0.0,50,H3
sample_2.pdf,4,results; see the supplemental material for full ex-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,436.7889709472656,0.0,51,H3
sample_2.pdf,4,perimental details.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,450.3379821777344,0.0,19,H3
sample_2.pdf,4,Question answering,10.909099578857422,NimbusRomNo9L-Medi,False,318.1850280761719,463.994384765625,0.05555555555555555,18,H3
sample_2.pdf,4,The Stanford Question,10.909099578857422,NimbusRomNo9L-Regu,False,413.8250732421875,464.093994140625,0.14285714285714285,21,H3
sample_2.pdf,4,Answering Dataset (SQuAD) (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,477.64300537109375,0.2222222222222222,27,H3
sample_2.pdf,4,Rajpurkar et al.,10.909099578857422,NimbusRomNo9L-Regu,False,449.9888000488281,477.64300537109375,0.0625,16,H3
sample_2.pdf,4,2016,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,491.1920166015625,0.0,4,H3
sample_2.pdf,4,) contains 100K+ crowd sourced question-,10.909099578857422,NimbusRomNo9L-Regu,False,329.0942687988281,491.1920166015625,0.025,40,H3
sample_2.pdf,4,answer pairs where the answer is a span in a given,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,504.7410583496094,0.0,50,H3
sample_2.pdf,4,Wikipedia paragraph. Our baseline model (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,518.2900390625,0.04878048780487805,41,H3
sample_2.pdf,4,Clark,10.909099578857422,NimbusRomNo9L-Regu,False,501.30511474609375,518.2900390625,0.2,5,H3
sample_2.pdf,4,and Gardner,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,531.840087890625,0.09090909090909091,11,H3
sample_2.pdf,4,2017,10.909099578857422,NimbusRomNo9L-Regu,False,364.63604736328125,531.840087890625,0.0,4,H3
sample_2.pdf,4,) is an improved version of the,10.909099578857422,NimbusRomNo9L-Regu,False,389.6070251464844,531.840087890625,0.0,31,H3
sample_2.pdf,4,Bidirectional Attention Flow model in,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,545.3890380859375,0.08108108108108109,37,H3
sample_2.pdf,4,Seo et al.,10.909099578857422,NimbusRomNo9L-Regu,False,478.985107421875,545.3890380859375,0.1,10,H3
sample_2.pdf,4,(BiDAF;,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,558.9381103515625,0.5714285714285714,7,H3
sample_2.pdf,4,2017,10.909099578857422,NimbusRomNo9L-Regu,False,345.63238525390625,558.9381103515625,0.0,4,H3
sample_2.pdf,4,). It adds a self-attention layer af-,10.909099578857422,NimbusRomNo9L-Regu,False,374.15972900390625,558.9381103515625,0.02702702702702703,37,H3
sample_2.pdf,4,"ter the bidirectional attention component, simpli-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,572.487060546875,0.0,50,H3
sample_2.pdf,4,ﬁes some of the pooling operations and substitutes,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,586.0360717773438,0.0,50,H3
sample_2.pdf,4,the LSTMs for gated recurrent units (GRUs;,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,599.5860595703125,0.16666666666666666,42,H3
sample_2.pdf,4,Cho,10.909099578857422,NimbusRomNo9L-Regu,False,501.54510498046875,599.5860595703125,0.3333333333333333,3,H3
sample_2.pdf,4,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,613.1350708007812,0.0,6,H3
sample_2.pdf,4,2014,10.909099578857422,NimbusRomNo9L-Regu,False,331.9741516113281,613.1350708007812,0.0,4,H3
sample_2.pdf,4,). After adding ELMo to the baseline,10.909099578857422,NimbusRomNo9L-Regu,False,357.2832946777344,613.1350708007812,0.1111111111111111,36,H3
sample_2.pdf,4,"model, test set F",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,626.68408203125,0.058823529411764705,17,H3
sample_2.pdf,4,improved by 4.7% from 81.1%,10.909099578857422,NimbusRomNo9L-Regu,False,384.55316162109375,626.68408203125,0.0,27,H3
sample_2.pdf,4,"to 85.8%, a 24.9% relative error reduction over the",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,640.2330932617188,0.0,51,H3
sample_2.pdf,4,"baseline, and improving the overall single model",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,653.7821044921875,0.0,48,H3
sample_2.pdf,4,state-of-the-art by 1.4%. A 11 member ensem-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,667.3320922851562,0.022727272727272728,44,H3
sample_2.pdf,4,ble pushes F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,680.881103515625,0.08333333333333333,12,H3
sample_2.pdf,4,"to 87.4, the overall state-of-the-art",10.909099578857422,NimbusRomNo9L-Regu,False,367.9641418457031,680.881103515625,0.0,37,H3
sample_2.pdf,4,at time of submission to the leaderboard.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,694.4300537109375,0.0,41,H3
sample_2.pdf,4,The,10.909099578857422,NimbusRomNo9L-Regu,False,508.58001708984375,694.4300537109375,0.3333333333333333,3,H3
sample_2.pdf,4,increase of 4.7% with ELMo is also signiﬁcantly,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,707.9790649414062,0.06382978723404255,47,H3
sample_2.pdf,4,larger then the 1.8% improvement from adding,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,721.528076171875,0.0,44,H3
sample_2.pdf,4,CoVe to a baseline model (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,735.0780639648438,0.07692307692307693,26,H3
sample_2.pdf,4,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,425.1377868652344,735.0780639648438,0.15384615384615385,13,H3
sample_2.pdf,4,2017,10.909099578857422,NimbusRomNo9L-Regu,False,489.3704528808594,735.0780639648438,0.0,4,H3
sample_2.pdf,4,"As of November 17, 2017.",8.966400146484375,NimbusRomNo9L-Regu,False,323.4150085449219,756.1659545898438,0.08333333333333333,24,P
sample_2.pdf,5,ASK,8.727299690246582,NimbusRomNo9L-Medi,False,105.39000701904297,76.97063446044922,1.0,3,P
sample_2.pdf,5,REVIOUS,8.727299690246582,NimbusRomNo9L-Medi,False,153.1649932861328,76.97063446044922,1.0,7,P
sample_2.pdf,5,SOTA,10.909099578857422,NimbusRomNo9L-Medi,False,196.16441345214844,75.29605865478516,1.0,4,H3
sample_2.pdf,5,BASELINE,8.727299690246582,NimbusRomNo9L-Medi,False,323.5450134277344,84.69164276123047,1.0,8,P
sample_2.pdf,5,ELM,10.909099578857422,NimbusRomNo9L-Medi,False,374.77301025390625,69.37808990478516,1.0,3,H3
sample_2.pdf,5,BASELINE,8.727299690246582,NimbusRomNo9L-Medi,False,374.77301025390625,84.60167694091797,1.0,8,P
sample_2.pdf,5,NCREASE,8.727299690246582,NimbusRomNo9L-Medi,False,450.426025390625,63.44664764404297,1.0,7,P
sample_2.pdf,5,ABSOLUTE,8.727299690246582,NimbusRomNo9L-Medi,False,449.8150329589844,76.99565887451172,1.0,8,P
sample_2.pdf,5,RELATIVE,8.727299690246582,NimbusRomNo9L-Medi,False,445.63702392578125,90.54467010498047,1.0,8,P
sample_2.pdf,5,SQuAD,10.909099578857422,NimbusRomNo9L-Regu,False,98.17900085449219,103.07669067382812,0.8,5,H3
sample_2.pdf,5,Liu et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,103.07669067382812,0.1,10,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,191.1283416748047,103.07669067382812,0.0,4,H3
sample_2.pdf,5,84.4,10.909099578857422,NimbusRomNo9L-Regu,False,289.4411315917969,103.07669067382812,0.0,4,H3
sample_2.pdf,5,81.1,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,103.07669067382812,0.0,4,H3
sample_2.pdf,5,85.8,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,103.07669067382812,0.0,4,H3
sample_2.pdf,5,4.7 / 24.9%,10.909099578857422,NimbusRomNo9L-Regu,False,445.36669921875,103.07669067382812,0.0,11,H3
sample_2.pdf,5,SNLI,10.909099578857422,NimbusRomNo9L-Regu,False,98.17900085449219,116.62570190429688,1.0,4,H3
sample_2.pdf,5,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,116.62564086914062,0.09090909090909091,11,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,199.00469970703125,116.62564086914062,0.0,4,H3
sample_2.pdf,5,88.6,10.909099578857422,NimbusRomNo9L-Regu,False,289.4411315917969,116.62564086914062,0.0,4,H3
sample_2.pdf,5,88.0,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,116.62564086914062,0.0,4,H3
sample_2.pdf,5,88.7,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,116.62564086914062,0.0,4,H3
sample_2.pdf,5,0.17,10.909099578857422,NimbusRomNo9L-Regu,False,404.8052673339844,116.62564086914062,0.0,4,H3
sample_2.pdf,5,0.7 / 5.8%,10.909099578857422,NimbusRomNo9L-Regu,False,445.36376953125,116.62564086914062,0.0,10,H3
sample_2.pdf,5,SRL,10.909099578857422,NimbusRomNo9L-Regu,False,98.17901611328125,130.17465209960938,1.0,3,H3
sample_2.pdf,5,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,130.17465209960938,0.1111111111111111,9,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,188.69561767578125,130.17465209960938,0.0,4,H3
sample_2.pdf,5,81.7,10.909099578857422,NimbusRomNo9L-Regu,False,289.4411315917969,130.17465209960938,0.0,4,H3
sample_2.pdf,5,81.4,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,130.17465209960938,0.0,4,H3
sample_2.pdf,5,84.6,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,130.17465209960938,0.0,4,H3
sample_2.pdf,5,3.2 / 17.2%,10.909099578857422,NimbusRomNo9L-Regu,False,445.36669921875,130.17465209960938,0.0,11,H3
sample_2.pdf,5,Coref,10.909099578857422,NimbusRomNo9L-Regu,False,98.17900085449219,143.72366333007812,0.2,5,H3
sample_2.pdf,5,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,143.72366333007812,0.1,10,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,192.32835388183594,143.72366333007812,0.0,4,H3
sample_2.pdf,5,67.2,10.909099578857422,NimbusRomNo9L-Regu,False,289.441162109375,143.72366333007812,0.0,4,H3
sample_2.pdf,5,67.2,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,143.72366333007812,0.0,4,H3
sample_2.pdf,5,70.4,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,143.72366333007812,0.0,4,H3
sample_2.pdf,5,3.2 / 9.8%,10.909099578857422,NimbusRomNo9L-Regu,False,445.36669921875,143.72366333007812,0.0,10,H3
sample_2.pdf,5,NER,10.909099578857422,NimbusRomNo9L-Regu,False,98.17900085449219,157.27267456054688,1.0,3,H3
sample_2.pdf,5,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,157.27267456054688,0.07692307692307693,13,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,202.637451171875,157.27267456054688,0.0,4,H3
sample_2.pdf,5,91.93,10.909099578857422,NimbusRomNo9L-Regu,False,250.95384216308594,157.27267456054688,0.0,5,H3
sample_2.pdf,5,0.19,10.909099578857422,NimbusRomNo9L-Regu,False,286.7122802734375,157.27267456054688,0.0,4,H3
sample_2.pdf,5,90.15,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,157.27267456054688,0.0,5,H3
sample_2.pdf,5,92.22,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,157.27267456054688,0.0,5,H3
sample_2.pdf,5,0.10,10.909099578857422,NimbusRomNo9L-Regu,False,410.2602844238281,157.27267456054688,0.0,4,H3
sample_2.pdf,5,2.06 / 21%,10.909099578857422,NimbusRomNo9L-Regu,False,445.3632507324219,157.27267456054688,0.0,10,H3
sample_2.pdf,5,SST-5,10.909099578857422,NimbusRomNo9L-Regu,False,98.17901611328125,170.82266235351562,0.6,5,H3
sample_2.pdf,5,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,145.68099975585938,170.82266235351562,0.15384615384615385,13,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,213.54653930664062,170.82266235351562,0.0,4,H3
sample_2.pdf,5,53.7,10.909099578857422,NimbusRomNo9L-Regu,False,289.4411315917969,170.82266235351562,0.0,4,H3
sample_2.pdf,5,51.4,10.909099578857422,NimbusRomNo9L-Regu,False,323.2720031738281,170.82266235351562,0.0,4,H3
sample_2.pdf,5,54.7,10.909099578857422,NimbusRomNo9L-Regu,False,374.50115966796875,170.82266235351562,0.0,4,H3
sample_2.pdf,5,0.5,10.909099578857422,NimbusRomNo9L-Regu,False,404.8052673339844,170.82266235351562,0.0,3,H3
sample_2.pdf,5,3.3 / 6.8%,10.909099578857422,NimbusRomNo9L-Regu,False,445.36376953125,170.82266235351562,0.0,10,H3
sample_2.pdf,5,Table 1: Test set comparison of ELMo enhanced neural models with state-of-the-art single model baselines across,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,193.3584747314453,0.04504504504504504,111,H3
sample_2.pdf,5,six benchmark NLP tasks. The performance metric varies across tasks – accuracy for SNLI and SST-5; F,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,205.31349182128906,0.12,100,H3
sample_2.pdf,5,for,9.962599754333496,NimbusRomNo9L-Regu,False,510.0950622558594,205.31349182128906,0.0,3,H3
sample_2.pdf,5,"SQuAD, SRL and NER; average F",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,217.2685089111328,0.3793103448275862,29,H3
sample_2.pdf,5,"for Coref. Due to the small test sizes for NER and SST-5, we report the mean",9.962599754333496,NimbusRomNo9L-Regu,False,214.49307250976562,217.2685089111328,0.10526315789473684,76,H3
sample_2.pdf,5,and standard deviation across ﬁve runs with different random seeds. The “increase” column lists both the absolute,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,229.22352600097656,0.008849557522123894,113,H3
sample_2.pdf,5,and relative improvements over our baseline.,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,241.1785430908203,0.0,44,H3
sample_2.pdf,5,Textual entailment,10.909099578857422,NimbusRomNo9L-Medi,False,82.90899658203125,273.4021301269531,0.05555555555555555,18,H3
sample_2.pdf,5,Textual entailment is the,10.909099578857422,NimbusRomNo9L-Regu,False,172.12362670898438,273.5017395019531,0.04,25,H3
sample_2.pdf,5,task of determining whether a “hypothesis” is,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,287.0517272949219,0.0,45,H3
sample_2.pdf,5,"true, given a “premise”.",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,300.6007385253906,0.0,24,H3
sample_2.pdf,5,The Stanford Natu-,10.909099578857422,NimbusRomNo9L-Regu,False,198.99285888671875,300.6007385253906,0.16666666666666666,18,H3
sample_2.pdf,5,ral Language Inference (SNLI) corpus (,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,314.1497497558594,0.15789473684210525,38,H3
sample_2.pdf,5,Bowman,10.909099578857422,NimbusRomNo9L-Regu,False,251.14926147460938,314.1497497558594,0.16666666666666666,6,H3
sample_2.pdf,5,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,327.6987609863281,0.0,6,H3
sample_2.pdf,5,2015,10.909099578857422,NimbusRomNo9L-Regu,False,95.3781967163086,327.6987609863281,0.0,4,H3
sample_2.pdf,5,) provides approximately 550K hypoth-,10.909099578857422,NimbusRomNo9L-Regu,False,119.37821960449219,327.6987609863281,0.02702702702702703,37,H3
sample_2.pdf,5,esis/premise pairs.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,341.2477722167969,0.0,19,H3
sample_2.pdf,5,"Our baseline, the ESIM se-",10.909099578857422,NimbusRomNo9L-Regu,False,163.65826416015625,341.2477722167969,0.19230769230769232,26,H3
sample_2.pdf,5,quence model from,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,354.7977600097656,0.0,17,H3
sample_2.pdf,5,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,156.5128173828125,354.7977600097656,0.09090909090909091,11,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,211.9310760498047,354.7977600097656,0.0,4,H3
sample_2.pdf,5,"), uses a biL-",10.909099578857422,NimbusRomNo9L-Regu,False,233.74925231933594,354.7977600097656,0.07142857142857142,14,H3
sample_2.pdf,5,"STM to encode the premise and hypothesis, fol-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,368.3467712402344,0.06521739130434782,46,H3
sample_2.pdf,5,"lowed by a matrix attention layer, a local infer-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,381.8957824707031,0.0,49,H3
sample_2.pdf,5,"ence layer, another biLSTM inference composi-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,395.4447937011719,0.08888888888888889,45,H3
sample_2.pdf,5,"tion layer, and ﬁnally a pooling operation before",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,408.9938049316406,0.0,49,H3
sample_2.pdf,5,the output layer.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,422.5428161621094,0.0,17,H3
sample_2.pdf,5,"Overall, adding ELMo to the",10.909099578857422,NimbusRomNo9L-Regu,False,155.77098083496094,422.5428161621094,0.14814814814814814,27,H3
sample_2.pdf,5,ESIM model improves accuracy by an average of,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,436.0928039550781,0.08888888888888889,45,H3
sample_2.pdf,5,0.7% across ﬁve random seeds. A ﬁve member,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,449.6418151855469,0.023809523809523808,42,H3
sample_2.pdf,5,"ensemble pushes the overall accuracy to 89.3%,",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,463.1908264160156,0.0,46,H3
sample_2.pdf,5,exceeding the previous ensemble best of 88.9%,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,476.7398376464844,0.0,45,H3
sample_2.pdf,5,Gong et al.,10.909099578857422,NimbusRomNo9L-Regu,False,75.63272094726562,490.2888488769531,0.09090909090909091,11,H3
sample_2.pdf,5,2018,10.909099578857422,NimbusRomNo9L-Regu,False,126.53458404541016,490.2888488769531,0.0,4,H3
sample_2.pdf,5,Semantic role labeling,10.909099578857422,NimbusRomNo9L-Medi,False,82.90899658203125,507.2232360839844,0.045454545454545456,22,H3
sample_2.pdf,5,A semantic role label-,10.909099578857422,NimbusRomNo9L-Regu,False,187.8654327392578,507.3228454589844,0.045454545454545456,22,H3
sample_2.pdf,5,ing (SRL) system models the predicate-argument,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,520.8718872070312,0.06521739130434782,46,H3
sample_2.pdf,5,"structure of a sentence, and is often described as",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,534.4208984375,0.0,50,H3
sample_2.pdf,5,answering “Who did what to whom”.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,547.9699096679688,0.030303030303030304,33,H3
sample_2.pdf,5,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,242.6182861328125,547.9699096679688,0.1111111111111111,9,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,75.63272857666016,561.5198974609375,0.0,4,H3
sample_2.pdf,5,) modeled SRL as a BIO tagging problem,10.909099578857422,NimbusRomNo9L-Regu,False,97.45093536376953,561.5198974609375,0.15789473684210525,38,H3
sample_2.pdf,5,and used an 8-layer deep biLSTM with forward,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,575.0689086914062,0.09090909090909091,44,H3
sample_2.pdf,5,"and backward directions interleaved, following",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,588.617919921875,0.0,46,H3
sample_2.pdf,5,Zhou and Xu,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,602.1668701171875,0.18181818181818182,11,H3
sample_2.pdf,5,2015,10.909099578857422,NimbusRomNo9L-Regu,False,137.13824462890625,602.1668701171875,0.0,4,H3
sample_2.pdf,5,). As shown in Table,10.909099578857422,NimbusRomNo9L-Regu,False,158.9564208984375,602.1668701171875,0.1,20,H3
sample_2.pdf,5,", when",10.909099578857422,NimbusRomNo9L-Regu,False,260.6837463378906,602.1668701171875,0.0,6,H3
sample_2.pdf,5,adding ELMo to a re-implementation of,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,615.7158813476562,0.08108108108108109,37,H3
sample_2.pdf,5,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,249.3601531982422,615.7158813476562,0.1111111111111111,9,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,75.63272857666016,629.265869140625,0.0,4,H3
sample_2.pdf,5,) the single model test set F,10.909099578857422,NimbusRomNo9L-Regu,False,97.45093536376953,629.265869140625,0.034482758620689655,29,H3
sample_2.pdf,5,jumped 3.2%,10.909099578857422,NimbusRomNo9L-Regu,False,227.06712341308594,629.265869140625,0.0,11,H3
sample_2.pdf,5,from 81.4% to 84.6% – a new state-of-the-art on,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,642.8148803710938,0.0,47,H3
sample_2.pdf,5,the OntoNotes benchmark (,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,656.3638916015625,0.08,25,H3
sample_2.pdf,5,Pradhan et al.,10.909099578857422,NimbusRomNo9L-Regu,False,194.912841796875,656.3638916015625,0.07142857142857142,14,H3
sample_2.pdf,5,2013,10.909099578857422,NimbusRomNo9L-Regu,False,258.68743896484375,656.3638916015625,0.0,4,H3
sample_2.pdf,5,even improving over the previous best ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,669.9129028320312,0.0,46,H3
sample_2.pdf,5,result by 1.2%.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,683.4619140625,0.0,15,H3
sample_2.pdf,5,Coreference resolution,10.909099578857422,NimbusRomNo9L-Medi,False,82.90899658203125,700.396240234375,0.045454545454545456,22,H3
sample_2.pdf,5,Coreference resolution,10.909099578857422,NimbusRomNo9L-Regu,False,188.38909912109375,700.495849609375,0.045454545454545456,22,H3
sample_2.pdf,5,is the task of clustering mentions in text that re-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,714.0448608398438,0.0,51,H3
sample_2.pdf,5,fer to the same underlying real world entities. Our,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,727.5938720703125,0.0196078431372549,51,H3
sample_2.pdf,5,baseline model is the end-to-end span-based neu-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,741.1428833007812,0.0,48,H3
sample_2.pdf,5,ral model of,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,754.69287109375,0.0,12,H3
sample_2.pdf,5,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,126.64368438720703,754.69287109375,0.1,10,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,178.66920471191406,754.69287109375,0.0,4,H3
sample_2.pdf,5,). It uses a biLSTM,10.909099578857422,NimbusRomNo9L-Regu,False,200.4873809814453,754.69287109375,0.2631578947368421,19,H3
sample_2.pdf,5,and attention mechanism to ﬁrst compute span,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,273.5018005371094,0.0,44,H3
sample_2.pdf,5,representations and then applies a softmax men-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,287.0508117675781,0.0,47,H3
sample_2.pdf,5,tion ranking model to ﬁnd coreference chains. In,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,300.6007995605469,0.020833333333333332,48,H3
sample_2.pdf,5,our experiments with the OntoNotes coreference,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,314.1498107910156,0.043478260869565216,46,H3
sample_2.pdf,5,annotations from the CoNLL 2012 shared task,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,327.6988220214844,0.09302325581395349,43,H3
sample_2.pdf,5,Pradhan et al.,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087219238281,341.2478332519531,0.07142857142857142,14,H3
sample_2.pdf,5,2012,10.909099578857422,NimbusRomNo9L-Regu,False,372.55596923828125,341.2478332519531,0.0,4,H3
sample_2.pdf,5,"), adding ELMo improved the",10.909099578857422,NimbusRomNo9L-Regu,False,396.71966552734375,341.2478332519531,0.1111111111111111,27,H3
sample_2.pdf,5,average F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,354.7968444824219,0.1111111111111111,9,H3
sample_2.pdf,5,"by 3.2% from 67.2 to 70.4, establish-",10.909099578857422,NimbusRomNo9L-Regu,False,354.57012939453125,354.7968444824219,0.0,37,H3
sample_2.pdf,5,"ing a new state of the art, again improving over the",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,368.3468322753906,0.0,52,H3
sample_2.pdf,5,previous best ensemble result by 1.6% F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,381.8958435058594,0.02564102564102564,39,H3
sample_2.pdf,5,Named entity extraction,10.909099578857422,NimbusRomNo9L-Medi,False,318.1850280761719,398.8292236328125,0.043478260869565216,23,H3
sample_2.pdf,5,The CoNLL 2003,10.909099578857422,NimbusRomNo9L-Regu,False,436.38507080078125,398.9288330078125,0.35714285714285715,14,H3
sample_2.pdf,5,NER task (,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,412.47784423828125,0.3,10,H3
sample_2.pdf,5,Sang and Meulder,10.909099578857422,NimbusRomNo9L-Regu,False,358.5597229003906,412.47784423828125,0.125,16,H3
sample_2.pdf,5,2003,10.909099578857422,NimbusRomNo9L-Regu,False,444.07611083984375,412.47784423828125,0.0,4,H3
sample_2.pdf,5,) consists of,10.909099578857422,NimbusRomNo9L-Regu,False,470.0179748535156,412.47784423828125,0.0,13,H3
sample_2.pdf,5,newswire from the Reuters RCV1 corpus tagged,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,426.02783203125,0.09090909090909091,44,H3
sample_2.pdf,5,with four different entity types (,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,439.57684326171875,0.0,34,H3
sample_2.pdf,5,PER,10.909099578857422,NimbusMonL-Regu,False,451.36505126953125,439.0183410644531,1.0,3,H3
sample_2.pdf,5,LOC,10.909099578857422,NimbusMonL-Regu,False,473.7283020019531,439.0183410644531,1.0,3,H3
sample_2.pdf,5,ORG,10.909099578857422,NimbusMonL-Regu,False,499.6352844238281,439.0183410644531,1.0,3,H3
sample_2.pdf,5,MISC,10.909099578857422,NimbusMonL-Regu,False,307.27606201171875,452.5673522949219,1.0,4,H3
sample_2.pdf,5,). Following recent state-of-the-art systems,10.909099578857422,NimbusRomNo9L-Regu,False,333.4570617675781,453.1258544921875,0.022727272727272728,44,H3
sample_2.pdf,5,Lample et al.,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087829589844,466.67486572265625,0.07692307692307693,13,H3
sample_2.pdf,5,2016,10.909099578857422,NimbusRomNo9L-Regu,False,370.5159912109375,466.67486572265625,0.0,4,H3
sample_2.pdf,5,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,397.8978576660156,466.67486572265625,0.07692307692307693,13,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,453.3705139160156,466.67486572265625,0.0,4,H3
sample_2.pdf,5,"), the base-",10.909099578857422,NimbusRomNo9L-Regu,False,477.7305603027344,466.67486572265625,0.0,12,H3
sample_2.pdf,5,"line model uses pre-trained word embeddings, a",10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,480.223876953125,0.0,46,H3
sample_2.pdf,5,"character-based CNN representation, two biLSTM",10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,493.77386474609375,0.15217391304347827,46,H3
sample_2.pdf,5,layers and a conditional random ﬁeld (CRF) loss,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,507.3228454589844,0.06382978723404255,47,H3
sample_2.pdf,5,Lafferty et al.,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087829589844,520.8719482421875,0.06666666666666667,15,H3
sample_2.pdf,5,2001,10.909099578857422,NimbusRomNo9L-Regu,False,375.3377990722656,520.8719482421875,0.0,4,H3
sample_2.pdf,5,"), similar to",10.909099578857422,NimbusRomNo9L-Regu,False,401.0287780761719,520.8719482421875,0.0,13,H3
sample_2.pdf,5,Collobert et al.,10.909099578857422,NimbusRomNo9L-Regu,False,454.2214660644531,520.8719482421875,0.0625,16,H3
sample_2.pdf,5,2011,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087829589844,534.4208984375,0.0,4,H3
sample_2.pdf,5,). As shown in Table,10.909099578857422,NimbusRomNo9L-Regu,False,332.7270202636719,534.4208984375,0.1,20,H3
sample_2.pdf,5,", our ELMo enhanced",10.909099578857422,NimbusRomNo9L-Regu,False,430.8870849609375,534.4208984375,0.15789473684210525,19,H3
sample_2.pdf,5,biLSTM-CRF achieves 92.22% F,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,547.969970703125,0.2857142857142857,28,H3
sample_2.pdf,5,averaged over,10.909099578857422,NimbusRomNo9L-Regu,False,460.2621765136719,547.969970703125,0.0,13,H3
sample_2.pdf,5,ﬁve runs. The key difference between our system,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,561.5198974609375,0.02127659574468085,47,H3
sample_2.pdf,5,and the previous state of the art from,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,575.0689697265625,0.0,38,H3
sample_2.pdf,5,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,470.92333984375,575.0689697265625,0.07692307692307693,13,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,310.9087829589844,588.617919921875,0.0,4,H3
sample_2.pdf,5,) is that we allowed the task model to learn a,10.909099578857422,NimbusRomNo9L-Regu,False,332.7270202636719,588.617919921875,0.0,46,H3
sample_2.pdf,5,"weighted average of all biLM layers, whereas",10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,602.1669311523438,0.045454545454545456,44,H3
sample_2.pdf,5,Pe-,10.909099578857422,NimbusRomNo9L-Regu,False,508.0361022949219,602.1669311523438,0.3333333333333333,3,H3
sample_2.pdf,5,ters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,615.7159423828125,0.0,11,H3
sample_2.pdf,5,2017,10.909099578857422,NimbusRomNo9L-Regu,False,354.54510498046875,615.7159423828125,0.0,4,H3
sample_2.pdf,5,) only use the top biLM layer. As,10.909099578857422,NimbusRomNo9L-Regu,False,376.36334228515625,615.7159423828125,0.09090909090909091,33,H3
sample_2.pdf,5,shown in Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,629.2659301757812,0.07692307692307693,13,H3
sample_2.pdf,5,5.1,10.909099578857422,NimbusRomNo9L-Regu,False,369.16339111328125,629.2659301757812,0.0,3,H3
sample_2.pdf,5,", using all layers instead of just",10.909099578857422,NimbusRomNo9L-Regu,False,386.1597900390625,629.2659301757812,0.0,34,H3
sample_2.pdf,5,the last layer improves performance across multi-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,642.81494140625,0.0,49,H3
sample_2.pdf,5,ple tasks.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,656.3638916015625,0.0,10,H3
sample_2.pdf,5,Sentiment analysis,10.909099578857422,NimbusRomNo9L-Medi,False,318.18505859375,673.2973022460938,0.05555555555555555,18,H3
sample_2.pdf,5,The ﬁne-grained sentiment,10.909099578857422,NimbusRomNo9L-Regu,False,405.1850891113281,673.3969116210938,0.04,25,H3
sample_2.pdf,5,classiﬁcation task in the Stanford Sentiment Tree-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,686.9468994140625,0.06,50,H3
sample_2.pdf,5,bank (SST-5;,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,700.4959106445312,0.25,12,H3
sample_2.pdf,5,Socher et al.,10.909099578857422,NimbusRomNo9L-Regu,False,365.1597595214844,700.4959106445312,0.07692307692307693,13,H3
sample_2.pdf,5,2013,10.909099578857422,NimbusRomNo9L-Regu,False,426.065185546875,700.4959106445312,0.0,4,H3
sample_2.pdf,5,) involves select-,10.909099578857422,NimbusRomNo9L-Regu,False,451.01434326171875,700.4959106445312,0.0,18,H3
sample_2.pdf,5,ing one of ﬁve labels (from very negative to very,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,714.044921875,0.0,49,H3
sample_2.pdf,5,positive) to describe a sentence from a movie re-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,727.5939331054688,0.0,49,H3
sample_2.pdf,5,view.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,741.1429443359375,0.0,5,H3
sample_2.pdf,5,The sentences contain diverse linguistic,10.909099578857422,NimbusRomNo9L-Regu,False,341.5196838378906,741.1429443359375,0.025,40,H3
sample_2.pdf,5,phenomena such as idioms and complex syntac-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,754.6929321289062,0.0,44,H3
sample_2.pdf,6,Task,10.909099578857422,NimbusRomNo9L-Regu,False,77.97799682617188,70.79367065429688,0.25,4,H3
sample_2.pdf,6,Baseline,10.909099578857422,NimbusRomNo9L-Regu,False,125.4800033569336,70.79367065429688,0.125,8,H3
sample_2.pdf,6,Last Only,10.909099578857422,NimbusRomNo9L-Regu,False,175.4040069580078,70.79367065429688,0.2222222222222222,9,H3
sample_2.pdf,6,All layers,10.909099578857422,NimbusRomNo9L-Regu,False,243.78199768066406,64.01968383789062,0.1,10,H3
sample_2.pdf,6,=0.001,10.909099578857422,NimbusRomNo9L-Regu,False,268.4980163574219,77.56869506835938,0.0,6,H3
sample_2.pdf,6,SQuAD,10.909099578857422,NimbusRomNo9L-Regu,False,77.97799682617188,93.90768432617188,0.8,5,H3
sample_2.pdf,6,80.8,10.909099578857422,NimbusRomNo9L-Regu,False,134.72000122070312,93.90768432617188,0.0,4,H3
sample_2.pdf,6,84.7,10.909099578857422,NimbusRomNo9L-Regu,False,187.5240020751953,93.90768432617188,0.0,4,H3
sample_2.pdf,6,85.0,10.909099578857422,NimbusRomNo9L-Regu,False,231.08799743652344,93.90768432617188,0.0,4,H3
sample_2.pdf,6,85.2,10.909099578857422,NimbusRomNo9L-Medi,False,271.1199951171875,93.8080825805664,0.0,4,H3
sample_2.pdf,6,SNLI,10.909099578857422,NimbusRomNo9L-Regu,False,77.97799682617188,107.45669555664062,1.0,4,H3
sample_2.pdf,6,88.1,10.909099578857422,NimbusRomNo9L-Regu,False,134.72000122070312,107.45669555664062,0.0,4,H3
sample_2.pdf,6,89.1,10.909099578857422,NimbusRomNo9L-Regu,False,187.5240020751953,107.45669555664062,0.0,4,H3
sample_2.pdf,6,89.3,10.909099578857422,NimbusRomNo9L-Regu,False,231.08799743652344,107.45669555664062,0.0,4,H3
sample_2.pdf,6,89.5,10.909099578857422,NimbusRomNo9L-Medi,False,271.1199951171875,107.35709381103516,0.0,4,H3
sample_2.pdf,6,SRL,10.909099578857422,NimbusRomNo9L-Regu,False,77.97799682617188,121.00570678710938,1.0,3,H3
sample_2.pdf,6,81.6,10.909099578857422,NimbusRomNo9L-Regu,False,134.72000122070312,121.00564575195312,0.0,4,H3
sample_2.pdf,6,84.1,10.909099578857422,NimbusRomNo9L-Regu,False,187.5240020751953,121.00564575195312,0.0,4,H3
sample_2.pdf,6,84.6,10.909099578857422,NimbusRomNo9L-Regu,False,231.08799743652344,121.00564575195312,0.0,4,H3
sample_2.pdf,6,84.8,10.909099578857422,NimbusRomNo9L-Medi,False,271.1199951171875,120.90604400634766,0.0,4,H3
sample_2.pdf,6,"Table 2: Development set performance for SQuAD,",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,143.5414581298828,0.1276595744680851,47,H3
sample_2.pdf,6,SNLI and SRL comparing using all layers of the biLM,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,155.49647521972656,0.17647058823529413,51,H3
sample_2.pdf,6,(with different choices of regularization strength,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,167.4514923095703,0.0,50,H3
sample_2.pdf,6,) to,9.962599754333496,NimbusRomNo9L-Regu,False,276.22100830078125,167.4514923095703,0.0,4,H3
sample_2.pdf,6,just the top layer.,9.962599754333496,NimbusRomNo9L-Regu,False,72.00001525878906,179.40748596191406,0.0,19,H3
sample_2.pdf,6,Task,10.909099578857422,NimbusRomNo9L-Regu,False,91.42201232910156,211.91964721679688,0.25,4,H3
sample_2.pdf,6,Input,10.909099578857422,NimbusRomNo9L-Regu,False,143.04800415039062,204.88064575195312,0.2,5,H3
sample_2.pdf,6,Only,10.909099578857422,NimbusRomNo9L-Regu,False,143.04800415039062,218.42965698242188,0.25,4,H3
sample_2.pdf,6,Input &,10.909099578857422,NimbusRomNo9L-Regu,False,194.6739959716797,204.95669555664062,0.14285714285714285,7,H3
sample_2.pdf,6,Output,10.909099578857422,NimbusRomNo9L-Regu,False,194.6739959716797,218.50570678710938,0.16666666666666666,6,H3
sample_2.pdf,6,Output,10.909099578857422,NimbusRomNo9L-Regu,False,241.39199829101562,204.95669555664062,0.16666666666666666,6,H3
sample_2.pdf,6,Only,10.909099578857422,NimbusRomNo9L-Regu,False,241.39199829101562,218.50570678710938,0.25,4,H3
sample_2.pdf,6,SQuAD,10.909099578857422,NimbusRomNo9L-Regu,False,91.4219970703125,233.14169311523438,0.8,5,H3
sample_2.pdf,6,85.1,10.909099578857422,NimbusRomNo9L-Regu,False,163.22999572753906,233.14169311523438,0.0,4,H3
sample_2.pdf,6,85.6,10.909099578857422,NimbusRomNo9L-Medi,False,209.94700622558594,233.04209899902344,0.0,4,H3
sample_2.pdf,6,84.8,10.909099578857422,NimbusRomNo9L-Regu,False,251.7550048828125,233.14169311523438,0.0,4,H3
sample_2.pdf,6,SNLI,10.909099578857422,NimbusRomNo9L-Regu,False,91.42201232910156,246.69070434570312,1.0,4,H3
sample_2.pdf,6,88.9,10.909099578857422,NimbusRomNo9L-Regu,False,163.22999572753906,246.69064331054688,0.0,4,H3
sample_2.pdf,6,89.5,10.909099578857422,NimbusRomNo9L-Medi,False,209.94700622558594,246.59104919433594,0.0,4,H3
sample_2.pdf,6,88.7,10.909099578857422,NimbusRomNo9L-Regu,False,251.7550048828125,246.69064331054688,0.0,4,H3
sample_2.pdf,6,SRL,10.909099578857422,NimbusRomNo9L-Regu,False,91.42201232910156,260.2396545410156,1.0,3,H3
sample_2.pdf,6,84.7,10.909099578857422,NimbusRomNo9L-Medi,False,163.22999572753906,260.1400451660156,0.0,4,H3
sample_2.pdf,6,84.3,10.909099578857422,NimbusRomNo9L-Regu,False,209.94700622558594,260.2396545410156,0.0,4,H3
sample_2.pdf,6,80.9,10.909099578857422,NimbusRomNo9L-Regu,False,251.7550048828125,260.2396545410156,0.0,4,H3
sample_2.pdf,6,"Table 3: Development set performance for SQuAD,",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,282.77545166015625,0.1276595744680851,47,H3
sample_2.pdf,6,SNLI and SRL when including ELMo at different lo-,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,294.7314453125,0.20408163265306123,49,H3
sample_2.pdf,6,cations in the supervised model.,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,306.68646240234375,0.0,32,H3
sample_2.pdf,6,tic constructions such as negations that are difﬁ-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,343.72467041015625,0.0,50,H3
sample_2.pdf,6,cult for models to learn. Our baseline model is,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,357.273681640625,0.02127659574468085,47,H3
sample_2.pdf,6,the biattentive classiﬁcation network (BCN) from,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,370.82366943359375,0.0625,48,H3
sample_2.pdf,6,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,384.3726806640625,0.15384615384615385,13,H3
sample_2.pdf,6,2017,10.909099578857422,NimbusRomNo9L-Regu,False,143.88006591796875,384.3726806640625,0.0,4,H3
sample_2.pdf,6,"), which also held the prior",10.909099578857422,NimbusRomNo9L-Regu,False,165.6982421875,384.3726806640625,0.0,28,H3
sample_2.pdf,6,state-of-the-art result when augmented with CoVe,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,397.92169189453125,0.041666666666666664,48,H3
sample_2.pdf,6,embeddings. Replacing CoVe with ELMo in the,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,411.470703125,0.13953488372093023,43,H3
sample_2.pdf,6,BCN model results in a 1.0% absolute accuracy,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,425.01971435546875,0.06666666666666667,45,H3
sample_2.pdf,6,improvement over the state of the art.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,438.5697021484375,0.0,38,H3
sample_2.pdf,6,Analysis,11.9552001953125,NimbusRomNo9L-Medi,False,89.93280029296875,469.5992126464844,0.125,8,H3
sample_2.pdf,6,This section provides an ablation analysis to vali-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,497.2577209472656,0.0196078431372549,51,H3
sample_2.pdf,6,date our chief claims and to elucidate some inter-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,510.8067321777344,0.0,50,H3
sample_2.pdf,6,esting aspects of ELMo representations. Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,524.3557739257812,0.09090909090909091,44,H3
sample_2.pdf,6,5.1,10.909099578857422,NimbusRomNo9L-Regu,False,273.25103759765625,524.3557739257812,0.0,3,H3
sample_2.pdf,6,shows that using deep contextual representations,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,537.90576171875,0.0,48,H3
sample_2.pdf,6,in downstream tasks improves performance over,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,551.4547729492188,0.0,45,H3
sample_2.pdf,6,"previous work that uses just the top layer, regard-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,565.0037841796875,0.0,51,H3
sample_2.pdf,6,less of whether they are produced from a biLM or,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,578.5527954101562,0.041666666666666664,48,H3
sample_2.pdf,6,"MT encoder, and that ELMo representations pro-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,592.101806640625,0.10869565217391304,46,H3
sample_2.pdf,6,vide the best overall performance. Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,605.6517944335938,0.02564102564102564,39,H3
sample_2.pdf,6,5.3,10.909099578857422,NimbusRomNo9L-Regu,False,254.0511016845703,605.6517944335938,0.0,3,H3
sample_2.pdf,6,ex-,10.909099578857422,NimbusRomNo9L-Regu,False,272.0947570800781,605.6517944335938,0.0,3,H3
sample_2.pdf,6,plores the different types of contextual informa-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,619.2008056640625,0.0,49,H3
sample_2.pdf,6,tion captured in biLMs and uses two intrinsic eval-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,632.749755859375,0.0392156862745098,51,H3
sample_2.pdf,6,uations to show that syntactic information is better,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,646.2987670898438,0.0,52,H3
sample_2.pdf,6,represented at lower layers while semantic infor-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,659.8477783203125,0.0,49,H3
sample_2.pdf,6,"mation is captured a higher layers, consistent with",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,673.3977661132812,0.0,51,H3
sample_2.pdf,6,MT encoders. It also shows that our biLM consis-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,686.94677734375,0.10416666666666667,48,H3
sample_2.pdf,6,tently provides richer representations then CoVe.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,700.4957275390625,0.04081632653061224,49,H3
sample_2.pdf,6,"Additionally, we analyze the sensitivity to where",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,714.0447387695312,0.02040816326530612,49,H3
sample_2.pdf,6,ELMo is included in the task model (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,727.59375,0.1,40,H3
sample_2.pdf,6,5.2,10.909099578857422,NimbusRomNo9L-Regu,False,265.7564697265625,727.59375,0.0,3,H3
sample_2.pdf,6,training set size (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,741.1437377929688,0.043478260869565216,23,H3
sample_2.pdf,6,5.4,10.909099578857422,NimbusRomNo9L-Regu,False,163.42918395996094,741.1437377929688,0.0,3,H3
sample_2.pdf,6,"), and visualize the ELMo",10.909099578857422,NimbusRomNo9L-Regu,False,179.16009521484375,741.1437377929688,0.12,25,H3
sample_2.pdf,6,learned weights across the tasks (Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,754.6927490234375,0.02631578947368421,38,H3
sample_2.pdf,6,5.5,10.909099578857422,NimbusRomNo9L-Regu,False,236.20379638671875,754.6927490234375,0.0,3,H3
sample_2.pdf,6,5.1,10.909099578857422,NimbusRomNo9L-Medi,False,307.2760009765625,65.3941421508789,0.0,3,H3
sample_2.pdf,6,Alternate layer weighting schemes,10.909099578857422,NimbusRomNo9L-Medi,False,331.82147216796875,65.3941421508789,0.030303030303030304,33,H3
sample_2.pdf,6,There are many alternatives to Equation,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,84.77975463867188,0.05128205128205128,39,H3
sample_2.pdf,6,for com-,10.909099578857422,NimbusRomNo9L-Regu,False,486.13055419921875,84.77975463867188,0.0,8,H3
sample_2.pdf,6,bining the biLM layers. Previous work on con-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,98.32876586914062,0.06666666666666667,45,H3
sample_2.pdf,6,"textual representations used only the last layer,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,111.87777709960938,0.0,49,H3
sample_2.pdf,6,whether it be from a biLM (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,125.42678833007812,0.07407407407407407,27,H3
sample_2.pdf,6,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,431.2032775878906,125.42678833007812,0.07692307692307693,13,H3
sample_2.pdf,6,2017,10.909099578857422,NimbusRomNo9L-Regu,False,485.0395812988281,125.42678833007812,0.0,4,H3
sample_2.pdf,6,) or,10.909099578857422,NimbusRomNo9L-Regu,False,509.83599853515625,125.42678833007812,0.0,4,H3
sample_2.pdf,6,an MT encoder (CoVe;,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,138.97677612304688,0.2,20,H3
sample_2.pdf,6,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,407.4651184082031,138.97677612304688,0.15384615384615385,13,H3
sample_2.pdf,6,2017,10.909099578857422,NimbusRomNo9L-Regu,False,474.3377990722656,138.97677612304688,0.0,4,H3
sample_2.pdf,6,). The,10.909099578857422,NimbusRomNo9L-Regu,False,498.8505859375,138.97677612304688,0.16666666666666666,6,H3
sample_2.pdf,6,choice of the regularization parameter,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,152.52578735351562,0.0,38,H3
sample_2.pdf,6,is also,10.909099578857422,NimbusRomNo9L-Regu,False,491.5110168457031,152.52578735351562,0.0,7,H3
sample_2.pdf,6,"important, as large values such as",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,166.07479858398438,0.0,34,H3
sample_2.pdf,6,= 1,10.909099578857422,CMR10,False,471.1620178222656,165.8223419189453,0.0,3,H3
sample_2.pdf,6,effec-,10.909099578857422,NimbusRomNo9L-Regu,False,496.2802734375,166.07479858398438,0.0,6,H3
sample_2.pdf,6,tively reduce the weighting function to a simple,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,179.62380981445312,0.0,48,H3
sample_2.pdf,6,"average over the layers, while smaller values (e.g.,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,193.17282104492188,0.0,52,H3
sample_2.pdf,6,= 0,10.909099578857422,CMR10,False,313.6360168457031,206.47035217285156,0.0,3,H3
sample_2.pdf,6,001,10.909099578857422,CMR10,False,336.6700134277344,206.47035217285156,0.0,3,H3
sample_2.pdf,6,) allow the layer weights to vary.,10.909099578857422,NimbusRomNo9L-Regu,False,353.03302001953125,206.72280883789062,0.0,34,H3
sample_2.pdf,6,Table,10.909099578857422,NimbusRomNo9L-Regu,False,318.1850280761719,221.18283081054688,0.2,5,H3
sample_2.pdf,6,"compares these alternatives for SQuAD,",10.909099578857422,NimbusRomNo9L-Regu,False,349.8213806152344,221.18283081054688,0.10526315789473684,38,H3
sample_2.pdf,6,SNLI and SRL. Including representations from all,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,234.73184204101562,0.16666666666666666,48,H3
sample_2.pdf,6,layers improves overall performance over just us-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,248.28085327148438,0.0,49,H3
sample_2.pdf,6,"ing the last layer, and including contextual rep-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,261.8308410644531,0.0,49,H3
sample_2.pdf,6,resentations from the last layer improves perfor-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,275.3798522949219,0.0,49,H3
sample_2.pdf,6,mance over the baseline.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,288.9288635253906,0.0,24,H3
sample_2.pdf,6,"For example, in the",10.909099578857422,NimbusRomNo9L-Regu,False,433.0032958984375,288.9288635253906,0.05263157894736842,19,H3
sample_2.pdf,6,"case of SQuAD, using just the last biLM layer im-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,302.4778747558594,0.12244897959183673,49,H3
sample_2.pdf,6,proves development F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,316.0268859863281,0.05,20,H3
sample_2.pdf,6,by 3.9% over the baseline.,10.909099578857422,NimbusRomNo9L-Regu,False,407.4771423339844,316.0268859863281,0.0,26,H3
sample_2.pdf,6,Averaging all biLM layers instead of using just the,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,329.5768737792969,0.058823529411764705,51,H3
sample_2.pdf,6,last layer improves F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760314941406,343.1258850097656,0.047619047619047616,21,H3
sample_2.pdf,6,another 0.3% (comparing,10.909099578857422,NimbusRomNo9L-Regu,False,407.0611572265625,343.1258850097656,0.0,23,H3
sample_2.pdf,6,“Last Only” to,10.909099578857422,NimbusRomNo9L-Regu,False,307.27606201171875,356.6748962402344,0.14285714285714285,14,H3
sample_2.pdf,6,"=1 columns), and allowing the",10.909099578857422,NimbusRomNo9L-Regu,False,385.60809326171875,356.6748962402344,0.0,29,H3
sample_2.pdf,6,task model to learn individual layer weights im-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760925292969,370.2239074707031,0.0,48,H3
sample_2.pdf,6,proves F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760925292969,383.7729187011719,0.125,8,H3
sample_2.pdf,6,another 0.2% (,10.909099578857422,NimbusRomNo9L-Regu,False,350.6522216796875,383.7729187011719,0.0,14,H3
sample_2.pdf,6,=1 vs.,10.909099578857422,NimbusRomNo9L-Regu,False,429.5561218261719,383.7729187011719,0.0,6,H3
sample_2.pdf,6,=0.001). A,10.909099578857422,NimbusRomNo9L-Regu,False,472.442138671875,383.7729187011719,0.1,10,H3
sample_2.pdf,6,small,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,397.3219299316406,0.0,5,H3
sample_2.pdf,6,"is preferred in most cases with ELMo, al-",10.909099578857422,NimbusRomNo9L-Regu,False,340.17913818359375,397.3219299316406,0.07317073170731707,41,H3
sample_2.pdf,6,"though for NER, a task with a smaller training set,",10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,410.8719177246094,0.058823529411764705,51,H3
sample_2.pdf,6,the results are insensitive to,10.909099578857422,NimbusRomNo9L-Regu,False,307.276123046875,424.4209289550781,0.0,30,H3
sample_2.pdf,6,(not shown).,10.909099578857422,NimbusRomNo9L-Regu,False,437.1251525878906,424.4209289550781,0.0,12,H3
sample_2.pdf,6,The overall trend is similar with CoVe but with,10.909099578857422,NimbusRomNo9L-Regu,False,318.1851501464844,438.88092041015625,0.06382978723404255,47,H3
sample_2.pdf,6,"smaller increases over the baseline. For SNLI, av-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2761535644531,452.429931640625,0.1,50,H3
sample_2.pdf,6,eraging all layers with,10.909099578857422,NimbusRomNo9L-Regu,False,307.2761535644531,465.97991943359375,0.0,23,H3
sample_2.pdf,6,=1 improves development,10.909099578857422,NimbusRomNo9L-Regu,False,412.7311706542969,465.97991943359375,0.0,23,H3
sample_2.pdf,6,accuracy from 88.2 to 88.7% over using just the,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,479.5289306640625,0.0,47,H3
sample_2.pdf,6,last layer. SRL F,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,493.07794189453125,0.23529411764705882,17,H3
sample_2.pdf,6,increased a marginal 0.1% to,10.909099578857422,NimbusRomNo9L-Regu,False,390.539306640625,493.07794189453125,0.0,28,H3
sample_2.pdf,6,82.2 for the,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,506.6269226074219,0.0,12,H3
sample_2.pdf,6,=1 case compared to using the last,10.909099578857422,NimbusRomNo9L-Regu,False,369.7001953125,506.6269226074219,0.0,34,H3
sample_2.pdf,6,layer only.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,520.176025390625,0.0,11,H3
sample_2.pdf,6,5.2,10.909099578857422,NimbusRomNo9L-Medi,False,307.27618408203125,545.618408203125,0.0,3,H3
sample_2.pdf,6,Where to include ELMo?,10.909099578857422,NimbusRomNo9L-Medi,False,331.8216552734375,545.618408203125,0.18181818181818182,22,H3
sample_2.pdf,6,All of the task architectures in this paper include,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,565.0040283203125,0.0196078431372549,51,H3
sample_2.pdf,6,word embeddings only as input to the lowest layer,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,578.552978515625,0.0,49,H3
sample_2.pdf,6,"biRNN. However, we ﬁnd that including ELMo at",10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,592.1019897460938,0.15555555555555556,45,H3
sample_2.pdf,6,the output of the biRNN in task-speciﬁc architec-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,605.6510009765625,0.061224489795918366,49,H3
sample_2.pdf,6,tures improves overall results for some tasks. As,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,619.2009887695312,0.02040816326530612,49,H3
sample_2.pdf,6,shown in Table,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,632.75,0.07142857142857142,14,H3
sample_2.pdf,6,", including ELMo at both the in-",10.909099578857422,NimbusRomNo9L-Regu,False,382.37445068359375,632.75,0.09375,32,H3
sample_2.pdf,6,put and output layers for SNLI and SQuAD im-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,646.2989501953125,0.18181818181818182,44,H3
sample_2.pdf,6,"proves over just the input layer, but for SRL (and",10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,659.8479614257812,0.06,50,H3
sample_2.pdf,6,"coreference resolution, not shown) performance is",10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,673.39697265625,0.0,49,H3
sample_2.pdf,6,highest when it is included at just the input layer.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,686.9469604492188,0.0,52,H3
sample_2.pdf,6,One possible explanation for this result is that both,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,700.4959716796875,0.018867924528301886,53,H3
sample_2.pdf,6,the SNLI and SQuAD architectures use attention,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,714.0449829101562,0.17391304347826086,46,H3
sample_2.pdf,6,"layers after the biRNN, so introducing ELMo at",10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,727.593994140625,0.13043478260869565,46,H3
sample_2.pdf,6,this layer allows the model to attend directly to the,10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,741.1429443359375,0.0,53,H3
sample_2.pdf,6,"biLM’s internal representations. In the SRL case,",10.909099578857422,NimbusRomNo9L-Regu,False,307.27618408203125,754.6919555664062,0.12244897959183673,49,H3
sample_2.pdf,7,Source,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,77.56869506835938,0.16666666666666666,6,H3
sample_2.pdf,7,Nearest Neighbors,10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,77.56869506835938,0.11764705882352941,17,H3
sample_2.pdf,7,GloVe,10.909099578857422,NimbusRomNo9L-Regu,False,91.26300048828125,100.71664428710938,0.4,5,H3
sample_2.pdf,7,play,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,100.69961547851562,0.0,4,H3
sample_2.pdf,7,"playing, game, games, played, players, plays, player,",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,93.92465209960938,0.0,53,H3
sample_2.pdf,7,"Play, football, multiplayer",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,107.47366333007812,0.037037037037037035,27,H3
sample_2.pdf,7,biLM,10.909099578857422,NimbusRomNo9L-Regu,False,91.26300048828125,156.72964477539062,0.5,4,H3
sample_2.pdf,7,Chico Ruiz made a spec-,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,121.66061401367188,0.08695652173913043,23,H3
sample_2.pdf,7,tacular play on Alusik ’s,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,135.21060180664062,0.04,25,H3
sample_2.pdf,7,grounder,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,148.75967407226562,0.0,8,H3
sample_2.pdf,7,. . .,10.909099578857422,NimbusRomNo9L-Regu,False,178.6540069580078,148.75967407226562,0.0,5,H3
sample_2.pdf,7,"Kieffer , the only junior in the group , was commended",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,121.42166137695312,0.018518518518518517,54,H3
sample_2.pdf,7,"for his ability to hit in the clutch , as well as his all-round",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,134.97067260742188,0.0,63,H3
sample_2.pdf,7,excellent play .,10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,148.51968383789062,0.0,16,H3
sample_2.pdf,7,Olivia,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,162.54769897460938,0.16666666666666666,6,H3
sample_2.pdf,7,Havilland,10.909099578857422,NimbusRomNo9L-Regu,False,201.67288208007812,162.54769897460938,0.1111111111111111,9,H3
sample_2.pdf,7,signed to do a Broadway,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,176.09768676757812,0.043478260869565216,23,H3
sample_2.pdf,7,play for Garson,10.909099578857422,NimbusRomNo9L-Regu,False,131.09100341796875,189.64669799804688,0.06666666666666667,15,H3
sample_2.pdf,7,. . .,10.909099578857422,NimbusRomNo9L-Regu,False,207.7369842529297,189.64669799804688,0.0,5,H3
sample_2.pdf,7,...,10.909099578857422,NimbusRomNo9L-Regu,False,262.28497314453125,162.78768920898438,0.0,3,H3
sample_2.pdf,7,they were actors who had been handed fat roles in,10.909099578857422,NimbusRomNo9L-Regu,False,280.82952880859375,162.78768920898438,0.0,49,H3
sample_2.pdf,7,"a successful play , and had talent enough to ﬁll the roles",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,176.33663940429688,0.0,58,H3
sample_2.pdf,7,"competently , with nice understatement .",10.909099578857422,NimbusRomNo9L-Regu,False,256.8299865722656,189.88565063476562,0.0,40,H3
sample_2.pdf,7,Table 4: Nearest neighbors to “play” using GloVe and the context embeddings from a biLM.,9.962599754333496,NimbusRomNo9L-Regu,False,114.52899169921875,212.6604766845703,0.06818181818181818,88,H3
sample_2.pdf,7,Model,10.909099578857422,NimbusRomNo9L-Medi,False,103.38299560546875,243.4100799560547,0.2,5,H3
sample_2.pdf,7,WordNet 1st Sense Baseline,10.909099578857422,NimbusRomNo9L-Regu,False,103.38300323486328,259.8486633300781,0.15384615384615385,26,H3
sample_2.pdf,7,65.9,10.909099578857422,NimbusRomNo9L-Regu,False,239.38999938964844,259.8486633300781,0.0,4,H3
sample_2.pdf,7,Raganato et al.,10.909099578857422,NimbusRomNo9L-Regu,False,103.38299560546875,273.3976745605469,0.06666666666666667,15,H3
sample_2.pdf,7,2017a,10.909099578857422,NimbusRomNo9L-Regu,False,174.82672119140625,273.3976745605469,0.0,5,H3
sample_2.pdf,7,69.9,10.909099578857422,NimbusRomNo9L-Regu,False,239.38999938964844,273.3976745605469,0.0,4,H3
sample_2.pdf,7,Iacobacci et al.,10.909099578857422,NimbusRomNo9L-Regu,False,103.38299560546875,286.9466857910156,0.0625,16,H3
sample_2.pdf,7,2016,10.909099578857422,NimbusRomNo9L-Regu,False,175.47036743164062,286.9466857910156,0.0,4,H3
sample_2.pdf,7,70.1,10.909099578857422,NimbusRomNo9L-Medi,False,239.38999938964844,286.8470764160156,0.0,4,H3
sample_2.pdf,7,"CoVe, First Layer",10.909099578857422,NimbusRomNo9L-Regu,False,103.38300323486328,300.8946838378906,0.23529411764705882,17,H3
sample_2.pdf,7,59.4,10.909099578857422,NimbusRomNo9L-Regu,False,239.38999938964844,300.8946838378906,0.0,4,H3
sample_2.pdf,7,"CoVe, Second Layer",10.909099578857422,NimbusRomNo9L-Regu,False,103.38299560546875,314.4436950683594,0.2222222222222222,18,H3
sample_2.pdf,7,64.7,10.909099578857422,NimbusRomNo9L-ReguItal,False,239.38999938964844,314.2504577636719,0.0,4,H3
sample_2.pdf,7,"biLM, First layer",10.909099578857422,NimbusRomNo9L-Regu,False,103.38300323486328,328.39166259765625,0.17647058823529413,17,H3
sample_2.pdf,7,67.4,10.909099578857422,NimbusRomNo9L-Regu,False,239.38999938964844,328.39166259765625,0.0,4,H3
sample_2.pdf,7,"biLM, Second layer",10.909099578857422,NimbusRomNo9L-Regu,False,103.38299560546875,341.940673828125,0.16666666666666666,18,H3
sample_2.pdf,7,69.0,10.909099578857422,NimbusRomNo9L-ReguItal,False,239.38999938964844,341.7474365234375,0.0,4,H3
sample_2.pdf,7,Table 5: All-words ﬁne grained WSD F,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,364.4764709472656,0.16666666666666666,36,H3
sample_2.pdf,7,. For CoVe,9.962599754333496,NimbusRomNo9L-Regu,False,242.0349884033203,364.4764709472656,0.3,10,H3
sample_2.pdf,7,"and the biLM, we report scores for both the ﬁrst and",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,376.43145751953125,0.038461538461538464,52,H3
sample_2.pdf,7,second layer biLSTMs.,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,388.3864440917969,0.19047619047619047,21,H3
sample_2.pdf,7,the task-speciﬁc context representations are likely,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,422.9796447753906,0.0,51,H3
sample_2.pdf,7,more important than those from the biLM.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,436.5286560058594,0.05,40,H3
sample_2.pdf,7,5.3,10.909099578857422,NimbusRomNo9L-Medi,False,71.99998474121094,462.74505615234375,0.0,3,H3
sample_2.pdf,7,What information is captured by the,10.909099578857422,NimbusRomNo9L-Medi,False,96.54546356201172,462.74505615234375,0.02857142857142857,35,H3
sample_2.pdf,7,biLM’s representations?,10.909099578857422,NimbusRomNo9L-Medi,False,96.54498291015625,476.2940673828125,0.08695652173913043,23,H3
sample_2.pdf,7,Since adding ELMo improves task performance,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,496.1226806640625,0.09302325581395349,43,H3
sample_2.pdf,7,"over word vectors alone, the biLM’s contextual",10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,509.6726989746094,0.043478260869565216,46,H3
sample_2.pdf,7,representations must encode information gener-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,523.2216796875,0.0,46,H3
sample_2.pdf,7,ally useful for NLP tasks that is not captured,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,536.770751953125,0.06521739130434782,46,H3
sample_2.pdf,7,in word vectors.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,550.3197021484375,0.0,16,H3
sample_2.pdf,7,"Intuitively, the biLM must",10.909099578857422,NimbusRomNo9L-Regu,False,163.85462951660156,550.3197021484375,0.11538461538461539,26,H3
sample_2.pdf,7,be disambiguating the meaning of words using,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,563.8687744140625,0.0,44,H3
sample_2.pdf,7,their context.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,577.418701171875,0.0,14,H3
sample_2.pdf,7,"Consider “play”, a highly poly-",10.909099578857422,NimbusRomNo9L-Regu,False,142.59278869628906,577.418701171875,0.03225806451612903,31,H3
sample_2.pdf,7,semous word.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,590.9677124023438,0.0,12,H3
sample_2.pdf,7,The top of Table,10.909099578857422,NimbusRomNo9L-Regu,False,147.4145965576172,590.9677124023438,0.125,16,H3
sample_2.pdf,7,lists near-,10.909099578857422,NimbusRomNo9L-Regu,False,239.2692413330078,590.9677124023438,0.0,11,H3
sample_2.pdf,7,est neighbors to “play” using GloVe vectors.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,604.5167236328125,0.045454545454545456,44,H3
sample_2.pdf,7,They are spread across several parts of speech,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,618.0657348632812,0.021739130434782608,46,H3
sample_2.pdf,7,"(e.g., “played”, “playing” as verbs, and “player”,",10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,631.61474609375,0.0,50,H3
sample_2.pdf,7,“game” as nouns) but concentrated in the sports-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,645.1647338867188,0.0,48,H3
sample_2.pdf,7,"related senses of “play”. In contrast, the bottom",10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,658.7137451171875,0.02040816326530612,49,H3
sample_2.pdf,7,two rows show nearest neighbor sentences from,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,672.2626953125,0.0,45,H3
sample_2.pdf,7,the SemCor dataset (see below) using the biLM’s,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,685.8117065429688,0.0851063829787234,47,H3
sample_2.pdf,7,context representation of “play” in the source sen-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,699.3607177734375,0.0,51,H3
sample_2.pdf,7,"tence. In these cases, the biLM is able to disam-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,712.9107055664062,0.061224489795918366,49,H3
sample_2.pdf,7,biguate both the part of speech and word sense in,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,726.459716796875,0.0,49,H3
sample_2.pdf,7,the source sentence.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,740.0086669921875,0.0,20,H3
sample_2.pdf,7,These observations can be quantiﬁed using an,10.909099578857422,NimbusRomNo9L-Regu,False,82.90898132324219,754.6926879882812,0.022727272727272728,44,H3
sample_2.pdf,7,Model,10.909099578857422,NimbusRomNo9L-Medi,False,351.60797119140625,243.4100799560547,0.2,5,H3
sample_2.pdf,7,Acc.,10.909099578857422,NimbusRomNo9L-Medi,False,460.9200134277344,243.4100799560547,0.25,4,H3
sample_2.pdf,7,Collobert et al.,10.909099578857422,NimbusRomNo9L-Regu,False,351.6080017089844,259.8486633300781,0.0625,16,H3
sample_2.pdf,7,2011,10.909099578857422,NimbusRomNo9L-Regu,False,423.11700439453125,259.8486633300781,0.0,4,H3
sample_2.pdf,7,97.3,10.909099578857422,NimbusRomNo9L-Regu,False,460.9200134277344,259.8486633300781,0.0,4,H3
sample_2.pdf,7,Ma and Hovy,10.909099578857422,NimbusRomNo9L-Regu,False,351.6080322265625,273.3976745605469,0.18181818181818182,11,H3
sample_2.pdf,7,2016,10.909099578857422,NimbusRomNo9L-Regu,False,417.79351806640625,273.3976745605469,0.0,4,H3
sample_2.pdf,7,97.6,10.909099578857422,NimbusRomNo9L-Regu,False,460.9200134277344,273.3976745605469,0.0,4,H3
sample_2.pdf,7,Ling et al.,10.909099578857422,NimbusRomNo9L-Regu,False,351.6080322265625,286.9466857910156,0.09090909090909091,11,H3
sample_2.pdf,7,2015,10.909099578857422,NimbusRomNo9L-Regu,False,402.5097961425781,286.9466857910156,0.0,4,H3
sample_2.pdf,7,97.8,10.909099578857422,NimbusRomNo9L-Medi,False,460.9200134277344,286.8470764160156,0.0,4,H3
sample_2.pdf,7,"CoVe, First Layer",10.909099578857422,NimbusRomNo9L-Regu,False,351.6080017089844,300.8946838378906,0.23529411764705882,17,H3
sample_2.pdf,7,93.3,10.909099578857422,NimbusRomNo9L-ReguItal,False,460.9200134277344,300.7014465332031,0.0,4,H3
sample_2.pdf,7,"CoVe, Second Layer",10.909099578857422,NimbusRomNo9L-Regu,False,351.6080322265625,314.4436950683594,0.2222222222222222,18,H3
sample_2.pdf,7,92.8,10.909099578857422,NimbusRomNo9L-Regu,False,460.9200134277344,314.4436950683594,0.0,4,H3
sample_2.pdf,7,"biLM, First Layer",10.909099578857422,NimbusRomNo9L-Regu,False,351.6080017089844,328.39166259765625,0.23529411764705882,17,H3
sample_2.pdf,7,97.3,10.909099578857422,NimbusRomNo9L-ReguItal,False,460.9200134277344,328.19842529296875,0.0,4,H3
sample_2.pdf,7,"biLM, Second Layer",10.909099578857422,NimbusRomNo9L-Regu,False,351.6080322265625,341.940673828125,0.2222222222222222,18,H3
sample_2.pdf,7,96.8,10.909099578857422,NimbusRomNo9L-Regu,False,460.9200134277344,341.940673828125,0.0,4,H3
sample_2.pdf,7,Table 6: Test set POS tagging accuracies for PTB. For,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,364.4764709472656,0.16981132075471697,53,H3
sample_2.pdf,7,"CoVe and the biLM, we report scores for both the ﬁrst",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,376.43145751953125,0.07547169811320754,53,H3
sample_2.pdf,7,and second layer biLSTMs.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,388.3864440917969,0.16,25,H3
sample_2.pdf,7,intrinsic evaluation of the contextual representa-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,425.1106262207031,0.0,50,H3
sample_2.pdf,7,tions similar to,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,438.6596374511719,0.0,16,H3
sample_2.pdf,7,Belinkov et al.,10.909099578857422,NimbusRomNo9L-Regu,False,373.94146728515625,438.6596374511719,0.06666666666666667,15,H3
sample_2.pdf,7,2017,10.909099578857422,NimbusRomNo9L-Regu,False,449.1159973144531,438.6596374511719,0.0,4,H3
sample_2.pdf,7,). To isolate,10.909099578857422,NimbusRomNo9L-Regu,False,470.9342346191406,438.6596374511719,0.07692307692307693,13,H3
sample_2.pdf,7,"the information encoded by the biLM, the repre-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,452.2096252441406,0.0425531914893617,47,H3
sample_2.pdf,7,sentations are used to directly make predictions for,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,465.7586364746094,0.0,52,H3
sample_2.pdf,7,a ﬁne grained word sense disambiguation (WSD),10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,479.3076477050781,0.06666666666666667,45,H3
sample_2.pdf,7,"task and a POS tagging task. Using this approach,",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,492.8566589355469,0.08163265306122448,49,H3
sample_2.pdf,7,"it is also possible to compare to CoVe, and across",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,506.4056701660156,0.04,50,H3
sample_2.pdf,7,each of the individual layers.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,519.9556884765625,0.0,30,H3
sample_2.pdf,7,Word sense disambiguation,10.909099578857422,NimbusRomNo9L-Medi,False,318.18499755859375,535.6051025390625,0.04,25,H3
sample_2.pdf,7,"Given a sentence,",10.909099578857422,NimbusRomNo9L-Regu,False,446.2905578613281,535.7047119140625,0.058823529411764705,17,H3
sample_2.pdf,7,we can use the biLM representations to predict,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,549.253662109375,0.043478260869565216,46,H3
sample_2.pdf,7,the sense of a target word using a simple 1-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,562.8037109375,0.0,44,H3
sample_2.pdf,7,"nearest neighbor approach, similar to",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,576.3526611328125,0.0,37,H3
sample_2.pdf,7,Melamud,10.909099578857422,NimbusRomNo9L-Regu,False,478.7887878417969,576.3526611328125,0.14285714285714285,7,H3
sample_2.pdf,7,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,589.9016723632812,0.0,6,H3
sample_2.pdf,7,2016,10.909099578857422,NimbusRomNo9L-Regu,False,338.60687255859375,589.9016723632812,0.0,4,H3
sample_2.pdf,7,"To do so, we ﬁrst use the biLM",10.909099578857422,NimbusRomNo9L-Regu,False,375.8069152832031,589.9016723632812,0.1,30,H3
sample_2.pdf,7,to compute representations for all words in Sem-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,603.45068359375,0.020833333333333332,48,H3
sample_2.pdf,7,"Cor 3.0, our training corpus (",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,616.9996948242188,0.03333333333333333,30,H3
sample_2.pdf,7,Miller et al.,10.909099578857422,NimbusRomNo9L-Regu,False,438.5670166015625,616.9996948242188,0.07692307692307693,13,H3
sample_2.pdf,7,1994,10.909099578857422,NimbusRomNo9L-Regu,False,493.9305419921875,616.9996948242188,0.0,4,H3
sample_2.pdf,7,and then take the average representation for each,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,630.5496826171875,0.0,49,H3
sample_2.pdf,7,"sense. At test time, we again use the biLM to com-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,644.0986938476562,0.06,50,H3
sample_2.pdf,7,pute representations for a given target word and,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,657.647705078125,0.0,48,H3
sample_2.pdf,7,take the nearest neighbor sense from the training,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,671.1966552734375,0.0,49,H3
sample_2.pdf,7,"set, falling back to the ﬁrst sense from WordNet",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,684.7456665039062,0.041666666666666664,48,H3
sample_2.pdf,7,for lemmas not observed during training.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,698.295654296875,0.0,40,H3
sample_2.pdf,7,Table,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,714.044677734375,0.2,5,H3
sample_2.pdf,7,compares WSD results using the eval-,10.909099578857422,NimbusRomNo9L-Regu,False,351.2068176269531,714.044677734375,0.08333333333333333,36,H3
sample_2.pdf,7,uation framework from,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.5936889648438,0.0,21,H3
sample_2.pdf,7,Raganato et al.,10.909099578857422,NimbusRomNo9L-Regu,False,412.61419677734375,727.5936889648438,0.06666666666666667,15,H3
sample_2.pdf,7,2017b,10.909099578857422,NimbusRomNo9L-Regu,False,494.6396484375,727.5936889648438,0.0,5,H3
sample_2.pdf,7,across the same suite of four test sets in,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,741.1436767578125,0.0,42,H3
sample_2.pdf,7,Raganato,10.909099578857422,NimbusRomNo9L-Regu,False,481.4832763671875,741.1436767578125,0.125,8,H3
sample_2.pdf,7,et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,754.6926879882812,0.0,6,H3
sample_2.pdf,7,2017a,10.909099578857422,NimbusRomNo9L-Regu,False,337.5487060546875,754.6926879882812,0.0,5,H3
sample_2.pdf,7,"). Overall, the biLM top layer rep-",10.909099578857422,NimbusRomNo9L-Regu,False,364.2105712890625,754.6926879882812,0.08571428571428572,35,H3
sample_2.pdf,8,resentations have F,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,65.49368286132812,0.05263157894736842,19,H3
sample_2.pdf,8,of 69.0 and are better at,10.909099578857422,NimbusRomNo9L-Regu,False,165.91812133789062,65.49368286132812,0.0,25,H3
sample_2.pdf,8,WSD then the ﬁrst layer. This is competitive with,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,79.04367065429688,0.08163265306122448,49,H3
sample_2.pdf,8,a state-of-the-art WSD-speciﬁc supervised model,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,92.59268188476562,0.06382978723404255,47,H3
sample_2.pdf,8,using hand crafted features (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,106.14169311523438,0.0,29,H3
sample_2.pdf,8,Iacobacci et al.,10.909099578857422,NimbusRomNo9L-Regu,False,194.73834228515625,106.14169311523438,0.0625,16,H3
sample_2.pdf,8,2016,10.909099578857422,NimbusRomNo9L-Regu,False,262.45111083984375,106.14169311523438,0.0,4,H3
sample_2.pdf,8,and a task speciﬁc biLSTM that is also trained,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,119.69070434570312,0.08695652173913043,46,H3
sample_2.pdf,8,with auxiliary coarse-grained semantic labels and,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,133.23971557617188,0.0,49,H3
sample_2.pdf,8,POS tags (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,146.78872680664062,0.3,10,H3
sample_2.pdf,8,Raganato et al.,10.909099578857422,NimbusRomNo9L-Regu,False,123.27278900146484,146.78872680664062,0.06666666666666667,15,H3
sample_2.pdf,8,2017a,10.909099578857422,NimbusRomNo9L-Regu,False,195.68740844726562,146.78872680664062,0.0,5,H3
sample_2.pdf,8,The CoVe,10.909099578857422,NimbusRomNo9L-Regu,False,244.03652954101562,146.78872680664062,0.375,8,H3
sample_2.pdf,8,biLSTM layers follow a similar pattern to those,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,160.33871459960938,0.0851063829787234,47,H3
sample_2.pdf,8,from the biLM (higher overall performance at the,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,173.88772583007812,0.041666666666666664,48,H3
sample_2.pdf,8,"second layer compared to the ﬁrst); however, our",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,187.43673706054688,0.0,48,H3
sample_2.pdf,8,"biLM outperforms the CoVe biLSTM, which trails",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,200.98574829101562,0.17391304347826086,46,H3
sample_2.pdf,8,the WordNet ﬁrst sense baseline.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,214.53475952148438,0.0625,32,H3
sample_2.pdf,8,POS tagging,10.909099578857422,NimbusRomNo9L-Medi,False,82.90901184082031,229.6661834716797,0.2727272727272727,11,H3
sample_2.pdf,8,To examine whether the biLM,10.909099578857422,NimbusRomNo9L-Regu,False,143.71632385253906,229.76577758789062,0.1111111111111111,27,H3
sample_2.pdf,8,"captures basic syntax, we used the context repre-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,243.31478881835938,0.0,49,H3
sample_2.pdf,8,sentations as input to a linear classiﬁer that pre-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,256.8638000488281,0.0,51,H3
sample_2.pdf,8,dicts POS tags with the Wall Street Journal portion,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,270.4128112792969,0.11764705882352941,51,H3
sample_2.pdf,8,of the Penn Treebank (PTB) (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,283.9627990722656,0.17857142857142858,28,H3
sample_2.pdf,8,Marcus et al.,10.909099578857422,NimbusRomNo9L-Regu,False,200.5856170654297,283.9627990722656,0.07692307692307693,13,H3
sample_2.pdf,8,1993,10.909099578857422,NimbusRomNo9L-Regu,False,259.5602111816406,283.9627990722656,0.0,4,H3
sample_2.pdf,8,As the linear classiﬁer adds only a small amount,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,297.5118103027344,0.020833333333333332,48,H3
sample_2.pdf,8,"of model capacity, this is direct test of the biLM’s",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,311.0608215332031,0.038461538461538464,52,H3
sample_2.pdf,8,"representations. Similar to WSD, the biLM rep-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,324.6098327636719,0.13043478260869565,46,H3
sample_2.pdf,8,"resentations are competitive with carefully tuned,",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,338.1588439941406,0.0,50,H3
sample_2.pdf,8,task speciﬁc biLSTMs (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,351.7088317871094,0.18181818181818182,22,H3
sample_2.pdf,8,Ling et al.,10.909099578857422,NimbusRomNo9L-Regu,False,177.72010803222656,351.7088317871094,0.09090909090909091,11,H3
sample_2.pdf,8,2015,10.909099578857422,NimbusRomNo9L-Regu,False,225.7637939453125,351.7088317871094,0.0,4,H3
sample_2.pdf,8,Ma and,10.909099578857422,NimbusRomNo9L-Regu,False,253.7346954345703,351.7088317871094,0.16666666666666666,6,H3
sample_2.pdf,8,Hovy,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,365.2578430175781,0.25,4,H3
sample_2.pdf,8,2016,10.909099578857422,NimbusRomNo9L-Regu,False,98.80367279052734,365.2578430175781,0.0,4,H3
sample_2.pdf,8,"). However, unlike WSD, accuracies",10.909099578857422,NimbusRomNo9L-Regu,False,124.4400634765625,365.2578430175781,0.11764705882352941,34,H3
sample_2.pdf,8,using the ﬁrst biLM layer are higher than the,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,378.8068542480469,0.044444444444444446,45,H3
sample_2.pdf,8,"top layer, consistent with results from deep biL-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,392.3558654785156,0.02040816326530612,49,H3
sample_2.pdf,8,STMs in multi-task training (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,405.9048767089844,0.10344827586206896,29,H3
sample_2.pdf,8,Søgaard and Gold-,10.909099578857422,NimbusRomNo9L-Regu,False,205.24374389648438,405.9048767089844,0.11764705882352941,17,H3
sample_2.pdf,8,berg,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,419.4548645019531,0.0,4,H3
sample_2.pdf,8,2016,10.909099578857422,NimbusRomNo9L-Regu,False,93.91638946533203,419.4548645019531,0.0,4,H3
sample_2.pdf,8,Hashimoto et al.,10.909099578857422,NimbusRomNo9L-Regu,False,121.9527816772461,419.4548645019531,0.0625,16,H3
sample_2.pdf,8,2017,10.909099578857422,NimbusRomNo9L-Regu,False,200.58555603027344,419.4548645019531,0.0,4,H3
sample_2.pdf,8,) and MT (,10.909099578857422,NimbusRomNo9L-Regu,False,225.5891876220703,419.4548645019531,0.2,10,H3
sample_2.pdf,8,Be-,10.909099578857422,NimbusRomNo9L-Regu,False,274.5164794921875,419.4548645019531,0.3333333333333333,3,H3
sample_2.pdf,8,linkov et al.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,433.0038757324219,0.0,13,H3
sample_2.pdf,8,2017,10.909099578857422,NimbusRomNo9L-Regu,False,126.00006103515625,433.0038757324219,0.0,4,H3
sample_2.pdf,8,). CoVe POS tagging accuracies,10.909099578857422,NimbusRomNo9L-Regu,False,150.4036865234375,433.0038757324219,0.16666666666666666,30,H3
sample_2.pdf,8,"follow the same pattern as those from the biLM,",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,446.5528869628906,0.0425531914893617,47,H3
sample_2.pdf,8,"and just like for WSD, the biLM achieves higher",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,460.1018981933594,0.10638297872340426,47,H3
sample_2.pdf,8,accuracies than the CoVe encoder.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,473.6509094238281,0.06060606060606061,33,H3
sample_2.pdf,8,Implications for supervised tasks,10.909099578857422,NimbusRomNo9L-Medi,False,82.90901184082031,488.78228759765625,0.030303030303030304,33,H3
sample_2.pdf,8,Taken to-,10.909099578857422,NimbusRomNo9L-Regu,False,242.31277465820312,488.88189697265625,0.1111111111111111,9,H3
sample_2.pdf,8,"gether, these experiments conﬁrm different layers",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,502.430908203125,0.0,49,H3
sample_2.pdf,8,in the biLM represent different types of informa-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,515.97998046875,0.04081632653061224,49,H3
sample_2.pdf,8,tion and explain why including all biLM layers is,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,529.5289306640625,0.04081632653061224,49,H3
sample_2.pdf,8,important for the highest performance in down-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,543.0789794921875,0.0,46,H3
sample_2.pdf,8,"stream tasks. In addition, the biLM’s representa-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,556.6279296875,0.061224489795918366,49,H3
sample_2.pdf,8,tions are more transferable to WSD and POS tag-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,570.177001953125,0.1276595744680851,47,H3
sample_2.pdf,8,"ging than those in CoVe, helping to illustrate why",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,583.7259521484375,0.04,50,H3
sample_2.pdf,8,ELMo outperforms CoVe in downstream tasks.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,597.2749633789062,0.11904761904761904,42,H3
sample_2.pdf,8,5.4,10.909099578857422,NimbusRomNo9L-Medi,False,72.00001525878906,625.3843383789062,0.0,3,H3
sample_2.pdf,8,Sample efﬁciency,10.909099578857422,NimbusRomNo9L-Medi,False,96.54549407958984,625.3843383789062,0.0625,16,H3
sample_2.pdf,8,Adding ELMo to a model increases the sample ef-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,646.2989501953125,0.0851063829787234,47,H3
sample_2.pdf,8,"ﬁciency considerably, both in terms of number of",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,659.8479614257812,0.0,48,H3
sample_2.pdf,8,parameter updates to reach state-of-the-art perfor-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,673.39697265625,0.0,51,H3
sample_2.pdf,8,mance and the overall training set size. For ex-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,686.9469604492188,0.020833333333333332,48,H3
sample_2.pdf,8,"ample, the SRL model reaches a maximum devel-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,700.4959716796875,0.06666666666666667,45,H3
sample_2.pdf,8,opment F,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,714.044921875,0.125,8,H3
sample_2.pdf,8,after 486 epochs of training without,10.909099578857422,NimbusRomNo9L-Regu,False,119.55814361572266,714.044921875,0.0,36,H3
sample_2.pdf,8,"ELMo. After adding ELMo, the model exceeds",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,727.5939331054688,0.16666666666666666,42,H3
sample_2.pdf,8,"the baseline maximum at epoch 10, a 98% relative",10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,741.1429443359375,0.0,48,H3
sample_2.pdf,8,decrease in the number of updates needed to reach,10.909099578857422,NimbusRomNo9L-Regu,False,72.00001525878906,754.6929321289062,0.0,49,H3
sample_2.pdf,8,Figure 1: Comparison of baseline vs. ELMo perfor-,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,204.12147521972656,0.10204081632653061,49,H3
sample_2.pdf,8,mance for SNLI and SRL as the training set size is var-,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,216.0774688720703,0.12727272727272726,55,H3
sample_2.pdf,8,ied from 0.1% to 100%.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,228.03248596191406,0.0,22,H3
sample_2.pdf,8,Figure 2: Visualization of softmax normalized biLM,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,361.2724609375,0.08,50,H3
sample_2.pdf,8,layer weights across tasks and ELMo locations. Nor-,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,373.2274475097656,0.0784313725490196,51,H3
sample_2.pdf,8,malized weights less then,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,385.18243408203125,0.0,25,H3
sample_2.pdf,8,are hatched with hori-,9.962599754333496,NimbusRomNo9L-Regu,False,431.08428955078125,385.18243408203125,0.0,22,H3
sample_2.pdf,8,zontal lines and those greater then,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,397.1374206542969,0.0,35,H3
sample_2.pdf,8,are speckled.,9.962599754333496,NimbusRomNo9L-Regu,False,460.55926513671875,397.1374206542969,0.0,13,H3
sample_2.pdf,8,the same level of performance.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,436.32861328125,0.0,30,H3
sample_2.pdf,8,"addition,",10.909099578857422,NimbusRomNo9L-Regu,False,336.937744140625,453.14361572265625,0.0,9,H3
sample_2.pdf,8,ELMo-enhanced,10.909099578857422,NimbusRomNo9L-Regu,False,386.8359375,453.14361572265625,0.23076923076923078,13,H3
sample_2.pdf,8,models,10.909099578857422,NimbusRomNo9L-Regu,False,469.810546875,453.14361572265625,0.0,6,H3
sample_2.pdf,8,use,10.909099578857422,NimbusRomNo9L-Regu,False,511.0032958984375,453.14361572265625,0.0,3,H3
sample_2.pdf,8,smaller training sets more efﬁciently than mod-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,466.693603515625,0.0,47,H3
sample_2.pdf,8,els without ELMo. Figure 1 compares the per-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,480.24261474609375,0.09090909090909091,44,H3
sample_2.pdf,8,formance of baselines models with and without,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,493.7916259765625,0.0,45,H3
sample_2.pdf,8,ELMo as the percentage of the full training set is,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,507.3406677246094,0.06,50,H3
sample_2.pdf,8,varied from 0.1% to 100%. Improvements with,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,520.8896484375,0.023255813953488372,43,H3
sample_2.pdf,8,ELMo are largest for smaller training sets and,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,534.439697265625,0.06521739130434782,46,H3
sample_2.pdf,8,signiﬁcantly reduce the amount of training data,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,547.9886474609375,0.0,47,H3
sample_2.pdf,8,needed to reach a given level of performance. In,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,561.5377197265625,0.020833333333333332,48,H3
sample_2.pdf,8,"the SRL case, the ELMo model with 1% of the",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,575.086669921875,0.13953488372093023,43,H3
sample_2.pdf,8,training set has about the same F,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,588.6356811523438,0.030303030303030304,33,H3
sample_2.pdf,8,as the baseline,10.909099578857422,NimbusRomNo9L-Regu,False,457.30511474609375,588.6356811523438,0.0,15,H3
sample_2.pdf,8,model with 10% of the training set.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,602.1856689453125,0.0,35,H3
sample_2.pdf,8,5.5,10.909099578857422,NimbusRomNo9L-Medi,False,307.2760009765625,635.7860717773438,0.0,3,H3
sample_2.pdf,8,Visualization of learned weights,10.909099578857422,NimbusRomNo9L-Medi,False,331.82147216796875,635.7860717773438,0.03125,32,H3
sample_2.pdf,8,Figure,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,659.8477172851562,0.16666666666666666,6,H3
sample_2.pdf,8,visualizes,10.909099578857422,NimbusRomNo9L-Regu,False,361.2651062011719,659.8477172851562,0.0,10,H3
sample_2.pdf,8,the,10.909099578857422,NimbusRomNo9L-Regu,False,414.3269348144531,659.8477172851562,0.0,3,H3
sample_2.pdf,8,softmax-normalized,10.909099578857422,NimbusRomNo9L-Regu,False,437.68328857421875,659.8477172851562,0.0,18,H3
sample_2.pdf,8,learned layer weights.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,673.397705078125,0.0,22,H3
sample_2.pdf,8,"At the input layer, the",10.909099578857422,NimbusRomNo9L-Regu,False,419.5850830078125,673.397705078125,0.043478260869565216,23,H3
sample_2.pdf,8,task model favors the ﬁrst biLSTM layer.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,686.9467163085938,0.1,40,H3
sample_2.pdf,8,For,10.909099578857422,NimbusRomNo9L-Regu,False,510.55615234375,686.9467163085938,0.3333333333333333,3,H3
sample_2.pdf,8,"coreference and SQuAD, the this is strongly",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,700.4957275390625,0.09302325581395349,43,H3
sample_2.pdf,8,"favored, but the distribution is less peaked for",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,714.044677734375,0.0,48,H3
sample_2.pdf,8,the other tasks.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.5936889648438,0.0,16,H3
sample_2.pdf,8,The output layer weights are,10.909099578857422,NimbusRomNo9L-Regu,False,389.9123840332031,727.5936889648438,0.03571428571428571,28,H3
sample_2.pdf,8,"relatively balanced, with a slight preference for",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,741.1436767578125,0.0,49,H3
sample_2.pdf,8,the lower layers.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,754.6926879882812,0.0,17,H3
sample_2.pdf,9,Conclusion,11.9552001953125,NimbusRomNo9L-Medi,False,89.93280029296875,64.59117889404297,0.1,10,H3
sample_2.pdf,9,We have introduced a general approach for learn-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,87.36166381835938,0.020833333333333332,48,H3
sample_2.pdf,9,ing high-quality deep context-dependent represen-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,100.91067504882812,0.0,49,H3
sample_2.pdf,9,"tations from biLMs, and shown large improve-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,114.45968627929688,0.045454545454545456,44,H3
sample_2.pdf,9,ments when applying ELMo to a broad range of,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,128.00869750976562,0.06818181818181818,44,H3
sample_2.pdf,9,NLP tasks. Through ablations and other controlled,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,141.55770874023438,0.08163265306122448,49,H3
sample_2.pdf,9,"experiments, we have also conﬁrmed that the",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,155.10769653320312,0.0,43,H3
sample_2.pdf,9,biLM layers efﬁciently encode different types of,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,168.65670776367188,0.041666666666666664,48,H3
sample_2.pdf,9,syntactic and semantic information about words-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,182.20571899414062,0.0,47,H3
sample_2.pdf,9,"in-context, and that using all layers improves over-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,195.75473022460938,0.0,52,H3
sample_2.pdf,9,all task performance.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,209.30374145507812,0.0,21,H3
sample_2.pdf,9,References,11.9552001953125,NimbusRomNo9L-Medi,False,72.0,246.11627197265625,0.1,10,H3
sample_2.pdf,9,"Jimmy Ba, Ryan Kiros, and Geoffrey E. Hinton. 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,266.3255615234375,0.13725490196078433,51,H3
sample_2.pdf,9,Layer normalization.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,277.2845458984375,0.05,20,H3
sample_2.pdf,9,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,166.46533203125,277.10809326171875,0.75,4,H3
sample_2.pdf,9,abs/1607.06450.,9.962599754333496,NimbusRomNo9L-Regu,False,193.85162353515625,277.2845458984375,0.0,15,H3
sample_2.pdf,9,"Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Has-",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,298.75054931640625,0.14,50,H3
sample_2.pdf,9,"san Sajjad, and James R. Glass. 2017. What do neu-",9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,309.70953369140625,0.1,50,H3
sample_2.pdf,9,ral machine translation models learn about morphol-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,320.66851806640625,0.0,51,H3
sample_2.pdf,9,ogy? In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,331.62750244140625,0.14285714285714285,7,H3
sample_2.pdf,9,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,114.75941467285156,331.4510498046875,1.0,3,H3
sample_2.pdf,9,"Piotr Bojanowski, Edouard Grave, Armand Joulin, and",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,353.093505859375,0.11764705882352941,51,H3
sample_2.pdf,9,Tomas Mikolov. 2017. Enriching word vectors with,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,364.052490234375,0.0625,48,H3
sample_2.pdf,9,subword information.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,375.011474609375,0.0,20,H3
sample_2.pdf,9,TACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,169.14523315429688,374.83502197265625,1.0,4,H3
sample_2.pdf,9,5:135–146.,9.962599754333496,NimbusRomNo9L-Regu,False,195.7445831298828,375.011474609375,0.0,10,H3
sample_2.pdf,9,"Samuel R. Bowman, Gabor Angeli, Christopher Potts,",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,396.47747802734375,0.14,50,H3
sample_2.pdf,9,and Christopher D. Manning. 2015.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,407.43646240234375,0.09090909090909091,33,H3
sample_2.pdf,9,A large an-,9.962599754333496,NimbusRomNo9L-Regu,False,241.90203857421875,407.43646240234375,0.09090909090909091,11,H3
sample_2.pdf,9,notated corpus for learning natural language infer-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,418.39544677734375,0.0,51,H3
sample_2.pdf,9,ence.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,429.35345458984375,0.0,5,H3
sample_2.pdf,9,Proceedings of the 2015 Conference on,9.962599754333496,NimbusRomNo9L-ReguItal,False,120.77681732177734,429.177001953125,0.05405405405405406,37,H3
sample_2.pdf,9,Empirical Methods in Natural Language Processing,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90898132324219,440.135986328125,0.10416666666666667,48,H3
sample_2.pdf,9,(EMNLP),9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90898132324219,451.094970703125,0.7142857142857143,7,H3
sample_2.pdf,9,. Association for Computational Linguis-,9.962599754333496,NimbusRomNo9L-Regu,False,122.20098114013672,451.27142333984375,0.075,40,H3
sample_2.pdf,9,tics.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,462.23040771484375,0.0,5,H3
sample_2.pdf,9,"Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge,",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,483.6964111328125,0.15384615384615385,52,H3
sample_2.pdf,9,"Thorsten Brants, Phillipp Koehn, and Tony Robin-",9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,494.6553955078125,0.125,48,H3
sample_2.pdf,9,son. 2014. One billion word benchmark for mea-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,505.6143798828125,0.021739130434782608,46,H3
sample_2.pdf,9,suring progress in statistical language modeling. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,516.5733642578125,0.019230769230769232,52,H3
sample_2.pdf,9,INTERSPEECH,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90898132324219,527.3558959960938,1.0,11,H3
sample_2.pdf,9,"Qian Chen, Xiao-Dan Zhu, Zhen-Hua Ling, Si Wei,",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,548.9983520507812,0.2127659574468085,47,H3
sample_2.pdf,9,"Hui Jiang, and Diana Inkpen. 2017. Enhanced lstm",9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,559.9573364257812,0.10416666666666667,48,H3
sample_2.pdf,9,for natural language inference. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,570.9163208007812,0.029411764705882353,34,H3
sample_2.pdf,9,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,217.06533813476562,570.7398681640625,1.0,3,H3
sample_2.pdf,9,Jason Chiu and Eric Nichols. 2016.,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,592.38232421875,0.11764705882352941,34,H3
sample_2.pdf,9,Named entity,9.962599754333496,NimbusRomNo9L-Regu,False,234.15122985839844,592.38232421875,0.08333333333333333,12,H3
sample_2.pdf,9,recognition with bidirectional LSTM-CNNs.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,603.34033203125,0.17073170731707318,41,H3
sample_2.pdf,9,TACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90898132324219,614.1228637695312,1.0,4,H3
sample_2.pdf,9,"Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bah-",9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,635.7653198242188,0.12244897959183673,49,H3
sample_2.pdf,9,"danau, and Yoshua Bengio. 2014. On the properties",9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,646.724365234375,0.061224489795918366,49,H3
sample_2.pdf,9,of neural machine translation: Encoder-decoder ap-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,657.683349609375,0.02,50,H3
sample_2.pdf,9,proaches. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,668.642333984375,0.08333333333333333,12,H3
sample_2.pdf,9,SSST@EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,132.69207763671875,668.4658813476562,0.9,10,H3
sample_2.pdf,9,Christopher Clark and Matthew Gardner. 2017. Sim-,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,690.1083374023438,0.10204081632653061,49,H3
sample_2.pdf,9,ple and effective multi-paragraph reading compre-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,701.0673217773438,0.0,49,H3
sample_2.pdf,9,hension.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,712.0263671875,0.0,8,H3
sample_2.pdf,9,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,116.39327239990234,711.8499145507812,0.75,4,H3
sample_2.pdf,9,abs/1710.10723.,9.962599754333496,NimbusRomNo9L-Regu,False,143.78062438964844,712.0263671875,0.0,15,H3
sample_2.pdf,9,Kevin Clark and Christopher D. Manning. 2016. Deep,9.962599754333496,NimbusRomNo9L-Regu,False,71.9999771118164,733.4923095703125,0.12,50,H3
sample_2.pdf,9,reinforcement learning for mention-ranking corefer-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,744.4513549804688,0.0,51,H3
sample_2.pdf,9,ence models. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,755.4103393554688,0.06666666666666667,15,H3
sample_2.pdf,9,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,146.80908203125,755.23388671875,1.0,5,H3
sample_2.pdf,9,"Ronan Collobert, Jason Weston, L´eon Bottou, Michael",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,66.16139221191406,0.1346153846153846,52,H3
sample_2.pdf,9,"Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa.",9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,77.17036437988281,0.13043478260869565,46,H3
sample_2.pdf,9,2011.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,88.12934875488281,0.0,5,H3
sample_2.pdf,9,Natural language processing (almost) from,9.962599754333496,NimbusRomNo9L-Regu,False,348.800048828125,88.12934875488281,0.024390243902439025,41,H3
sample_2.pdf,9,scratch. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,99.08833312988281,0.09090909090909091,11,H3
sample_2.pdf,9,JMLR,9.962599754333496,NimbusRomNo9L-ReguItal,False,360.7751159667969,98.911865234375,1.0,4,H3
sample_2.pdf,9,Andrew M. Dai and Quoc V. Le. 2015.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,120.19435119628906,0.17142857142857143,35,H3
sample_2.pdf,9,Semi-,9.962599754333496,NimbusRomNo9L-Regu,False,501.74591064453125,120.19435119628906,0.2,5,H3
sample_2.pdf,9,supervised sequence learning. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,131.15333557128906,0.03125,32,H3
sample_2.pdf,9,NIPS,9.962599754333496,NimbusRomNo9L-ReguItal,False,449.3127136230469,130.97686767578125,1.0,4,H3
sample_2.pdf,9,Greg Durrett and Dan Klein. 2013. Easy victories and,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,152.2603302001953,0.09615384615384616,52,H3
sample_2.pdf,9,uphill battles in coreference resolution. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,163.2183380126953,0.022727272727272728,44,H3
sample_2.pdf,9,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,485.8454895019531,163.0418701171875,1.0,5,H3
sample_2.pdf,9,Yarin Gal and Zoubin Ghahramani. 2016. A theoret-,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,184.32533264160156,0.10204081632653061,49,H3
sample_2.pdf,9,ically grounded application of dropout in recurrent,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,195.28431701660156,0.0,51,H3
sample_2.pdf,9,neural networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,206.24330139160156,0.05263157894736842,19,H3
sample_2.pdf,9,NIPS,9.962599754333496,NimbusRomNo9L-ReguItal,False,396.3714294433594,206.06683349609375,1.0,4,H3
sample_2.pdf,9,"Yichen Gong, Heng Luo, and Jian Zhang. 2018. Nat-",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,227.3493194580078,0.14285714285714285,49,H3
sample_2.pdf,9,ural language inference over interaction space. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,238.3083038330078,0.02,50,H3
sample_2.pdf,9,ICLR,9.962599754333496,NimbusRomNo9L-ReguItal,False,318.18499755859375,249.0908203125,1.0,4,H3
sample_2.pdf,9,"Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsu-",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,270.373291015625,0.1276595744680851,47,H3
sample_2.pdf,9,"ruoka, and Richard Socher. 2017. A joint many-task",9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,281.332275390625,0.06,50,H3
sample_2.pdf,9,model: Growing a neural network for multiple nlp,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,292.291259765625,0.020833333333333332,48,H3
sample_2.pdf,9,tasks. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,303.250244140625,0.1111111111111111,9,H3
sample_2.pdf,9,EMNLP 2017,9.962599754333496,NimbusRomNo9L-ReguItal,False,352.4862365722656,303.07379150390625,0.5,10,H3
sample_2.pdf,9,"Luheng He, Kenton Lee, Mike Lewis, and Luke S.",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760314941406,324.3562316894531,0.17391304347826086,46,H3
sample_2.pdf,9,Zettlemoyer. 2017.,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,335.31524658203125,0.05555555555555555,18,H3
sample_2.pdf,9,Deep semantic role labeling:,9.962599754333496,NimbusRomNo9L-Regu,False,405.41754150390625,335.31524658203125,0.03571428571428571,28,H3
sample_2.pdf,9,What works and what’s next. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,346.27423095703125,0.06666666666666667,30,H3
sample_2.pdf,9,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,445.7560729980469,346.0977783203125,1.0,3,H3
sample_2.pdf,9,Sepp Hochreiter and J¨urgen Schmidhuber. 1997. Long,9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,367.3312072753906,0.09803921568627451,51,H3
sample_2.pdf,9,short-term memory.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,378.3392333984375,0.0,18,H3
sample_2.pdf,9,Neural Computation,9.962599754333496,NimbusRomNo9L-ReguItal,False,397.2283020019531,378.16278076171875,0.1111111111111111,18,H3
sample_2.pdf,9,"Ignacio Iacobacci, Mohammad Taher Pilehvar, and",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,399.44622802734375,0.10638297872340426,47,H3
sample_2.pdf,9,Roberto Navigli. 2016. Embeddings for word sense,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,410.40521240234375,0.0625,48,H3
sample_2.pdf,9,disambiguation: An evaluation study. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,421.36419677734375,0.05128205128205128,39,H3
sample_2.pdf,9,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,478.9613952636719,421.187744140625,1.0,3,H3
sample_2.pdf,9,"Rafal J´ozefowicz, Oriol Vinyals, Mike Schuster, Noam",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,442.4201965332031,0.1320754716981132,53,H3
sample_2.pdf,9,"Shazeer, and Yonghui Wu. 2016. Exploring the lim-",9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,453.42919921875,0.08163265306122448,49,H3
sample_2.pdf,9,its of language modeling.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,464.38818359375,0.0,25,H3
sample_2.pdf,9,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,419.4648132324219,464.21173095703125,0.75,4,H3
sample_2.pdf,9,abs/1602.02410.,9.962599754333496,NimbusRomNo9L-Regu,False,446.8517150878906,464.38818359375,0.0,15,H3
sample_2.pdf,9,Rafal,9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,485.4941711425781,0.2,5,H3
sample_2.pdf,9,"J´ozefowicz,",9.962599754333496,NimbusRomNo9L-Regu,False,337.0841369628906,485.4441833496094,0.08333333333333333,12,H3
sample_2.pdf,9,Wojciech,9.962599754333496,NimbusRomNo9L-Regu,False,393.9332275390625,485.4941711425781,0.125,8,H3
sample_2.pdf,9,"Zaremba,",9.962599754333496,NimbusRomNo9L-Regu,False,439.6416320800781,485.4941711425781,0.125,8,H3
sample_2.pdf,9,and,9.962599754333496,NimbusRomNo9L-Regu,False,487.3326416015625,485.4941711425781,0.0,3,H3
sample_2.pdf,9,Ilya,9.962599754333496,NimbusRomNo9L-Regu,False,510.04736328125,485.4941711425781,0.25,4,H3
sample_2.pdf,9,Sutskever. 2015. An empirical exploration of recur-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,496.45318603515625,0.0392156862745098,51,H3
sample_2.pdf,9,rent network architectures. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,507.41217041015625,0.03333333333333333,30,H3
sample_2.pdf,9,ICML,9.962599754333496,NimbusRomNo9L-ReguItal,False,436.48089599609375,507.2357177734375,1.0,4,H3
sample_2.pdf,9,"Yoon Kim, Yacine Jernite, David Sontag, and Alexan-",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,528.5181884765625,0.13725490196078433,51,H3
sample_2.pdf,9,der M Rush. 2015. Character-aware neural language,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,539.4771728515625,0.061224489795918366,49,H3
sample_2.pdf,9,models. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,550.4361572265625,0.1,10,H3
sample_2.pdf,9,AAAI 2016,9.962599754333496,NimbusRomNo9L-ReguItal,False,361.3430480957031,550.2597045898438,0.4444444444444444,9,H3
sample_2.pdf,9,Diederik P. Kingma and Jimmy Ba. 2015. Adam: A,9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,571.5421142578125,0.15217391304347827,46,H3
sample_2.pdf,9,method for stochastic optimization. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,582.5011596679688,0.02631578947368421,38,H3
sample_2.pdf,9,ICLR,9.962599754333496,NimbusRomNo9L-ReguItal,False,471.2005615234375,582.32470703125,1.0,4,H3
sample_2.pdf,9,"Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,603.608154296875,0.15217391304347827,46,H3
sample_2.pdf,9,"Iyyer, Ishaan Gulrajani James Bradbury, Victor",9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,614.567138671875,0.13043478260869565,46,H3
sample_2.pdf,9,"Zhong, Romain Paulus, and Richard Socher. 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,625.526123046875,0.10638297872340426,47,H3
sample_2.pdf,9,Ask me anything: Dynamic memory networks for,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,636.484130859375,0.045454545454545456,44,H3
sample_2.pdf,9,natural language processing. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,647.443115234375,0.03225806451612903,31,H3
sample_2.pdf,9,ICML,9.962599754333496,NimbusRomNo9L-ReguItal,False,443.78350830078125,647.2666625976562,1.0,4,H3
sample_2.pdf,9,"John D. Lafferty, Andrew McCallum, and Fernando",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,668.5501098632812,0.14893617021276595,47,H3
sample_2.pdf,9,Pereira. 2001.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,679.5091552734375,0.07142857142857142,14,H3
sample_2.pdf,9,Conditional random ﬁelds: Prob-,9.962599754333496,NimbusRomNo9L-Regu,False,385.6318359375,679.5091552734375,0.06451612903225806,31,H3
sample_2.pdf,9,abilistic models for segmenting and labeling se-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,690.4681396484375,0.0,48,H3
sample_2.pdf,9,quence data. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,701.4261474609375,0.06666666666666667,15,H3
sample_2.pdf,9,ICML,9.962599754333496,NimbusRomNo9L-ReguItal,False,379.863525390625,701.2496948242188,1.0,4,H3
sample_2.pdf,9,"Guillaume Lample, Miguel Ballesteros, Sandeep Sub-",9.962599754333496,NimbusRomNo9L-Regu,False,307.27606201171875,722.5331420898438,0.12,50,H3
sample_2.pdf,9,"ramanian, Kazuya Kawakami, and Chris Dyer. 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,733.4921264648438,0.08333333333333333,48,H3
sample_2.pdf,9,Neural architectures for named entity recognition.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18505859375,744.4511108398438,0.02,50,H3
sample_2.pdf,9,NAACL-HLT,9.962599754333496,NimbusRomNo9L-ReguItal,False,326.48388671875,755.233642578125,0.8888888888888888,9,H3
sample_2.pdf,10,"Kenton Lee, Luheng He, Mike Lewis, and Luke S.",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,66.21150207519531,0.17391304347826086,46,H3
sample_2.pdf,10,Zettlemoyer. 2017. End-to-end neural coreference,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,77.17048645019531,0.041666666666666664,48,H3
sample_2.pdf,10,resolution. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,88.12947082519531,0.07142857142857142,14,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,137.13540649414062,87.9530029296875,1.0,5,H3
sample_2.pdf,10,"Wang Ling, Chris Dyer, Alan W. Black, Isabel Tran-",9.962599754333496,NimbusRomNo9L-Regu,False,71.99999237060547,108.39546203613281,0.18,50,H3
sample_2.pdf,10,"coso, Ramon Fermandez, Silvio Amir, Lu´ıs Marujo,",9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,119.30445861816406,0.12244897959183673,49,H3
sample_2.pdf,10,and Tiago Lu´ıs. 2015.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,130.26344299316406,0.09090909090909091,22,H3
sample_2.pdf,10,Finding function in form:,9.962599754333496,NimbusRomNo9L-Regu,False,183.8662872314453,130.3134307861328,0.04,25,H3
sample_2.pdf,10,Compositional character models for open vocabu-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,141.2724151611328,0.02127659574468085,47,H3
sample_2.pdf,10,lary word representation. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,152.2304229736328,0.03571428571428571,28,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,194.56980895996094,152.053955078125,1.0,5,H3
sample_2.pdf,10,"Xiaodong Liu, Yelong Shen, Kevin Duh, and Jian-",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,172.4964141845703,0.14893617021276595,47,H3
sample_2.pdf,10,feng Gao. 2017.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,183.4553985595703,0.06666666666666667,15,H3
sample_2.pdf,10,Stochastic answer networks for,9.962599754333496,NimbusRomNo9L-Regu,False,160.1390380859375,183.4553985595703,0.03333333333333333,30,H3
sample_2.pdf,10,machine reading comprehension.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,194.4143829345703,0.0,30,H3
sample_2.pdf,10,arXiv preprint,9.962599754333496,NimbusRomNo9L-ReguItal,False,230.9510040283203,194.2379150390625,0.07142857142857142,14,H3
sample_2.pdf,10,arXiv:1712.03556,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90899658203125,205.1968994140625,0.0625,16,H3
sample_2.pdf,10,Xuezhe Ma and Eduard H. Hovy. 2016. End-to-end,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,225.6383819580078,0.13043478260869565,46,H3
sample_2.pdf,10,sequence labeling via bi-directional LSTM-CNNs-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,236.5973663330078,0.14893617021276595,47,H3
sample_2.pdf,10,CRF. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,247.5563507080078,0.5714285714285714,7,H3
sample_2.pdf,10,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,116.11432647705078,247.3798828125,1.0,3,H3
sample_2.pdf,10,"Mitchell P. Marcus, Beatrice Santorini, and Mary Ann",9.962599754333496,NimbusRomNo9L-Regu,False,71.9999771118164,267.82232666015625,0.1346153846153846,52,H3
sample_2.pdf,10,Marcinkiewicz. 1993.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,278.78131103515625,0.05,20,H3
sample_2.pdf,10,Building a large annotated,9.962599754333496,NimbusRomNo9L-Regu,False,180.18377685546875,278.78131103515625,0.038461538461538464,26,H3
sample_2.pdf,10,corpus of english: The penn treebank.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,289.74029541015625,0.02702702702702703,37,H3
sample_2.pdf,10,Computa-,9.962599754333496,NimbusRomNo9L-ReguItal,False,250.41697692871094,289.5638427734375,0.125,8,H3
sample_2.pdf,10,tional Linguistics,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.90898132324219,300.5228271484375,0.05555555555555555,18,H3
sample_2.pdf,10,19:313–330.,9.962599754333496,NimbusRomNo9L-Regu,False,152.38816833496094,300.69927978515625,0.0,11,H3
sample_2.pdf,10,"Bryan McCann, James Bradbury, Caiming Xiong, and",9.962599754333496,NimbusRomNo9L-Regu,False,71.99999237060547,320.96429443359375,0.14583333333333334,48,H3
sample_2.pdf,10,Richard Socher. 2017. Learned in translation: Con-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,331.92327880859375,0.08,50,H3
sample_2.pdf,10,textualized word vectors. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,342.88226318359375,0.03571428571428571,28,H3
sample_2.pdf,10,NIPS 2017,9.962599754333496,NimbusRomNo9L-ReguItal,False,194.8288116455078,342.705810546875,0.4444444444444444,9,H3
sample_2.pdf,10,"Oren Melamud, Jacob Goldberger, and Ido Dagan.",9.962599754333496,NimbusRomNo9L-Regu,False,72.00001525878906,363.14825439453125,0.13043478260869565,46,H3
sample_2.pdf,10,2016. context2vec: Learning generic context em-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90901184082031,374.10723876953125,0.02127659574468085,47,H3
sample_2.pdf,10,bedding with bidirectional lstm. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90901184082031,385.06524658203125,0.02857142857142857,35,H3
sample_2.pdf,10,CoNLL,9.962599754333496,NimbusRomNo9L-ReguItal,False,222.09649658203125,384.8887939453125,0.8,5,H3
sample_2.pdf,10,"G´abor Melis, Chris Dyer, and Phil Blunsom. 2017. On",9.962599754333496,NimbusRomNo9L-Regu,False,72.00001525878906,405.28125,0.1346153846153846,52,H3
sample_2.pdf,10,the state of the art of evaluation in neural language,9.962599754333496,NimbusRomNo9L-Regu,False,82.90901947021484,416.29022216796875,0.0,53,H3
sample_2.pdf,10,models.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90901947021484,427.24920654296875,0.0,7,H3
sample_2.pdf,10,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,114.18161010742188,427.07275390625,0.75,4,H3
sample_2.pdf,10,abs/1707.05589.,9.962599754333496,NimbusRomNo9L-Regu,False,141.56866455078125,427.24920654296875,0.0,15,H3
sample_2.pdf,10,"Stephen Merity, Nitish Shirish Keskar, and Richard",9.962599754333496,NimbusRomNo9L-Regu,False,72.0000228881836,447.51519775390625,0.12,50,H3
sample_2.pdf,10,Socher. 2017. Regularizing and optimizing lstm lan-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,458.47320556640625,0.0392156862745098,51,H3
sample_2.pdf,10,guage models.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,469.43218994140625,0.0,13,H3
sample_2.pdf,10,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,140.4629669189453,469.2557373046875,0.75,4,H3
sample_2.pdf,10,abs/1708.02182.,9.962599754333496,NimbusRomNo9L-Regu,False,167.8496551513672,469.43218994140625,0.0,15,H3
sample_2.pdf,10,"Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-",9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,489.69818115234375,0.17307692307692307,52,H3
sample_2.pdf,10,"rado, and Jeff Dean. 2013. Distributed representa-",9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,500.65716552734375,0.06,50,H3
sample_2.pdf,10,tions of words and phrases and their compositional-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,511.61614990234375,0.0,51,H3
sample_2.pdf,10,ity. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,522.5751342773438,0.14285714285714285,7,H3
sample_2.pdf,10,NIPS,9.962599754333496,NimbusRomNo9L-ReguItal,False,107.1579818725586,522.398681640625,1.0,4,H3
sample_2.pdf,10,"George A. Miller, Martin Chodorow, Shari Landes,",9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,542.8401489257812,0.14583333333333334,48,H3
sample_2.pdf,10,"Claudia Leacock, and Robert G. Thomas. 1994. Us-",9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,553.7991333007812,0.125,48,H3
sample_2.pdf,10,ing a semantic concordance for sense identiﬁcation.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,564.7581176757812,0.0,51,H3
sample_2.pdf,10,HLT,9.962599754333496,NimbusRomNo9L-ReguItal,False,91.20787048339844,575.5406494140625,1.0,3,H3
sample_2.pdf,10,Tsendsuren Munkhdalai and Hong Yu. 2017. Neural,9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,595.9830932617188,0.10638297872340426,47,H3
sample_2.pdf,10,tree indexers for text understanding. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,606.942138671875,0.025,40,H3
sample_2.pdf,10,EACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,238.4949188232422,606.7656860351562,1.0,4,H3
sample_2.pdf,10,"Arvind Neelakantan, Jeevan Shankar, Alexandre Pas-",9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,627.2070922851562,0.12,50,H3
sample_2.pdf,10,"sos, and Andrew McCallum. 2014. Efﬁcient non-",9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,638.1661376953125,0.08888888888888889,45,H3
sample_2.pdf,10,parametric estimation of multiple embeddings per,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,649.1251220703125,0.0,48,H3
sample_2.pdf,10,word in vector space. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,660.0841064453125,0.041666666666666664,24,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,179.75546264648438,659.9076538085938,1.0,5,H3
sample_2.pdf,10,"Martha Palmer, Paul Kingsbury, and Daniel Gildea.",9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,680.35009765625,0.12244897959183673,49,H3
sample_2.pdf,10,2005. The proposition bank: An annotated corpus of,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,691.30810546875,0.04,50,H3
sample_2.pdf,10,semantic roles.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,702.26708984375,0.0,15,H3
sample_2.pdf,10,Computational Linguistics,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.93991088867188,702.0906372070312,0.08,25,H3
sample_2.pdf,10,31:71–,9.962599754333496,NimbusRomNo9L-Regu,False,258.8412780761719,702.26708984375,0.0,6,H3
sample_2.pdf,10,106.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,713.22607421875,0.0,4,H3
sample_2.pdf,10,"Jeffrey Pennington, Richard Socher, and Christo-",9.962599754333496,NimbusRomNo9L-Regu,False,72.00003051757812,733.4921264648438,0.10416666666666667,48,H3
sample_2.pdf,10,pher D. Manning. 2014. Glove: Global vectors for,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,744.4511108398438,0.08333333333333333,48,H3
sample_2.pdf,10,word representation. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90902709960938,755.4100952148438,0.043478260869565216,23,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,176.58734130859375,755.233642578125,1.0,5,H3
sample_2.pdf,10,"Matthew E. Peters, Waleed Ammar, Chandra Bhaga-",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760314941406,66.21113586425781,0.14893617021276595,47,H3
sample_2.pdf,10,"vatula, and Russell Power. 2017. Semi-supervised",9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,77.17012023925781,0.0625,48,H3
sample_2.pdf,10,sequence tagging with bidirectional language mod-,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,88.12910461425781,0.0,49,H3
sample_2.pdf,10,els. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,99.08808898925781,0.14285714285714285,7,H3
sample_2.pdf,10,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,343.6295166015625,98.91162109375,1.0,3,H3
sample_2.pdf,10,"Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760314941406,120.06910705566406,0.12,50,H3
sample_2.pdf,10,"Hwee Tou Ng, Anders Bj¨orkelund, Olga Uryupina,",9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,130.9790802001953,0.14893617021276595,47,H3
sample_2.pdf,10,"Yuchen Zhang, and Zhi Zhong. 2013. Towards ro-",9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,141.98707580566406,0.10869565217391304,46,H3
sample_2.pdf,10,bust linguistic analysis using ontonotes. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,152.94606018066406,0.022727272727272728,44,H3
sample_2.pdf,10,CoNLL,9.962599754333496,NimbusRomNo9L-ReguItal,False,488.4557189941406,152.76959228515625,0.8,5,H3
sample_2.pdf,10,"Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760314941406,173.9280548095703,0.12,50,H3
sample_2.pdf,10,"Olga Uryupina, and Yuchen Zhang. 2012.",9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,184.8870391845703,0.10526315789473684,38,H3
sample_2.pdf,10,Conll-,9.962599754333496,NimbusRomNo9L-Regu,False,500.08209228515625,184.8870391845703,0.16666666666666666,6,H3
sample_2.pdf,10,2012 shared task:,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,195.8460235595703,0.0,17,H3
sample_2.pdf,10,Modeling multilingual unre-,9.962599754333496,NimbusRomNo9L-Regu,False,405.04888916015625,195.8460235595703,0.037037037037037035,27,H3
sample_2.pdf,10,stricted coreference in ontonotes.,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,206.8040313720703,0.0,34,H3
sample_2.pdf,10,EMNLP-,9.962599754333496,NimbusRomNo9L-ReguItal,False,483.6337890625,206.6275634765625,0.8333333333333334,6,H3
sample_2.pdf,10,CoNLL Shared Task,9.962599754333496,NimbusRomNo9L-ReguItal,False,318.1850280761719,217.5865478515625,0.35294117647058826,17,H3
sample_2.pdf,10,"Alessandro Raganato, Claudio Delli Bovi, and Roberto",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760314941406,238.74501037597656,0.11538461538461539,52,H3
sample_2.pdf,10,Navigli. 2017a. Neural sequence learning models,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,249.70399475097656,0.0425531914893617,47,H3
sample_2.pdf,10,for word sense disambiguation. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.1850280761719,260.6629638671875,0.030303030303030304,33,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,455.04119873046875,260.48651123046875,1.0,5,H3
sample_2.pdf,10,"Alessandro Raganato, Jose Camacho-Collados, and",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,281.64398193359375,0.10638297872340426,47,H3
sample_2.pdf,10,Roberto Navigli. 2017b. Word sense disambigua-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,292.60296630859375,0.06521739130434782,46,H3
sample_2.pdf,10,tion: A uniﬁed evaluation framework and empirical,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,303.56195068359375,0.02040816326530612,49,H3
sample_2.pdf,10,comparison. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,314.52093505859375,0.07142857142857142,14,H3
sample_2.pdf,10,EACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,379.0465087890625,314.344482421875,1.0,4,H3
sample_2.pdf,10,"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and",9.962599754333496,NimbusRomNo9L-Regu,False,307.2759704589844,335.5019226074219,0.11320754716981132,53,H3
sample_2.pdf,10,"Percy Liang. 2016. Squad: 100, 000+ questions for",9.962599754333496,NimbusRomNo9L-Regu,False,318.1849670410156,346.4609375,0.061224489795918366,49,H3
sample_2.pdf,10,machine comprehension of text. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.1849670410156,357.419921875,0.030303030303030304,33,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,457.7510070800781,357.24346923828125,1.0,5,H3
sample_2.pdf,10,"Prajit Ramachandran, Peter Liu, and Quoc Le. 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,378.40191650390625,0.12,50,H3
sample_2.pdf,10,Improving sequence to sequence learning with unla-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,389.36090087890625,0.02,50,H3
sample_2.pdf,10,beled data. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,400.31988525390625,0.07142857142857142,14,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,373.2283630371094,400.1434326171875,1.0,5,H3
sample_2.pdf,10,Erik F. Tjong Kim Sang and Fien De Meulder.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,421.3008728027344,0.18604651162790697,43,H3
sample_2.pdf,10,2003. Introduction to the CoNLL-2003 shared task:,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,432.2598876953125,0.10204081632653061,49,H3
sample_2.pdf,10,Language-independent named entity recognition. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,443.2188720703125,0.04081632653061224,49,H3
sample_2.pdf,10,CoNLL,9.962599754333496,NimbusRomNo9L-ReguItal,False,318.18499755859375,454.00140380859375,0.8,5,H3
sample_2.pdf,10,"Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,475.1588439941406,0.14,50,H3
sample_2.pdf,10,Hannaneh Hajishirzi. 2017. Bidirectional attention,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,486.11785888671875,0.06,50,H3
sample_2.pdf,10,ﬂow for machine comprehension. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,497.07684326171875,0.030303030303030304,33,H3
sample_2.pdf,10,ICLR,9.962599754333496,NimbusRomNo9L-ReguItal,False,463.73858642578125,496.900390625,1.0,4,H3
sample_2.pdf,10,"Richard Socher, Alex Perelygin, Jean Y Wu, Jason",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,518.058837890625,0.16666666666666666,48,H3
sample_2.pdf,10,"Chuang, Christopher D Manning, Andrew Y Ng,",9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,529.017822265625,0.16279069767441862,43,H3
sample_2.pdf,10,and Christopher Potts. 2013. Recursive deep mod-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,539.976806640625,0.0625,48,H3
sample_2.pdf,10,els for semantic compositionality over a sentiment,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,550.934814453125,0.0,50,H3
sample_2.pdf,10,treebank. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,561.893798828125,0.08333333333333333,12,H3
sample_2.pdf,10,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,366.86224365234375,561.7173461914062,1.0,5,H3
sample_2.pdf,10,Anders Søgaard and Yoav Goldberg. 2016.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,582.8757934570312,0.10256410256410256,39,H3
sample_2.pdf,10,Deep,9.962599754333496,NimbusRomNo9L-Regu,False,504.525390625,582.8757934570312,0.25,4,H3
sample_2.pdf,10,multi-task learning with low level tasks supervised,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,593.8347778320312,0.0,51,H3
sample_2.pdf,10,at lower layers. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,604.7938232421875,0.05263157894736842,19,H3
sample_2.pdf,10,ACL 2016,9.962599754333496,NimbusRomNo9L-ReguItal,False,390.9617919921875,604.6173706054688,0.375,8,H3
sample_2.pdf,10,Nitish,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,625.7747802734375,0.16666666666666666,6,H3
sample_2.pdf,10,"Srivastava,",9.962599754333496,NimbusRomNo9L-Regu,False,342.2845458984375,625.7747802734375,0.09090909090909091,11,H3
sample_2.pdf,10,Geoffrey,9.962599754333496,NimbusRomNo9L-Regu,False,398.02532958984375,625.7747802734375,0.125,8,H3
sample_2.pdf,10,"Hinton,",9.962599754333496,NimbusRomNo9L-Regu,False,463.4696350097656,625.7747802734375,0.14285714285714285,7,H3
sample_2.pdf,10,Alex,9.962599754333496,NimbusRomNo9L-Regu,False,506.3287048339844,625.7747802734375,0.25,4,H3
sample_2.pdf,10,"Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-",9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,636.7337646484375,0.1,50,H3
sample_2.pdf,10,nov. 2014. Dropout: a simple way to prevent neural,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,647.6928100585938,0.02,50,H3
sample_2.pdf,10,networks from overﬁtting.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,658.6517944335938,0.0,25,H3
sample_2.pdf,10,Journal of Machine,9.962599754333496,NimbusRomNo9L-ReguItal,False,441.4939880371094,658.475341796875,0.1111111111111111,18,H3
sample_2.pdf,10,Learning Research,9.962599754333496,NimbusRomNo9L-ReguItal,False,318.18499755859375,669.434326171875,0.11764705882352941,17,H3
sample_2.pdf,10,15:1929–1958.,9.962599754333496,NimbusRomNo9L-Regu,False,393.76129150390625,669.6107788085938,0.0,13,H3
sample_2.pdf,10,"Rupesh Kumar Srivastava, Klaus Greff, and J¨urgen",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,690.5427856445312,0.12244897959183673,49,H3
sample_2.pdf,10,Schmidhuber. 2015. Training very deep networks.,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,701.55078125,0.0425531914893617,47,H3
sample_2.pdf,10,NIPS,9.962599754333496,NimbusRomNo9L-ReguItal,False,326.48382568359375,712.3333129882812,1.0,4,H3
sample_2.pdf,10,"Joseph P. Turian, Lev-Arie Ratinov, and Yoshua Ben-",9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,733.4918212890625,0.1568627450980392,51,H3
sample_2.pdf,10,gio. 2010. Word representations: A simple and gen-,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,744.4508056640625,0.04,50,H3
sample_2.pdf,10,eral method for semi-supervised learning. In,9.962599754333496,NimbusRomNo9L-Regu,False,318.18499755859375,755.4097900390625,0.022727272727272728,44,H3
sample_2.pdf,10,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,496.3560791015625,755.2333374023438,1.0,3,H3
sample_2.pdf,11,"Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang,",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,66.21150207519531,0.17391304347826086,46,H3
sample_2.pdf,11,and Ming Zhou. 2017.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,77.17048645019531,0.1,20,H3
sample_2.pdf,11,Gated self-matching net-,9.962599754333496,NimbusRomNo9L-Regu,False,187.47637939453125,77.17048645019531,0.041666666666666664,24,H3
sample_2.pdf,11,works for reading comprehension and question an-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,88.12947082519531,0.0,48,H3
sample_2.pdf,11,swering. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,99.08845520019531,0.09090909090909091,11,H3
sample_2.pdf,11,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,128.82659912109375,98.9119873046875,1.0,3,H3
sample_2.pdf,11,"John Wieting, Mohit Bansal, Kevin Gimpel, and Karen",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,119.01344299316406,0.13725490196078433,51,H3
sample_2.pdf,11,Livescu. 2016. Charagram: Embedding words and,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,129.97242736816406,0.06666666666666667,45,H3
sample_2.pdf,11,sentences via character n-grams. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,140.93141174316406,0.02857142857142857,35,H3
sample_2.pdf,11,EMNLP,9.962599754333496,NimbusRomNo9L-ReguItal,False,224.25839233398438,140.75494384765625,1.0,5,H3
sample_2.pdf,11,"Sam Wiseman, Alexander M. Rush, and Stuart M.",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,160.8563995361328,0.15555555555555556,45,H3
sample_2.pdf,11,Shieber. 2016. Learning global features for coref-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,171.8153839111328,0.04,50,H3
sample_2.pdf,11,erence resolution. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90899658203125,182.7743682861328,0.047619047619047616,21,H3
sample_2.pdf,11,HLT-NAACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,165.61846923828125,182.597900390625,0.8888888888888888,9,H3
sample_2.pdf,11,Matthew D. Zeiler. 2012. Adadelta: An adaptive learn-,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,202.69935607910156,0.09433962264150944,53,H3
sample_2.pdf,11,ing rate method.,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,213.65834045410156,0.0,16,H3
sample_2.pdf,11,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,147.93482971191406,213.48187255859375,0.75,4,H3
sample_2.pdf,11,abs/1212.5701.,9.962599754333496,NimbusRomNo9L-Regu,False,175.3216094970703,213.65834045410156,0.0,14,H3
sample_2.pdf,11,Jie Zhou and Wei Xu. 2015. End-to-end learning of,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,233.58436584472656,0.10204081632653061,49,H3
sample_2.pdf,11,semantic role labeling using recurrent neural net-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,244.54237365722656,0.0,50,H3
sample_2.pdf,11,works. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,255.50135803222656,0.1111111111111111,9,H3
sample_2.pdf,11,ACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,121.53397369384766,255.32489013671875,1.0,3,H3
sample_2.pdf,11,"Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu,",9.962599754333496,NimbusRomNo9L-Regu,False,71.9999771118164,275.4273681640625,0.16666666666666666,48,H3
sample_2.pdf,11,"Hongyun Bao, and Bo Xu. 2016. Text classiﬁcation",9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,286.3863525390625,0.10416666666666667,48,H3
sample_2.pdf,11,improved by integrating bidirectional lstm with two-,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,297.3443603515625,0.0,52,H3
sample_2.pdf,11,dimensional max pooling. In,9.962599754333496,NimbusRomNo9L-Regu,False,82.90898132324219,308.3033447265625,0.037037037037037035,27,H3
sample_2.pdf,11,COLING,9.962599754333496,NimbusRomNo9L-ReguItal,False,198.57472229003906,308.12689208984375,1.0,6,H3
sample_2.pdf,12,Supplemental Material to accompany,11.9552001953125,NimbusRomNo9L-Medi,False,92.58685302734375,64.59117889404297,0.058823529411764705,34,H3
sample_2.pdf,12,Deep contextualized word,11.9552001953125,NimbusRomNo9L-MediItal,False,92.58699798583984,78.54537200927734,0.041666666666666664,24,H3
sample_2.pdf,12,representations,11.9552001953125,NimbusRomNo9L-MediItal,False,92.58699798583984,92.49337005615234,0.0,15,H3
sample_2.pdf,12,This supplement contains details of the model ar-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,114.97567749023438,0.02040816326530612,49,H3
sample_2.pdf,12,"chitectures, training routines and hyper-parameter",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,128.52566528320312,0.0,50,H3
sample_2.pdf,12,choices for the state-of-the-art models in Section,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,142.07467651367188,0.02,50,H3
sample_2.pdf,12,All of the individual models share a common ar-,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,169.44467163085938,0.02127659574468085,47,H3
sample_2.pdf,12,chitecture in the lowest layers with a context inde-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,182.99368286132812,0.0,52,H3
sample_2.pdf,12,pendent token representation below several layers,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,196.54269409179688,0.0,49,H3
sample_2.pdf,12,of stacked RNNs – LSTMs in every case except,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,210.09268188476562,0.1590909090909091,44,H3
sample_2.pdf,12,the SQuAD model that uses GRUs.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,223.64169311523438,0.22580645161290322,31,H3
sample_2.pdf,12,A.1,10.909099578857422,NimbusRomNo9L-Medi,False,72.0,246.86912536621094,0.3333333333333333,3,H3
sample_2.pdf,12,Fine tuning biLM,10.909099578857422,NimbusRomNo9L-Medi,False,98.96730041503906,246.86912536621094,0.1875,16,H3
sample_2.pdf,12,As noted in Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,264.9857482910156,0.125,16,H3
sample_2.pdf,12,3.4,10.909099578857422,NimbusRomNo9L-Regu,False,143.42190551757812,264.9857482910156,0.0,3,H3
sample_2.pdf,12,", ﬁne tuning the biLM on task",10.909099578857422,NimbusRomNo9L-Regu,False,160.42918395996094,264.9857482910156,0.06896551724137931,29,H3
sample_2.pdf,12,speciﬁc data typically resulted in signiﬁcant drops,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,278.5347595214844,0.0,51,H3
sample_2.pdf,12,"in perplexity. To ﬁne tune on a given task, the",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,292.0837707519531,0.02127659574468085,47,H3
sample_2.pdf,12,"supervised labels were temporarily ignored, the",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,305.6327819824219,0.0,47,H3
sample_2.pdf,12,biLM ﬁne tuned for one epoch on the training split,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,319.1817932128906,0.04,50,H3
sample_2.pdf,12,and evaluated on the development split. Once ﬁne,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,332.7317810058594,0.020833333333333332,48,H3
sample_2.pdf,12,"tuned, the biLM weights were ﬁxed during task",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,346.2807922363281,0.044444444444444446,45,H3
sample_2.pdf,12,training.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,359.8298034667969,0.0,9,H3
sample_2.pdf,12,Table,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,373.65081787109375,0.2,5,H3
sample_2.pdf,12,lists the development set perplexities for,10.909099578857422,NimbusRomNo9L-Regu,False,114.54539489746094,373.65081787109375,0.0,42,H3
sample_2.pdf,12,the considered tasks. In every case except CoNLL,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,387.1998291015625,0.10416666666666667,48,H3
sample_2.pdf,12,"2012, ﬁne tuning results in a large improvement in",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,400.74884033203125,0.0,50,H3
sample_2.pdf,12,"perplexity, e.g., from 72.1 to 16.8 for SNLI.",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,414.298828125,0.08888888888888889,45,H3
sample_2.pdf,12,The impact of ﬁne tuning on supervised perfor-,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,428.1198425292969,0.021739130434782608,46,H3
sample_2.pdf,12,"mance is task dependent. In the case of SNLI,",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,441.6688537597656,0.1111111111111111,45,H3
sample_2.pdf,12,ﬁne tuning the biLM increased development accu-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,455.2178649902344,0.0425531914893617,47,H3
sample_2.pdf,12,racy 0.6% from 88.9% to 89.5% for our single best,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,468.7668762207031,0.0,49,H3
sample_2.pdf,12,"model. However, for sentiment classiﬁcation de-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,482.3168640136719,0.02127659574468085,47,H3
sample_2.pdf,12,velopment set accuracy is approximately the same,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,495.8658752441406,0.0,48,H3
sample_2.pdf,12,regardless whether a ﬁne tuned biLM was used.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,509.4148864746094,0.044444444444444446,45,H3
sample_2.pdf,12,A.2,10.909099578857422,NimbusRomNo9L-Medi,False,72.0,532.642333984375,0.3333333333333333,3,H3
sample_2.pdf,12,Importance of,10.909099578857422,NimbusRomNo9L-Medi,False,98.96730041503906,532.642333984375,0.07692307692307693,13,H3
sample_2.pdf,12,in Eqn. (1),10.909099578857422,NimbusRomNo9L-Medi,False,173.69390869140625,532.642333984375,0.09090909090909091,11,H3
sample_2.pdf,12,The,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,550.7589111328125,0.3333333333333333,3,H3
sample_2.pdf,12,parameter in Eqn. (,10.909099578857422,NimbusRomNo9L-Regu,False,97.89391326904297,550.7589111328125,0.05263157894736842,19,H3
sample_2.pdf,12,) was of practical im-,10.909099578857422,NimbusRomNo9L-Regu,False,194.86337280273438,550.7589111328125,0.0,22,H3
sample_2.pdf,12,"portance to aid optimization, due to the differ-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,564.3079223632812,0.0,48,H3
sample_2.pdf,12,ent distributions between the biLM internal rep-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,577.85693359375,0.041666666666666664,48,H3
sample_2.pdf,12,resentations and the task speciﬁc representations.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,591.4058837890625,0.0,50,H3
sample_2.pdf,12,It is especially important in the last-only case in,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,604.9548950195312,0.0196078431372549,51,H3
sample_2.pdf,12,Sec.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,618.5048828125,0.25,4,H3
sample_2.pdf,12,5.1,10.909099578857422,NimbusRomNo9L-Regu,False,90.48001098632812,618.5048828125,0.0,3,H3
sample_2.pdf,12,"Without this parameter, the last-only",10.909099578857422,NimbusRomNo9L-Regu,False,121.63639831542969,618.5048828125,0.02702702702702703,37,H3
sample_2.pdf,12,case performed poorly (well below the baseline),10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,632.0538940429688,0.0,47,H3
sample_2.pdf,12,for SNLI and training failed completely for SRL.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,645.6029052734375,0.14583333333333334,48,H3
sample_2.pdf,12,A.3,10.909099578857422,NimbusRomNo9L-Medi,False,71.99999237060547,668.830322265625,0.3333333333333333,3,H3
sample_2.pdf,12,Textual Entailment,10.909099578857422,NimbusRomNo9L-Medi,False,98.96729278564453,668.830322265625,0.1111111111111111,18,H3
sample_2.pdf,12,Our baseline SNLI model is the ESIM sequence,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,686.9468994140625,0.20454545454545456,44,H3
sample_2.pdf,12,model from,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,700.4959106445312,0.0,10,H3
sample_2.pdf,12,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,125.31277465820312,700.4959106445312,0.09090909090909091,11,H3
sample_2.pdf,12,2017,10.909099578857422,NimbusRomNo9L-Regu,False,189.79647827148438,700.4959106445312,0.0,4,H3
sample_2.pdf,12,Following the,10.909099578857422,NimbusRomNo9L-Regu,False,227.68377685546875,700.4959106445312,0.07692307692307693,13,H3
sample_2.pdf,12,"original implementation, we used 300 dimensions",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,714.044921875,0.0,47,H3
sample_2.pdf,12,for all LSTM and feed forward layers and pre-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,727.5938720703125,0.08888888888888889,45,H3
sample_2.pdf,12,trained 300 dimensional GloVe embeddings that,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,741.1439208984375,0.044444444444444446,45,H3
sample_2.pdf,12,"were ﬁxed during training. For regularization, we",10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,754.69287109375,0.02040816326530612,49,H3
sample_2.pdf,12,Dataset,10.909099578857422,NimbusRomNo9L-Medi,False,356.1159973144531,70.7122573852539,0.14285714285714285,7,H3
sample_2.pdf,12,Before,10.909099578857422,NimbusRomNo9L-Medi,False,443.0,63.920082092285156,0.16666666666666666,6,H3
sample_2.pdf,12,tuning,10.909099578857422,NimbusRomNo9L-Medi,False,443.0,77.4690933227539,0.0,6,H3
sample_2.pdf,12,After,10.909099578857422,NimbusRomNo9L-Medi,False,485.77899169921875,63.920082092285156,0.2,5,H3
sample_2.pdf,12,tuning,10.909099578857422,NimbusRomNo9L-Medi,False,485.77899169921875,77.4690933227539,0.0,6,H3
sample_2.pdf,12,SNLI,10.909099578857422,NimbusRomNo9L-Regu,False,316.7239990234375,93.90768432617188,1.0,4,H3
sample_2.pdf,12,72.1,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,93.90768432617188,0.0,4,H3
sample_2.pdf,12,16.8,10.909099578857422,NimbusRomNo9L-Regu,False,485.77899169921875,93.90768432617188,0.0,4,H3
sample_2.pdf,12,CoNLL 2012 (coref/SRL),10.909099578857422,NimbusRomNo9L-Regu,False,316.7239990234375,107.85464477539062,0.3181818181818182,22,H3
sample_2.pdf,12,92.3,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,107.85464477539062,0.0,4,H3
sample_2.pdf,12,CoNLL 2003 (NER),10.909099578857422,NimbusRomNo9L-Regu,False,316.7239990234375,121.80264282226562,0.4375,16,H3
sample_2.pdf,12,103.2,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,121.80264282226562,0.0,5,H3
sample_2.pdf,12,46.3,10.909099578857422,NimbusRomNo9L-Regu,False,485.77899169921875,121.80264282226562,0.0,4,H3
sample_2.pdf,12,SQuAD,10.909099578857422,NimbusRomNo9L-Regu,False,316.7239990234375,142.52468872070312,0.8,5,H3
sample_2.pdf,12,Context,10.909099578857422,NimbusRomNo9L-Regu,False,363.8280029296875,135.75070190429688,0.14285714285714285,7,H3
sample_2.pdf,12,99.1,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,135.75064086914062,0.0,4,H3
sample_2.pdf,12,43.5,10.909099578857422,NimbusRomNo9L-Regu,False,485.77899169921875,135.75064086914062,0.0,4,H3
sample_2.pdf,12,Questions,10.909099578857422,NimbusRomNo9L-Regu,False,363.8280029296875,149.29965209960938,0.1111111111111111,9,H3
sample_2.pdf,12,158.2,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,149.29965209960938,0.0,5,H3
sample_2.pdf,12,52.0,10.909099578857422,NimbusRomNo9L-Regu,False,485.77899169921875,149.29965209960938,0.0,4,H3
sample_2.pdf,12,SST,10.909099578857422,NimbusRomNo9L-Regu,False,316.7239990234375,163.24765014648438,1.0,3,H3
sample_2.pdf,12,131.5,10.909099578857422,NimbusRomNo9L-Regu,False,443.0,163.24765014648438,0.0,5,H3
sample_2.pdf,12,78.6,10.909099578857422,NimbusRomNo9L-Regu,False,485.77899169921875,163.24765014648438,0.0,4,H3
sample_2.pdf,12,Table 7: Development set perplexity before and after,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,185.78346252441406,0.038461538461538464,52,H3
sample_2.pdf,12,ﬁne tuning for one epoch on the training set for vari-,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,197.7384796142578,0.0,54,H3
sample_2.pdf,12,ous datasets (lower is better). Reported values are the,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,209.69349670410156,0.01818181818181818,55,H3
sample_2.pdf,12,average of the forward and backward perplexities.,9.962599754333496,NimbusRomNo9L-Regu,False,307.2760009765625,221.6485137939453,0.0,49,H3
sample_2.pdf,12,added 50% variational dropout (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,254.01168823242188,0.0,31,H3
sample_2.pdf,12,Gal and Ghahra-,10.909099578857422,NimbusRomNo9L-Regu,False,451.29791259765625,254.01168823242188,0.13333333333333333,15,H3
sample_2.pdf,12,mani,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,267.5606994628906,0.0,4,H3
sample_2.pdf,12,2016,10.909099578857422,NimbusRomNo9L-Regu,False,331.8214416503906,267.5606994628906,0.0,4,H3
sample_2.pdf,12,) to the input of each LSTM layer and,10.909099578857422,NimbusRomNo9L-Regu,False,356.781494140625,267.5606994628906,0.10810810810810811,37,H3
sample_2.pdf,12,50% dropout (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,281.1097106933594,0.0,13,H3
sample_2.pdf,12,Srivastava et al.,10.909099578857422,NimbusRomNo9L-Regu,False,371.3451843261719,281.1097106933594,0.058823529411764705,17,H3
sample_2.pdf,12,2014,10.909099578857422,NimbusRomNo9L-Regu,False,443.4541931152344,281.1097106933594,0.0,4,H3
sample_2.pdf,12,) at the input,10.909099578857422,NimbusRomNo9L-Regu,False,468.5233459472656,281.1097106933594,0.0,14,H3
sample_2.pdf,12,to the ﬁnal two fully connected layers. All feed,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,294.6587219238281,0.020833333333333332,48,H3
sample_2.pdf,12,forward layers use ReLU activations.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,308.2077331542969,0.08333333333333333,36,H3
sample_2.pdf,12,Parame-,10.909099578857422,NimbusRomNo9L-Regu,False,489.35968017578125,308.2077331542969,0.14285714285714285,7,H3
sample_2.pdf,12,ters were optimized using Adam (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,321.7577209472656,0.03125,32,H3
sample_2.pdf,12,Kingma and Ba,10.909099578857422,NimbusRomNo9L-Regu,False,454.6469421386719,321.7577209472656,0.15384615384615385,13,H3
sample_2.pdf,12,2015,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,335.3067321777344,0.0,4,H3
sample_2.pdf,12,) with gradient norms clipped at 5.0 and ini-,10.909099578857422,NimbusRomNo9L-Regu,False,329.09423828125,335.3067321777344,0.0,45,H3
sample_2.pdf,12,"tial learning rate 0.0004, decreasing by half each",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,348.8557434082031,0.0,50,H3
sample_2.pdf,12,time accuracy on the development set did not in-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,362.4047546386719,0.0,48,H3
sample_2.pdf,12,crease in subsequent epochs. The batch size was,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,375.9537658691406,0.02127659574468085,47,H3
sample_2.pdf,12,32.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,389.5037536621094,0.0,3,H3
sample_2.pdf,12,The best ELMo conﬁguration added ELMo vec-,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,403.0717468261719,0.16666666666666666,42,H3
sample_2.pdf,12,tors to both the input and output of the lowest,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,416.6217346191406,0.0,47,H3
sample_2.pdf,12,"layer LSTM, using (",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,430.1707458496094,0.21052631578947367,19,H3
sample_2.pdf,12,) with layer normalization,10.909099578857422,NimbusRomNo9L-Regu,False,406.86517333984375,430.1707458496094,0.0,26,H3
sample_2.pdf,12,and,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,443.7197570800781,0.0,3,H3
sample_2.pdf,12,= 0,10.909099578857422,CMR10,False,332.9570007324219,443.46728515625,0.0,3,H3
sample_2.pdf,12,001,10.909099578857422,CMR10,False,359.1059875488281,443.46728515625,0.0,3,H3
sample_2.pdf,12,. Due to the increased number of,10.909099578857422,NimbusRomNo9L-Regu,False,375.4700012207031,443.7197570800781,0.03125,32,H3
sample_2.pdf,12,"parameters in the ELMo model, we added",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,457.2687683105469,0.07894736842105263,38,H3
sample_2.pdf,12,reg-,10.909099578857422,NimbusRomNo9L-Regu,False,508.14300537109375,457.2687683105469,0.0,4,H3
sample_2.pdf,12,ularization with regularization coefﬁcient 0.0001,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,470.8177795410156,0.0,49,H3
sample_2.pdf,12,to all recurrent and feed forward weight matrices,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,484.3677673339844,0.0,49,H3
sample_2.pdf,12,and 50% dropout after the attention layer.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,497.9167785644531,0.0,42,H3
sample_2.pdf,12,Table,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,511.4858093261719,0.2,5,H3
sample_2.pdf,12,compares test set accuracy of our sys-,10.909099578857422,NimbusRomNo9L-Regu,False,351.2395324707031,511.4858093261719,0.0,38,H3
sample_2.pdf,12,tem to previously published systems.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,525.0347900390625,0.0,36,H3
sample_2.pdf,12,"Overall,",10.909099578857422,NimbusRomNo9L-Regu,False,490.26519775390625,525.0347900390625,0.125,8,H3
sample_2.pdf,12,adding ELMo to the ESIM model improved ac-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,538.5838623046875,0.16666666666666666,42,H3
sample_2.pdf,12,curacy by 0.7% establishing a new single model,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,552.1328125,0.0,46,H3
sample_2.pdf,12,"state-of-the-art of 88.7%, and a ﬁve member en-",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,565.681884765625,0.0,47,H3
sample_2.pdf,12,semble pushes the overall accuracy to 89.3%.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,579.2318725585938,0.0,44,H3
sample_2.pdf,12,A.4,10.909099578857422,NimbusRomNo9L-Medi,False,307.2760009765625,601.5852661132812,0.3333333333333333,3,H3
sample_2.pdf,12,Question Answering,10.909099578857422,NimbusRomNo9L-Medi,False,334.2432861328125,601.5852661132812,0.1111111111111111,18,H3
sample_2.pdf,12,Our QA model is a simpliﬁed version of the model,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,619.2008666992188,0.0625,48,H3
sample_2.pdf,12,from,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,632.7498779296875,0.0,4,H3
sample_2.pdf,12,Clark and Gardner,10.909099578857422,NimbusRomNo9L-Regu,False,328.4832763671875,632.7498779296875,0.11764705882352941,17,H3
sample_2.pdf,12,2017,10.909099578857422,NimbusRomNo9L-Regu,False,426.59967041015625,632.7498779296875,0.0,4,H3
sample_2.pdf,12,It embeds to-,10.909099578857422,NimbusRomNo9L-Regu,False,464.0506286621094,632.7498779296875,0.07692307692307693,13,H3
sample_2.pdf,12,kens by concatenating each token’s case-sensitive,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,646.298828125,0.0,49,H3
sample_2.pdf,12,300 dimensional GloVe word vector (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,659.8478393554688,0.05714285714285714,35,H3
sample_2.pdf,12,Penning-,10.909099578857422,NimbusRomNo9L-Regu,False,486.1524658203125,659.8478393554688,0.125,8,H3
sample_2.pdf,12,ton et al.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,673.3978271484375,0.0,10,H3
sample_2.pdf,12,2014,10.909099578857422,NimbusRomNo9L-Regu,False,349.5814208984375,673.3978271484375,0.0,4,H3
sample_2.pdf,12,) with a character-derived embed-,10.909099578857422,NimbusRomNo9L-Regu,False,374.97784423828125,673.3978271484375,0.0,33,H3
sample_2.pdf,12,ding produced using a convolutional neural net-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,686.9468383789062,0.0,47,H3
sample_2.pdf,12,work followed by max-pooling on learned char-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,700.495849609375,0.0,45,H3
sample_2.pdf,12,acter embeddings.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,714.0448608398438,0.0,17,H3
sample_2.pdf,12,The token embeddings are,10.909099578857422,NimbusRomNo9L-Regu,False,401.5741882324219,714.0448608398438,0.041666666666666664,24,H3
sample_2.pdf,12,"passed through a shared bi-directional GRU, and",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.5938720703125,0.06382978723404255,47,H3
sample_2.pdf,12,then the bi-directional attention mechanism from,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,741.1438598632812,0.0,48,H3
sample_2.pdf,12,BiDAF (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,754.69287109375,0.5714285714285714,7,H3
sample_2.pdf,12,Seo et al.,10.909099578857422,NimbusRomNo9L-Regu,False,346.7996520996094,754.69287109375,0.1,10,H3
sample_2.pdf,12,2017,10.909099578857422,NimbusRomNo9L-Regu,False,392.7596130371094,754.69287109375,0.0,4,H3
sample_2.pdf,12,). The augmented con-,10.909099578857422,NimbusRomNo9L-Regu,False,418.7778625488281,754.69287109375,0.047619047619047616,21,H3
sample_2.pdf,13,Model,10.909099578857422,NimbusRomNo9L-Medi,False,177.0590057373047,63.920082092285156,0.2,5,H3
sample_2.pdf,13,Acc.,10.909099578857422,NimbusRomNo9L-Medi,False,368.3630065917969,63.920082092285156,0.25,4,H3
sample_2.pdf,13,Feature based (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,80.35867309570312,0.06666666666666667,15,H3
sample_2.pdf,13,Bowman et al.,10.909099578857422,NimbusRomNo9L-Regu,False,243.7027130126953,80.35867309570312,0.07692307692307693,13,H3
sample_2.pdf,13,2015,10.909099578857422,NimbusRomNo9L-Regu,False,309.4844665527344,80.35867309570312,0.0,4,H3
sample_2.pdf,13,78.2,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,80.35867309570312,0.0,4,H3
sample_2.pdf,13,DIIN (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,93.90768432617188,0.6666666666666666,6,H3
sample_2.pdf,13,Gong et al.,10.909099578857422,NimbusRomNo9L-Regu,False,206.43724060058594,93.90768432617188,0.09090909090909091,11,H3
sample_2.pdf,13,2018,10.909099578857422,NimbusRomNo9L-Regu,False,257.339111328125,93.90768432617188,0.0,4,H3
sample_2.pdf,13,88.0,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,93.90768432617188,0.0,4,H3
sample_2.pdf,13,BCN+Char+CoVe (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,107.45669555664062,0.4,15,H3
sample_2.pdf,13,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,263.6008605957031,107.45669555664062,0.15384615384615385,13,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,327.8335266113281,107.45669555664062,0.0,4,H3
sample_2.pdf,13,88.1,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,107.45669555664062,0.0,4,H3
sample_2.pdf,13,ESIM (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,121.00570678710938,0.6666666666666666,6,H3
sample_2.pdf,13,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,209.4808807373047,121.00570678710938,0.09090909090909091,11,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,259.17181396484375,121.00570678710938,0.0,4,H3
sample_2.pdf,13,88.0,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,121.00564575195312,0.0,4,H3
sample_2.pdf,13,ESIM+TreeLSTM (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,134.55465698242188,0.6,15,H3
sample_2.pdf,13,Chen et al.,10.909099578857422,NimbusRomNo9L-Regu,False,264.3318176269531,134.55465698242188,0.09090909090909091,11,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,314.0226745605469,134.55465698242188,0.0,4,H3
sample_2.pdf,13,88.6,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,134.55465698242188,0.0,4,H3
sample_2.pdf,13,ESIM+ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,148.10366821289062,0.7777777777777778,9,H3
sample_2.pdf,13,88.7,10.909099578857422,NimbusRomNo9L-Medi,False,368.3630065917969,148.0040740966797,0.0,4,H3
sample_2.pdf,13,0.17,10.909099578857422,NimbusRomNo9L-Regu,False,398.66827392578125,148.10366821289062,0.0,4,H3
sample_2.pdf,13,DIIN ensemble (,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,162.05166625976562,0.26666666666666666,15,H3
sample_2.pdf,13,Gong et al.,10.909099578857422,NimbusRomNo9L-Regu,False,250.36817932128906,162.05166625976562,0.09090909090909091,11,H3
sample_2.pdf,13,2018,10.909099578857422,NimbusRomNo9L-Regu,False,301.26995849609375,162.05166625976562,0.0,4,H3
sample_2.pdf,13,88.9,10.909099578857422,NimbusRomNo9L-Regu,False,368.3630065917969,162.05166625976562,0.0,4,H3
sample_2.pdf,13,ESIM+ELMo ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,177.0590057373047,175.60067749023438,0.3888888888888889,18,H3
sample_2.pdf,13,89.3,10.909099578857422,NimbusRomNo9L-Medi,False,368.3630065917969,175.50108337402344,0.0,4,H3
sample_2.pdf,13,Table 8: SNLI test set accuracy.,9.962599754333496,NimbusRomNo9L-Regu,False,78.1510009765625,199.71351623535156,0.15625,32,H3
sample_2.pdf,13,"Single model results occupy the portion, with ensemble results at the bottom.",9.962599754333496,NimbusRomNo9L-Regu,False,208.9600067138672,199.71351623535156,0.012987012987012988,77,H3
sample_2.pdf,13,text vectors are then passed through a linear layer,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,232.03671264648438,0.0,51,H3
sample_2.pdf,13,"with ReLU activations, a residual self-attention",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,245.58670043945312,0.0625,48,H3
sample_2.pdf,13,layer that uses a GRU followed by the same atten-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,259.1357116699219,0.061224489795918366,49,H3
sample_2.pdf,13,"tion mechanism applied context-to-context, and",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,272.6847229003906,0.0,46,H3
sample_2.pdf,13,another linear layer with ReLU activations. Fi-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,286.2337341308594,0.0851063829787234,47,H3
sample_2.pdf,13,"nally, the results are fed through linear layers to",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,299.7827453613281,0.0,51,H3
sample_2.pdf,13,predict the start and end token of the answer.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,313.3327331542969,0.0,46,H3
sample_2.pdf,13,Variational dropout is used before the input to,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,327.4027404785156,0.02127659574468085,47,H3
sample_2.pdf,13,the GRUs and the linear layers at a rate of 0.2. A,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,340.9527282714844,0.08,50,H3
sample_2.pdf,13,"dimensionality of 90 is used for the GRUs, and",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,354.5017395019531,0.06521739130434782,46,H3
sample_2.pdf,13,180 for the linear layers. We optimize the model,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,368.0507507324219,0.020833333333333332,48,H3
sample_2.pdf,13,using Adadelta with a batch size of 45. At test,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,381.5997619628906,0.0425531914893617,47,H3
sample_2.pdf,13,time we use an exponential moving average of the,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,395.1487731933594,0.0,48,H3
sample_2.pdf,13,weights and limit the output span to be of at most,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,408.6987609863281,0.0,50,H3
sample_2.pdf,13,size 17. We do not update the word vectors during,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,422.2477722167969,0.02040816326530612,49,H3
sample_2.pdf,13,training.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,435.7967834472656,0.0,9,H3
sample_2.pdf,13,Performance was highest when adding ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,449.8677978515625,0.1,40,H3
sample_2.pdf,13,without layer normalization to both the input and,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,463.41680908203125,0.0,49,H3
sample_2.pdf,13,output of the contextual GRU layer and leaving the,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,476.9658203125,0.06,50,H3
sample_2.pdf,13,ELMo weights unregularized (,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,490.51483154296875,0.10714285714285714,28,H3
sample_2.pdf,13,= 0,10.909099578857422,CMR10,False,212.41000366210938,490.2623596191406,0.0,3,H3
sample_2.pdf,13,Table,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,504.5858459472656,0.2,5,H3
sample_2.pdf,13,compares test set results from the,10.909099578857422,NimbusRomNo9L-Regu,False,118.87631225585938,504.5858459472656,0.0,34,H3
sample_2.pdf,13,"SQuAD leaderboard as of November 17, 2017",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,518.1348876953125,0.12195121951219512,41,H3
sample_2.pdf,13,"when we submitted our system. Overall, our sub-",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,531.6838989257812,0.02127659574468085,47,H3
sample_2.pdf,13,mission had the highest single model and ensem-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,545.23388671875,0.0,47,H3
sample_2.pdf,13,"ble results, improving the previous single model",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,558.7828979492188,0.0,48,H3
sample_2.pdf,13,result (SAN) by 1.4% F,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,572.3319091796875,0.18181818181818182,22,H3
sample_2.pdf,13,and our baseline by,10.909099578857422,NimbusRomNo9L-Regu,False,191.03311157226562,572.3319091796875,0.0,19,H3
sample_2.pdf,13,4.2%.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99999237060547,585.8809204101562,0.0,5,H3
sample_2.pdf,13,A 11 member ensemble pushes F,10.909099578857422,NimbusRomNo9L-Regu,False,110.29093170166016,585.8809204101562,0.06896551724137931,29,H3
sample_2.pdf,13,"87.4%, 1.0% increase over the previous ensemble",10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,599.429931640625,0.0,47,H3
sample_2.pdf,13,best.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,612.9799194335938,0.0,5,H3
sample_2.pdf,13,A.5,10.909099578857422,NimbusRomNo9L-Medi,False,71.99996948242188,637.072265625,0.3333333333333333,3,H3
sample_2.pdf,13,Semantic Role Labeling,10.909099578857422,NimbusRomNo9L-Medi,False,98.96726989746094,637.072265625,0.13636363636363635,22,H3
sample_2.pdf,13,Our baseline SRL model is an exact reimplemen-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,655.6838989257812,0.08695652173913043,46,H3
sample_2.pdf,13,tation of (,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,669.23291015625,0.0,11,H3
sample_2.pdf,13,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,115.88729095458984,669.23291015625,0.1111111111111111,9,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,156.13096618652344,669.23291015625,0.0,4,H3
sample_2.pdf,13,). Words are represented,10.909099578857422,NimbusRomNo9L-Regu,False,181.10186767578125,669.23291015625,0.041666666666666664,24,H3
sample_2.pdf,13,using a concatenation of 100 dimensional vector,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,682.7818603515625,0.0,47,H3
sample_2.pdf,13,"representations, initialized using GloVe (",10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,696.3308715820312,0.047619047619047616,42,H3
sample_2.pdf,13,Penning-,10.909099578857422,NimbusRomNo9L-Regu,False,250.87646484375,696.3308715820312,0.125,8,H3
sample_2.pdf,13,ton et al.,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,709.880859375,0.0,10,H3
sample_2.pdf,13,2014,10.909099578857422,NimbusRomNo9L-Regu,False,113.98910522460938,709.880859375,0.0,4,H3
sample_2.pdf,13,") and a binary, per-word predicate",10.909099578857422,NimbusRomNo9L-Regu,False,139.23275756835938,709.880859375,0.0,34,H3
sample_2.pdf,13,"feature, represented using an 100 dimensional em-",10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,723.4298706054688,0.0,49,H3
sample_2.pdf,13,A comprehensive comparison can be found at,8.966400146484375,NimbusRomNo9L-Regu,False,88.13899993896484,746.2029418945312,0.023809523809523808,42,P
sample_2.pdf,13,https:,8.966400146484375,NimbusMonL-Regu,False,255.2278594970703,745.743896484375,0.0,6,P
sample_2.pdf,13,//nlp.stanford.edu/projects/snli/,8.966400146484375,NimbusMonL-Regu,False,72.00001525878906,755.7069091796875,0.0,33,P
sample_2.pdf,13,bedding. This 200 dimensional token represen-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,232.03665161132812,0.022222222222222223,45,H3
sample_2.pdf,13,tation is then passed through an 8 layer “inter-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,245.58663940429688,0.0,48,H3
sample_2.pdf,13,leaved” biLSTM with a 300 dimensional hidden,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,259.1356506347656,0.09090909090909091,44,H3
sample_2.pdf,13,"size, in which the directions of the LSTM layers",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,272.6846618652344,0.08333333333333333,48,H3
sample_2.pdf,13,alternate per layer. This deep LSTM uses High-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,286.2336730957031,0.13043478260869565,46,H3
sample_2.pdf,13,way connections (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,299.7826843261719,0.0,17,H3
sample_2.pdf,13,Srivastava et al.,10.909099578857422,NimbusRomNo9L-Regu,False,386.7705993652344,299.7826843261719,0.058823529411764705,17,H3
sample_2.pdf,13,2015,10.909099578857422,NimbusRomNo9L-Regu,False,458.0614318847656,299.7826843261719,0.0,4,H3
sample_2.pdf,13,) between,10.909099578857422,NimbusRomNo9L-Regu,False,482.7269592285156,299.7826843261719,0.0,9,H3
sample_2.pdf,13,layers and variational recurrent dropout (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,313.3326721191406,0.0,42,H3
sample_2.pdf,13,Gal and,10.909099578857422,NimbusRomNo9L-Regu,False,490.4287109375,313.3326721191406,0.14285714285714285,7,H3
sample_2.pdf,13,Ghahramani,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,326.8816833496094,0.1,10,H3
sample_2.pdf,13,2016,10.909099578857422,NimbusRomNo9L-Regu,False,363.9269104003906,326.8816833496094,0.0,4,H3
sample_2.pdf,13,). This deep representation is,10.909099578857422,NimbusRomNo9L-Regu,False,389.91241455078125,326.8816833496094,0.03333333333333333,30,H3
sample_2.pdf,13,then projected using a ﬁnal dense layer followed,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,340.4306945800781,0.0,48,H3
sample_2.pdf,13,by a softmax activation to form a distribution over,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,353.9797058105469,0.0,51,H3
sample_2.pdf,13,all possible tags. Labels consist of semantic roles,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,367.5287170410156,0.0196078431372549,51,H3
sample_2.pdf,13,from PropBank (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,381.0787048339844,0.13333333333333333,15,H3
sample_2.pdf,13,Palmer et al.,10.909099578857422,NimbusRomNo9L-Regu,False,383.92333984375,381.0787048339844,0.07692307692307693,13,H3
sample_2.pdf,13,2005,10.909099578857422,NimbusRomNo9L-Regu,False,444.0541687011719,381.0787048339844,0.0,4,H3
sample_2.pdf,13,) augmented,10.909099578857422,NimbusRomNo9L-Regu,False,469.9524230957031,381.0787048339844,0.0,11,H3
sample_2.pdf,13,with a BIO labeling scheme to represent argu-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,394.6277160644531,0.06666666666666667,45,H3
sample_2.pdf,13,ment spans.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,408.1767272949219,0.0,11,H3
sample_2.pdf,13,"During training, we minimize the",10.909099578857422,NimbusRomNo9L-Regu,False,370.71240234375,408.1767272949219,0.03125,32,H3
sample_2.pdf,13,negative log likelihood of the tag sequence using,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,421.7257385253906,0.0,49,H3
sample_2.pdf,13,Adadelta with a learning rate of 1.0 and,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,435.2747497558594,0.025,40,H3
sample_2.pdf,13,= 0,10.909099578857422,CMR10,False,490.75799560546875,435.02227783203125,0.0,3,H3
sample_2.pdf,13,Zeiler,10.909099578857422,NimbusRomNo9L-Regu,False,310.90869140625,448.8247375488281,0.16666666666666666,6,H3
sample_2.pdf,13,2012,10.909099578857422,NimbusRomNo9L-Regu,False,339.68682861328125,448.8247375488281,0.0,4,H3
sample_2.pdf,13,"). At test time, we perform Viterbi",10.909099578857422,NimbusRomNo9L-Regu,False,365.48687744140625,448.8247375488281,0.05714285714285714,35,H3
sample_2.pdf,13,decoding to enforce valid spans using BIO con-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,462.3737487792969,0.06521739130434782,46,H3
sample_2.pdf,13,straints. Variational dropout of 10% is added to,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,475.9227600097656,0.020833333333333332,48,H3
sample_2.pdf,13,all LSTM hidden layers. Gradients are clipped if,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,489.4717712402344,0.10416666666666667,48,H3
sample_2.pdf,13,their value exceeds 1.0. Models are trained for 500,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,503.0207824707031,0.0196078431372549,51,H3
sample_2.pdf,13,epochs or until validation F1 does not improve for,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,516.57080078125,0.02,50,H3
sample_2.pdf,13,"200 epochs, whichever is sooner. The pretrained",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,530.1198120117188,0.02127659574468085,47,H3
sample_2.pdf,13,GloVe vectors are ﬁne-tuned during training. The,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,543.6688232421875,0.0625,48,H3
sample_2.pdf,13,ﬁnal dense layer and all cells of all LSTMs are ini-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,557.2178344726562,0.07692307692307693,52,H3
sample_2.pdf,13,tialized to be orthogonal. The forget gate bias is,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,570.766845703125,0.02,50,H3
sample_2.pdf,13,"initialized to 1 for all LSTMs, with all other gates",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,584.3158569335938,0.07692307692307693,52,H3
sample_2.pdf,13,"initialized to 0, as per (",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,597.8658447265625,0.0,26,H3
sample_2.pdf,13,J´ozefowicz et al.,10.909099578857422,NimbusRomNo9L-Regu,False,407.86859130859375,597.8108520507812,0.05555555555555555,18,H3
sample_2.pdf,13,2015,10.909099578857422,NimbusRomNo9L-Regu,False,483.32440185546875,597.8658447265625,0.0,4,H3
sample_2.pdf,13,Table,10.909099578857422,NimbusRomNo9L-Regu,False,318.1849365234375,612.7438354492188,0.2,5,H3
sample_2.pdf,13,compares test set F1 scores of our,10.909099578857422,NimbusRomNo9L-Regu,False,358.1885986328125,612.7438354492188,0.029411764705882353,34,H3
sample_2.pdf,13,ELMo augmented implementation of (,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,626.2928466796875,0.08823529411764706,34,H3
sample_2.pdf,13,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,482.69415283203125,626.2928466796875,0.1111111111111111,9,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,639.8418579101562,0.0,4,H3
sample_2.pdf,13,) with previous results.,10.909099578857422,NimbusRomNo9L-Regu,False,329.09417724609375,639.8418579101562,0.0,24,H3
sample_2.pdf,13,Our single model,10.909099578857422,NimbusRomNo9L-Regu,False,445.39605712890625,639.8418579101562,0.0625,16,H3
sample_2.pdf,13,score of 84.6 F1 represents a new state-of-the-art,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,653.391845703125,0.02,50,H3
sample_2.pdf,13,result on the CONLL 2012 Semantic Role Label-,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,666.9408569335938,0.17777777777777778,45,H3
sample_2.pdf,13,"ing task, surpassing the previous single model re-",10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,680.4898681640625,0.0,50,H3
sample_2.pdf,13,sult by 2.9 F1 and a 5-model ensemble by 1.2 F1.,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,694.038818359375,0.041666666666666664,48,H3
sample_2.pdf,13,A.6,10.909099578857422,NimbusRomNo9L-Medi,False,307.27593994140625,720.92822265625,0.3333333333333333,3,H3
sample_2.pdf,13,Coreference resolution,10.909099578857422,NimbusRomNo9L-Medi,False,334.24322509765625,720.92822265625,0.045454545454545456,22,H3
sample_2.pdf,13,Our baseline coreference model is the end-to-end,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,741.143798828125,0.020833333333333332,48,H3
sample_2.pdf,13,neural model from,10.909099578857422,NimbusRomNo9L-Regu,False,307.27593994140625,754.6928100585938,0.0,17,H3
sample_2.pdf,13,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,390.53411865234375,754.6928100585938,0.1,10,H3
sample_2.pdf,13,2017,10.909099578857422,NimbusRomNo9L-Regu,False,444.0322265625,754.6928100585938,0.0,4,H3
sample_2.pdf,13,) with all hy-,10.909099578857422,NimbusRomNo9L-Regu,False,465.8504638671875,754.6928100585938,0.0,14,H3
sample_2.pdf,14,Model,10.909099578857422,NimbusRomNo9L-Medi,False,171.99899291992188,63.920082092285156,0.2,5,H3
sample_2.pdf,14,BiDAF (,10.909099578857422,NimbusRomNo9L-Regu,False,171.99899291992188,80.35867309570312,0.5714285714285714,7,H3
sample_2.pdf,14,Seo et al.,10.909099578857422,NimbusRomNo9L-Regu,False,210.04994201660156,80.35867309570312,0.1,10,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,253.07545471191406,80.35867309570312,0.0,4,H3
sample_2.pdf,14,68.0,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,80.35867309570312,0.0,4,H3
sample_2.pdf,14,77.3,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,80.35867309570312,0.0,4,H3
sample_2.pdf,14,BiDAF + Self Attention,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,93.90768432617188,0.2727272727272727,22,H3
sample_2.pdf,14,72.1,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,93.90768432617188,0.0,4,H3
sample_2.pdf,14,81.1,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,93.90768432617188,0.0,4,H3
sample_2.pdf,14,DCN+,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,107.45669555664062,0.75,4,H3
sample_2.pdf,14,75.1,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,107.45669555664062,0.0,4,H3
sample_2.pdf,14,83.1,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,107.45669555664062,0.0,4,H3
sample_2.pdf,14,Reg-RaSoR,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,121.00570678710938,0.4444444444444444,9,H3
sample_2.pdf,14,75.8,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,121.00564575195312,0.0,4,H3
sample_2.pdf,14,83.3,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,121.00564575195312,0.0,4,H3
sample_2.pdf,14,FusionNet,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,134.55465698242188,0.2222222222222222,9,H3
sample_2.pdf,14,76.0,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,134.55465698242188,0.0,4,H3
sample_2.pdf,14,83.9,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,134.55465698242188,0.0,4,H3
sample_2.pdf,14,r-net (,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,148.10366821289062,0.0,7,H3
sample_2.pdf,14,Wang et al.,10.909099578857422,NimbusRomNo9L-Regu,False,198.7372283935547,148.10366821289062,0.09090909090909091,11,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,250.57728576660156,148.10366821289062,0.0,4,H3
sample_2.pdf,14,76.5,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,148.10366821289062,0.0,4,H3
sample_2.pdf,14,84.3,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,148.10366821289062,0.0,4,H3
sample_2.pdf,14,SAN (,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,161.65365600585938,0.6,5,H3
sample_2.pdf,14,Liu et al.,10.909099578857422,NimbusRomNo9L-Regu,False,200.17723083496094,161.65365600585938,0.1,10,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,241.99183654785156,161.65365600585938,0.0,4,H3
sample_2.pdf,14,76.8,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,161.65365600585938,0.0,4,H3
sample_2.pdf,14,84.4,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,161.65365600585938,0.0,4,H3
sample_2.pdf,14,BiDAF + Self Attention + ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,175.20266723632812,0.3103448275862069,29,H3
sample_2.pdf,14,78.6,10.909099578857422,NimbusRomNo9L-Medi,False,375.0090026855469,175.1030731201172,0.0,4,H3
sample_2.pdf,14,85.8,10.909099578857422,NimbusRomNo9L-Medi,False,406.4530029296875,175.1030731201172,0.0,4,H3
sample_2.pdf,14,DCN+ Ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,171.99899291992188,189.14968872070312,0.3076923076923077,13,H3
sample_2.pdf,14,78.9,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,189.14968872070312,0.0,4,H3
sample_2.pdf,14,86.0,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,189.14968872070312,0.0,4,H3
sample_2.pdf,14,FusionNet Ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,202.69967651367188,0.16666666666666666,18,H3
sample_2.pdf,14,79.0,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,202.69967651367188,0.0,4,H3
sample_2.pdf,14,86.0,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,202.69967651367188,0.0,4,H3
sample_2.pdf,14,Interactive AoA Reader+ Ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,216.24868774414062,0.15625,32,H3
sample_2.pdf,14,79.1,10.909099578857422,NimbusRomNo9L-Regu,False,375.0090026855469,216.24868774414062,0.0,4,H3
sample_2.pdf,14,86.5,10.909099578857422,NimbusRomNo9L-Regu,False,406.4530029296875,216.24868774414062,0.0,4,H3
sample_2.pdf,14,BiDAF + Self Attention + ELMo Ensemble,10.909099578857422,NimbusRomNo9L-Regu,False,171.99900817871094,229.79769897460938,0.2631578947368421,38,H3
sample_2.pdf,14,81.0,10.909099578857422,NimbusRomNo9L-Medi,False,375.0090026855469,229.69810485839844,0.0,4,H3
sample_2.pdf,14,87.4,10.909099578857422,NimbusRomNo9L-Medi,False,406.4530029296875,229.69810485839844,0.0,4,H3
sample_2.pdf,14,"Table 9: Test set results for SQuAD, showing both Exact Match (EM) and F",9.962599754333496,NimbusRomNo9L-Regu,False,72.0,252.33351135253906,0.1527777777777778,72,H3
sample_2.pdf,14,. The top half of the table contains,9.962599754333496,NimbusRomNo9L-Regu,False,384.9100036621094,252.33351135253906,0.027777777777777776,36,H3
sample_2.pdf,14,single model results with ensembles at the bottom. References provided where available.,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,264.28851318359375,0.011494252873563218,87,H3
sample_2.pdf,14,Model,10.909099578857422,NimbusRomNo9L-Medi,False,107.8499984741211,295.0381164550781,0.2,5,H3
sample_2.pdf,14,Pradhan et al.,10.909099578857422,NimbusRomNo9L-Regu,False,107.8499984741211,311.4766540527344,0.07142857142857142,14,H3
sample_2.pdf,14,2013,10.909099578857422,NimbusRomNo9L-Regu,False,173.8937225341797,311.4766540527344,0.0,4,H3
sample_2.pdf,14,77.5,10.909099578857422,NimbusRomNo9L-Regu,False,235.3260040283203,311.4766540527344,0.0,4,H3
sample_2.pdf,14,Zhou and Xu,10.909099578857422,NimbusRomNo9L-Regu,False,107.85000610351562,325.0256652832031,0.18181818181818182,11,H3
sample_2.pdf,14,2015,10.909099578857422,NimbusRomNo9L-Regu,False,171.77734375,325.0256652832031,0.0,4,H3
sample_2.pdf,14,81.3,10.909099578857422,NimbusRomNo9L-Regu,False,235.3260040283203,325.0256652832031,0.0,4,H3
sample_2.pdf,14,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,107.85000610351562,338.5746765136719,0.1111111111111111,9,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,150.86460876464844,338.5746765136719,0.0,4,H3
sample_2.pdf,14,"), single",10.909099578857422,NimbusRomNo9L-Regu,False,172.6827850341797,338.5746765136719,0.0,9,H3
sample_2.pdf,14,81.7,10.909099578857422,NimbusRomNo9L-Regu,False,235.3260040283203,338.5746765136719,0.0,4,H3
sample_2.pdf,14,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,107.85000610351562,352.1236877441406,0.1111111111111111,9,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,150.86460876464844,352.1236877441406,0.0,4,H3
sample_2.pdf,14,"), ensemble",10.909099578857422,NimbusRomNo9L-Regu,False,172.6827850341797,352.1236877441406,0.0,11,H3
sample_2.pdf,14,83.4,10.909099578857422,NimbusRomNo9L-Regu,False,235.3260040283203,352.1236572265625,0.0,4,H3
sample_2.pdf,14,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,107.8499984741211,366.0716552734375,0.1111111111111111,9,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,150.86460876464844,366.0716552734375,0.0,4,H3
sample_2.pdf,14,"), our impl.",10.909099578857422,NimbusRomNo9L-Regu,False,172.6827850341797,366.0716552734375,0.0,12,H3
sample_2.pdf,14,81.4,10.909099578857422,NimbusRomNo9L-Regu,False,235.3260040283203,366.0716552734375,0.0,4,H3
sample_2.pdf,14,He et al.,10.909099578857422,NimbusRomNo9L-Regu,False,107.85000610351562,379.62066650390625,0.1111111111111111,9,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,150.86460876464844,379.62066650390625,0.0,4,H3
sample_2.pdf,14,) + ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,172.6827850341797,379.62066650390625,0.375,8,H3
sample_2.pdf,14,84.6,10.909099578857422,NimbusRomNo9L-Medi,False,235.3260040283203,379.52105712890625,0.0,4,H3
sample_2.pdf,14,Table 10: SRL CoNLL 2012 test set F,9.962599754333496,NimbusRomNo9L-Regu,False,99.96600341796875,402.1564636230469,0.2571428571428571,35,H3
sample_2.pdf,14,Model,10.909099578857422,NimbusRomNo9L-Medi,False,87.46299743652344,426.0390625,0.2,5,H3
sample_2.pdf,14,Average F,10.909099578857422,NimbusRomNo9L-Medi,False,223.10899353027344,426.0390625,0.2222222222222222,9,H3
sample_2.pdf,14,Durrett and Klein,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,442.4776611328125,0.11764705882352941,17,H3
sample_2.pdf,14,2013,10.909099578857422,NimbusRomNo9L-Regu,False,170.7758026123047,442.4776611328125,0.0,4,H3
sample_2.pdf,14,60.3,10.909099578857422,NimbusRomNo9L-Regu,False,223.10899353027344,442.4776611328125,0.0,4,H3
sample_2.pdf,14,Wiseman et al.,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,456.02667236328125,0.07142857142857142,14,H3
sample_2.pdf,14,2016,10.909099578857422,NimbusRomNo9L-Regu,False,158.52490234375,456.02667236328125,0.0,4,H3
sample_2.pdf,14,64.2,10.909099578857422,NimbusRomNo9L-Regu,False,223.10899353027344,456.02667236328125,0.0,4,H3
sample_2.pdf,14,Clark and Manning,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,469.57568359375,0.11764705882352941,17,H3
sample_2.pdf,14,2016,10.909099578857422,NimbusRomNo9L-Regu,False,178.66307067871094,469.57568359375,0.0,4,H3
sample_2.pdf,14,65.7,10.909099578857422,NimbusRomNo9L-Regu,False,223.10899353027344,469.57568359375,0.0,4,H3
sample_2.pdf,14,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,483.12469482421875,0.1,10,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,134.11032104492188,483.12469482421875,0.0,4,H3
sample_2.pdf,14,) (single),10.909099578857422,NimbusRomNo9L-Regu,False,155.92849731445312,483.12469482421875,0.0,10,H3
sample_2.pdf,14,67.2,10.909099578857422,NimbusRomNo9L-Regu,False,223.10899353027344,483.1246643066406,0.0,4,H3
sample_2.pdf,14,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,496.6746520996094,0.1,10,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,134.11032104492188,496.6746520996094,0.0,4,H3
sample_2.pdf,14,) (ensemble),10.909099578857422,NimbusRomNo9L-Regu,False,155.92849731445312,496.6746520996094,0.0,12,H3
sample_2.pdf,14,68.8,10.909099578857422,NimbusRomNo9L-Regu,False,223.10899353027344,496.6746826171875,0.0,4,H3
sample_2.pdf,14,Lee et al.,10.909099578857422,NimbusRomNo9L-Regu,False,87.46299743652344,510.2237243652344,0.1,10,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,134.11032104492188,510.2237243652344,0.0,4,H3
sample_2.pdf,14,) + ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,155.92849731445312,510.2237243652344,0.375,8,H3
sample_2.pdf,14,70.4,10.909099578857422,NimbusRomNo9L-Medi,False,223.10899353027344,510.1240539550781,0.0,4,H3
sample_2.pdf,14,Table 11: Coreference resolution average F,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,532.7594604492188,0.07142857142857142,42,H3
sample_2.pdf,14,on the test,9.962599754333496,NimbusRomNo9L-Regu,False,247.13107299804688,532.7594604492188,0.0,11,H3
sample_2.pdf,14,set from the CoNLL 2012 shared task.,9.962599754333496,NimbusRomNo9L-Regu,False,72.0,544.7144775390625,0.1111111111111111,36,H3
sample_2.pdf,14,perparameters exactly following the original im-,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,576.7866821289062,0.0,48,H3
sample_2.pdf,14,plementation.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,590.335693359375,0.0,13,H3
sample_2.pdf,14,The best conﬁguration added ELMo to the in-,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,604.7686767578125,0.09302325581395349,43,H3
sample_2.pdf,14,put of the lowest layer biLSTM and weighted the,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,618.3176879882812,0.0851063829787234,47,H3
sample_2.pdf,14,biLM layers using (,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,631.86669921875,0.10526315789473684,19,H3
sample_2.pdf,14,) without any regularization,10.909099578857422,NimbusRomNo9L-Regu,False,166.4509735107422,631.86669921875,0.0,28,H3
sample_2.pdf,14,= 0,10.909099578857422,CMR10,False,81.99301147460938,645.1631469726562,0.0,3,H3
sample_2.pdf,14,) or layer normalization. 50% dropout was,10.909099578857422,NimbusRomNo9L-Regu,False,102.822998046875,645.4156494140625,0.0,41,H3
sample_2.pdf,14,added to the ELMo representations.,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,658.9646606445312,0.08823529411764706,34,H3
sample_2.pdf,14,Table,10.909099578857422,NimbusRomNo9L-Regu,False,82.90899658203125,673.3976440429688,0.2,5,H3
sample_2.pdf,14,compares our results with previously,10.909099578857422,NimbusRomNo9L-Regu,False,121.5272216796875,673.3976440429688,0.0,36,H3
sample_2.pdf,14,"published results. Overall, we improve the single",10.909099578857422,NimbusRomNo9L-Regu,False,72.0,686.9466552734375,0.02040816326530612,49,H3
sample_2.pdf,14,model state-of-the-art by 3.2% average F,10.909099578857422,NimbusRomNo9L-Regu,False,72.0,700.4956665039062,0.025,40,H3
sample_2.pdf,14,", and our",10.909099578857422,NimbusRomNo9L-Regu,False,252.82398986816406,700.4956665039062,0.0,9,H3
sample_2.pdf,14,single model result improves the previous ensem-,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,714.044677734375,0.0,48,H3
sample_2.pdf,14,ble best by 1.6% F,10.909099578857422,NimbusRomNo9L-Regu,False,71.99998474121094,727.5936279296875,0.05555555555555555,18,H3
sample_2.pdf,14,. Adding ELMo to the output,10.909099578857422,NimbusRomNo9L-Regu,False,159.73297119140625,727.5936279296875,0.14814814814814814,27,H3
sample_2.pdf,14,from the biLSTM in addition to the biLSTM input,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,741.1436767578125,0.1702127659574468,47,H3
sample_2.pdf,14,reduced F,10.909099578857422,NimbusRomNo9L-Regu,False,71.99996948242188,754.692626953125,0.1111111111111111,9,H3
sample_2.pdf,14,by approximately 0.7% (not shown).,10.909099578857422,NimbusRomNo9L-Regu,False,119.55209350585938,754.692626953125,0.0,34,H3
sample_2.pdf,14,A.7,10.909099578857422,NimbusRomNo9L-Medi,False,307.2759704589844,296.5119934082031,0.3333333333333333,3,H3
sample_2.pdf,14,Named Entity Recognition,10.909099578857422,NimbusRomNo9L-Medi,False,334.2432556152344,296.5119934082031,0.125,24,H3
sample_2.pdf,14,Our baseline NER model concatenates 50 dimen-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,316.8876037597656,0.08888888888888889,45,H3
sample_2.pdf,14,sional pre-trained Senna vectors (,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,330.4375915527344,0.029411764705882353,34,H3
sample_2.pdf,14,Collobert et al.,10.909099578857422,NimbusRomNo9L-Regu,False,456.35968017578125,330.4375915527344,0.0625,16,H3
sample_2.pdf,14,2011,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,343.9866027832031,0.0,4,H3
sample_2.pdf,14,) with a CNN character based representation.,10.909099578857422,NimbusRomNo9L-Regu,False,329.0942077636719,343.9866027832031,0.06818181818181818,44,H3
sample_2.pdf,14,The character representation uses 16 dimensional,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,357.5356140136719,0.020833333333333332,48,H3
sample_2.pdf,14,character embeddings and 128 convolutional ﬁl-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,371.0846252441406,0.0,46,H3
sample_2.pdf,14,"ters of width three characters, a ReLU activation",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,384.6336364746094,0.061224489795918366,49,H3
sample_2.pdf,14,and by max pooling. The token representation is,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,398.1836242675781,0.02127659574468085,47,H3
sample_2.pdf,14,"passed through two biLSTM layers, the ﬁrst with",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,411.7326354980469,0.0851063829787234,47,H3
sample_2.pdf,14,200 hidden units and the second with 100 hid-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,425.2816467285156,0.0,45,H3
sample_2.pdf,14,den units before a ﬁnal dense layer and softmax,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,438.8306579589844,0.0,47,H3
sample_2.pdf,14,"layer. During training, we use a CRF loss and at",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,452.3796691894531,0.08333333333333333,48,H3
sample_2.pdf,14,test time perform decoding using the Viterbi algo-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,465.9286804199219,0.02,50,H3
sample_2.pdf,14,rithm while ensuring that the output tag sequence,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,479.4786682128906,0.0,49,H3
sample_2.pdf,14,is valid.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,493.0276794433594,0.0,9,H3
sample_2.pdf,14,Variational dropout is added to the input of both,10.909099578857422,NimbusRomNo9L-Regu,False,318.1849670410156,507.9866638183594,0.02040816326530612,49,H3
sample_2.pdf,14,biLSTM layers. During training the gradients are,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,521.5357055664062,0.10416666666666667,48,H3
sample_2.pdf,14,rescaled if their,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,535.084716796875,0.0,17,H3
sample_2.pdf,14,norm exceeds 5.0 and param-,10.909099578857422,NimbusRomNo9L-Regu,False,393.40997314453125,535.084716796875,0.0,27,H3
sample_2.pdf,14,eters updated using Adam with constant learning,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,548.6347045898438,0.02127659574468085,47,H3
sample_2.pdf,14,rate of 0.001. The pre-trained Senna embeddings,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,562.1837158203125,0.0425531914893617,47,H3
sample_2.pdf,14,are ﬁne tuned during training. We employ early,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,575.7327270507812,0.021739130434782608,46,H3
sample_2.pdf,14,stopping on the development set and report the av-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,589.28173828125,0.0,50,H3
sample_2.pdf,14,eraged test set score across ﬁve runs with different,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,602.8306884765625,0.0,52,H3
sample_2.pdf,14,random seeds.,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,616.3807373046875,0.0,13,H3
sample_2.pdf,14,ELMo was added to the input of the lowest layer,10.909099578857422,NimbusRomNo9L-Regu,False,318.1849670410156,631.3397216796875,0.06382978723404255,47,H3
sample_2.pdf,14,task biLSTM. As the CoNLL 2003 NER data set,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,644.8887329101562,0.27906976744186046,43,H3
sample_2.pdf,14,"is relatively small, we found the best performance",10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,658.437744140625,0.0,50,H3
sample_2.pdf,14,by constraining the trainable layer weights to be,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,671.9866943359375,0.0,49,H3
sample_2.pdf,14,effectively constant by setting,10.909099578857422,NimbusRomNo9L-Regu,False,307.2759704589844,685.5367431640625,0.0,31,H3
sample_2.pdf,14,= 0,10.909099578857422,CMR10,False,446.8450012207031,685.2842407226562,0.0,3,H3
sample_2.pdf,14,with (,10.909099578857422,NimbusRomNo9L-Regu,False,475.33355712890625,685.5367431640625,0.0,6,H3
sample_2.pdf,14,Table,10.909099578857422,NimbusRomNo9L-Regu,False,318.18499755859375,700.4957275390625,0.2,5,H3
sample_2.pdf,14,compares test set F,10.909099578857422,NimbusRomNo9L-Regu,False,358.2759094238281,700.4957275390625,0.05263157894736842,19,H3
sample_2.pdf,14,scores of our,10.909099578857422,NimbusRomNo9L-Regu,False,458.50811767578125,700.4957275390625,0.0,13,H3
sample_2.pdf,14,ELMo enhanced biLSTM-CRF tagger with previ-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,714.044677734375,0.23255813953488372,43,H3
sample_2.pdf,14,"ous results. Overall, the 92.22% F",10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,727.5936889648438,0.058823529411764705,34,H3
sample_2.pdf,14,from our sys-,10.909099578857422,NimbusRomNo9L-Regu,False,462.64013671875,727.5936889648438,0.0,13,H3
sample_2.pdf,14,tem establishes a new state-of-the-art. When com-,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,741.1427001953125,0.02040816326530612,49,H3
sample_2.pdf,14,pared to,10.909099578857422,NimbusRomNo9L-Regu,False,307.2760009765625,754.6926879882812,0.0,8,H3
sample_2.pdf,14,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,342.69781494140625,754.6926879882812,0.07692307692307693,13,H3
sample_2.pdf,14,2017,10.909099578857422,NimbusRomNo9L-Regu,False,402.27227783203125,754.6926879882812,0.0,4,H3
sample_2.pdf,14,"), using representations",10.909099578857422,NimbusRomNo9L-Regu,False,424.09051513671875,754.6926879882812,0.0,24,H3
sample_2.pdf,15,Model,10.909099578857422,NimbusRomNo9L-Medi,False,84.07099914550781,63.920082092285156,0.2,5,H3
sample_2.pdf,15,std.,10.909099578857422,NimbusRomNo9L-Medi,False,243.2332763671875,63.920082092285156,0.0,4,H3
sample_2.pdf,15,Collobert et al.,10.909099578857422,NimbusRomNo9L-Regu,False,84.07099914550781,80.36764526367188,0.0625,16,H3
sample_2.pdf,15,2011,10.909099578857422,NimbusRomNo9L-Regu,False,155.58018493652344,80.36764526367188,0.0,4,H3
sample_2.pdf,15,89.59,10.909099578857422,NimbusRomNo9L-Regu,False,220.62100219726562,80.36764526367188,0.0,5,H3
sample_2.pdf,15,Lample et al.,10.909099578857422,NimbusRomNo9L-Regu,False,84.07099914550781,93.91665649414062,0.07692307692307693,13,H3
sample_2.pdf,15,2016,10.909099578857422,NimbusRomNo9L-Regu,False,147.69290161132812,93.91665649414062,0.0,4,H3
sample_2.pdf,15,90.94,10.909099578857422,NimbusRomNo9L-Regu,False,220.62100219726562,93.91665649414062,0.0,5,H3
sample_2.pdf,15,Ma and Hovy,10.909099578857422,NimbusRomNo9L-Regu,False,84.07099914550781,107.46566772460938,0.18181818181818182,11,H3
sample_2.pdf,15,2016,10.909099578857422,NimbusRomNo9L-Regu,False,150.2565155029297,107.46566772460938,0.0,4,H3
sample_2.pdf,15,91.2,10.909099578857422,NimbusRomNo9L-Regu,False,220.62100219726562,107.46566772460938,0.0,4,H3
sample_2.pdf,15,Chiu and Nichols,10.909099578857422,NimbusRomNo9L-Regu,False,84.07099914550781,121.02468872070312,0.125,16,H3
sample_2.pdf,15,2016,10.909099578857422,NimbusRomNo9L-Regu,False,166.79470825195312,121.02468872070312,0.0,4,H3
sample_2.pdf,15,91.62,10.909099578857422,NimbusRomNo9L-Regu,False,220.62100219726562,121.02468872070312,0.0,5,H3
sample_2.pdf,15,0.33,10.909099578857422,NimbusRomNo9L-Regu,False,256.38128662109375,121.02468872070312,0.0,4,H3
sample_2.pdf,15,Peters et al.,10.909099578857422,NimbusRomNo9L-Regu,False,84.07098388671875,134.58267211914062,0.07692307692307693,13,H3
sample_2.pdf,15,2017,10.909099578857422,NimbusRomNo9L-Regu,False,141.02740478515625,134.58267211914062,0.0,4,H3
sample_2.pdf,15,91.93,10.909099578857422,NimbusRomNo9L-Regu,False,220.62100219726562,134.58267211914062,0.0,5,H3
sample_2.pdf,15,0.19,10.909099578857422,NimbusRomNo9L-Regu,False,256.38128662109375,134.58267211914062,0.0,4,H3
sample_2.pdf,15,biLSTM-CRF + ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,84.07098388671875,148.13168334960938,0.5882352941176471,17,H3
sample_2.pdf,15,92.22,10.909099578857422,NimbusRomNo9L-Medi,False,220.62100219726562,148.03208923339844,0.0,5,H3
sample_2.pdf,15,0.10,10.909099578857422,NimbusRomNo9L-Medi,False,256.38128662109375,148.03208923339844,0.0,4,H3
sample_2.pdf,15,Table 12: Test set F,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,170.66749572753906,0.15,20,H3
sample_2.pdf,15,for CoNLL 2003 NER task. Mod-,9.962599754333496,NimbusRomNo9L-Regu,False,152.9820556640625,170.66749572753906,0.27586206896551724,29,H3
sample_2.pdf,15,els with,9.962599754333496,NimbusRomNo9L-Regu,False,71.99999237060547,182.6225128173828,0.0,8,H3
sample_2.pdf,15,included gazetteers and those with,9.962599754333496,NimbusRomNo9L-Regu,False,117.69099426269531,182.6225128173828,0.0,34,H3
sample_2.pdf,15,used,9.962599754333496,NimbusRomNo9L-Regu,False,272.0059814453125,182.6225128173828,0.0,4,H3
sample_2.pdf,15,both the train and development splits for training.,9.962599754333496,NimbusRomNo9L-Regu,False,71.99998474121094,194.57850646972656,0.0,51,H3
sample_2.pdf,15,Model,10.909099578857422,NimbusRomNo9L-Medi,False,77.97798156738281,217.3571014404297,0.2,5,H3
sample_2.pdf,15,Acc.,10.909099578857422,NimbusRomNo9L-Medi,False,269.2820129394531,217.3571014404297,0.25,4,H3
sample_2.pdf,15,DMN (,10.909099578857422,NimbusRomNo9L-Regu,False,77.97799682617188,233.79568481445312,0.6,5,H3
sample_2.pdf,15,Kumar et al.,10.909099578857422,NimbusRomNo9L-Regu,False,109.78893280029297,233.79568481445312,0.08333333333333333,12,H3
sample_2.pdf,15,2016,10.909099578857422,NimbusRomNo9L-Regu,False,166.5817413330078,233.79568481445312,0.0,4,H3
sample_2.pdf,15,52.1,10.909099578857422,NimbusRomNo9L-Regu,False,269.2820129394531,233.79568481445312,0.0,4,H3
sample_2.pdf,15,LSTM-CNN (,10.909099578857422,NimbusRomNo9L-Regu,False,77.97801208496094,247.34469604492188,0.7,10,H3
sample_2.pdf,15,Zhou et al.,10.909099578857422,NimbusRomNo9L-Regu,False,140.0944366455078,247.34469604492188,0.09090909090909091,11,H3
sample_2.pdf,15,2016,10.909099578857422,NimbusRomNo9L-Regu,False,189.785400390625,247.34469604492188,0.0,4,H3
sample_2.pdf,15,52.4,10.909099578857422,NimbusRomNo9L-Regu,False,269.2820129394531,247.34469604492188,0.0,4,H3
sample_2.pdf,15,NTI (,10.909099578857422,NimbusRomNo9L-Regu,False,77.97801208496094,260.8937072753906,0.6,5,H3
sample_2.pdf,15,Munkhdalai and Yu,10.909099578857422,NimbusRomNo9L-Regu,False,102.5125732421875,260.8937072753906,0.11764705882352941,17,H3
sample_2.pdf,15,2017,10.909099578857422,NimbusRomNo9L-Regu,False,191.29083251953125,260.8937072753906,0.0,4,H3
sample_2.pdf,15,53.1,10.909099578857422,NimbusRomNo9L-Regu,False,269.2820129394531,260.8936462402344,0.0,4,H3
sample_2.pdf,15,BCN+Char+CoVe (,10.909099578857422,NimbusRomNo9L-Regu,False,77.97801208496094,274.4426574707031,0.4,15,H3
sample_2.pdf,15,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,164.51991271972656,274.4426574707031,0.15384615384615385,13,H3
sample_2.pdf,15,2017,10.909099578857422,NimbusRomNo9L-Regu,False,228.75271606445312,274.4426574707031,0.0,4,H3
sample_2.pdf,15,53.7,10.909099578857422,NimbusRomNo9L-Regu,False,269.2820129394531,274.4426574707031,0.0,4,H3
sample_2.pdf,15,BCN+ELMo,10.909099578857422,NimbusRomNo9L-Regu,False,77.97801208496094,287.9916687011719,0.75,8,H3
sample_2.pdf,15,54.7,10.909099578857422,NimbusRomNo9L-Medi,False,269.2820129394531,287.8920593261719,0.0,4,H3
sample_2.pdf,15,Table 13: Test set accuracy for SST-5.,9.962599754333496,NimbusRomNo9L-Regu,False,103.79400634765625,310.5274658203125,0.13157894736842105,38,H3
sample_2.pdf,15,from all layers of the biLM provides a modest im-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,342.8506774902344,0.04081632653061224,49,H3
sample_2.pdf,15,provement.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,356.4006652832031,0.0,10,H3
sample_2.pdf,15,A.8,10.909099578857422,NimbusRomNo9L-Medi,False,72.00000762939453,378.6860656738281,0.3333333333333333,3,H3
sample_2.pdf,15,Sentiment classiﬁcation,10.909099578857422,NimbusRomNo9L-Medi,False,98.9673080444336,378.6860656738281,0.043478260869565216,23,H3
sample_2.pdf,15,We use almost the same biattention classiﬁcation,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,396.2626647949219,0.020833333333333332,48,H3
sample_2.pdf,15,network architecture described in,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,409.8116760253906,0.0,33,H3
sample_2.pdf,15,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,221.814697265625,409.8116760253906,0.15384615384615385,13,H3
sample_2.pdf,15,2017,10.909099578857422,NimbusRomNo9L-Regu,False,75.63273620605469,423.3606872558594,0.0,4,H3
sample_2.pdf,15,"), with the exception of replacing the ﬁnal",10.909099578857422,NimbusRomNo9L-Regu,False,97.45094299316406,423.3606872558594,0.0,43,H3
sample_2.pdf,15,maxout network with a simpler feedforward net-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,436.9096984863281,0.0,46,H3
sample_2.pdf,15,work composed of two ReLu layers with dropout.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,450.4587097167969,0.043478260869565216,46,H3
sample_2.pdf,15,A BCN model with a batch-normalized maxout,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,464.0086975097656,0.09523809523809523,42,H3
sample_2.pdf,15,network reached signiﬁcantly lower validation ac-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,477.5577087402344,0.0,49,H3
sample_2.pdf,15,"curacies in our experiments, although there may",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,491.1067199707031,0.0,47,H3
sample_2.pdf,15,be discrepancies between our implementation and,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,504.6557312011719,0.0,47,H3
sample_2.pdf,15,that of,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,518.2047729492188,0.0,7,H3
sample_2.pdf,15,McCann et al.,10.909099578857422,NimbusRomNo9L-Regu,False,100.5709457397461,518.2047729492188,0.15384615384615385,13,H3
sample_2.pdf,15,2017,10.909099578857422,NimbusRomNo9L-Regu,False,172.7128143310547,518.2047729492188,0.0,4,H3
sample_2.pdf,15,). To match the CoVe,10.909099578857422,NimbusRomNo9L-Regu,False,194.53099060058594,518.2047729492188,0.15,20,H3
sample_2.pdf,15,"training setup, we only train on phrases that con-",10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,531.7547607421875,0.0,50,H3
sample_2.pdf,15,tain four or more tokens. We use 300-d hidden,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,545.3037719726562,0.022222222222222223,45,H3
sample_2.pdf,15,states for the biLSTM and optimize the model pa-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,558.852783203125,0.08333333333333333,48,H3
sample_2.pdf,15,rameters with Adam (,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,572.4017944335938,0.05,20,H3
sample_2.pdf,15,Kingma and Ba,10.909099578857422,NimbusRomNo9L-Regu,False,170.6073760986328,572.4017944335938,0.15384615384615385,13,H3
sample_2.pdf,15,2015,10.909099578857422,NimbusRomNo9L-Regu,False,243.91651916503906,572.4017944335938,0.0,4,H3
sample_2.pdf,15,) us-,10.909099578857422,NimbusRomNo9L-Regu,False,269.52020263671875,572.4017944335938,0.0,5,H3
sample_2.pdf,15,ing a learning rate of 0.0001. The trainable biLM,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,585.9508056640625,0.061224489795918366,49,H3
sample_2.pdf,15,layer weights are regularized by,10.909099578857422,NimbusRomNo9L-Regu,False,72.00000762939453,599.5007934570312,0.0,32,H3
sample_2.pdf,15,= 0,10.909099578857422,CMR10,False,225.2890167236328,599.248291015625,0.0,3,H3
sample_2.pdf,15,001,10.909099578857422,CMR10,False,251.593017578125,599.248291015625,0.0,3,H3
sample_2.pdf,15,", and",10.909099578857422,NimbusRomNo9L-Regu,False,267.95703125,599.5007934570312,0.0,5,H3
sample_2.pdf,15,we add ELMo to both the input and output of the,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,613.0498046875,0.06382978723404255,47,H3
sample_2.pdf,15,biLSTM; the output ELMo vectors are computed,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,626.5987548828125,0.1590909090909091,44,H3
sample_2.pdf,15,with a second biLSTM and concatenated to the in-,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,640.1477661132812,0.08333333333333333,48,H3
sample_2.pdf,15,put.,10.909099578857422,NimbusRomNo9L-Regu,False,72.00003051757812,653.69677734375,0.0,4,H3
sample_3.pdf,1,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,1,EURAL,13.772299766540527,NimbusRomNo9L-Regu,False,121.72100067138672,82.865234375,1.0,5,TITLE
sample_3.pdf,1,ACHINE,13.772299766540527,NimbusRomNo9L-Regu,False,192.33700561523438,82.865234375,1.0,6,TITLE
sample_3.pdf,1,RANSLATION,13.772299766540527,NimbusRomNo9L-Regu,False,264.5899963378906,82.865234375,1.0,10,TITLE
sample_3.pdf,1,OINTLY,13.772299766540527,NimbusRomNo9L-Regu,False,141.1219940185547,102.79022216796875,1.0,6,TITLE
sample_3.pdf,1,EARNING TO,13.772299766540527,NimbusRomNo9L-Regu,False,211.75599670410156,102.79022216796875,0.9,10,TITLE
sample_3.pdf,1,LIGN AND,13.772299766540527,NimbusRomNo9L-Regu,False,321.3819885253906,102.79022216796875,0.875,8,TITLE
sample_3.pdf,1,RANSLATE,13.772299766540527,NimbusRomNo9L-Regu,False,410.0409851074219,102.79022216796875,1.0,8,TITLE
sample_3.pdf,1,Dzmitry Bahdanau,9.962599754333496,NimbusRomNo9L-Medi,False,113.97799682617188,136.6884765625,0.125,16,H3
sample_3.pdf,1,"Jacobs University Bremen, Germany",9.962599754333496,NimbusRomNo9L-Regu,False,113.97799682617188,147.73744201660156,0.12121212121212122,33,H3
sample_3.pdf,1,KyungHyun Cho,9.962599754333496,NimbusRomNo9L-Medi,False,113.97799682617188,175.84149169921875,0.23076923076923078,13,H3
sample_3.pdf,1,Yoshua Bengio,9.962599754333496,NimbusRomNo9L-Medi,False,203.77085876464844,175.84149169921875,0.15384615384615385,13,H3
sample_3.pdf,1,Universit´e de Montr´eal,9.962599754333496,NimbusRomNo9L-Regu,False,113.97799682617188,186.84144592285156,0.08333333333333333,24,H3
sample_3.pdf,1,BSTRACT,9.56410026550293,NimbusRomNo9L-Regu,False,287.5180358886719,228.4396209716797,1.0,7,H3
sample_3.pdf,1,Neural machine translation is a recently proposed approach to machine transla-,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,250.37440490722656,0.01282051282051282,78,H3
sample_3.pdf,1,"tion. Unlike the traditional statistical machine translation, the neural machine",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,261.3333740234375,0.0125,80,H3
sample_3.pdf,1,translation aims at building a single neural network that can be jointly tuned to,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,272.2923583984375,0.0,81,H3
sample_3.pdf,1,maximize the translation performance. The models proposed recently for neu-,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,283.2513427734375,0.013333333333333334,75,H3
sample_3.pdf,1,ral machine translation often belong to a family of encoder–decoders and encode,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,294.2103271484375,0.0,79,H3
sample_3.pdf,1,a source sentence into a ﬁxed-length vector from which a decoder generates a,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,305.1693115234375,0.0,76,H3
sample_3.pdf,1,"translation. In this paper, we conjecture that the use of a ﬁxed-length vector is a",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,316.1273193359375,0.012048192771084338,83,H3
sample_3.pdf,1,bottleneck in improving the performance of this basic encoder–decoder architec-,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,327.0863037109375,0.0,79,H3
sample_3.pdf,1,"ture, and propose to extend this by allowing a model to automatically (soft-)search",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,338.0452880859375,0.0,83,H3
sample_3.pdf,1,"for parts of a source sentence that are relevant to predicting a target word, without",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,349.0042724609375,0.0,85,H3
sample_3.pdf,1,"having to form these parts as a hard segment explicitly. With this new approach,",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,359.9632568359375,0.0125,80,H3
sample_3.pdf,1,we achieve a translation performance comparable to the existing state-of-the-art,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,370.9222412109375,0.0,80,H3
sample_3.pdf,1,"phrase-based system on the task of English-to-French translation. Furthermore,",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,381.8812255859375,0.038461538461538464,78,H3
sample_3.pdf,1,qualitative analysis reveals that the (soft-)alignments found by the model agree,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,392.8402099609375,0.0,80,H3
sample_3.pdf,1,well with our intuition.,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,403.7991943359375,0.0,24,H3
sample_3.pdf,1,NTRODUCTION,9.56410026550293,NimbusRomNo9L-Regu,False,131.4080352783203,435.35943603515625,1.0,11,H3
sample_3.pdf,1,Neural machine translation,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.00003051757812,457.8497314453125,0.038461538461538464,26,H3
sample_3.pdf,1,"is a newly emerging approach to machine translation, recently proposed",9.962599754333496,NimbusRomNo9L-Regu,False,217.28973388671875,458.02618408203125,0.0,70,H3
sample_3.pdf,1,"by Kalchbrenner and Blunsom (2013), Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,468.98516845703125,0.06666666666666667,45,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,305.8870849609375,468.8087158203125,0.0,6,H3
sample_3.pdf,1,(2014) and Cho,9.962599754333496,NimbusRomNo9L-Regu,False,329.4650573730469,468.98516845703125,0.07142857142857142,14,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,396.2278747558594,468.8087158203125,0.0,6,H3
sample_3.pdf,1,(2014b). Unlike the,9.962599754333496,NimbusRomNo9L-Regu,False,419.8050842285156,468.98516845703125,0.05263157894736842,19,H3
sample_3.pdf,1,"traditional phrase-based translation system (see, e.g., Koehn",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,479.94415283203125,0.01639344262295082,61,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,351.9543151855469,479.7677001953125,0.0,6,H3
sample_3.pdf,1,", 2003) which consists of many",9.962599754333496,NimbusRomNo9L-Regu,False,375.8720397949219,479.94415283203125,0.0,30,H3
sample_3.pdf,1,"small sub-components that are tuned separately, neural machine translation attempts to build and",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,490.90313720703125,0.0,96,H3
sample_3.pdf,1,"train a single, large neural network that reads a sentence and outputs a correct translation.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,501.86114501953125,0.0,93,H3
sample_3.pdf,1,Most of the proposed neural machine translation models belong to a family of,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,518.7981567382812,0.013157894736842105,76,H3
sample_3.pdf,1,encoder–,9.962599754333496,NimbusRomNo9L-ReguItal,False,461.0744323730469,518.6217041015625,0.0,8,H3
sample_3.pdf,1,decoders,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.00003051757812,529.5806884765625,0.0,8,H3
sample_3.pdf,1,(Sutskever,9.962599754333496,NimbusRomNo9L-Regu,False,143.8654022216797,529.7571411132812,0.1,10,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,189.16494750976562,529.5806884765625,0.0,6,H3
sample_3.pdf,1,", 2014; Cho",9.962599754333496,NimbusRomNo9L-Regu,False,212.97402954101562,529.7571411132812,0.09090909090909091,11,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,261.1431579589844,529.5806884765625,0.0,6,H3
sample_3.pdf,1,", 2014a), with an encoder and a decoder for each lan-",9.962599754333496,NimbusRomNo9L-Regu,False,284.9520263671875,529.7571411132812,0.0,53,H3
sample_3.pdf,1,"guage, or involve a language-speciﬁc encoder applied to each sentence whose outputs are then com-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,540.7161865234375,0.0,97,H3
sample_3.pdf,1,"pared (Hermann and Blunsom, 2014). An encoder neural network reads and encodes a source sen-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,551.6751708984375,0.03260869565217391,92,H3
sample_3.pdf,1,tence into a ﬁxed-length vector. A decoder then outputs a translation from the encoded vector. The,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,562.6341552734375,0.02040816326530612,98,H3
sample_3.pdf,1,"whole encoder–decoder system, which consists of the encoder and the decoder for a language pair,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,573.5931396484375,0.0,96,H3
sample_3.pdf,1,is jointly trained to maximize the probability of a correct translation given a source sentence.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,584.5511474609375,0.0,96,H3
sample_3.pdf,1,A potential issue with this encoder–decoder approach is that a neural network needs to be able to,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,601.4881591796875,0.010309278350515464,97,H3
sample_3.pdf,1,compress all the necessary information of a source sentence into a ﬁxed-length vector. This may,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,612.4471435546875,0.010526315789473684,95,H3
sample_3.pdf,1,"make it difﬁcult for the neural network to cope with long sentences, especially those that are longer",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,623.4061279296875,0.0,101,H3
sample_3.pdf,1,than the sentences in the training corpus. Cho,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,634.3651123046875,0.021739130434782608,46,H3
sample_3.pdf,1,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,290.1064147949219,634.1886596679688,0.0,6,H3
sample_3.pdf,1,(2014b) showed that indeed the performance of,9.962599754333496,NimbusRomNo9L-Regu,False,312.5252380371094,634.3651123046875,0.0,45,H3
sample_3.pdf,1,a basic encoder–decoder deteriorates rapidly as the length of an input sentence increases.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,645.3241577148438,0.0,90,H3
sample_3.pdf,1,"In order to address this issue, we introduce an extension to the encoder–decoder model which learns",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,662.2601318359375,0.010101010101010102,99,H3
sample_3.pdf,1,"to align and translate jointly. Each time the proposed model generates a word in a translation, it",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,673.2191162109375,0.01020408163265306,98,H3
sample_3.pdf,1,(soft-)searches for a set of positions in a source sentence where the most relevant information is,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,684.1781616210938,0.0,98,H3
sample_3.pdf,1,concentrated. The model then predicts a target word based on the context vectors associated with,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,695.1371459960938,0.010416666666666666,96,H3
sample_3.pdf,1,these source positions and all the previous generated target words.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,706.0961303710938,0.0,67,H3
sample_3.pdf,1,CIFAR Senior Fellow,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.3684210526315789,19,P
sample_3.pdf,1,arXiv:1409.0473v7  [cs.CL]  19 May 2016,20.0,Times-Roman,False,10.940000534057617,211.699951171875,0.10256410256410256,39,TITLE
sample_3.pdf,2,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,2,The most important distinguishing feature of this approach from the basic encoder–decoder is that,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.010309278350515464,97,H3
sample_3.pdf,2,"it does not attempt to encode a whole input sentence into a single ﬁxed-length vector. Instead, it en-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,95.22743225097656,0.00980392156862745,102,H3
sample_3.pdf,2,codes the input sentence into a sequence of vectors and chooses a subset of these vectors adaptively,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,106.18641662597656,0.0,100,H3
sample_3.pdf,2,while decoding the translation. This frees a neural translation model from having to squash all the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,117.14540100097656,0.010101010101010102,99,H3
sample_3.pdf,2,"information of a source sentence, regardless of its length, into a ﬁxed-length vector. We show this",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,128.10438537597656,0.010101010101010102,99,H3
sample_3.pdf,2,allows a model to cope better with long sentences.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,139.06336975097656,0.0,50,H3
sample_3.pdf,2,"In this paper, we show that the proposed approach of jointly learning to align and translate achieves",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,155.9993438720703,0.009900990099009901,101,H3
sample_3.pdf,2,signiﬁcantly improved translation performance over the basic encoder–decoder approach. The im-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,166.9583282470703,0.010638297872340425,94,H3
sample_3.pdf,2,"provement is more apparent with longer sentences, but can be observed with sentences of any",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,177.9173126220703,0.0,91,H3
sample_3.pdf,2,"length. On the task of English-to-French translation, the proposed approach achieves, with a single",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,188.8762969970703,0.030303030303030304,99,H3
sample_3.pdf,2,"model, a translation performance comparable, or close, to the conventional phrase-based system.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,199.8352813720703,0.0,95,H3
sample_3.pdf,2,"Furthermore, qualitative analysis reveals that the proposed model ﬁnds a linguistically plausible",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,210.7942657470703,0.010309278350515464,97,H3
sample_3.pdf,2,(soft-)alignment between a source sentence and the corresponding target sentence.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,221.7532501220703,0.0,81,H3
sample_3.pdf,2,ACKGROUND,9.56410026550293,NimbusRomNo9L-Regu,False,135.031005859375,250.17149353027344,1.0,9,H3
sample_3.pdf,2,: N,11.9552001953125,NimbusRomNo9L-Regu,False,200.67599487304688,248.3581085205078,0.3333333333333333,3,H3
sample_3.pdf,2,EURAL,9.56410026550293,NimbusRomNo9L-Regu,False,217.53199768066406,250.17149353027344,1.0,5,H3
sample_3.pdf,2,ACHINE,9.56410026550293,NimbusRomNo9L-Regu,False,266.5719909667969,250.17149353027344,1.0,6,H3
sample_3.pdf,2,RANSLATION,9.56410026550293,NimbusRomNo9L-Regu,False,316.74700927734375,250.17149353027344,1.0,10,H3
sample_3.pdf,2,"From a probabilistic perspective, translation is equivalent to ﬁnding a target sentence",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,272.7562561035156,0.011494252873563218,87,H3
sample_3.pdf,2,that max-,9.962599754333496,NimbusRomNo9L-Regu,False,462.1383056640625,272.7562561035156,0.0,9,H3
sample_3.pdf,2,imizes the conditional probability of,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,283.71527099609375,0.0,37,H3
sample_3.pdf,2,given a source sentence,9.962599754333496,NimbusRomNo9L-Regu,False,268.50830078125,283.71527099609375,0.0,23,H3
sample_3.pdf,2,", i.e.,",9.962599754333496,NimbusRomNo9L-Regu,False,380.5979919433594,283.71527099609375,0.0,7,H3
sample_3.pdf,2,arg max,9.962599754333496,CMR10,False,401.98773193359375,283.4847412109375,0.0,7,H3
sample_3.pdf,2,. In,9.962599754333496,NimbusRomNo9L-Regu,False,485.94195556640625,283.71527099609375,0.25,4,H3
sample_3.pdf,2,"neural machine translation, we ﬁt a parameterized model to maximize the conditional probability",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,294.67327880859375,0.0,95,H3
sample_3.pdf,2,of sentence pairs using a parallel training corpus. Once the conditional distribution is learned by a,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,305.63226318359375,0.009900990099009901,101,H3
sample_3.pdf,2,"translation model, given a source sentence a corresponding translation can be generated by searching",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,316.59124755859375,0.0,100,H3
sample_3.pdf,2,for the sentence that maximizes the conditional probability.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,327.55023193359375,0.0,60,H3
sample_3.pdf,2,"Recently, a number of papers have proposed the use of neural networks to directly learn this condi-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,344.48724365234375,0.010101010101010102,99,H3
sample_3.pdf,2,"tional distribution (see, e.g., Kalchbrenner and Blunsom, 2013; Cho",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,355.44622802734375,0.04477611940298507,67,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,381.134521484375,355.269775390625,0.0,6,H3
sample_3.pdf,2,", 2014a; Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,404.2669677734375,355.44622802734375,0.05555555555555555,18,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,478.3687438964844,355.269775390625,0.0,6,H3
sample_3.pdf,2,2014; Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,366.40423583984375,0.1111111111111111,9,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,150.23141479492188,366.227783203125,0.0,6,H3
sample_3.pdf,2,", 2014b; Forcada and",9.962599754333496,NimbusRomNo9L-Regu,False,173.53497314453125,366.40423583984375,0.05,20,H3
sample_3.pdf,2,"Neco, 1997). This neural machine translation approach typ-",9.962599754333496,NimbusRomNo9L-Regu,False,261.75799560546875,366.40423583984375,0.034482758620689655,58,H3
sample_3.pdf,2,"ically consists of two components, the ﬁrst of which encodes a source sentence",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,377.36322021484375,0.0,78,H3
sample_3.pdf,2,and the second,9.962599754333496,NimbusRomNo9L-Regu,False,440.2222900390625,377.36322021484375,0.0,14,H3
sample_3.pdf,2,decodes to a target sentence,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,388.32220458984375,0.0,28,H3
sample_3.pdf,2,". For instance, two recurrent neural networks (RNN) were used by",9.962599754333496,NimbusRomNo9L-Regu,False,231.23196411132812,388.32220458984375,0.0625,64,H3
sample_3.pdf,2,(Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,399.28118896484375,0.25,4,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,127.92516326904297,399.104736328125,0.0,6,H3
sample_3.pdf,2,", 2014a) and (Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,151.376953125,399.28118896484375,0.043478260869565216,23,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,247.0577392578125,399.104736328125,0.0,6,H3
sample_3.pdf,2,", 2014) to encode a variable-length source sentence into a",9.962599754333496,NimbusRomNo9L-Regu,False,270.5089416503906,399.28118896484375,0.0,58,H3
sample_3.pdf,2,ﬁxed-length vector and to decode the vector into a variable-length target sentence.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,410.24017333984375,0.0,83,H3
sample_3.pdf,2,"Despite being a quite new approach, neural machine translation has already shown promising results.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,427.1761779785156,0.010101010101010102,99,H3
sample_3.pdf,2,Sutskever,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,438.13519287109375,0.1111111111111111,9,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,146.79429626464844,437.958740234375,0.0,6,H3
sample_3.pdf,2,(2014) reported that the neural machine translation based on RNNs with long short-,9.962599754333496,NimbusRomNo9L-Regu,False,169.02748107910156,438.13519287109375,0.036585365853658534,82,H3
sample_3.pdf,2,term memory (LSTM) units achieves close to the state-of-the-art performance of the conventional,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,449.09417724609375,0.042105263157894736,95,H3
sample_3.pdf,2,phrase-based machine translation system on an English-to-French translation task.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,460.05316162109375,0.024691358024691357,81,H3
sample_3.pdf,2,Adding neural,9.962599754333496,NimbusRomNo9L-Regu,False,446.41094970703125,460.05316162109375,0.07692307692307693,13,H3
sample_3.pdf,2,"components to existing translation systems, for instance, to score the phrase pairs in the phrase",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,471.01214599609375,0.0,97,H3
sample_3.pdf,2,table (Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,481.97113037109375,0.1,10,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,149.80299377441406,481.794677734375,0.0,6,H3
sample_3.pdf,2,", 2014a) or to re-rank candidate translations (Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,172.2439422607422,481.97113037109375,0.017857142857142856,56,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,390.9826965332031,481.794677734375,0.0,6,H3
sample_3.pdf,2,", 2014), has allowed to",9.962599754333496,NimbusRomNo9L-Regu,False,413.4249267578125,481.97113037109375,0.0,23,H3
sample_3.pdf,2,surpass the previous state-of-the-art performance level.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,492.93011474609375,0.0,56,H3
sample_3.pdf,2,2.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24893951416016,517.1611328125,0.0,3,H3
sample_3.pdf,2,RNN E,9.962599754333496,NimbusRomNo9L-Regu,False,132.1591796875,517.1611328125,0.8,5,H3
sample_3.pdf,2,NCODER,7.970099925994873,NimbusRomNo9L-Regu,False,163.7609405517578,518.6722412109375,1.0,6,P
sample_3.pdf,2,ECODER,7.970099925994873,NimbusRomNo9L-Regu,False,212.64694213867188,518.6722412109375,1.0,6,P
sample_3.pdf,2,"Here, we describe brieﬂy the underlying framework, called",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,537.68408203125,0.017543859649122806,57,H3
sample_3.pdf,2,RNN Encoder–Decoder,9.962599754333496,NimbusRomNo9L-ReguItal,False,349.31402587890625,537.5076293945312,0.2631578947368421,19,H3
sample_3.pdf,2,", proposed by",9.962599754333496,NimbusRomNo9L-Regu,False,448.1729431152344,537.68408203125,0.0,13,H3
sample_3.pdf,2,Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,548.64306640625,0.3333333333333333,3,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,124.60759735107422,548.4666137695312,0.0,6,H3
sample_3.pdf,2,(2014a) and Sutskever,9.962599754333496,NimbusRomNo9L-Regu,False,147.40443420410156,548.64306640625,0.047619047619047616,21,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,239.62379455566406,548.4666137695312,0.0,6,H3
sample_3.pdf,2,(2014) upon which we build a novel architecture that learns,9.962599754333496,NimbusRomNo9L-Regu,False,262.41644287109375,548.64306640625,0.0,59,H3
sample_3.pdf,2,to align and translate simultaneously.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,559.6021118164062,0.0,38,H3
sample_3.pdf,2,"In the Encoder–Decoder framework, an encoder reads the input sentence, a sequence of vectors",9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,576.5380859375,0.03260869565217391,92,H3
sample_3.pdf,2,= (,9.962599754333496,CMR10,False,114.04722595214844,587.2665405273438,0.0,3,H3
sample_3.pdf,2,", x",9.962599754333496,CMMI10,False,157.42230224609375,587.2665405273438,0.0,3,H3
sample_3.pdf,2,", into a vector",9.962599754333496,NimbusRomNo9L-Regu,False,184.3809051513672,587.4970703125,0.0,15,H3
sample_3.pdf,2,The most common approach is to use an RNN such that,9.962599754333496,NimbusRomNo9L-Regu,False,255.3819122314453,587.4970703125,0.0784313725490196,51,H3
sample_3.pdf,2,", h",9.962599754333496,CMMI10,False,313.73486328125,600.8935546875,0.0,3,H3
sample_3.pdf,2,(1),9.962599754333496,NimbusRomNo9L-Regu,False,492.38385009765625,601.1240844726562,0.0,3,H3
sample_3.pdf,2,and,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,614.7510986328125,0.0,3,H3
sample_3.pdf,2,", h",9.962599754333496,CMMI10,False,317.38214111328125,628.1475830078125,0.0,3,H3
sample_3.pdf,2,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99980163574219,642.005126953125,0.0,5,H3
sample_3.pdf,2,is a hidden state at time,9.962599754333496,NimbusRomNo9L-Regu,False,176.60281372070312,642.005126953125,0.0,25,H3
sample_3.pdf,2,", and",9.962599754333496,NimbusRomNo9L-Regu,False,282.01080322265625,642.005126953125,0.0,5,H3
sample_3.pdf,2,is a vector generated from the sequence of the,9.962599754333496,NimbusRomNo9L-Regu,False,310.2496032714844,642.005126953125,0.0,46,H3
sample_3.pdf,2,hidden states.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99980163574219,652.964111328125,0.0,14,H3
sample_3.pdf,2,and,9.962599754333496,NimbusRomNo9L-Regu,False,169.96847534179688,652.964111328125,0.0,3,H3
sample_3.pdf,2,are some nonlinear functions. Sutskever,9.962599754333496,NimbusRomNo9L-Regu,False,194.49111938476562,652.964111328125,0.02564102564102564,39,H3
sample_3.pdf,2,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,356.3172912597656,652.7876586914062,0.0,6,H3
sample_3.pdf,2,(2014) used an LSTM as,9.962599754333496,NimbusRomNo9L-Regu,False,378.379638671875,652.964111328125,0.18181818181818182,22,H3
sample_3.pdf,2,and,9.962599754333496,NimbusRomNo9L-Regu,False,486.2324523925781,652.964111328125,0.0,3,H3
sample_3.pdf,2,", h",9.962599754333496,CMMI10,False,149.58412170410156,663.6925659179688,0.0,3,H3
sample_3.pdf,2,) =,9.962599754333496,CMR10,False,174.32675170898438,663.6925659179688,0.0,3,H3
sample_3.pdf,2,", for instance.",9.962599754333496,NimbusRomNo9L-Regu,False,201.9320831298828,663.923095703125,0.0,15,H3
sample_3.pdf,2,"We mean by the state-of-the-art performance, the performance of the conventional phrase-based system",8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,678.4899291992188,0.01,100,P
sample_3.pdf,2,without using any neural network-based component.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,692.261962890625,0.0,49,P
sample_3.pdf,2,"Although most of the previous works (see, e.g., Cho",8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,699.3269653320312,0.0392156862745098,51,P
sample_3.pdf,2,et al.,8.966400146484375,NimbusRomNo9L-ReguItal,False,309.94970703125,702.9771118164062,0.0,6,P
sample_3.pdf,2,", 2014a; Sutskever",8.966400146484375,NimbusRomNo9L-Regu,False,329.3500061035156,703.1359252929688,0.05555555555555555,18,P
sample_3.pdf,2,et al.,8.966400146484375,NimbusRomNo9L-ReguItal,False,394.6253662109375,702.9771118164062,0.0,6,P
sample_3.pdf,2,", 2014; Kalchbrenner and",8.966400146484375,NimbusRomNo9L-Regu,False,414.0249938964844,703.1359252929688,0.041666666666666664,24,P
sample_3.pdf,2,"Blunsom, 2013) used to encode a variable-length input sentence into a",8.966400146484375,NimbusRomNo9L-Regu,False,108.0,713.0989379882812,0.014492753623188406,69,P
sample_3.pdf,2,ﬁxed-length,8.966400146484375,NimbusRomNo9L-ReguItal,False,363.174560546875,712.9401245117188,0.0,11,P
sample_3.pdf,2,"vector, it is not necessary,",8.966400146484375,NimbusRomNo9L-Regu,False,408.058349609375,713.0989379882812,0.0,28,P
sample_3.pdf,2,and even it may be beneﬁcial to have a,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,723.0619506835938,0.0,38,P
sample_3.pdf,2,variable-length,8.966400146484375,NimbusRomNo9L-ReguItal,False,246.7730255126953,722.9031372070312,0.0,15,P
sample_3.pdf,2,"vector, as we will show later.",8.966400146484375,NimbusRomNo9L-Regu,False,304.29974365234375,723.0619506835938,0.0,30,P
sample_3.pdf,3,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,3,The decoder is often trained to predict the next word,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.018867924528301886,53,H3
sample_3.pdf,3,given the context vector,9.962599754333496,NimbusRomNo9L-Regu,False,343.457763671875,83.77046203613281,0.0,24,H3
sample_3.pdf,3,and all the,9.962599754333496,NimbusRomNo9L-Regu,False,455.90283203125,84.26844787597656,0.0,11,H3
sample_3.pdf,3,previously predicted words,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,95.22743225097656,0.0,26,H3
sample_3.pdf,3,", y",9.962599754333496,CMMI10,False,249.5194091796875,94.99687194824219,0.0,3,H3
sample_3.pdf,3,". In other words, the decoder deﬁnes a probability over",9.962599754333496,NimbusRomNo9L-Regu,False,283.5310363769531,95.22743225097656,0.01818181818181818,55,H3
sample_3.pdf,3,the translation,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,106.18641662597656,0.0,15,H3
sample_3.pdf,3,by decomposing the joint probability into the ordered conditionals:,9.962599754333496,NimbusRomNo9L-Regu,False,173.2643280029297,106.18641662597656,0.0,67,H3
sample_3.pdf,3,) =,9.962599754333496,CMR10,False,245.42501831054688,133.6538543701172,0.0,3,H3
sample_3.pdf,3,| {,9.962599754333496,CMSY10,False,294.1236877441406,133.52479553222656,0.0,3,H3
sample_3.pdf,3,", y",9.962599754333496,CMMI10,False,333.310302734375,133.65391540527344,0.0,3,H3
sample_3.pdf,3,", c",9.962599754333496,CMMI10,False,364.62628173828125,133.65391540527344,0.0,3,H3
sample_3.pdf,3,(2),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,133.8844757080078,0.0,3,H3
sample_3.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,162.30848693847656,0.0,5,H3
sample_3.pdf,3,", y",9.962599754333496,CMMI10,False,184.29237365722656,162.0779266357422,0.0,3,H3
sample_3.pdf,3,". With an RNN, each conditional probability is modeled as",9.962599754333496,NimbusRomNo9L-Regu,False,211.00900268554688,162.3085479736328,0.07017543859649122,57,H3
sample_3.pdf,3,| {,9.962599754333496,CMSY10,False,237.5816650390625,180.43287658691406,0.0,3,H3
sample_3.pdf,3,", y",9.962599754333496,CMMI10,False,276.768310546875,180.56199645996094,0.0,3,H3
sample_3.pdf,3,", c",9.962599754333496,CMMI10,False,308.0853271484375,180.56199645996094,0.0,3,H3
sample_3.pdf,3,) =,9.962599754333496,CMR10,False,318.4840393066406,180.56199645996094,0.0,3,H3
sample_3.pdf,3,", s",9.962599754333496,CMMI10,False,363.21600341796875,180.56199645996094,0.0,3,H3
sample_3.pdf,3,", c",9.962599754333496,CMMI10,False,375.8219909667969,180.56199645996094,0.0,3,H3
sample_3.pdf,3,(3),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,180.7925567626953,0.0,3,H3
sample_3.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,198.08058166503906,0.0,5,H3
sample_3.pdf,3,"is a nonlinear, potentially multi-layered, function that outputs the probability of",9.962599754333496,NimbusRomNo9L-Regu,False,139.2791748046875,198.08058166503906,0.0,83,H3
sample_3.pdf,3,", and",9.962599754333496,NimbusRomNo9L-Regu,False,465.6750183105469,198.08058166503906,0.0,5,H3
sample_3.pdf,3,the hidden state of the RNN. It should be noted that other architectures such as a hybrid of an RNN,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,209.03956604003906,0.0707070707070707,99,H3
sample_3.pdf,3,"and a de-convolutional neural network can be used (Kalchbrenner and Blunsom, 2013).",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,219.99855041503906,0.024096385542168676,83,H3
sample_3.pdf,3,EARNING TO,9.56410026550293,NimbusRomNo9L-Regu,False,134.73204040527344,249.07579040527344,0.9,10,H3
sample_3.pdf,3,LIGN AND,9.56410026550293,NimbusRomNo9L-Regu,False,210.86105346679688,249.07579040527344,0.875,8,H3
sample_3.pdf,3,RANSLATE,9.56410026550293,NimbusRomNo9L-Regu,False,272.4300537109375,249.07579040527344,1.0,8,H3
sample_3.pdf,3,"In this section, we propose a novel architecture for neural machine translation. The new architecture",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,272.31854248046875,0.019801980198019802,101,H3
sample_3.pdf,3,consists of a bidirectional RNN as an encoder (Sec. 3.2) and a decoder that emulates searching,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,283.27752685546875,0.0425531914893617,94,H3
sample_3.pdf,3,through a source sentence during decoding a translation (Sec. 3.1).,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,294.23651123046875,0.014925373134328358,67,H3
sample_3.pdf,3,3.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24906158447266,319.12652587890625,0.0,3,H3
sample_3.pdf,3,ECODER,7.970099925994873,NimbusRomNo9L-Regu,False,139.85105895996094,320.63763427734375,1.0,6,P
sample_3.pdf,3,: G,9.962599754333496,NimbusRomNo9L-Regu,False,174.67906188964844,319.12652587890625,0.3333333333333333,3,H3
sample_3.pdf,3,ENERAL,7.970099925994873,NimbusRomNo9L-Regu,False,188.72706604003906,320.63763427734375,1.0,6,P
sample_3.pdf,3,ESCRIPTION,7.970099925994873,NimbusRomNo9L-Regu,False,233.2890625,320.63763427734375,1.0,10,P
sample_3.pdf,3,"t,1",5.077171802520752,BitstreamVeraSans-Roman,False,409.8197021484375,418.0811462402344,0.0,3,P
sample_3.pdf,3,"t,2",4.823312759399414,BitstreamVeraSans-Roman,False,417.1496887207031,428.9750061035156,0.0,3,P
sample_3.pdf,3,"t,3",4.823312759399414,BitstreamVeraSans-Roman,False,449.43359375,430.3544616699219,0.0,3,P
sample_3.pdf,3,"t,T",4.823312759399414,BitstreamVeraSans-Roman,False,464.75213623046875,419.8304443359375,0.3333333333333333,3,P
sample_3.pdf,3,t-1,6.906853199005127,BitstreamVeraSans-Roman,False,425.5003662109375,355.6778564453125,0.0,3,P
sample_3.pdf,3,t-1,5.077171802520752,BitstreamVeraSans-Roman,False,423.7228698730469,373.4351806640625,0.0,3,P
sample_3.pdf,3,Figure 1: The graphical illus-,9.962599754333496,NimbusRomNo9L-Regu,False,385.1990051269531,521.689453125,0.06666666666666667,30,H3
sample_3.pdf,3,tration of the proposed model,9.962599754333496,NimbusRomNo9L-Regu,False,385.1990051269531,532.6484375,0.0,29,H3
sample_3.pdf,3,trying to generate the,9.962599754333496,NimbusRomNo9L-Regu,False,385.1990051269531,543.607421875,0.0,22,H3
sample_3.pdf,3,-th tar-,9.962599754333496,NimbusRomNo9L-Regu,False,476.69500732421875,543.607421875,0.0,8,H3
sample_3.pdf,3,get word,9.962599754333496,NimbusRomNo9L-Regu,False,385.1990051269531,554.5664672851562,0.0,8,H3
sample_3.pdf,3,given a source,9.962599754333496,NimbusRomNo9L-Regu,False,435.9226989746094,554.5664672851562,0.0,14,H3
sample_3.pdf,3,sentence,9.962599754333496,NimbusRomNo9L-Regu,False,385.1990051269531,565.5254516601562,0.0,8,H3
sample_3.pdf,3,", x",9.962599754333496,CMMI10,False,436.0279846191406,565.294921875,0.0,3,H3
sample_3.pdf,3,", . . . , x",9.962599754333496,CMMI10,False,450.6189880371094,565.294921875,0.0,11,H3
sample_3.pdf,3,"In a new model architecture, we deﬁne each conditional probability",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,339.6494445800781,0.015151515151515152,66,H3
sample_3.pdf,3,in Eq. (2) as:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,350.60845947265625,0.07142857142857142,14,H3
sample_3.pdf,3,", . . . , y",9.962599754333496,CMMI10,False,192.88998413085938,367.6659240722656,0.0,11,H3
sample_3.pdf,3,) =,9.962599754333496,CMR10,False,243.90296936035156,367.6659240722656,0.0,3,H3
sample_3.pdf,3,", s",9.962599754333496,CMMI10,False,288.44293212890625,367.6659240722656,0.0,3,H3
sample_3.pdf,3,", c",9.962599754333496,CMMI10,False,300.85791015625,367.6659240722656,0.0,3,H3
sample_3.pdf,3,(4),9.962599754333496,NimbusRomNo9L-Regu,False,363.6199035644531,367.8964538574219,0.0,3,H3
sample_3.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,385.1844482421875,0.0,5,H3
sample_3.pdf,3,is an RNN hidden state for time,9.962599754333496,NimbusRomNo9L-Regu,False,142.31631469726562,385.1844482421875,0.0967741935483871,31,H3
sample_3.pdf,3,", computed by",9.962599754333496,NimbusRomNo9L-Regu,False,277.962890625,385.1844482421875,0.0,13,H3
sample_3.pdf,3,", y",9.962599754333496,CMMI10,False,245.494873046875,402.242919921875,0.0,3,H3
sample_3.pdf,3,", c",9.962599754333496,CMMI10,False,268.3218688964844,402.242919921875,0.0,3,H3
sample_3.pdf,3,It should be noted that unlike the existing encoder–decoder ap-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99986267089844,419.7614440917969,0.015873015873015872,63,H3
sample_3.pdf,3,"proach (see Eq. (2)), here the probability is conditioned on a distinct",9.962599754333496,NimbusRomNo9L-Regu,False,107.99986267089844,430.720458984375,0.014084507042253521,71,H3
sample_3.pdf,3,context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.99986267089844,441.679443359375,0.0,14,H3
sample_3.pdf,3,for each target word,9.962599754333496,NimbusRomNo9L-Regu,False,174.0372772216797,441.679443359375,0.0,20,H3
sample_3.pdf,3,The context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.99986267089844,458.6154479980469,0.05555555555555555,18,H3
sample_3.pdf,3,depends on a sequence of,9.962599754333496,NimbusRomNo9L-Regu,False,201.644287109375,458.6154479980469,0.0,24,H3
sample_3.pdf,3,annotations,9.962599754333496,NimbusRomNo9L-ReguItal,False,322.4825134277344,458.4389953613281,0.0,11,H3
sample_3.pdf,3,", h",9.962599754333496,CMMI10,False,138.1382293701172,469.34393310546875,0.0,3,H3
sample_3.pdf,3,to which an encoder maps the input sentence. Each,9.962599754333496,NimbusRomNo9L-Regu,False,165.14431762695312,469.574462890625,0.02040816326530612,49,H3
sample_3.pdf,3,annotation,9.962599754333496,NimbusRomNo9L-Regu,False,107.99986267089844,480.533447265625,0.0,10,H3
sample_3.pdf,3,contains information about the whole input sequence,9.962599754333496,NimbusRomNo9L-Regu,False,161.1462860107422,480.533447265625,0.0,51,H3
sample_3.pdf,3,with a strong focus on the parts surrounding the,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,491.492431640625,0.0,48,H3
sample_3.pdf,3,-th word of the,9.962599754333496,NimbusRomNo9L-Regu,False,312.96087646484375,491.492431640625,0.0,15,H3
sample_3.pdf,3,input sequence. We explain in detail how the annotations are com-,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,502.451416015625,0.015384615384615385,65,H3
sample_3.pdf,3,puted in the next section.,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,513.410400390625,0.0,26,H3
sample_3.pdf,3,The context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,530.346435546875,0.05555555555555555,18,H3
sample_3.pdf,3,"is, then, computed as a weighted sum of these",9.962599754333496,NimbusRomNo9L-Regu,False,191.40028381347656,530.346435546875,0.0,45,H3
sample_3.pdf,3,annotations,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,541.305419921875,0.0,11,H3
sample_3.pdf,3,(5),9.962599754333496,NimbusRomNo9L-Regu,False,363.6199035644531,568.451416015625,0.0,3,H3
sample_3.pdf,3,The weight,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,596.8023681640625,0.1,10,H3
sample_3.pdf,3,of each annotation,9.962599754333496,NimbusRomNo9L-Regu,False,168.07994079589844,596.8023681640625,0.0,18,H3
sample_3.pdf,3,is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,256.5945129394531,596.8023681640625,0.0,14,H3
sample_3.pdf,3,exp (,9.962599754333496,CMR10,False,299.8099060058594,614.2188720703125,0.0,5,H3
sample_3.pdf,3,exp (,9.962599754333496,CMR10,False,313.0409851074219,629.637939453125,0.0,5,H3
sample_3.pdf,3,(6),9.962599754333496,NimbusRomNo9L-Regu,False,492.384033203125,621.189453125,0.0,3,H3
sample_3.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,646.9764404296875,0.0,5,H3
sample_3.pdf,3,", h",9.962599754333496,CMMI10,False,323.01202392578125,657.7048950195312,0.0,3,H3
sample_3.pdf,3,is an,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,672.4934692382812,0.0,5,H3
sample_3.pdf,3,alignment model,9.962599754333496,NimbusRomNo9L-ReguItal,False,126.41089630126953,672.3170166015625,0.0,15,H3
sample_3.pdf,3,which scores how well the inputs around position,9.962599754333496,NimbusRomNo9L-Regu,False,195.33212280273438,672.4934692382812,0.0,48,H3
sample_3.pdf,3,and the output at position,9.962599754333496,NimbusRomNo9L-Regu,False,400.2995910644531,672.4934692382812,0.0,26,H3
sample_3.pdf,3,match. The score is based on the RNN hidden state,9.962599754333496,NimbusRomNo9L-Regu,False,111.43709564208984,683.4514770507812,0.08163265306122448,49,H3
sample_3.pdf,3,(just before emitting,9.962599754333496,NimbusRomNo9L-Regu,False,340.2530822753906,683.4514770507812,0.0,21,H3
sample_3.pdf,3,", Eq. (4)) and the",9.962599754333496,NimbusRomNo9L-Regu,False,435.8699951171875,683.4514770507812,0.05555555555555555,18,H3
sample_3.pdf,3,-th annotation,9.962599754333496,NimbusRomNo9L-Regu,False,112.6729965209961,694.4104614257812,0.0,14,H3
sample_3.pdf,3,of the input sentence.,9.962599754333496,NimbusRomNo9L-Regu,False,179.8236083984375,694.4104614257812,0.0,22,H3
sample_3.pdf,3,We parametrize the alignment model,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,711.3474731445312,0.029411764705882353,34,H3
sample_3.pdf,3,as a feedforward neural network which is jointly trained with,9.962599754333496,NimbusRomNo9L-Regu,False,261.1252136230469,711.3474731445312,0.0,61,H3
sample_3.pdf,3,"all the other components of the proposed system. Note that unlike in traditional machine translation,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,722.3064575195312,0.009900990099009901,101,H3
sample_3.pdf,4,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,4,"the alignment is not considered to be a latent variable. Instead, the alignment model directly com-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.010101010101010102,99,H3
sample_3.pdf,4,"putes a soft alignment, which allows the gradient of the cost function to be backpropagated through.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,95.22743225097656,0.0,100,H3
sample_3.pdf,4,This gradient can be used to train the alignment model as well as the whole translation model jointly.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,106.18641662597656,0.00980392156862745,102,H3
sample_3.pdf,4,We can understand the approach of taking a weighted sum of all the annotations as computing an,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,123.12342834472656,0.010638297872340425,94,H3
sample_3.pdf,4,expected annotation,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0,133.90594482421875,0.0,19,H3
sample_3.pdf,4,", where the expectation is over possible alignments. Let",9.962599754333496,NimbusRomNo9L-Regu,False,188.00100708007812,134.08241271972656,0.017857142857142856,56,H3
sample_3.pdf,4,be a probability that,9.962599754333496,NimbusRomNo9L-Regu,False,421.90802001953125,134.08241271972656,0.0,21,H3
sample_3.pdf,4,the target word,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,145.04139709472656,0.0,15,H3
sample_3.pdf,4,"is aligned to, or translated from, a source word",9.962599754333496,NimbusRomNo9L-Regu,False,179.01641845703125,145.04139709472656,0.0,48,H3
sample_3.pdf,4,". Then, the",9.962599754333496,NimbusRomNo9L-Regu,False,382.9840087890625,145.04139709472656,0.09090909090909091,11,H3
sample_3.pdf,4,-th context vector,9.962599754333496,NimbusRomNo9L-Regu,False,433.49603271484375,145.04139709472656,0.0,18,H3
sample_3.pdf,4,is the expected annotation over all the annotations with probabilities,9.962599754333496,NimbusRomNo9L-Regu,False,115.1284408569336,155.99940490722656,0.0,70,H3
sample_3.pdf,4,The probability,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,172.93641662597656,0.06666666666666667,15,H3
sample_3.pdf,4,", or its associated energy",9.962599754333496,NimbusRomNo9L-Regu,False,186.6020050048828,172.93641662597656,0.0,26,H3
sample_3.pdf,4,", reﬂects the importance of the annotation",9.962599754333496,NimbusRomNo9L-Regu,False,301.45001220703125,172.93641662597656,0.0,42,H3
sample_3.pdf,4,with,9.962599754333496,NimbusRomNo9L-Regu,False,482.3896179199219,172.93641662597656,0.0,4,H3
sample_3.pdf,4,respect to the previous hidden state,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,183.89540100097656,0.0,36,H3
sample_3.pdf,4,in deciding the next state,9.962599754333496,NimbusRomNo9L-Regu,False,268.9501037597656,183.89540100097656,0.0,26,H3
sample_3.pdf,4,and generating,9.962599754333496,NimbusRomNo9L-Regu,False,382.115478515625,183.89540100097656,0.0,14,H3
sample_3.pdf,4,". Intuitively,",9.962599754333496,NimbusRomNo9L-Regu,False,455.09405517578125,183.89540100097656,0.07142857142857142,14,H3
sample_3.pdf,4,this implements a mechanism of attention in the decoder. The decoder decides parts of the source,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,194.85438537597656,0.010416666666666666,96,H3
sample_3.pdf,4,"sentence to pay attention to. By letting the decoder have an attention mechanism, we relieve the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,205.81336975097656,0.010416666666666666,96,H3
sample_3.pdf,4,encoder from the burden of having to encode all information in the source sentence into a ﬁxed-,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,216.77235412597656,0.0,95,H3
sample_3.pdf,4,length vector. With this new approach the information can be spread throughout the sequence of,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,227.73036193847656,0.010638297872340425,94,H3
sample_3.pdf,4,"annotations, which can be selectively retrieved by the decoder accordingly.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,238.68934631347656,0.0,75,H3
sample_3.pdf,4,3.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24906158447266,264.40631103515625,0.0,3,H3
sample_3.pdf,4,NCODER,7.970099925994873,NimbusRomNo9L-Regu,False,138.74505615234375,265.91741943359375,1.0,6,P
sample_3.pdf,4,: B,9.962599754333496,NimbusRomNo9L-Regu,False,174.46005249023438,264.40631103515625,0.3333333333333333,3,H3
sample_3.pdf,4,IDIRECTIONAL,7.970099925994873,NimbusRomNo9L-Regu,False,187.95904541015625,265.91741943359375,1.0,12,P
sample_3.pdf,4,RNN,9.962599754333496,NimbusRomNo9L-Regu,False,249.32875061035156,264.40631103515625,1.0,3,H3
sample_3.pdf,4,FOR,7.970099925994873,NimbusRomNo9L-Regu,False,274.3343505859375,265.91741943359375,1.0,3,P
sample_3.pdf,4,NNOTATING,7.970099925994873,NimbusRomNo9L-Regu,False,304.4810485839844,265.91741943359375,1.0,9,P
sample_3.pdf,4,EQUENCES,7.970099925994873,NimbusRomNo9L-Regu,False,362.4130554199219,265.91741943359375,1.0,8,P
sample_3.pdf,4,"The usual RNN, described in Eq. (1), reads an input sequence",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,285.21331787109375,0.08333333333333333,60,H3
sample_3.pdf,4,in order starting from the ﬁrst,9.962599754333496,NimbusRomNo9L-Regu,False,376.10235595703125,285.21331787109375,0.0,31,H3
sample_3.pdf,4,symbol,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,296.17230224609375,0.0,6,H3
sample_3.pdf,4,to the last one,9.962599754333496,NimbusRomNo9L-Regu,False,150.46112060546875,296.17230224609375,0.0,15,H3
sample_3.pdf,4,". However, in the proposed scheme, we would like the annotation",9.962599754333496,NimbusRomNo9L-Regu,False,231.7060546875,296.17230224609375,0.015873015873015872,63,H3
sample_3.pdf,4,"of each word to summarize not only the preceding words, but also the following words. Hence,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00005340576172,307.13128662109375,0.010869565217391304,92,H3
sample_3.pdf,4,"we propose to use a bidirectional RNN (BiRNN, Schuster and Paliwal, 1997), which has been",9.962599754333496,NimbusRomNo9L-Regu,False,108.00005340576172,318.09027099609375,0.10112359550561797,89,H3
sample_3.pdf,4,"successfully used recently in speech recognition (see, e.g., Graves",9.962599754333496,NimbusRomNo9L-Regu,False,108.00005340576172,329.04827880859375,0.014925373134328358,67,H3
sample_3.pdf,4,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,370.4847106933594,328.871826171875,0.0,6,H3
sample_3.pdf,4,", 2013).",9.962599754333496,NimbusRomNo9L-Regu,False,392.8990478515625,329.04827880859375,0.0,8,H3
sample_3.pdf,4,A BiRNN consists of forward and backward RNN’s. The forward RNN,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,348.7532653808594,0.19047619047619047,63,H3
sample_3.pdf,4,reads the input sequence,9.962599754333496,NimbusRomNo9L-Regu,False,401.375732421875,348.7532653808594,0.0,24,H3
sample_3.pdf,4,as it is ordered (from,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,362.4792785644531,0.0,22,H3
sample_3.pdf,4,) and calculates a sequence of,9.962599754333496,NimbusRomNo9L-Regu,False,229.41500854492188,362.4792785644531,0.0,30,H3
sample_3.pdf,4,forward hidden states,9.962599754333496,NimbusRomNo9L-ReguItal,False,346.0471496582031,362.3028259277344,0.0,21,H3
sample_3.pdf,4,The backward RNN,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,376.540283203125,0.25,16,H3
sample_3.pdf,4,reads the sequence in the reverse order (from,9.962599754333496,NimbusRomNo9L-Regu,False,201.11366271972656,376.540283203125,0.0,45,H3
sample_3.pdf,4,"), resulting in a",9.962599754333496,NimbusRomNo9L-Regu,False,439.7689514160156,376.540283203125,0.0,17,H3
sample_3.pdf,4,sequence of,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,390.60028076171875,0.0,11,H3
sample_3.pdf,4,backward hidden states,9.962599754333496,NimbusRomNo9L-ReguItal,False,155.3023681640625,390.423828125,0.0,22,H3
sample_3.pdf,4,We obtain an annotation for each word,9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,410.6382751464844,0.02702702702702703,37,H3
sample_3.pdf,4,by concatenating the forward hidden state,9.962599754333496,NimbusRomNo9L-Regu,False,279.15252685546875,410.6382751464844,0.0,41,H3
sample_3.pdf,4,and the,9.962599754333496,NimbusRomNo9L-Regu,False,470.1075439453125,410.6382751464844,0.0,7,H3
sample_3.pdf,4,backward one,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,428.322265625,0.0,12,H3
sample_3.pdf,4,", i.e.,",9.962599754333496,NimbusRomNo9L-Regu,False,180.69692993164062,428.322265625,0.0,7,H3
sample_3.pdf,4,". In this way, the annotation",9.962599754333496,NimbusRomNo9L-Regu,False,281.6789245605469,428.3222961425781,0.034482758620689655,29,H3
sample_3.pdf,4,contains the summaries,9.962599754333496,NimbusRomNo9L-Regu,False,406.26654052734375,428.3222961425781,0.0,22,H3
sample_3.pdf,4,of both the preceding words and the following words. Due to the tendency of RNNs to better,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,442.5882873535156,0.044444444444444446,90,H3
sample_3.pdf,4,"represent recent inputs, the annotation",9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,453.54730224609375,0.0,39,H3
sample_3.pdf,4,will be focused on the words around,9.962599754333496,NimbusRomNo9L-Regu,False,274.3554992675781,453.54730224609375,0.0,35,H3
sample_3.pdf,4,. This sequence,9.962599754333496,NimbusRomNo9L-Regu,False,439.4739074707031,453.54730224609375,0.06666666666666667,15,H3
sample_3.pdf,4,of annotations is used by the decoder and the alignment model later to compute the context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,464.50628662109375,0.0,97,H3
sample_3.pdf,4,(Eqs. (5)–(6)).,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,475.46527099609375,0.06666666666666667,15,H3
sample_3.pdf,4,See Fig. 1 for the graphical illustration of the proposed model.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,492.40228271484375,0.03125,64,H3
sample_3.pdf,4,XPERIMENT,9.56410026550293,NimbusRomNo9L-Regu,False,134.73191833496094,522.3055419921875,1.0,9,H3
sample_3.pdf,4,ETTINGS,9.56410026550293,NimbusRomNo9L-Regu,False,205.00291442871094,522.3055419921875,1.0,7,H3
sample_3.pdf,4,We evaluate the proposed approach on the task of English-to-French translation. We use the bilin-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99991607666016,546.09130859375,0.041237113402061855,97,H3
sample_3.pdf,4,"gual, parallel corpora provided by ACL WMT ’14.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99991607666016,557.05029296875,0.1276595744680851,47,H3
sample_3.pdf,4,"As a comparison, we also report the perfor-",9.962599754333496,NimbusRomNo9L-Regu,False,325.34393310546875,557.05029296875,0.023255813953488372,43,H3
sample_3.pdf,4,mance of an RNN Encoder–Decoder which was proposed recently by Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,568.00927734375,0.09090909090909091,66,H3
sample_3.pdf,4,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,409.8367004394531,567.8328247070312,0.0,6,H3
sample_3.pdf,4,(2014a). We use,9.962599754333496,NimbusRomNo9L-Regu,False,433.3700256347656,568.00927734375,0.06666666666666667,15,H3
sample_3.pdf,4,the same training procedures and the same dataset for both models.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,578.96826171875,0.0,66,H3
sample_3.pdf,4,4.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24893188476562,604.684326171875,0.0,3,H3
sample_3.pdf,4,ATASET,7.970099925994873,NimbusRomNo9L-Regu,False,139.49192810058594,606.1954345703125,1.0,6,P
sample_3.pdf,4,"WMT ’14 contains the following English-French parallel corpora: Europarl (61M words), news",9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,625.4913330078125,0.07777777777777778,90,H3
sample_3.pdf,4,"commentary (5.5M), UN (421M) and two crawled corpora of 90M and 272.5M words respectively,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,636.4503173828125,0.06666666666666667,90,H3
sample_3.pdf,4,totaling 850M words. Following the procedure described in Cho,9.962599754333496,NimbusRomNo9L-Regu,False,107.99992370605469,647.4093017578125,0.04918032786885246,61,H3
sample_3.pdf,4,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,361.9066162109375,647.2328491210938,0.0,6,H3
sample_3.pdf,4,"(2014a), we reduce the size of",9.962599754333496,NimbusRomNo9L-Regu,False,383.5894775390625,647.4093017578125,0.0,30,H3
sample_3.pdf,4,the combined corpus to have 348M words using the data selection method by Axelrod,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,658.3682861328125,0.024691358024691357,81,H3
sample_3.pdf,4,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,446.9472351074219,658.1918334960938,0.0,6,H3
sample_3.pdf,4,(2011).,9.962599754333496,NimbusRomNo9L-Regu,False,468.7662353515625,658.3682861328125,0.0,7,H3
sample_3.pdf,4,"We do not use any monolingual data other than the mentioned parallel corpora, although it may be",9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,669.3272705078125,0.010416666666666666,96,H3
sample_3.pdf,4,possible to use a much larger monolingual corpus to pretrain an encoder. We concatenate news-test-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,680.2863159179688,0.01020408163265306,98,H3
sample_3.pdf,4,http://www.statmt.org/wmt14/translation-task.html,8.966400146484375,NimbusMonL-Regu,False,123.64179992675781,697.044921875,0.0,49,P
sample_3.pdf,4,Implementations are available at,8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,708.3779296875,0.03125,32,P
sample_3.pdf,4,https://github.com/lisa-groundhog/GroundHog,8.966400146484375,NimbusMonL-Regu,False,242.76487731933594,711.7279052734375,0.046511627906976744,43,P
sample_3.pdf,4,Available online at,8.966400146484375,NimbusRomNo9L-Regu,False,123.64181518554688,719.2529296875,0.05263157894736842,19,P
sample_3.pdf,4,http://www-lium.univ-lemans.fr/˜schwenk/cslm_joint_paper/,8.966400146484375,NimbusMonL-Regu,False,192.3311309814453,722.6029052734375,0.0,57,P
sample_3.pdf,5,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,5,Sentence length,8.739825248718262,CMR12,False,220.93405151367188,216.1603546142578,0.06666666666666667,15,P
sample_3.pdf,5,BLEU score,8.739825248718262,CMR12,False,115.42598724365234,123.44523620605469,0.4,10,P
sample_3.pdf,5,RNNsearch-50,7.280272006988525,CMR12,False,163.1103515625,160.90432739257812,0.25,12,P
sample_3.pdf,5,RNNsearch-30,7.280272006988525,CMR12,False,163.1103515625,171.08901977539062,0.25,12,P
sample_3.pdf,5,RNNenc-50,7.280272006988525,CMR12,False,163.1103515625,181.27371215820312,0.3333333333333333,9,P
sample_3.pdf,5,RNNenc-30,7.280272006988525,CMR12,False,163.1103515625,191.45840454101562,0.3333333333333333,9,P
sample_3.pdf,5,Figure 2: The BLEU scores,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,116.77845764160156,0.24,25,H3
sample_3.pdf,5,of the generated translations,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,127.73744201660156,0.0,29,H3
sample_3.pdf,5,on the test set with respect,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,138.69642639160156,0.0,28,H3
sample_3.pdf,5,to the lengths of the sen-,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,149.65541076660156,0.0,26,H3
sample_3.pdf,5,tences.,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,160.61439514160156,0.0,7,H3
sample_3.pdf,5,The results are on,9.962599754333496,NimbusRomNo9L-Regu,False,426.26373291015625,160.61439514160156,0.05555555555555555,18,H3
sample_3.pdf,5,the full test set which in-,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,171.57337951660156,0.0,27,H3
sample_3.pdf,5,cludes sentences having un-,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,182.53236389160156,0.0,27,H3
sample_3.pdf,5,known words to the models.,9.962599754333496,NimbusRomNo9L-Regu,False,389.1629943847656,193.49134826660156,0.0,26,H3
sample_3.pdf,5,"2012 and news-test-2013 to make a development (validation) set, and evaluate the models on the test",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,250.6763458251953,0.0,99,H3
sample_3.pdf,5,"set (news-test-2014) from WMT ’14, which consists of 3003 sentences not present in the training",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,261.63531494140625,0.031578947368421054,95,H3
sample_3.pdf,5,data.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,272.59429931640625,0.0,5,H3
sample_3.pdf,5,After a usual tokenization,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,289.53131103515625,0.038461538461538464,26,H3
sample_3.pdf,5,", we use a shortlist of 30,000 most frequent words in each language to",9.962599754333496,NimbusRomNo9L-Regu,False,217.0030059814453,289.53131103515625,0.0,70,H3
sample_3.pdf,5,train our models. Any word not included in the shortlist is mapped to a special token (,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,300.48931884765625,0.011494252873563218,87,H3
sample_3.pdf,5,UNK,9.962599754333496,NimbusRomNo9L-Regu,False,457.1750183105469,300.48931884765625,1.0,3,H3
sample_3.pdf,5,). We,9.962599754333496,NimbusRomNo9L-Regu,False,481.5210266113281,300.48931884765625,0.2,5,H3
sample_3.pdf,5,"do not apply any other special preprocessing, such as lowercasing or stemming, to the data.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,311.44830322265625,0.0,91,H3
sample_3.pdf,5,4.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24903106689453,338.07830810546875,0.0,3,H3
sample_3.pdf,5,ODELS,7.970099925994873,NimbusRomNo9L-Regu,False,141.5140380859375,339.58941650390625,1.0,5,P
sample_3.pdf,5,"We train two types of models. The ﬁrst one is an RNN Encoder–Decoder (RNNencdec, Cho",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003814697266,359.25030517578125,0.13095238095238096,84,H3
sample_3.pdf,5,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,478.6883850097656,359.0738525390625,0.0,6,H3
sample_3.pdf,5,"2014a), and the other is the proposed model, to which we refer as RNNsearch. We train each model",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,370.20928955078125,0.041666666666666664,96,H3
sample_3.pdf,5,"twice: ﬁrst with the sentences of length up to 30 words (RNNencdec-30, RNNsearch-30) and then",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,381.16827392578125,0.06451612903225806,93,H3
sample_3.pdf,5,"with the sentences of length up to 50 word (RNNencdec-50, RNNsearch-50).",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,392.12725830078125,0.08333333333333333,72,H3
sample_3.pdf,5,The encoder and decoder of the RNNencdec have 1000 hidden units each.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,409.0632629394531,0.057971014492753624,69,H3
sample_3.pdf,5,The encoder of the,9.962599754333496,NimbusRomNo9L-Regu,False,425.70703125,409.0632629394531,0.05555555555555555,18,H3
sample_3.pdf,5,RNNsearch consists of forward and backward recurrent neural networks (RNN) each having 1000,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,420.02227783203125,0.06593406593406594,91,H3
sample_3.pdf,5,"hidden units. Its decoder has 1000 hidden units. In both cases, we use a multilayer network with a",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,430.98126220703125,0.02040816326530612,98,H3
sample_3.pdf,5,single maxout (Goodfellow,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,441.94024658203125,0.04,25,H3
sample_3.pdf,5,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,216.93106079101562,441.7637939453125,0.0,6,H3
sample_3.pdf,5,", 2013) hidden layer to compute the conditional probability of each",9.962599754333496,NimbusRomNo9L-Regu,False,238.95602416992188,441.94024658203125,0.0,67,H3
sample_3.pdf,5,target word (Pascanu,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,452.89923095703125,0.05,20,H3
sample_3.pdf,5,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,191.67588806152344,452.7227783203125,0.0,6,H3
sample_3.pdf,5,", 2014).",9.962599754333496,NimbusRomNo9L-Regu,False,214.09103393554688,452.89923095703125,0.0,8,H3
sample_3.pdf,5,"We use a minibatch stochastic gradient descent (SGD) algorithm together with Adadelta (Zeiler,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,469.8352355957031,0.06382978723404255,94,H3
sample_3.pdf,5,2012) to train each model. Each SGD update direction is computed using a minibatch of 80 sen-,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,480.79425048828125,0.043010752688172046,93,H3
sample_3.pdf,5,tences. We trained each model for approximately 5 days.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,491.75323486328125,0.01818181818181818,55,H3
sample_3.pdf,5,"Once a model is trained, we use a beam search to ﬁnd a translation that approximately maximizes the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,508.69024658203125,0.010101010101010102,99,H3
sample_3.pdf,5,"conditional probability (see, e.g., Graves, 2012; Boulanger-Lewandowski",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,519.6492309570312,0.04225352112676056,71,H3
sample_3.pdf,5,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,404.52679443359375,519.4727783203125,0.0,6,H3
sample_3.pdf,5,", 2013). Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,428.4270324707031,519.6492309570312,0.05555555555555555,18,H3
sample_3.pdf,5,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.00003051757812,530.4317626953125,0.0,6,H3
sample_3.pdf,5,(2014) used this approach to generate translations from their neural machine translation model.,9.962599754333496,NimbusRomNo9L-Regu,False,127.55660247802734,530.6082153320312,0.0,95,H3
sample_3.pdf,5,"For more details on the architectures of the models and training procedure used in the experiments,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,547.5442504882812,0.010101010101010102,99,H3
sample_3.pdf,5,see Appendices A and B.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,558.5032348632812,0.13043478260869565,23,H3
sample_3.pdf,5,ESULTS,9.56410026550293,NimbusRomNo9L-Regu,False,135.40103149414062,589.3204956054688,1.0,6,H3
sample_3.pdf,5,5.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24903106689453,613.6531982421875,0.0,3,H3
sample_3.pdf,5,UANTITATIVE,7.970099925994873,NimbusRomNo9L-Regu,False,139.7610321044922,615.164306640625,1.0,11,P
sample_3.pdf,5,ESULTS,7.970099925994873,NimbusRomNo9L-Regu,False,206.4200439453125,615.164306640625,1.0,6,P
sample_3.pdf,5,"In Table 1, we list the translation performances measured in BLEU score. It is clear from the table",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,634.8262329101562,0.0707070707070707,99,H3
sample_3.pdf,5,"that in all the cases, the proposed RNNsearch outperforms the conventional RNNencdec. More",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,645.7842407226562,0.07777777777777778,90,H3
sample_3.pdf,5,"importantly, the performance of the RNNsearch is as high as that of the conventional phrase-based",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,656.7432250976562,0.030927835051546393,97,H3
sample_3.pdf,5,"translation system (Moses), when only the sentences consisting of known words are considered.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,667.7022705078125,0.010752688172043012,93,H3
sample_3.pdf,5,"This is a signiﬁcant achievement, considering that Moses uses a separate monolingual corpus (418M",9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,678.6612548828125,0.030927835051546393,97,H3
sample_3.pdf,5,words) in addition to the parallel corpora we used to train the RNNsearch and RNNencdec.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,689.6202392578125,0.06818181818181818,88,H3
sample_3.pdf,5,"We used the tokenization script from the open-source machine translation package, Moses.",8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,708.4619750976562,0.022727272727272728,88,P
sample_3.pdf,5,"In this paper, by a ’hidden unit’, we always mean the gated hidden unit (see Appendix A.1.1).",8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,719.2529296875,0.03225806451612903,93,P
sample_3.pdf,6,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,6,The,6.291199684143066,BitstreamVeraSans-Roman,False,154.0428466796875,108.64167022705078,0.3333333333333333,3,P
sample_3.pdf,6,agreement,6.291199684143066,BitstreamVeraSans-Roman,False,164.07281494140625,85.71656036376953,0.0,9,P
sample_3.pdf,6,the,6.291199684143066,BitstreamVeraSans-Roman,False,184.1327667236328,110.01944732666016,0.0,3,P
sample_3.pdf,6,European,6.291199684143066,BitstreamVeraSans-Roman,False,194.16273498535156,90.233642578125,0.125,8,P
sample_3.pdf,6,Economic,6.291199684143066,BitstreamVeraSans-Roman,False,204.1927032470703,89.88133239746094,0.125,8,P
sample_3.pdf,6,Area,6.291199684143066,BitstreamVeraSans-Roman,False,214.22267150878906,105.72885131835938,0.25,4,P
sample_3.pdf,6,was,6.291199684143066,BitstreamVeraSans-Roman,False,224.2526397705078,108.06285858154297,0.0,3,P
sample_3.pdf,6,signed,6.291199684143066,BitstreamVeraSans-Roman,False,234.28260803222656,99.4690933227539,0.0,6,P
sample_3.pdf,6,August,6.291199684143066,BitstreamVeraSans-Roman,False,254.34254455566406,98.32410430908203,0.16666666666666666,6,P
sample_3.pdf,6,1992,6.291199684143066,BitstreamVeraSans-Roman,False,264.3725280761719,104.33848571777344,0.0,4,P
sample_3.pdf,6,<end>,6.291199684143066,BitstreamVeraSans-Roman,False,284.4324645996094,97.9466323852539,0.0,5,P
sample_3.pdf,6,accord,6.291199684143066,BitstreamVeraSans-Roman,False,130.4497528076172,133.79519653320312,0.0,6,P
sample_3.pdf,6,sur,6.291199684143066,BitstreamVeraSans-Roman,False,141.10546875,143.82516479492188,0.0,3,P
sample_3.pdf,6,zone,6.291199684143066,BitstreamVeraSans-Roman,False,136.2101287841797,163.88510131835938,0.0,4,P
sample_3.pdf,6,économique,6.291199684143066,BitstreamVeraSans-Roman,False,112.5296630859375,174.04286193847656,0.0,10,P
sample_3.pdf,6,européenne,6.291199684143066,BitstreamVeraSans-Roman,False,113.56181335449219,184.0728302001953,0.0,10,P
sample_3.pdf,6,signé,6.291199684143066,BitstreamVeraSans-Roman,False,134.41123962402344,214.16275024414062,0.0,5,P
sample_3.pdf,6,août,6.291199684143066,BitstreamVeraSans-Roman,False,136.98670959472656,234.0948944091797,0.0,4,P
sample_3.pdf,6,1992,6.291199684143066,BitstreamVeraSans-Roman,False,135.9348907470703,244.12486267089844,0.0,4,P
sample_3.pdf,6,<end>,6.291199684143066,BitstreamVeraSans-Roman,False,129.5552215576172,264.184814453125,0.0,5,P
sample_3.pdf,6,should,5.995800018310547,BitstreamVeraSans-Roman,False,374.4883728027344,109.0632095336914,0.0,6,P
sample_3.pdf,6,noted,5.995800018310547,BitstreamVeraSans-Roman,False,391.2166442871094,111.61742401123047,0.0,5,P
sample_3.pdf,6,that,5.995800018310547,BitstreamVeraSans-Roman,False,399.580810546875,116.75581359863281,0.0,4,P
sample_3.pdf,6,the,5.995800018310547,BitstreamVeraSans-Roman,False,407.9449462890625,119.09418487548828,0.0,3,P
sample_3.pdf,6,marine,5.995800018310547,BitstreamVeraSans-Roman,False,416.30908203125,107.7981185913086,0.0,6,P
sample_3.pdf,6,environment,5.995800018310547,BitstreamVeraSans-Roman,False,424.6732177734375,90.61415100097656,0.0,11,P
sample_3.pdf,6,the,5.995800018310547,BitstreamVeraSans-Roman,False,441.4015197753906,119.09418487548828,0.0,3,P
sample_3.pdf,6,least,5.995800018310547,BitstreamVeraSans-Roman,False,449.7656555175781,114.42945861816406,0.0,5,P
sample_3.pdf,6,known,5.995800018310547,BitstreamVeraSans-Roman,False,458.1297912597656,109.2850570678711,0.0,5,P
sample_3.pdf,6,environments,5.995800018310547,BitstreamVeraSans-Roman,False,474.8580627441406,87.49034118652344,0.0,12,P
sample_3.pdf,6,<end>,5.995800018310547,BitstreamVeraSans-Roman,False,491.5863342285156,107.58824920654297,0.0,5,P
sample_3.pdf,6,convient,5.995800018310547,BitstreamVeraSans-Roman,False,338.0906982421875,139.9612579345703,0.0,8,P
sample_3.pdf,6,noter,5.995800018310547,BitstreamVeraSans-Roman,False,348.021240234375,156.68954467773438,0.0,5,P
sample_3.pdf,6,que,5.995800018310547,BitstreamVeraSans-Roman,False,352.8085021972656,165.05368041992188,0.0,3,P
sample_3.pdf,6,environnement,5.995800018310547,BitstreamVeraSans-Roman,False,318.2389831542969,181.78195190429688,0.0,13,P
sample_3.pdf,6,marin,5.995800018310547,BitstreamVeraSans-Roman,False,347.0656433105469,190.14610290527344,0.0,5,P
sample_3.pdf,6,est,5.995800018310547,BitstreamVeraSans-Roman,False,354.75714111328125,198.51025390625,0.0,3,P
sample_3.pdf,6,moins,5.995800018310547,BitstreamVeraSans-Roman,False,346.1850280761719,215.238525390625,0.0,5,P
sample_3.pdf,6,connu,5.995800018310547,BitstreamVeraSans-Roman,False,345.9508056640625,223.6026611328125,0.0,5,P
sample_3.pdf,6,environnement,5.995800018310547,BitstreamVeraSans-Roman,False,318.2389831542969,248.69509887695312,0.0,13,P
sample_3.pdf,6,<end>,5.995800018310547,BitstreamVeraSans-Roman,False,343.38385009765625,265.4233703613281,0.0,5,P
sample_3.pdf,6,(a),9.962599754333496,NimbusRomNo9L-Regu,False,197.50999450683594,281.2654724121094,0.0,3,H3
sample_3.pdf,6,(b),9.962599754333496,NimbusRomNo9L-Regu,False,403.1480407714844,281.2654724121094,0.0,3,H3
sample_3.pdf,6,Destruction,6.3125996589660645,BitstreamVeraSans-Roman,False,152.91946411132812,294.98651123046875,0.09090909090909091,11,P
sample_3.pdf,6,the,6.3125996589660645,BitstreamVeraSans-Roman,False,170.5316162109375,321.29742431640625,0.0,3,P
sample_3.pdf,6,equipment,6.3125996589660645,BitstreamVeraSans-Roman,False,179.33770751953125,297.49261474609375,0.0,9,P
sample_3.pdf,6,means,6.3125996589660645,BitstreamVeraSans-Roman,False,188.14376831054688,310.46502685546875,0.0,5,P
sample_3.pdf,6,that,6.3125996589660645,BitstreamVeraSans-Roman,False,196.94985961914062,318.83551025390625,0.0,4,P
sample_3.pdf,6,Syria,6.3125996589660645,BitstreamVeraSans-Roman,False,205.75592041015625,315.69183349609375,0.2,5,P
sample_3.pdf,6,can,6.3125996589660645,BitstreamVeraSans-Roman,False,214.56201171875,320.31268310546875,0.0,3,P
sample_3.pdf,6,longer,6.3125996589660645,BitstreamVeraSans-Roman,False,232.17416381835938,311.55078125,0.0,6,P
sample_3.pdf,6,produce,6.3125996589660645,BitstreamVeraSans-Roman,False,240.98023986816406,305.82525634765625,0.0,7,P
sample_3.pdf,6,new,6.3125996589660645,BitstreamVeraSans-Roman,False,249.78631591796875,318.6082763671875,0.0,3,P
sample_3.pdf,6,chemical,6.3125996589660645,BitstreamVeraSans-Roman,False,258.5923767089844,303.30023193359375,0.0,8,P
sample_3.pdf,6,weapons,6.3125996589660645,BitstreamVeraSans-Roman,False,267.3984680175781,303.5779724121094,0.0,7,P
sample_3.pdf,6,<end>,6.3125996589660645,BitstreamVeraSans-Roman,False,285.0105895996094,309.1835632324219,0.0,5,P
sample_3.pdf,6,destruction,6.3125996589660645,BitstreamVeraSans-Roman,False,115.16874694824219,343.2670593261719,0.0,11,P
sample_3.pdf,6,équipement,6.3125996589660645,BitstreamVeraSans-Roman,False,112.54507446289062,369.8135070800781,0.0,10,P
sample_3.pdf,6,signifie,6.3125996589660645,BitstreamVeraSans-Roman,False,128.11944580078125,378.4913635253906,0.0,8,P
sample_3.pdf,6,que,6.3125996589660645,BitstreamVeraSans-Roman,False,138.90017700195312,387.2974548339844,0.0,3,P
sample_3.pdf,6,Syrie,6.3125996589660645,BitstreamVeraSans-Roman,False,134.88575744628906,404.90960693359375,0.2,5,P
sample_3.pdf,6,peut,6.3125996589660645,BitstreamVeraSans-Roman,False,136.4639129638672,422.5217590332031,0.0,4,P
sample_3.pdf,6,plus,6.3125996589660645,BitstreamVeraSans-Roman,False,137.94342041015625,431.3278503417969,0.0,4,P
sample_3.pdf,6,produire,6.3125996589660645,BitstreamVeraSans-Roman,False,124.6277847290039,440.1339111328125,0.0,8,P
sample_3.pdf,6,nouvelles,6.3125996589660645,BitstreamVeraSans-Roman,False,120.81063079833984,457.7460632324219,0.0,9,P
sample_3.pdf,6,armes,6.3125996589660645,BitstreamVeraSans-Roman,False,131.09820556640625,466.5521240234375,0.0,5,P
sample_3.pdf,6,chimiques,6.3125996589660645,BitstreamVeraSans-Roman,False,118.44340515136719,475.35821533203125,0.0,9,P
sample_3.pdf,6,<end>,6.3125996589660645,BitstreamVeraSans-Roman,False,128.97755432128906,492.9703674316406,0.0,5,P
sample_3.pdf,6,This,6.740900039672852,BitstreamVeraSans-Roman,False,358.3902282714844,324.8533020019531,0.25,4,P
sample_3.pdf,6,will,6.740900039672852,BitstreamVeraSans-Roman,False,367.7937927246094,327.49578857421875,0.0,4,P
sample_3.pdf,6,change,6.740900039672852,BitstreamVeraSans-Roman,False,377.1973571777344,313.8184509277344,0.0,6,P
sample_3.pdf,6,future,6.740900039672852,BitstreamVeraSans-Roman,False,396.00445556640625,318.1528625488281,0.0,6,P
sample_3.pdf,6,with,6.740900039672852,BitstreamVeraSans-Roman,False,405.40802001953125,324.3275146484375,0.0,4,P
sample_3.pdf,6,family,6.740900039672852,BitstreamVeraSans-Roman,False,424.2151184082031,317.8226013183594,0.0,6,P
sample_3.pdf,6,the,6.740900039672852,BitstreamVeraSans-Roman,False,452.4258117675781,327.5699157714844,0.0,3,P
sample_3.pdf,6,man,6.740900039672852,BitstreamVeraSans-Roman,False,461.829345703125,323.6601867675781,0.0,3,P
sample_3.pdf,6,said,6.740900039672852,BitstreamVeraSans-Roman,False,471.23291015625,324.8331298828125,0.0,4,P
sample_3.pdf,6,<end>,6.740900039672852,BitstreamVeraSans-Roman,False,490.0400085449219,314.6341552734375,0.0,5,P
sample_3.pdf,6,Cela,6.740900039672852,BitstreamVeraSans-Roman,False,332.1203308105469,351.0301208496094,0.25,4,P
sample_3.pdf,6,changer,6.740900039672852,BitstreamVeraSans-Roman,False,318.77545166015625,369.8372497558594,0.0,7,P
sample_3.pdf,6,mon,6.740900039672852,BitstreamVeraSans-Roman,False,332.20458984375,379.2408142089844,0.0,3,P
sample_3.pdf,6,avenir,6.740900039672852,BitstreamVeraSans-Roman,False,325.2109069824219,388.6443786621094,0.0,6,P
sample_3.pdf,6,avec,6.740900039672852,BitstreamVeraSans-Roman,False,330.84588623046875,398.04791259765625,0.0,4,P
sample_3.pdf,6,famille,6.740900039672852,BitstreamVeraSans-Roman,False,323.66259765625,416.85504150390625,0.0,7,P
sample_3.pdf,6,dit,6.740900039672852,BitstreamVeraSans-Roman,False,337.72369384765625,454.4692687988281,0.0,3,P
sample_3.pdf,6,homme,6.740900039672852,BitstreamVeraSans-Roman,False,321.2611389160156,473.2763671875,0.0,5,P
sample_3.pdf,6,<end>,6.740900039672852,BitstreamVeraSans-Roman,False,323.42034912109375,492.08349609375,0.0,5,P
sample_3.pdf,6,(c),9.962599754333496,NimbusRomNo9L-Regu,False,197.50999450683594,509.46746826171875,0.0,3,H3
sample_3.pdf,6,(d),9.962599754333496,NimbusRomNo9L-Regu,False,403.1480407714844,509.46746826171875,0.0,3,H3
sample_3.pdf,6,Figure 3:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,530.367431640625,0.1111111111111111,9,H3
sample_3.pdf,6,Four sample alignments found by RNNsearch-50. The x-axis and y-axis of each plot,9.962599754333496,NimbusRomNo9L-Regu,False,154.7445068359375,530.367431640625,0.0625,80,H3
sample_3.pdf,6,"correspond to the words in the source sentence (English) and the generated translation (French),",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,541.3264770507812,0.020833333333333332,96,H3
sample_3.pdf,6,respectively. Each pixel shows the weight,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,552.284423828125,0.024390243902439025,41,H3
sample_3.pdf,6,of the annotation of the,9.962599754333496,NimbusRomNo9L-Regu,False,290.531005859375,552.284423828125,0.0,24,H3
sample_3.pdf,6,-th source word for the,9.962599754333496,NimbusRomNo9L-Regu,False,395.01397705078125,552.284423828125,0.0,23,H3
sample_3.pdf,6,-th,9.962599754333496,NimbusRomNo9L-Regu,False,492.9319763183594,552.284423828125,0.0,3,H3
sample_3.pdf,6,"target word (see Eq. (6)), in grayscale (",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,563.2434692382812,0.024390243902439025,41,H3
sample_3.pdf,6,": black,",9.962599754333496,NimbusRomNo9L-Regu,False,273.7109680175781,563.2434692382812,0.0,8,H3
sample_3.pdf,6,: white). (a) an arbitrary sentence. (b–d) three,9.962599754333496,NimbusRomNo9L-Regu,False,313.2189636230469,563.2434692382812,0.0,48,H3
sample_3.pdf,6,randomly selected samples among the sentences without any unknown words and of length between,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,574.2024536132812,0.0,93,H3
sample_3.pdf,6,10 and 20 words from the test set.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,585.1614379882812,0.0,34,H3
sample_3.pdf,6,One of the motivations behind the proposed approach was the use of a ﬁxed-length context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,645.5934448242188,0.010526315789473684,95,H3
sample_3.pdf,6,in the basic encoder–decoder approach. We conjectured that this limitation may make the basic,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,656.5524291992188,0.010752688172043012,93,H3
sample_3.pdf,6,"encoder–decoder approach to underperform with long sentences. In Fig. 2, we see that the perfor-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,667.511474609375,0.020833333333333332,96,H3
sample_3.pdf,6,"mance of RNNencdec dramatically drops as the length of the sentences increases. On the other hand,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,678.470458984375,0.04081632653061224,98,H3
sample_3.pdf,6,both RNNsearch-30 and RNNsearch-50 are more robust to the length of the sentences. RNNsearch-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,689.429443359375,0.0967741935483871,93,H3
sample_3.pdf,6,"50, especially, shows no performance deterioration even with sentences of length 50 or more. This",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,700.388427734375,0.010309278350515464,97,H3
sample_3.pdf,6,superiority of the proposed model over the basic encoder–decoder is further conﬁrmed by the fact,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,711.347412109375,0.0,96,H3
sample_3.pdf,6,that the RNNsearch-30 even outperforms RNNencdec-50 (see Table 1).,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,722.3064575195312,0.10606060606060606,66,H3
sample_3.pdf,7,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,7,Model,9.962599754333496,NimbusRomNo9L-Regu,False,136.0800018310547,97.37147521972656,0.2,5,H3
sample_3.pdf,7,All,9.962599754333496,NimbusRomNo9L-Regu,False,198.44900512695312,97.37147521972656,0.3333333333333333,3,H3
sample_3.pdf,7,No UNK,9.962599754333496,NimbusRomNo9L-Regu,False,228.3769989013672,97.37147521972656,0.6666666666666666,6,H3
sample_3.pdf,7,RNNencdec-30,9.962599754333496,NimbusRomNo9L-Regu,False,118.10199737548828,111.12049865722656,0.25,12,H3
sample_3.pdf,7,13.93,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,111.12049865722656,0.0,5,H3
sample_3.pdf,7,24.19,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,111.12049865722656,0.0,5,H3
sample_3.pdf,7,RNNsearch-30,9.962599754333496,NimbusRomNo9L-Regu,False,119.20799255371094,122.07948303222656,0.25,12,H3
sample_3.pdf,7,21.50,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,122.07948303222656,0.0,5,H3
sample_3.pdf,7,31.44,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,122.07948303222656,0.0,5,H3
sample_3.pdf,7,RNNencdec-50,9.962599754333496,NimbusRomNo9L-Regu,False,118.10199737548828,133.4364776611328,0.25,12,H3
sample_3.pdf,7,17.82,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,133.4364776611328,0.0,5,H3
sample_3.pdf,7,26.71,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,133.4364776611328,0.0,5,H3
sample_3.pdf,7,RNNsearch-50,9.962599754333496,NimbusRomNo9L-Regu,False,119.20799255371094,144.3954620361328,0.25,12,H3
sample_3.pdf,7,26.75,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,144.3954620361328,0.0,5,H3
sample_3.pdf,7,34.16,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,144.3954620361328,0.0,5,H3
sample_3.pdf,7,RNNsearch-50,9.962599754333496,NimbusRomNo9L-Regu,False,116.91799926757812,155.75245666503906,0.25,12,H3
sample_3.pdf,7,28.45,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,155.75245666503906,0.0,5,H3
sample_3.pdf,7,36.15,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,155.75245666503906,0.0,5,H3
sample_3.pdf,7,Moses,9.962599754333496,NimbusRomNo9L-Regu,False,136.0800018310547,167.11048889160156,0.2,5,H3
sample_3.pdf,7,33.30,9.962599754333496,NimbusRomNo9L-Regu,False,193.60699462890625,167.11048889160156,0.0,5,H3
sample_3.pdf,7,35.63,9.962599754333496,NimbusRomNo9L-Regu,False,237.58099365234375,167.11048889160156,0.0,5,H3
sample_3.pdf,7,Table 1: BLEU scores of the trained models com-,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,85.39448547363281,0.10638297872340426,47,H3
sample_3.pdf,7,puted on the test set. The second and third columns,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,96.35249328613281,0.0196078431372549,51,H3
sample_3.pdf,7,"show respectively the scores on all the sentences and,",9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,107.31147766113281,0.0,54,H3
sample_3.pdf,7,on the sentences without any unknown word in them-,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,118.27046203613281,0.0,50,H3
sample_3.pdf,7,selves and in the reference translations. Note that,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,129.2294464111328,0.0196078431372549,51,H3
sample_3.pdf,7,RNNsearch-50,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,140.1884307861328,0.25,12,H3
sample_3.pdf,7,was trained much longer until the,9.962599754333496,NimbusRomNo9L-Regu,False,360.0400085449219,140.1884307861328,0.0,33,H3
sample_3.pdf,7,performance on the development set stopped improv-,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,151.1474151611328,0.0,50,H3
sample_3.pdf,7,ing. (,9.962599754333496,NimbusRomNo9L-Regu,False,291.6300048828125,162.1063995361328,0.0,6,H3
sample_3.pdf,7,) We disallowed the models to generate [UNK],9.962599754333496,NimbusRomNo9L-Regu,False,318.0539855957031,162.1063995361328,0.09090909090909091,44,H3
sample_3.pdf,7,tokens when only the sentences having no unknown,9.962599754333496,NimbusRomNo9L-Regu,False,291.6299743652344,173.0653839111328,0.0,48,H3
sample_3.pdf,7,words were evaluated (last column).,9.962599754333496,NimbusRomNo9L-Regu,False,291.6299743652344,184.0243682861328,0.0,35,H3
sample_3.pdf,7,5.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24897766113281,218.61940002441406,0.0,3,H3
sample_3.pdf,7,UALITATIVE,7.970099925994873,NimbusRomNo9L-Regu,False,139.76097106933594,220.1304931640625,1.0,10,P
sample_3.pdf,7,NALYSIS,7.970099925994873,NimbusRomNo9L-Regu,False,200.72096252441406,220.1304931640625,1.0,7,P
sample_3.pdf,7,5.2.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24896240234375,240.46437072753906,0.0,5,H3
sample_3.pdf,7,LIGNMENT,7.970099925994873,NimbusRomNo9L-Regu,False,148.3189697265625,241.9754638671875,1.0,8,P
sample_3.pdf,7,The proposed approach provides an intuitive way to inspect the (soft-)alignment between the words,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,260.96533203125,0.010309278350515464,97,H3
sample_3.pdf,7,in a generated translation and those in a source sentence. This is done by visualizing the annotation,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,271.92431640625,0.009900990099009901,101,H3
sample_3.pdf,7,weights,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,282.88330078125,0.0,7,H3
sample_3.pdf,7,"from Eq. (6), as in Fig. 3. Each row of a matrix in each plot indicates the weights",9.962599754333496,NimbusRomNo9L-Regu,False,155.072998046875,282.88330078125,0.03614457831325301,83,H3
sample_3.pdf,7,associated with the annotations. From this we see which positions in the source sentence were,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,293.84228515625,0.010752688172043012,93,H3
sample_3.pdf,7,considered more important when generating the target word.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,304.80029296875,0.0,58,H3
sample_3.pdf,7,We can see from the alignments in Fig. 3 that the alignment of words between English and French,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,321.7373046875,0.042105263157894736,95,H3
sample_3.pdf,7,"is largely monotonic. We see strong weights along the diagonal of each matrix. However, we also",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,332.6962890625,0.021052631578947368,95,H3
sample_3.pdf,7,"observe a number of non-trivial, non-monotonic alignments. Adjectives and nouns are typically",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,343.6552734375,0.010752688172043012,93,H3
sample_3.pdf,7,"ordered differently between French and English, and we see an example in Fig. 3 (a). From this",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,354.6142578125,0.0425531914893617,94,H3
sample_3.pdf,7,"ﬁgure, we see that the model correctly translates a phrase [European Economic Area] into [zone",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,365.5732421875,0.031914893617021274,94,H3
sample_3.pdf,7,"´economique europ´een]. The RNNsearch was able to correctly align [zone] with [Area], jumping",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,376.48223876953125,0.053763440860215055,93,H3
sample_3.pdf,7,"over the two words ([European] and [Economic]), and then looked one word back at a time to",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,387.490234375,0.022222222222222223,90,H3
sample_3.pdf,7,complete the whole phrase [zone ´economique europ´eenne].,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,398.40020751953125,0.0,57,H3
sample_3.pdf,7,"The strength of the soft-alignment, opposed to a hard-alignment, is evident, for instance, from",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,415.38623046875,0.010526315789473684,95,H3
sample_3.pdf,7,Fig. 3 (d). Consider the source phrase [the man] which was translated into [l’ homme]. Any hard,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,426.34521484375,0.031578947368421054,95,H3
sample_3.pdf,7,"alignment will map [the] to [l’] and [man] to [homme]. This is not helpful for translation, as one",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,437.30419921875,0.01020408163265306,98,H3
sample_3.pdf,7,"must consider the word following [the] to determine whether it should be translated into [le], [la],",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,448.26318359375,0.0,100,H3
sample_3.pdf,7,[les] or [l’]. Our soft-alignment solves this issue naturally by letting the model look at both [the] and,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,459.22119140625,0.009523809523809525,105,H3
sample_3.pdf,7,"[man], and in this example, we see that the model was able to correctly translate [the] into [l’]. We",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,470.18017578125,0.009900990099009901,101,H3
sample_3.pdf,7,observe similar behaviors in all the presented cases in Fig. 3. An additional beneﬁt of the soft align-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,481.13916015625,0.019417475728155338,103,H3
sample_3.pdf,7,"ment is that it naturally deals with source and target phrases of different lengths, without requiring a",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,492.09814453125,0.0,104,H3
sample_3.pdf,7,"counter-intuitive way of mapping some words to or from nowhere ([NULL]) (see, e.g., Chapters 4",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,503.05712890625,0.05319148936170213,94,H3
sample_3.pdf,7,"and 5 of Koehn, 2010).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,514.01611328125,0.045454545454545456,22,H3
sample_3.pdf,7,5.2.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24897003173828,540.9830932617188,0.0,5,H3
sample_3.pdf,7,ONG,7.970099925994873,NimbusRomNo9L-Regu,False,147.2129669189453,542.4942016601562,1.0,3,P
sample_3.pdf,7,ENTENCES,7.970099925994873,NimbusRomNo9L-Regu,False,174.47996520996094,542.4942016601562,1.0,8,P
sample_3.pdf,7,As clearly visible from Fig. 2 the proposed model (RNNsearch) is much better than the conventional,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,561.484130859375,0.05102040816326531,98,H3
sample_3.pdf,7,model (RNNencdec) at translating long sentences. This is likely due to the fact that the RNNsearch,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,572.443115234375,0.07142857142857142,98,H3
sample_3.pdf,7,"does not require encoding a long sentence into a ﬁxed-length vector perfectly, but only accurately",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,583.402099609375,0.0,98,H3
sample_3.pdf,7,encoding the parts of the input sentence that surround a particular word.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,594.361083984375,0.0,73,H3
sample_3.pdf,7,"As an example, consider this source sentence from the test set:",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,611.297119140625,0.015873015873015872,63,H3
sample_3.pdf,7,An admitting privilege is the right of a doctor to admit a patient to a hospital or,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.865966796875,633.5116577148438,0.012048192771084338,83,H3
sample_3.pdf,7,"a medical centre to carry out a diagnosis or a procedure, based on his status as a",9.962599754333496,NimbusRomNo9L-ReguItal,False,143.865966796875,644.4706420898438,0.0,82,H3
sample_3.pdf,7,health care worker at a hospital.,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,655.4299926757812,0.0,33,H3
sample_3.pdf,7,The RNNencdec-50 translated this sentence into:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,677.9974365234375,0.0851063829787234,47,H3
sample_3.pdf,7,Un privil`ege d’admission est le droit d’un m´edecin de reconnaˆıtre un patient `a,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,700.2119750976562,0.012195121951219513,82,H3
sample_3.pdf,7,l’hˆopital ou un centre m´edical d’un diagnostic ou de prendre un diagnostic en,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.864990234375,711.1710205078125,0.0,79,H3
sample_3.pdf,7,fonction de son ´etat de sant´e.,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,722.1300048828125,0.0,32,H3
sample_3.pdf,8,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,8,"The RNNencdec-50 correctly translated the source sentence until [a medical center]. However, from",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.05154639175257732,97,H3
sample_3.pdf,8,"there on (underlined), it deviated from the original meaning of the source sentence. For instance, it",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,95.22743225097656,0.009900990099009901,101,H3
sample_3.pdf,8,replaced [based on his status as a health care worker at a hospital] in the source sentence with [en,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,106.18641662597656,0.0,100,H3
sample_3.pdf,8,fonction de son ´etat de sant´e] (“based on his state of health”).,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,117.09541320800781,0.0,66,H3
sample_3.pdf,8,"On the other hand, the RNNsearch-50 generated the following correct translation, preserving the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,134.08241271972656,0.042105263157894736,95,H3
sample_3.pdf,8,whole meaning of the input sentence without omitting any details:,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,145.04042053222656,0.0,65,H3
sample_3.pdf,8,Un privil`ege d’admission est le droit d’un m´edecin d’admettre un patient `a un,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.8660125732422,165.23492431640625,0.0125,80,H3
sample_3.pdf,8,"hˆopital ou un centre m´edical pour effectuer un diagnostic ou une proc´edure, selon",9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,176.19390869140625,0.0,84,H3
sample_3.pdf,8,son statut de travailleur des soins de sant´e `a l’hˆopital.,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,187.15301513671875,0.0,60,H3
sample_3.pdf,8,Let us consider another sentence from the test set:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,207.70045471191406,0.0196078431372549,51,H3
sample_3.pdf,8,This kind of experience is part of Disney’s efforts to ”extend the lifetime of its,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,227.89495849609375,0.024390243902439025,82,H3
sample_3.pdf,8,series and build new relationships with audiences via digital platforms that are,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,238.85394287109375,0.0,80,H3
sample_3.pdf,8,"becoming ever more important,” he added.",9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,249.81298828125,0.0,40,H3
sample_3.pdf,8,The translation by the RNNencdec-50 is,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,270.35943603515625,0.10526315789473684,38,H3
sample_3.pdf,8,Ce type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur´ee,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,290.5539855957031,0.023529411764705882,85,H3
sample_3.pdf,8,de vie de ses nouvelles et de d´evelopper des liens avec les lecteurs num´eriques qui,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,301.51300048828125,0.0,85,H3
sample_3.pdf,8,deviennent plus complexes.,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,312.4720153808594,0.0,26,H3
sample_3.pdf,8,"As with the previous example, the RNNencdec began deviating from the actual meaning of the",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,333.01947021484375,0.044444444444444446,90,H3
sample_3.pdf,8,source sentence after generating approximately 30 words (see the underlined phrase). After that,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,343.97845458984375,0.010526315789473684,95,H3
sample_3.pdf,8,"point, the quality of the translation deteriorates, with basic mistakes such as the lack of a closing",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,354.93743896484375,0.0,101,H3
sample_3.pdf,8,quotation mark.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,365.89642333984375,0.0,15,H3
sample_3.pdf,8,"Again, the RNNsearch-50 was able to translate this long sentence correctly:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,382.8324279785156,0.05333333333333334,75,H3
sample_3.pdf,8,Ce genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur´ee,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,403.0269775390625,0.024390243902439025,82,H3
sample_3.pdf,8,de vie de ses s´eries et cr´eer de nouvelles relations avec des publics via des,9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86599731445312,413.9859619140625,0.0,79,H3
sample_3.pdf,8,"plateformes num´eriques de plus en plus importantes”, a-t-il ajout´e.",9.962599754333496,NimbusRomNo9L-ReguItal,False,143.86500549316406,424.94500732421875,0.0,69,H3
sample_3.pdf,8,"In conjunction with the quantitative results presented already, these qualitative observations con-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,445.491455078125,0.010101010101010102,99,H3
sample_3.pdf,8,ﬁrm our hypotheses that the RNNsearch architecture enables far more reliable translation of long,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,456.450439453125,0.03125,96,H3
sample_3.pdf,8,sentences than the standard RNNencdec model.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,467.409423828125,0.06818181818181818,44,H3
sample_3.pdf,8,"In Appendix C, we provide a few more sample translations of long source sentences generated by",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,484.346435546875,0.031914893617021274,94,H3
sample_3.pdf,8,"the RNNencdec-50, RNNsearch-50 and Google Translate along with the reference translations.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,495.305419921875,0.08888888888888889,90,H3
sample_3.pdf,8,ELATED,9.56410026550293,NimbusRomNo9L-Regu,False,135.4010009765625,524.2506713867188,1.0,6,H3
sample_3.pdf,8,ORK,9.56410026550293,NimbusRomNo9L-Regu,False,189.82000732421875,524.2506713867188,1.0,3,H3
sample_3.pdf,8,6.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24900817871094,547.3624267578125,0.0,3,H3
sample_3.pdf,8,EARNING TO,7.970099925994873,NimbusRomNo9L-Regu,False,138.74501037597656,548.87353515625,0.9,10,P
sample_3.pdf,8,LIGN,7.970099925994873,NimbusRomNo9L-Regu,False,202.18600463867188,548.87353515625,1.0,4,P
sample_3.pdf,8,A similar approach of aligning an output symbol with an input symbol was proposed recently by,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,567.8854370117188,0.010752688172043012,93,H3
sample_3.pdf,8,Graves (2013) in the context of handwriting synthesis. Handwriting synthesis is a task where the,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,578.8444213867188,0.020833333333333332,96,H3
sample_3.pdf,8,"model is asked to generate handwriting of a given sequence of characters. In his work, he used a",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,589.8034057617188,0.010416666666666666,96,H3
sample_3.pdf,8,"mixture of Gaussian kernels to compute the weights of the annotations, where the location, width",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,600.762451171875,0.010416666666666666,96,H3
sample_3.pdf,8,"and mixture coefﬁcient of each kernel was predicted from an alignment model. More speciﬁcally,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,611.720458984375,0.010638297872340425,94,H3
sample_3.pdf,8,his alignment was restricted to predict the location such that the location increases monotonically.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,622.679443359375,0.0,100,H3
sample_3.pdf,8,"The main difference from our approach is that, in (Graves, 2013), the modes of the weights of the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,639.616455078125,0.020618556701030927,97,H3
sample_3.pdf,8,"annotations only move in one direction. In the context of machine translation, this is a severe limi-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,650.575439453125,0.009900990099009901,101,H3
sample_3.pdf,8,"tation, as (long-distance) reordering is often needed to generate a grammatically correct translation",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,661.534423828125,0.0,101,H3
sample_3.pdf,8,"(for instance, English-to-German).",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,672.493408203125,0.058823529411764705,34,H3
sample_3.pdf,8,"Our approach, on the other hand, requires computing the annotation weight of every word in the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,689.429443359375,0.010638297872340425,94,H3
sample_3.pdf,8,source sentence for each word in the translation. This drawback is not severe with the task of,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,700.388427734375,0.010638297872340425,94,H3
sample_3.pdf,8,"translation in which most of input and output sentences are only 15–40 words. However, this may",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,711.347412109375,0.010526315789473684,95,H3
sample_3.pdf,8,limit the applicability of the proposed scheme to other tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,722.306396484375,0.0,62,H3
sample_3.pdf,9,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,9,6.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,84.26844787597656,0.0,3,H3
sample_3.pdf,9,EURAL,7.970099925994873,NimbusRomNo9L-Regu,False,139.85000610351562,85.77953338623047,1.0,5,P
sample_3.pdf,9,ETWORKS FOR,7.970099925994873,NimbusRomNo9L-Regu,False,179.05299377441406,85.77953338623047,0.9090909090909091,11,P
sample_3.pdf,9,ACHINE,7.970099925994873,NimbusRomNo9L-Regu,False,252.24798583984375,85.77953338623047,1.0,6,P
sample_3.pdf,9,RANSLATION,7.970099925994873,NimbusRomNo9L-Regu,False,294.0599670410156,85.77953338623047,1.0,10,P
sample_3.pdf,9,Since Bengio,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,114.17243957519531,0.16666666666666666,12,H3
sample_3.pdf,9,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,161.06076049804688,113.9959716796875,0.0,6,H3
sample_3.pdf,9,(2003) introduced a neural probabilistic language model which uses a neural net-,9.962599754333496,NimbusRomNo9L-Regu,False,182.782470703125,114.17243957519531,0.0,80,H3
sample_3.pdf,9,"work to model the conditional probability of a word given a ﬁxed number of the preceding words,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,125.13142395019531,0.0,95,H3
sample_3.pdf,9,"neural networks have widely been used in machine translation. However, the role of neural net-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,136.0904083251953,0.010638297872340425,94,H3
sample_3.pdf,9,works has been largely limited to simply providing a single feature to an existing statistical machine,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,147.0493927001953,0.0,102,H3
sample_3.pdf,9,translation system or to re-rank a list of candidate translations provided by an existing system.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,158.0083770751953,0.0,97,H3
sample_3.pdf,9,"For instance, Schwenk (2012) proposed using a feedforward neural network to compute the score of",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,174.94435119628906,0.020833333333333332,96,H3
sample_3.pdf,9,a pair of source and target phrases and to use the score as an additional feature in the phrase-based,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,185.90333557128906,0.0,101,H3
sample_3.pdf,9,"statistical machine translation system. More recently, Kalchbrenner and Blunsom (2013) and Devlin",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,196.86231994628906,0.041237113402061855,97,H3
sample_3.pdf,9,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,107.99996185302734,207.64483642578125,0.0,6,H3
sample_3.pdf,9,(2014) reported the successful use of the neural networks as a sub-component of the existing,9.962599754333496,NimbusRomNo9L-Regu,False,128.22402954101562,207.82130432128906,0.0,92,H3
sample_3.pdf,9,"translation system. Traditionally, a neural network trained as a target-side language model has been",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,218.78028869628906,0.01,100,H3
sample_3.pdf,9,"used to rescore or rerank a list of candidate translations (see, e.g., Schwenk",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,229.73927307128906,0.01282051282051282,78,H3
sample_3.pdf,9,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,407.3562316894531,229.56280517578125,0.0,6,H3
sample_3.pdf,9,", 2006).",9.962599754333496,NimbusRomNo9L-Regu,False,429.76995849609375,229.73927307128906,0.0,8,H3
sample_3.pdf,9,Although the above approaches were shown to improve the translation performance over the state-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,246.6752471923828,0.010526315789473684,95,H3
sample_3.pdf,9,"of-the-art machine translation systems, we are more interested in a more ambitious objective of",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,257.63421630859375,0.0,95,H3
sample_3.pdf,9,designing a completely new translation system based on neural networks. The neural machine trans-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,268.59320068359375,0.010309278350515464,97,H3
sample_3.pdf,9,lation approach we consider in this paper is therefore a radical departure from these earlier works.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,279.55218505859375,0.0,100,H3
sample_3.pdf,9,"Rather than using a neural network as a part of the existing system, our model works on its own and",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,290.51116943359375,0.010101010101010102,99,H3
sample_3.pdf,9,generates a translation from a source sentence directly.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,301.47015380859375,0.0,56,H3
sample_3.pdf,9,ONCLUSION,9.56410026550293,NimbusRomNo9L-Regu,False,135.40097045898438,354.1153564453125,1.0,9,H3
sample_3.pdf,9,"The conventional approach to neural machine translation, called an encoder–decoder approach, en-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,391.546142578125,0.010416666666666666,96,H3
sample_3.pdf,9,codes a whole input sentence into a ﬁxed-length vector from which a translation will be decoded.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,402.505126953125,0.0,96,H3
sample_3.pdf,9,We conjectured that the use of a ﬁxed-length context vector is problematic for translating long sen-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,413.464111328125,0.01,100,H3
sample_3.pdf,9,"tences, based on a recent empirical study reported by Cho",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,424.423095703125,0.017543859649122806,57,H3
sample_3.pdf,9,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,342.6390686035156,424.24664306640625,0.0,6,H3
sample_3.pdf,9,(2014b) and Pouget-Abadie,9.962599754333496,NimbusRomNo9L-Regu,False,366.01434326171875,424.423095703125,0.08,25,H3
sample_3.pdf,9,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,480.6187744140625,424.24664306640625,0.0,6,H3
sample_3.pdf,9,(2014).,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,435.382080078125,0.0,7,H3
sample_3.pdf,9,"In this paper, we proposed a novel architecture that addresses this issue. We extended the basic",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,452.3180847167969,0.020833333333333332,96,H3
sample_3.pdf,9,"encoder–decoder by letting a model (soft-)search for a set of input words, or their annotations com-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,463.277099609375,0.0,100,H3
sample_3.pdf,9,"puted by an encoder, when generating each target word. This frees the model from having to encode",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,474.236083984375,0.010309278350515464,97,H3
sample_3.pdf,9,"a whole source sentence into a ﬁxed-length vector, and also lets the model focus only on information",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,485.195068359375,0.0,100,H3
sample_3.pdf,9,relevant to the generation of the next target word. This has a major positive impact on the ability,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,496.154052734375,0.010101010101010102,99,H3
sample_3.pdf,9,of the neural machine translation system to yield good results on longer sentences. Unlike with,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,507.113037109375,0.010526315789473684,95,H3
sample_3.pdf,9,"the traditional machine translation systems, all of the pieces of the translation system, including",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,518.072021484375,0.0,99,H3
sample_3.pdf,9,"the alignment mechanism, are jointly trained towards a better log-probability of producing correct",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,529.031005859375,0.0,98,H3
sample_3.pdf,9,translations.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,539.989013671875,0.0,13,H3
sample_3.pdf,9,"We tested the proposed model, called RNNsearch, on the task of English-to-French translation. The",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,556.926025390625,0.07216494845360824,97,H3
sample_3.pdf,9,experiment revealed that the proposed RNNsearch outperforms the conventional encoder–decoder,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,567.885009765625,0.03260869565217391,92,H3
sample_3.pdf,9,"model (RNNencdec) signiﬁcantly, regardless of the sentence length and that it is much more ro-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,578.843994140625,0.031914893617021274,94,H3
sample_3.pdf,9,bust to the length of a source sentence. From the qualitative analysis where we investigated the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,589.802978515625,0.010416666666666666,96,H3
sample_3.pdf,9,"(soft-)alignment generated by the RNNsearch, we were able to conclude that the model can cor-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,600.7620239257812,0.03225806451612903,93,H3
sample_3.pdf,9,"rectly align each target word with the relevant words, or their annotations, in the source sentence as",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,611.719970703125,0.0,102,H3
sample_3.pdf,9,it generated a correct translation.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,622.6790161132812,0.0,35,H3
sample_3.pdf,9,"Perhaps more importantly, the proposed approach achieved a translation performance comparable to",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,639.615966796875,0.010416666666666666,96,H3
sample_3.pdf,9,"the existing phrase-based statistical machine translation. It is a striking result, considering that the",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,650.5750122070312,0.009615384615384616,104,H3
sample_3.pdf,9,"proposed architecture, or the whole family of neural machine translation, has only been proposed",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,661.5339965820312,0.0,96,H3
sample_3.pdf,9,as recently as this year. We believe the architecture proposed here is a promising step toward better,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,672.4929809570312,0.009900990099009901,101,H3
sample_3.pdf,9,machine translation and a better understanding of natural languages in general.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,683.4509887695312,0.0,79,H3
sample_3.pdf,9,"One of challenges left for the future is to better handle unknown, or rare words. This will be required",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,700.3880004882812,0.019417475728155338,103,H3
sample_3.pdf,9,for the model to be more widely used and to match the performance of current state-of-the-art,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,711.3469848632812,0.0,93,H3
sample_3.pdf,9,machine translation systems in all contexts.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,722.3060302734375,0.0,44,H3
sample_3.pdf,10,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,10,CKNOWLEDGMENTS,9.56410026550293,NimbusRomNo9L-Regu,False,117.09800720214844,84.57066345214844,1.0,14,H3
sample_3.pdf,10,The authors would like to thank the developers of Theano (Bergstra,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,108.02247619628906,0.045454545454545456,66,H3
sample_3.pdf,10,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,389.3636779785156,107.84600830078125,0.0,6,H3
sample_3.pdf,10,", 2010; Bastien",9.962599754333496,NimbusRomNo9L-Regu,False,414.2010192871094,108.02247619628906,0.06666666666666667,15,H3
sample_3.pdf,10,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,476.67645263671875,107.84600830078125,0.0,6,H3
sample_3.pdf,10,2012). We acknowledge the support of the following agencies for research funding and computing,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,118.98146057128906,0.010638297872340425,94,H3
sample_3.pdf,10,"support: NSERC, Calcul Qu´ebec, Compute Canada, the Canada Research Chairs and CIFAR. Bah-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,129.8904571533203,0.2,90,H3
sample_3.pdf,10,"danau thanks the support from Planet Intelligent Systems GmbH. We also thank Felix Hill, Bart van",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003814697266,140.89942932128906,0.09278350515463918,97,H3
sample_3.pdf,10,"Merri´enboer, Jean Pouget-Abadie, Coline Devin and Tae-Ho Kim.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003814697266,151.8084259033203,0.14516129032258066,62,H3
sample_3.pdf,10,EFERENCES,9.56410026550293,NimbusRomNo9L-Regu,False,116.87102508544922,181.20664978027344,1.0,9,H3
sample_3.pdf,10,"Axelrod, A., He, X., and Gao, J. (2011). Domain adaptation via pseudo in-domain data selection.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0000228881836,198.68141174316406,0.07368421052631578,95,H3
sample_3.pdf,10,Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing,9.962599754333496,NimbusRomNo9L-ReguItal,False,126.2618637084961,209.46392822265625,0.11764705882352941,85,H3
sample_3.pdf,10,(EMNLP),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96302032470703,220.42291259765625,0.7142857142857143,7,H3
sample_3.pdf,10,", pages 355–362. Association for Computational Linguistics.",9.962599754333496,NimbusRomNo9L-Regu,False,157.25502014160156,220.59938049316406,0.05084745762711865,59,H3
sample_3.pdf,10,"Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N.,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,239.80335998535156,0.15151515151515152,99,H3
sample_3.pdf,10,"and Bengio, Y. (2012). Theano: new features and speed improvements. Deep Learning and",9.962599754333496,NimbusRomNo9L-Regu,False,117.9630126953125,250.76234436035156,0.058823529411764705,85,H3
sample_3.pdf,10,Unsupervised Feature Learning NIPS 2012 Workshop.,9.962599754333496,NimbusRomNo9L-Regu,False,117.9630126953125,261.7203369140625,0.16326530612244897,49,H3
sample_3.pdf,10,"Bengio, Y., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,280.9243469238281,0.07446808510638298,94,H3
sample_3.pdf,10,descent is difﬁcult.,9.962599754333496,NimbusRomNo9L-Regu,False,117.9630126953125,291.88336181640625,0.0,20,H3
sample_3.pdf,10,IEEE Transactions on Neural Networks,9.962599754333496,NimbusRomNo9L-ReguItal,False,193.26036071777344,291.7069091796875,0.19444444444444445,36,H3
sample_3.pdf,10,"(2), 157–166.",9.962599754333496,NimbusRomNo9L-Regu,False,364.81396484375,291.88336181640625,0.0,13,H3
sample_3.pdf,10,"Bengio, Y., Ducharme, R., Vincent, P., and Janvin, C. (2003). A neural probabilistic language model.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,311.0873718261719,0.09,100,H3
sample_3.pdf,10,J. Mach. Learn. Res.,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96296691894531,321.86993408203125,0.2,20,H3
sample_3.pdf,10,", 1137–1155.",9.962599754333496,NimbusRomNo9L-Regu,False,210.25596618652344,322.04638671875,0.0,12,H3
sample_3.pdf,10,"Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,341.2503967285156,0.1485148514851485,101,H3
sample_3.pdf,10,"Farley, D., and Bengio, Y. (2010). Theano: a CPU and GPU math expression compiler. In",9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,352.20941162109375,0.1411764705882353,85,H3
sample_3.pdf,10,Proceedings of the Python for Scientiﬁc Computing Conference (SciPy),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96296691894531,362.991943359375,0.10294117647058823,68,H3
sample_3.pdf,10,. Oral Presentation.,9.962599754333496,NimbusRomNo9L-Regu,False,402.70196533203125,363.16839599609375,0.1,20,H3
sample_3.pdf,10,"Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2013). Audio chord recognition with",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,382.3724060058594,0.08791208791208792,91,H3
sample_3.pdf,10,recurrent neural networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,393.3314208984375,0.034482758620689655,29,H3
sample_3.pdf,10,ISMIR,9.962599754333496,NimbusRomNo9L-ReguItal,False,234.59512329101562,393.15496826171875,1.0,5,H3
sample_3.pdf,10,"Cho, K., van Merrienboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y. (2014a).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,412.5354309082031,0.1276595744680851,94,H3
sample_3.pdf,10,Learning phrase representations using RNN encoder-decoder for statistical machine translation.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,423.49444580078125,0.0425531914893617,94,H3
sample_3.pdf,10,Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014),9.962599754333496,NimbusRomNo9L-ReguItal,False,126.26181030273438,434.2769775390625,0.13580246913580246,81,H3
sample_3.pdf,10,. to,9.962599754333496,NimbusRomNo9L-Regu,False,488.1429443359375,434.45343017578125,0.0,4,H3
sample_3.pdf,10,appear.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96295166015625,445.41241455078125,0.0,7,H3
sample_3.pdf,10,"Cho, K., van Merri¨enboer, B., Bahdanau, D., and Bengio, Y. (2014b). On the properties of neural",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,464.5664367675781,0.09375,96,H3
sample_3.pdf,10,machine translation: Encoder–Decoder approaches. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,475.575439453125,0.058823529411764705,51,H3
sample_3.pdf,10,"Eighth Workshop on Syntax, Semantics",9.962599754333496,NimbusRomNo9L-ReguItal,False,341.63330078125,475.39898681640625,0.1111111111111111,36,H3
sample_3.pdf,10,and Structure in Statistical Translation,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96296691894531,486.35797119140625,0.075,40,H3
sample_3.pdf,10,. to appear.,9.962599754333496,NimbusRomNo9L-Regu,False,272.99896240234375,486.534423828125,0.0,12,H3
sample_3.pdf,10,"Devlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., and Makhoul, J. (2014). Fast and robust",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,505.7384033203125,0.13402061855670103,97,H3
sample_3.pdf,10,neural network joint models for statistical machine translation. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,516.6974487304688,0.014925373134328358,67,H3
sample_3.pdf,10,Association for Computational,9.962599754333496,NimbusRomNo9L-ReguItal,False,378.79376220703125,516.52099609375,0.06896551724137931,29,H3
sample_3.pdf,10,Linguistics,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,527.47900390625,0.09090909090909091,11,H3
sample_3.pdf,10,"Forcada, M. L. and",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,546.8594360351562,0.16666666666666666,18,H3
sample_3.pdf,10,"Neco, R. P. (1997). Recursive hetero-associative memories for translation. In",9.962599754333496,NimbusRomNo9L-Regu,False,188.92098999023438,546.8594360351562,0.06493506493506493,77,H3
sample_3.pdf,10,"J. Mira, R. Moreno-D´ıaz, and J. Cabestany, editors,",9.962599754333496,NimbusRomNo9L-Regu,False,117.9629898071289,557.7694702148438,0.1346153846153846,52,H3
sample_3.pdf,10,Biological and Artiﬁcial Computation: From,9.962599754333496,NimbusRomNo9L-ReguItal,False,322.58013916015625,557.6420288085938,0.09523809523809523,42,H3
sample_3.pdf,10,Neuroscience to Technology,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,568.6010131835938,0.07692307692307693,26,H3
sample_3.pdf,10,", volume 1240 of",9.962599754333496,NimbusRomNo9L-Regu,False,229.02899169921875,568.7774658203125,0.0,16,H3
sample_3.pdf,10,Lecture Notes in Computer Science,9.962599754333496,NimbusRomNo9L-ReguItal,False,295.8381042480469,568.6010131835938,0.12121212121212122,33,H3
sample_3.pdf,10,", pages 453–462.",9.962599754333496,NimbusRomNo9L-Regu,False,437.16998291015625,568.7774658203125,0.0,16,H3
sample_3.pdf,10,Springer Berlin Heidelberg.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,579.7364501953125,0.1111111111111111,27,H3
sample_3.pdf,10,"Goodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013). Maxout net-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,598.9404296875,0.1276595744680851,94,H3
sample_3.pdf,10,works. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,609.8994140625,0.1111111111111111,9,H3
sample_3.pdf,10,Proceedings of The 30th International Conference on Machine Learning,9.962599754333496,NimbusRomNo9L-ReguItal,False,156.76731872558594,609.7229614257812,0.08823529411764706,68,H3
sample_3.pdf,10,", pages 1319–",9.962599754333496,NimbusRomNo9L-Regu,False,448.8079833984375,609.8994140625,0.0,13,H3
sample_3.pdf,10,1327.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,620.8584594726562,0.0,5,H3
sample_3.pdf,10,"Graves, A. (2012). Sequence transduction with recurrent neural networks. In",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,640.0624389648438,0.05333333333333334,75,H3
sample_3.pdf,10,Proceedings of the,9.962599754333496,NimbusRomNo9L-ReguItal,False,425.0196533203125,639.885986328125,0.05555555555555555,18,H3
sample_3.pdf,10,29th International Conference on Machine Learning (ICML 2012),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96295166015625,650.844970703125,0.13114754098360656,61,H3
sample_3.pdf,10,"Graves, A. (2013).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,670.2254638671875,0.1111111111111111,18,H3
sample_3.pdf,10,Generating sequences with recurrent neural networks.,9.962599754333496,NimbusRomNo9L-Regu,False,194.00706481933594,670.2254638671875,0.019230769230769232,52,H3
sample_3.pdf,10,arXiv:,9.962599754333496,NimbusRomNo9L-ReguItal,False,424.7479553222656,670.0490112304688,0.16666666666666666,6,H3
sample_3.pdf,10,1308.0850,9.962599754333496,NimbusMonL-Regu,False,450.20196533203125,669.7154541015625,0.0,9,H3
sample_3.pdf,10,[cs.NE],9.962599754333496,NimbusMonL-Regu,False,117.96295166015625,680.6744384765625,0.2857142857142857,7,H3
sample_3.pdf,10,"Graves, A., Jaitly, N., and Mohamed, A.-R. (2013). Hybrid speech recognition with deep bidirec-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,700.388427734375,0.08421052631578947,95,H3
sample_3.pdf,10,tional LSTM. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96295166015625,711.347412109375,0.3333333333333333,15,H3
sample_3.pdf,10,"Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Work-",9.962599754333496,NimbusRomNo9L-ReguItal,False,186.46575927734375,711.1709594726562,0.18571428571428572,70,H3
sample_3.pdf,10,shop on,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96295928955078,722.1300048828125,0.0,7,H3
sample_3.pdf,10,", pages 273–278.",9.962599754333496,NimbusRomNo9L-Regu,False,149.23495483398438,722.3064575195312,0.0,16,H3
sample_3.pdf,11,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,11,"Hermann, K. and Blunsom, P. (2014). Multilingual distributed representations without word align-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.052083333333333336,96,H3
sample_3.pdf,11,ment. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,95.22743225097656,0.125,8,H3
sample_3.pdf,11,Proceedings of the Second International Conference on Learning Representations (ICLR,9.962599754333496,NimbusRomNo9L-ReguItal,False,151.44729614257812,95.05096435546875,0.11904761904761904,84,H3
sample_3.pdf,11,2014),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.9629898071289,106.00994873046875,0.0,5,H3
sample_3.pdf,11,"Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,125.11543273925781,0.0625,96,H3
sample_3.pdf,11,"f¨ur Informatik, Lehrstuhl Prof. Brauer, Technische Universit¨at M¨unchen.",9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,136.02442932128906,0.0945945945945946,74,H3
sample_3.pdf,11,"Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,155.00343322753906,0.07575757575757576,66,H3
sample_3.pdf,11,Neural Computation,9.962599754333496,NimbusRomNo9L-ReguItal,False,390.93780517578125,154.82696533203125,0.1111111111111111,18,H3
sample_3.pdf,11,"(8),",9.962599754333496,NimbusRomNo9L-Regu,False,489.8929748535156,155.00343322753906,0.0,4,H3
sample_3.pdf,11,1735–1780.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,165.96241760253906,0.0,10,H3
sample_3.pdf,11,"Kalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. In",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,184.8914337158203,0.07142857142857142,84,H3
sample_3.pdf,11,Proceedings,9.962599754333496,NimbusRomNo9L-ReguItal,False,452.3371276855469,184.7149658203125,0.09090909090909091,11,H3
sample_3.pdf,11,of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,195.6739501953125,0.1728395061728395,81,H3
sample_3.pdf,11,", pages",9.962599754333496,NimbusRomNo9L-Regu,False,476.1659851074219,195.8504180908203,0.0,7,H3
sample_3.pdf,11,1700–1709. Association for Computational Linguistics.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,206.8094024658203,0.05660377358490566,53,H3
sample_3.pdf,11,"Koehn, P. (2010).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,225.73841857910156,0.11764705882352941,17,H3
sample_3.pdf,11,Statistical Machine Translation,9.962599754333496,NimbusRomNo9L-ReguItal,False,179.52145385742188,225.56195068359375,0.0967741935483871,31,H3
sample_3.pdf,11,". Cambridge University Press, New York, NY,",9.962599754333496,NimbusRomNo9L-Regu,False,312.77899169921875,225.73841857910156,0.16279069767441862,43,H3
sample_3.pdf,11,USA.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,236.69740295410156,0.75,4,H3
sample_3.pdf,11,"Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase-based translation. In",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,255.6264190673828,0.10588235294117647,85,H3
sample_3.pdf,11,Proceedings,9.962599754333496,NimbusRomNo9L-ReguItal,False,451.4603576660156,255.449951171875,0.09090909090909091,11,H3
sample_3.pdf,11,of the 2003 Conference of the North American Chapter of the Association for Computational,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,266.408935546875,0.06741573033707865,89,H3
sample_3.pdf,11,Linguistics on Human Language Technology - Volume 1,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,277.367919921875,0.09803921568627451,51,H3
sample_3.pdf,11,", NAACL ’03, pages 48–54, Stroudsburg,",9.962599754333496,NimbusRomNo9L-Regu,False,339.67095947265625,277.54437255859375,0.15789473684210525,38,H3
sample_3.pdf,11,"PA, USA. Association for Computational Linguistics.",9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,288.50335693359375,0.1568627450980392,51,H3
sample_3.pdf,11,"Pascanu, R., Mikolov, T., and Bengio, Y. (2013a). On the difﬁculty of training recurrent neural",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,307.432373046875,0.07368421052631578,95,H3
sample_3.pdf,11,networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,318.390380859375,0.08333333333333333,12,H3
sample_3.pdf,11,ICML’2013,9.962599754333496,NimbusRomNo9L-ReguItal,False,168.7622528076172,318.21392822265625,0.4444444444444444,9,H3
sample_3.pdf,11,"Pascanu, R., Mikolov, T., and Bengio, Y. (2013b). On the difﬁculty of training recurrent neural",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,337.31939697265625,0.07368421052631578,95,H3
sample_3.pdf,11,networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,348.27838134765625,0.08333333333333333,12,H3
sample_3.pdf,11,Proceedings of the 30th International Conference on Machine Learning (ICML,9.962599754333496,NimbusRomNo9L-ReguItal,False,172.8568878173828,348.1019287109375,0.12162162162162163,74,H3
sample_3.pdf,11,2013),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96296691894531,359.0609130859375,0.0,5,H3
sample_3.pdf,11,"Pascanu, R., Gulcehre, C., Cho, K., and Bengio, Y. (2014). How to construct deep recurrent neural",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,378.1663818359375,0.09278350515463918,97,H3
sample_3.pdf,11,networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,389.1253662109375,0.08333333333333333,12,H3
sample_3.pdf,11,Proceedings of the Second International Conference on Learning Representations,9.962599754333496,NimbusRomNo9L-ReguItal,False,170.41604614257812,388.94891357421875,0.07692307692307693,78,H3
sample_3.pdf,11,(ICLR 2014),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96297454833984,399.90789794921875,0.36363636363636365,11,H3
sample_3.pdf,11,"Pouget-Abadie, J., Bahdanau, D., van Merri¨enboer, B., Cho, K., and Bengio, Y. (2014). Overcoming",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,418.96337890625,0.12371134020618557,97,H3
sample_3.pdf,11,the curse of sentence length for neural machine translation using automatic segmentation. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,429.97235107421875,0.010869565217391304,92,H3
sample_3.pdf,11,"Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96296691894531,440.7548828125,0.09090909090909091,77,H3
sample_3.pdf,11,. to appear.,9.962599754333496,NimbusRomNo9L-Regu,False,430.91595458984375,440.93133544921875,0.0,12,H3
sample_3.pdf,11,"Schuster, M. and Paliwal, K. K. (1997). Bidirectional recurrent neural networks.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,459.8603515625,0.075,80,H3
sample_3.pdf,11,"Signal Processing,",9.962599754333496,NimbusRomNo9L-ReguItal,False,426.753173828125,459.68389892578125,0.1111111111111111,18,H3
sample_3.pdf,11,IEEE Transactions on,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,470.64288330078125,0.25,20,H3
sample_3.pdf,11,"(11), 2673–2681.",9.962599754333496,NimbusRomNo9L-Regu,False,220.76698303222656,470.8193359375,0.0,16,H3
sample_3.pdf,11,"Schwenk, H. (2012).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,489.74835205078125,0.10526315789473684,19,H3
sample_3.pdf,11,Continuous space translation models for phrase-based statistical machine,9.962599754333496,NimbusRomNo9L-Regu,False,202.33580017089844,489.74835205078125,0.013888888888888888,72,H3
sample_3.pdf,11,"translation. In M. Kay and C. Boitet, editors,",9.962599754333496,NimbusRomNo9L-Regu,False,117.96298217773438,500.70733642578125,0.10869565217391304,46,H3
sample_3.pdf,11,Proceedings of the 24th International Conference on,9.962599754333496,NimbusRomNo9L-ReguItal,False,294.1415710449219,500.5308837890625,0.058823529411764705,51,H3
sample_3.pdf,11,Computational Linguistics (COLIN),9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96298217773438,511.4898681640625,0.21212121212121213,33,H3
sample_3.pdf,11,", pages 1071–1080. Indian Institute of Technology Bombay.",9.962599754333496,NimbusRomNo9L-Regu,False,262.43896484375,511.66632080078125,0.07017543859649122,57,H3
sample_3.pdf,11,"Schwenk, H., Dchelotte, D., and Gauvain, J.-L. (2006). Continuous space language models for",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,530.5953369140625,0.08791208791208792,91,H3
sample_3.pdf,11,statistical machine translation. In,9.962599754333496,NimbusRomNo9L-Regu,False,117.96296691894531,541.5543212890625,0.02857142857142857,35,H3
sample_3.pdf,11,Proceedings of the COLING/ACL on Main conference poster,9.962599754333496,NimbusRomNo9L-ReguItal,False,253.7333526611328,541.3778686523438,0.2,55,H3
sample_3.pdf,11,sessions,9.962599754333496,NimbusRomNo9L-ReguItal,False,117.96295166015625,552.3358764648438,0.0,8,H3
sample_3.pdf,11,", pages 723–730. Association for Computational Linguistics.",9.962599754333496,NimbusRomNo9L-Regu,False,150.6199493408203,552.5123291015625,0.05084745762711865,59,H3
sample_3.pdf,11,"Sutskever, I., Vinyals, O., and Le, Q. (2014). Sequence to sequence learning with neural networks.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,571.4423217773438,0.07142857142857142,98,H3
sample_3.pdf,11,Advances in Neural Information Processing Systems (NIPS 2014),9.962599754333496,NimbusRomNo9L-ReguItal,False,126.26179504394531,582.223876953125,0.14754098360655737,61,H3
sample_3.pdf,11,"Zeiler, M. D. (2012).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,601.329345703125,0.14285714285714285,21,H3
sample_3.pdf,11,ADADELTA: An adaptive learning rate method.,9.962599754333496,NimbusRomNo9L-Regu,False,209.7479248046875,601.329345703125,0.20930232558139536,43,H3
sample_3.pdf,11,arXiv:,9.962599754333496,NimbusRomNo9L-ReguItal,False,424.7479248046875,601.1528930664062,0.16666666666666666,6,H3
sample_3.pdf,11,1212.5701,9.962599754333496,NimbusMonL-Regu,False,450.2019348144531,600.8193359375,0.0,9,H3
sample_3.pdf,11,[cs.LG],9.962599754333496,NimbusMonL-Regu,False,117.96292114257812,611.7783203125,0.2857142857142857,7,H3
sample_3.pdf,12,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,12,ODEL,9.56410026550293,NimbusRomNo9L-Regu,False,140.70899963378906,84.57066345214844,1.0,4,H3
sample_3.pdf,12,RCHITECTURE,9.56410026550293,NimbusRomNo9L-Regu,False,180.78199768066406,84.57066345214844,1.0,11,H3
sample_3.pdf,12,A.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,109.73945617675781,0.3333333333333333,3,H3
sample_3.pdf,12,RCHITECTURAL,7.970099925994873,NimbusRomNo9L-Regu,False,142.06199645996094,111.25054168701172,1.0,12,P
sample_3.pdf,12,HOICES,7.970099925994873,NimbusRomNo9L-Regu,False,218.2550048828125,111.25054168701172,1.0,6,P
sample_3.pdf,12,"The proposed scheme in Section 3 is a general framework where one can freely deﬁne, for instance,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,131.4684600830078,0.020618556701030927,97,H3
sample_3.pdf,12,the activation functions,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,142.4274444580078,0.0,24,H3
sample_3.pdf,12,of recurrent neural networks (RNN) and the alignment model,9.962599754333496,NimbusRomNo9L-Regu,False,208.03468322753906,142.4274444580078,0.05172413793103448,58,H3
sample_3.pdf,12,". Here, we",9.962599754333496,NimbusRomNo9L-Regu,False,462.60498046875,142.4274444580078,0.1,10,H3
sample_3.pdf,12,describe the choices we made for the experiments in this paper.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,153.3864288330078,0.0,63,H3
sample_3.pdf,12,A.1.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24897003173828,180.0624542236328,0.2,5,H3
sample_3.pdf,12,ECURRENT,7.970099925994873,NimbusRomNo9L-Regu,False,149.98196411132812,181.57354736328125,1.0,8,P
sample_3.pdf,12,EURAL,7.970099925994873,NimbusRomNo9L-Regu,False,206.1609649658203,181.57354736328125,1.0,5,P
sample_3.pdf,12,ETWORK,7.970099925994873,NimbusRomNo9L-Regu,False,245.3629608154297,181.57354736328125,1.0,6,P
sample_3.pdf,12,For the activation function,9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,200.4474639892578,0.037037037037037035,27,H3
sample_3.pdf,12,"of an RNN, we use the gated hidden unit recently proposed by Cho",9.962599754333496,NimbusRomNo9L-Regu,False,223.5816192626953,200.4474639892578,0.0625,64,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,107.99994659423828,211.22900390625,0.0,6,H3
sample_3.pdf,12,(2014a). The gated hidden unit is an alternative to the conventional,9.962599754333496,NimbusRomNo9L-Regu,False,128.59263610839844,211.4054718017578,0.014705882352941176,68,H3
sample_3.pdf,12,simple,9.962599754333496,NimbusRomNo9L-ReguItal,False,406.86993408203125,211.22900390625,0.0,6,H3
sample_3.pdf,12,units such as an,9.962599754333496,NimbusRomNo9L-Regu,False,436.0412902832031,211.4054718017578,0.0,16,H3
sample_3.pdf,12,element-wise,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,222.3644561767578,0.0,12,H3
sample_3.pdf,12,tanh,9.962599754333496,CMR10,False,161.1205291748047,222.13389587402344,0.0,4,H3
sample_3.pdf,12,. This gated unit is similar to a long short-term memory (LSTM) unit proposed,9.962599754333496,NimbusRomNo9L-Regu,False,183.91793823242188,222.3644561767578,0.06493506493506493,77,H3
sample_3.pdf,12,"earlier by Hochreiter and Schmidhuber (1997), sharing with it the ability to better model and learn",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,233.3234405517578,0.020202020202020204,99,H3
sample_3.pdf,12,long-term dependencies. This is made possible by having computation paths in the unfolded RNN,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,244.2824249267578,0.043010752688172046,93,H3
sample_3.pdf,12,for which the product of derivatives is close to 1. These paths allow gradients to ﬂow backward,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,255.2414093017578,0.010526315789473684,95,H3
sample_3.pdf,12,"easily without suffering too much from the vanishing effect (Hochreiter, 1991; Bengio",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,266.20037841796875,0.023529411764705882,85,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,453.5027770996094,266.02392578125,0.0,6,H3
sample_3.pdf,12,", 1994;",9.962599754333496,NimbusRomNo9L-Regu,False,476.1889343261719,266.20037841796875,0.0,7,H3
sample_3.pdf,12,Pascanu,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,277.15936279296875,0.14285714285714285,7,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,140.4979248046875,276.98291015625,0.0,6,H3
sample_3.pdf,12,", 2013a). It is therefore possible to use LSTM units instead of the gated hidden unit",9.962599754333496,NimbusRomNo9L-Regu,False,163.89395141601562,277.15936279296875,0.058823529411764705,85,H3
sample_3.pdf,12,"described here, as was done in a similar context by Sutskever",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,288.11834716796875,0.01639344262295082,61,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,351.5655517578125,287.94189453125,0.0,6,H3
sample_3.pdf,12,(2014).,9.962599754333496,NimbusRomNo9L-Regu,False,373.9801330566406,288.11834716796875,0.0,7,H3
sample_3.pdf,12,The new state,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,305.0543518066406,0.07692307692307693,13,H3
sample_3.pdf,12,of the RNN employing,9.962599754333496,NimbusRomNo9L-Regu,False,173.0613555908203,305.0543518066406,0.15,20,H3
sample_3.pdf,12,gated hidden units,9.962599754333496,NimbusRomNo9L-Regu,False,276.0155334472656,305.0543518066406,0.0,18,H3
sample_3.pdf,12,is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,357.989990234375,305.0543518066406,0.0,14,H3
sample_3.pdf,12,", y",9.962599754333496,CMMI10,False,254.2489776611328,325.43682861328125,0.0,3,H3
sample_3.pdf,12,", c",9.962599754333496,CMMI10,False,277.0759582519531,325.43682861328125,0.0,3,H3
sample_3.pdf,12,) = (1,9.962599754333496,CMR10,False,289.1319580078125,325.43682861328125,0.0,6,H3
sample_3.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,346.2803649902344,0.0,5,H3
sample_3.pdf,12,"is an element-wise multiplication, and",9.962599754333496,NimbusRomNo9L-Regu,False,142.3689727783203,346.2803649902344,0.0,38,H3
sample_3.pdf,12,is the output of the update gates (see below). The,9.962599754333496,NimbusRomNo9L-Regu,False,304.40838623046875,346.2803649902344,0.02,50,H3
sample_3.pdf,12,proposed updated state,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,357.2393798828125,0.0,22,H3
sample_3.pdf,12,is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,209.28439331054688,357.2393798828125,0.0,14,H3
sample_3.pdf,12,= tanh (,9.962599754333496,CMR10,False,220.02938842773438,377.6218566894531,0.0,8,H3
sample_3.pdf,12,) +,9.962599754333496,CMR10,False,296.97796630859375,377.6218566894531,0.0,3,H3
sample_3.pdf,12,] +,9.962599754333496,CMR10,False,360.7499694824219,377.6218566894531,0.0,3,H3
sample_3.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,398.46539306640625,0.0,5,H3
sample_3.pdf,12,is an,9.962599754333496,NimbusRomNo9L-Regu,False,198.49090576171875,398.46539306640625,0.0,5,H3
sample_3.pdf,12,-dimensional embedding of a word,9.962599754333496,NimbusRomNo9L-Regu,False,229.47691345214844,398.46539306640625,0.0,32,H3
sample_3.pdf,12,", and",9.962599754333496,NimbusRomNo9L-Regu,False,392.74188232421875,398.46539306640625,0.0,5,H3
sample_3.pdf,12,is the output of the,9.962599754333496,NimbusRomNo9L-Regu,False,423.27130126953125,398.46539306640625,0.0,20,H3
sample_3.pdf,12,reset gates (see below). When,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,409.42437744140625,0.034482758620689655,29,H3
sample_3.pdf,12,is represented as a,9.962599754333496,NimbusRomNo9L-Regu,False,239.7313232421875,409.42437744140625,0.0,19,H3
sample_3.pdf,12,-of-,9.962599754333496,NimbusRomNo9L-Regu,False,324.3838806152344,409.42437744140625,0.0,4,H3
sample_3.pdf,12,"vector,",9.962599754333496,NimbusRomNo9L-Regu,False,347.776123046875,409.42437744140625,0.0,7,H3
sample_3.pdf,12,is simply a column of an,9.962599754333496,NimbusRomNo9L-Regu,False,401.5483093261719,409.42437744140625,0.0,24,H3
sample_3.pdf,12,embedding matrix,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,420.38336181640625,0.0,16,H3
sample_3.pdf,12,". Whenever possible, we omit bias terms to make the equations less",9.962599754333496,NimbusRomNo9L-Regu,False,232.65084838867188,420.38336181640625,0.015151515151515152,66,H3
sample_3.pdf,12,cluttered.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,431.34234619140625,0.0,10,H3
sample_3.pdf,12,The update gates,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,448.27935791015625,0.0625,16,H3
sample_3.pdf,12,"allow each hidden unit to maintain its previous activation, and the reset gates",9.962599754333496,NimbusRomNo9L-Regu,False,185.30625915527344,448.27935791015625,0.0,79,H3
sample_3.pdf,12,control how much and what information from the previous state should be reset. We compute them,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,459.23834228515625,0.010638297872340425,94,H3
sample_3.pdf,12,) +,9.962599754333496,CMR10,False,300.1418151855469,490.5788269042969,0.0,3,H3
sample_3.pdf,12,) +,9.962599754333496,CMR10,False,299.9627990722656,504.52679443359375,0.0,3,H3
sample_3.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,525.370361328125,0.0,5,H3
sample_3.pdf,12,is a logistic sigmoid function.,9.962599754333496,NimbusRomNo9L-Regu,False,153.05723571777344,525.370361328125,0.0,31,H3
sample_3.pdf,12,"At each step of the decoder, we compute the output probability (Eq. (4)) as a multi-layered func-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,542.307373046875,0.020618556701030927,97,H3
sample_3.pdf,12,tion (Pascanu,9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,553.266357421875,0.07692307692307693,13,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,161.96717834472656,553.0899047851562,0.0,6,H3
sample_3.pdf,12,", 2014). We use a single hidden layer of maxout units (Goodfellow",9.962599754333496,NimbusRomNo9L-Regu,False,184.71678161621094,553.266357421875,0.03076923076923077,65,H3
sample_3.pdf,12,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,452.8699035644531,553.0899047851562,0.0,6,H3
sample_3.pdf,12,", 2013)",9.962599754333496,NimbusRomNo9L-Regu,False,475.61077880859375,553.266357421875,0.0,7,H3
sample_3.pdf,12,and normalize the output probabilities (one for each word) with a softmax function (see Eq. (6)).,9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,564.225341796875,0.010309278350515464,97,H3
sample_3.pdf,12,A.1.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24878692626953,590.9013671875,0.2,5,H3
sample_3.pdf,12,LIGNMENT,7.970099925994873,NimbusRomNo9L-Regu,False,150.52978515625,592.4124755859375,1.0,8,P
sample_3.pdf,12,ODEL,7.970099925994873,NimbusRomNo9L-Regu,False,207.9237823486328,592.4124755859375,1.0,4,P
sample_3.pdf,12,The alignment model should be designed considering that the model needs to be evaluated,9.962599754333496,NimbusRomNo9L-Regu,False,107.9997787475586,611.2853393554688,0.011494252873563218,87,H3
sample_3.pdf,12,times for each sentence pair of lengths,9.962599754333496,NimbusRomNo9L-Regu,False,107.999755859375,622.244384765625,0.0,39,H3
sample_3.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,274.6417541503906,622.244384765625,0.0,3,H3
sample_3.pdf,12,". In order to reduce computation, we use a single-",9.962599754333496,NimbusRomNo9L-Regu,False,305.270751953125,622.244384765625,0.02,50,H3
sample_3.pdf,12,layer multilayer perceptron such that,9.962599754333496,NimbusRomNo9L-Regu,False,107.999755859375,633.203369140625,0.0,37,H3
sample_3.pdf,12,", h",9.962599754333496,CMMI10,False,247.15875244140625,654.73681640625,0.0,3,H3
sample_3.pdf,12,) =,9.962599754333496,CMR10,False,261.5247497558594,654.73681640625,0.0,3,H3
sample_3.pdf,12,tanh (,9.962599754333496,CMR10,False,292.2537536621094,654.73681640625,0.0,6,H3
sample_3.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,677.015380859375,0.0,5,H3
sample_3.pdf,12,", U",9.962599754333496,CMMI10,False,190.13580322265625,676.7848510742188,0.3333333333333333,3,H3
sample_3.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,253.7248077392578,677.015380859375,0.0,3,H3
sample_3.pdf,12,are the weight matrices. Since,9.962599754333496,NimbusRomNo9L-Regu,False,313.7588195800781,677.015380859375,0.03333333333333333,30,H3
sample_3.pdf,12,does not,9.962599754333496,NimbusRomNo9L-Regu,False,464.9434509277344,677.015380859375,0.0,8,H3
sample_3.pdf,12,depend on,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,687.974365234375,0.0,9,H3
sample_3.pdf,12,", we can pre-compute it in advance to minimize the computational cost.",9.962599754333496,NimbusRomNo9L-Regu,False,155.14785766601562,687.974365234375,0.0,70,H3
sample_3.pdf,12,"Here, we show the formula of the decoder. The same formula can be used in the encoder by simply",8.966400146484375,NimbusRomNo9L-Regu,False,123.64179992675781,709.2899169921875,0.021052631578947368,95,P
sample_3.pdf,12,ignoring the context vector,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,723.0619506835938,0.0,27,P
sample_3.pdf,12,and the related terms.,8.966400146484375,NimbusRomNo9L-Regu,False,213.50001525878906,723.0619506835938,0.0,22,P
sample_3.pdf,13,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,13,A.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,84.26844787597656,0.3333333333333333,3,H3
sample_3.pdf,13,ETAILED,7.970099925994873,NimbusRomNo9L-Regu,False,142.06199645996094,85.77953338623047,1.0,7,P
sample_3.pdf,13,ESCRIPTION OF THE,7.970099925994873,NimbusRomNo9L-Regu,False,188.5869903564453,85.77953338623047,0.8823529411764706,17,P
sample_3.pdf,13,ODEL,7.970099925994873,NimbusRomNo9L-Regu,False,284.5159912109375,85.77953338623047,1.0,4,P
sample_3.pdf,13,A.2.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24899291992188,104.79145812988281,0.2,5,H3
sample_3.pdf,13,NCODER,7.970099925994873,NimbusRomNo9L-Regu,False,149.42498779296875,106.30254364013672,1.0,6,P
sample_3.pdf,13,"In this section, we describe in detail the architecture of the proposed model (RNNsearch) used in the",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,123.96943664550781,0.039603960396039604,101,H3
sample_3.pdf,13,"experiments (see Sec. 4–5). From here on, we omit all bias terms in order to increase readability.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,134.9284210205078,0.02040816326530612,98,H3
sample_3.pdf,13,The model takes a source sentence of 1-of-K coded word vectors as input,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,151.8654327392578,0.028169014084507043,71,H3
sample_3.pdf,13,= (,9.962599754333496,CMR10,False,251.2192840576172,168.3298797607422,0.0,3,H3
sample_3.pdf,13,", . . . , x",9.962599754333496,CMMI10,False,278.53997802734375,168.3298797607422,0.0,11,H3
sample_3.pdf,13,", x",9.962599754333496,CMMI10,False,319.8929748535156,168.3298797607422,0.0,3,H3
sample_3.pdf,13,and outputs a translated sentence of 1-of-K coded word vectors,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,184.1824493408203,0.016129032258064516,62,H3
sample_3.pdf,13,= (,9.962599754333496,CMR10,False,251.09629821777344,200.6459197998047,0.0,3,H3
sample_3.pdf,13,", . . . , y",9.962599754333496,CMMI10,False,277.7660217285156,200.6459197998047,0.0,11,H3
sample_3.pdf,13,", y",9.962599754333496,CMMI10,False,318.1839904785156,200.64585876464844,0.0,3,H3
sample_3.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,216.49842834472656,0.0,5,H3
sample_3.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,148.0060577392578,216.49842834472656,0.0,3,H3
sample_3.pdf,13,"are the vocabulary sizes of source and target languages, respectively.",9.962599754333496,NimbusRomNo9L-Regu,False,180.7628631591797,216.49842834472656,0.0,70,H3
sample_3.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,473.13201904296875,216.49842834472656,0.0,3,H3
sample_3.pdf,13,respectively denote the lengths of source and target sentences.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,227.45741271972656,0.0,63,H3
sample_3.pdf,13,"First, the forward states of the bidirectional recurrent neural network (BiRNN) are computed:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,244.39442443847656,0.053763440860215055,93,H3
sample_3.pdf,13,", if",9.962599754333496,NimbusRomNo9L-Regu,False,369.10498046875,263.8934326171875,0.0,4,H3
sample_3.pdf,13,i >,9.962599754333496,CMMI10,False,380.1734313964844,263.66290283203125,0.0,3,H3
sample_3.pdf,13,", if",9.962599754333496,NimbusRomNo9L-Regu,False,369.10498046875,277.0434265136719,0.0,4,H3
sample_3.pdf,13,= 0,9.962599754333496,CMR10,False,386.10107421875,276.8128967285156,0.0,3,H3
sample_3.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,294.5514221191406,0.0,5,H3
sample_3.pdf,13,= tanh,9.962599754333496,CMR10,False,235.7554168701172,311.5769348144531,0.0,6,H3
sample_3.pdf,13,WEx,9.962599754333496,CMMI10,False,275.9670104980469,311.5769348144531,0.6666666666666666,3,H3
sample_3.pdf,13,is the word embedding matrix.,9.962599754333496,NimbusRomNo9L-Regu,False,168.13902282714844,378.241455078125,0.0,29,H3
sample_3.pdf,13,"U ,",9.962599754333496,CMMI10,False,401.2720031738281,378.01092529296875,0.3333333333333333,3,H3
sample_3.pdf,13,are,9.962599754333496,NimbusRomNo9L-Regu,False,491.83599853515625,378.241455078125,0.0,3,H3
sample_3.pdf,13,weight matrices.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,389.200439453125,0.0,16,H3
sample_3.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,186.41116333007812,389.200439453125,0.0,3,H3
sample_3.pdf,13,"are the word embedding dimensionality and the number of hidden units,",9.962599754333496,NimbusRomNo9L-Regu,False,212.11756896972656,389.200439453125,0.0,69,H3
sample_3.pdf,13,respectively.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0000228881836,400.159423828125,0.0,13,H3
sample_3.pdf,13,is as usual a logistic sigmoid function.,9.962599754333496,NimbusRomNo9L-Regu,False,177.23948669433594,400.159423828125,0.0,40,H3
sample_3.pdf,13,The backward states,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003814697266,420.1974182128906,0.05263157894736842,19,H3
sample_3.pdf,13,are computed similarly. We share the word embedding matrix,9.962599754333496,NimbusRomNo9L-Regu,False,256.8014831542969,420.1974182128906,0.017241379310344827,58,H3
sample_3.pdf,13,"between the forward and backward RNNs, unlike the weight matrices.",9.962599754333496,NimbusRomNo9L-Regu,False,115.35240173339844,432.4844665527344,0.045454545454545456,66,H3
sample_3.pdf,13,We concatenate the forward and backward states to to obtain the annotations,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,449.42047119140625,0.013333333333333334,75,H3
sample_3.pdf,13,", h",9.962599754333496,CMMI10,False,443.81298828125,449.18994140625,0.0,3,H3
sample_3.pdf,13,", h",9.962599754333496,CMMI10,False,474.5043029785156,449.18994140625,0.0,3,H3
sample_3.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,460.37945556640625,0.0,5,H3
sample_3.pdf,13,(7),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,483.6124267578125,0.0,3,H3
sample_3.pdf,13,A.2.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24896240234375,514.4674072265625,0.2,5,H3
sample_3.pdf,13,ECODER,7.970099925994873,NimbusRomNo9L-Regu,False,150.52996826171875,515.978515625,1.0,6,P
sample_3.pdf,13,The hidden state,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,533.6454467773438,0.0625,16,H3
sample_3.pdf,13,of the decoder given the annotations from the encoder is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,183.83038330078125,533.6454467773438,0.0,68,H3
sample_3.pdf,13,=(1,9.962599754333496,CMR10,False,253.86537170410156,549.0369262695312,0.0,3,H3
sample_3.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,564.889404296875,0.0,5,H3
sample_3.pdf,13,= tanh (,9.962599754333496,CMR10,False,225.02638244628906,580.2799072265625,0.0,8,H3
sample_3.pdf,13,WEy,9.962599754333496,CMMI10,False,263.1619567871094,580.2799072265625,0.6666666666666666,3,H3
sample_3.pdf,13,] +,9.962599754333496,CMR10,False,360.18096923828125,580.2799072265625,0.0,3,H3
sample_3.pdf,13,is the word embedding matrix for the target language.,9.962599754333496,NimbusRomNo9L-Regu,False,115.35235595703125,625.285400390625,0.0,53,H3
sample_3.pdf,13,"W, W",9.962599754333496,CMMI10,False,333.7859191894531,625.0548706054688,0.5,4,H3
sample_3.pdf,13,", W",9.962599754333496,CMMI10,False,364.8349609375,625.0548706054688,0.3333333333333333,3,H3
sample_3.pdf,13,"U, U",9.962599754333496,CMMI10,False,424.16259765625,625.0548706054688,0.5,4,H3
sample_3.pdf,13,", U",9.962599754333496,CMMI10,False,449.4239196777344,625.0548706054688,0.3333333333333333,3,H3
sample_3.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,636.244384765625,0.0,3,H3
sample_3.pdf,13,"C, C",9.962599754333496,CMMI10,False,122.38593292236328,636.0138549804688,0.5,4,H3
sample_3.pdf,13,", C",9.962599754333496,CMMI10,False,149.52394104003906,636.0138549804688,0.3333333333333333,3,H3
sample_3.pdf,13,"are weights. Again,",9.962599754333496,NimbusRomNo9L-Regu,False,213.67393493652344,636.244384765625,0.05263157894736842,19,H3
sample_3.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,309.3821105957031,636.244384765625,0.0,3,H3
sample_3.pdf,13,are the word embedding dimensionality,9.962599754333496,NimbusRomNo9L-Regu,False,337.1855163574219,636.244384765625,0.0,37,H3
sample_3.pdf,13,"and the number of hidden units, respectively. The initial hidden state",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,647.2034301757812,0.014285714285714285,70,H3
sample_3.pdf,13,is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,410.21905517578125,647.2034301757812,0.0,14,H3
sample_3.pdf,13,tanh,9.962599754333496,CMR10,False,108.0,661.5828857421875,0.0,4,H3
sample_3.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,174.0155792236328,661.8134155273438,0.0,5,H3
sample_3.pdf,13,The context vector,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,682.0574340820312,0.05555555555555555,18,H3
sample_3.pdf,13,are recomputed at each step by the alignment model:,9.962599754333496,NimbusRomNo9L-Regu,False,192.02037048339844,682.0574340820312,0.0,51,H3
sample_3.pdf,14,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,14,Model,9.962599754333496,NimbusRomNo9L-Regu,False,133.13900756835938,81.97749328613281,0.2,5,H3
sample_3.pdf,14,Updates,9.962599754333496,NimbusRomNo9L-Regu,False,190.66700744628906,81.97749328613281,0.14285714285714285,7,H3
sample_3.pdf,14,Epochs,9.962599754333496,NimbusRomNo9L-Regu,False,260.4620361328125,81.97749328613281,0.16666666666666666,6,H3
sample_3.pdf,14,Hours,9.962599754333496,NimbusRomNo9L-Regu,False,301.7470397949219,81.97749328613281,0.2,5,H3
sample_3.pdf,14,GPU,9.962599754333496,NimbusRomNo9L-Regu,False,357.2486572265625,81.97749328613281,1.0,3,H3
sample_3.pdf,14,Train NLL,9.962599754333496,NimbusRomNo9L-Regu,False,408.326904296875,81.97749328613281,0.4444444444444444,9,H3
sample_3.pdf,14,Dev. NLL,9.962599754333496,NimbusRomNo9L-Regu,False,463.3702697753906,81.97749328613281,0.5,8,H3
sample_3.pdf,14,RNNenc-30,9.962599754333496,NimbusRomNo9L-Regu,False,122.07599639892578,95.72547912597656,0.3333333333333333,9,H3
sample_3.pdf,14,8.46,9.962599754333496,NimbusRomNo9L-Regu,False,210.86900329589844,95.72547912597656,0.0,4,H3
sample_3.pdf,14,6.4,9.962599754333496,NimbusRomNo9L-Regu,False,268.901123046875,95.72547912597656,0.0,3,H3
sample_3.pdf,14,109,9.962599754333496,NimbusRomNo9L-Regu,False,306.4501647949219,95.72547912597656,0.0,3,H3
sample_3.pdf,14,TITAN BLACK,8.966400146484375,NimbusRomNo9L-Regu,False,338.04998779296875,96.48098754882812,0.9090909090909091,11,P
sample_3.pdf,14,28.1,9.962599754333496,NimbusRomNo9L-Regu,False,421.1579895019531,95.72547912597656,0.0,4,H3
sample_3.pdf,14,53.0,9.962599754333496,NimbusRomNo9L-Regu,False,474.98590087890625,95.72547912597656,0.0,4,H3
sample_3.pdf,14,RNNenc-50,9.962599754333496,NimbusRomNo9L-Regu,False,122.07598876953125,106.68446350097656,0.3333333333333333,9,H3
sample_3.pdf,14,6.00,9.962599754333496,NimbusRomNo9L-Regu,False,210.86900329589844,106.68446350097656,0.0,4,H3
sample_3.pdf,14,4.5,9.962599754333496,NimbusRomNo9L-Regu,False,268.901123046875,106.68446350097656,0.0,3,H3
sample_3.pdf,14,108,9.962599754333496,NimbusRomNo9L-Regu,False,306.4501647949219,106.68446350097656,0.0,3,H3
sample_3.pdf,14,Quadro K-6000,8.966400146484375,NimbusRomNo9L-Regu,False,338.95098876953125,107.43997192382812,0.15384615384615385,13,P
sample_3.pdf,14,44.0,9.962599754333496,NimbusRomNo9L-Regu,False,421.1579895019531,106.68446350097656,0.0,4,H3
sample_3.pdf,14,43.6,9.962599754333496,NimbusRomNo9L-Regu,False,474.98590087890625,106.68446350097656,0.0,4,H3
sample_3.pdf,14,RNNsearch-30,9.962599754333496,NimbusRomNo9L-Regu,False,116.26799774169922,118.04249572753906,0.25,12,H3
sample_3.pdf,14,4.71,9.962599754333496,NimbusRomNo9L-Regu,False,210.86900329589844,118.04249572753906,0.0,4,H3
sample_3.pdf,14,3.6,9.962599754333496,NimbusRomNo9L-Regu,False,268.901123046875,118.04249572753906,0.0,3,H3
sample_3.pdf,14,113,9.962599754333496,NimbusRomNo9L-Regu,False,306.4501647949219,118.04249572753906,0.0,3,H3
sample_3.pdf,14,TITAN BLACK,8.966400146484375,NimbusRomNo9L-Regu,False,338.04998779296875,118.79800415039062,0.9090909090909091,11,P
sample_3.pdf,14,26.7,9.962599754333496,NimbusRomNo9L-Regu,False,421.1579895019531,118.04249572753906,0.0,4,H3
sample_3.pdf,14,47.2,9.962599754333496,NimbusRomNo9L-Regu,False,474.98590087890625,118.04249572753906,0.0,4,H3
sample_3.pdf,14,RNNsearch-50,9.962599754333496,NimbusRomNo9L-Regu,False,116.26797485351562,129.00148010253906,0.25,12,H3
sample_3.pdf,14,2.88,9.962599754333496,NimbusRomNo9L-Regu,False,210.86900329589844,129.00148010253906,0.0,4,H3
sample_3.pdf,14,2.2,9.962599754333496,NimbusRomNo9L-Regu,False,268.901123046875,129.00148010253906,0.0,3,H3
sample_3.pdf,14,111,9.962599754333496,NimbusRomNo9L-Regu,False,306.4501647949219,129.00148010253906,0.0,3,H3
sample_3.pdf,14,Quadro K-6000,8.966400146484375,NimbusRomNo9L-Regu,False,338.95098876953125,129.75698852539062,0.15384615384615385,13,P
sample_3.pdf,14,40.7,9.962599754333496,NimbusRomNo9L-Regu,False,421.1579895019531,129.00148010253906,0.0,4,H3
sample_3.pdf,14,38.1,9.962599754333496,NimbusRomNo9L-Regu,False,474.98590087890625,129.00148010253906,0.0,4,H3
sample_3.pdf,14,RNNsearch-50,9.962599754333496,NimbusRomNo9L-Regu,False,113.97799682617188,140.3584747314453,0.25,12,H3
sample_3.pdf,14,6.67,9.962599754333496,NimbusRomNo9L-Regu,False,210.86900329589844,140.3584747314453,0.0,4,H3
sample_3.pdf,14,5.0,9.962599754333496,NimbusRomNo9L-Regu,False,268.901123046875,140.3584747314453,0.0,3,H3
sample_3.pdf,14,252,9.962599754333496,NimbusRomNo9L-Regu,False,306.4501647949219,140.3584747314453,0.0,3,H3
sample_3.pdf,14,Quadro K-6000,8.966400146484375,NimbusRomNo9L-Regu,False,338.95098876953125,141.11398315429688,0.15384615384615385,13,P
sample_3.pdf,14,36.7,9.962599754333496,NimbusRomNo9L-Regu,False,421.1579895019531,140.3584747314453,0.0,4,H3
sample_3.pdf,14,35.2,9.962599754333496,NimbusRomNo9L-Regu,False,474.98590087890625,140.3584747314453,0.0,4,H3
sample_3.pdf,14,Table 2: Learning statistics and relevant information. Each update corresponds to updating the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,161.3994903564453,0.031914893617021274,94,H3
sample_3.pdf,14,parameters once using a single minibatch. One epoch is one pass through the training set. NLL is,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,172.3584747314453,0.041666666666666664,96,H3
sample_3.pdf,14,the average conditional log-probabilities of the sentences in either the training set or the development,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,183.3174591064453,0.0,104,H3
sample_3.pdf,14,set. Note that the lengths of the sentences differ.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,194.2764434814453,0.0196078431372549,51,H3
sample_3.pdf,14,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,226.03944396972656,0.0,5,H3
sample_3.pdf,14,exp (,9.962599754333496,CMR10,False,276.34100341796875,241.0378875732422,0.0,5,H3
sample_3.pdf,14,exp (,9.962599754333496,CMR10,False,289.5719909667969,256.4559326171875,0.0,5,H3
sample_3.pdf,14,tanh (,9.962599754333496,CMR10,False,274.78302001953125,272.38592529296875,0.0,6,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,292.9114685058594,0.0,3,H3
sample_3.pdf,14,is the,9.962599754333496,NimbusRomNo9L-Regu,False,134.91964721679688,292.9114685058594,0.0,6,H3
sample_3.pdf,14,-th annotation in the source sentence (see Eq. (7)).,9.962599754333496,NimbusRomNo9L-Regu,False,169.79702758789062,292.9114685058594,0.019230769230769232,52,H3
sample_3.pdf,14,", W",9.962599754333496,CMMI10,False,425.10101318359375,292.68096923828125,0.3333333333333333,3,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,489.614013671875,292.9114990234375,0.0,3,H3
sample_3.pdf,14,are weight matrices. Note that the model becomes RNN Encoder–Decoder (Cho,9.962599754333496,NimbusRomNo9L-Regu,False,170.16500854492188,306.1474914550781,0.0958904109589041,73,H3
sample_3.pdf,14,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.00000762939453,319.6980285644531,0.0,6,H3
sample_3.pdf,14,", 2014a), if we ﬁx",9.962599754333496,NimbusRomNo9L-Regu,False,127.92500305175781,319.8744812011719,0.0,18,H3
sample_3.pdf,14,With the decoder state,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,336.81048583984375,0.045454545454545456,22,H3
sample_3.pdf,14,", the context",9.962599754333496,NimbusRomNo9L-Regu,False,215.2930145263672,336.81048583984375,0.0,13,H3
sample_3.pdf,14,and the last generated word,9.962599754333496,NimbusRomNo9L-Regu,False,272.0954284667969,336.81048583984375,0.0,27,H3
sample_3.pdf,14,", we deﬁne the probability",9.962599754333496,NimbusRomNo9L-Regu,False,401.9120178222656,336.81048583984375,0.0,26,H3
sample_3.pdf,14,of a target word,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,347.76947021484375,0.0,16,H3
sample_3.pdf,14,", y",9.962599754333496,CMMI10,False,262.8730163574219,366.2699279785156,0.0,3,H3
sample_3.pdf,14,", c",9.962599754333496,CMMI10,False,285.70001220703125,366.2699279785156,0.0,3,H3
sample_3.pdf,14,exp,9.962599754333496,CMR10,False,313.8070068359375,366.2699279785156,0.0,3,H3
sample_3.pdf,14,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,384.0814208984375,0.0,5,H3
sample_3.pdf,14,max,9.962599754333496,CMR10,False,261.031005859375,402.4798889160156,0.0,3,H3
sample_3.pdf,14,",...,l",6.973800182342529,CMMI7,False,359.32305908203125,408.8006896972656,0.0,6,P
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,424.1614074707031,0.0,3,H3
sample_3.pdf,14,"i,k",6.973800182342529,CMMI7,False,128.47406005859375,427.76068115234375,0.0,3,P
sample_3.pdf,14,is the,9.962599754333496,NimbusRomNo9L-Regu,False,137.88868713378906,424.1614074707031,0.0,6,H3
sample_3.pdf,14,-th element of a vector,9.962599754333496,NimbusRomNo9L-Regu,False,170.35206604003906,424.1614074707031,0.0,23,H3
sample_3.pdf,14,which is computed by,9.962599754333496,NimbusRomNo9L-Regu,False,269.2994689941406,424.1614074707031,0.0,20,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,273.2300720214844,462.4854431152344,0.0,3,H3
sample_3.pdf,14,are weight matrices. This can be under-,9.962599754333496,NimbusRomNo9L-Regu,False,345.88507080078125,462.4854431152344,0.02564102564102564,39,H3
sample_3.pdf,14,stood as having a deep output (Pascanu,9.962599754333496,NimbusRomNo9L-Regu,False,108.00007629394531,473.4444580078125,0.02631578947368421,38,H3
sample_3.pdf,14,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,263.5660400390625,473.26800537109375,0.0,6,H3
sample_3.pdf,14,", 2014) with a single maxout hidden layer (Goodfellow",9.962599754333496,NimbusRomNo9L-Regu,False,285.7510681152344,473.4444580078125,0.018867924528301886,53,H3
sample_3.pdf,14,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.00006103515625,484.22698974609375,0.0,6,H3
sample_3.pdf,14,", 2013).",9.962599754333496,NimbusRomNo9L-Regu,False,127.92506408691406,484.4034423828125,0.0,8,H3
sample_3.pdf,14,A.2.3,9.962599754333496,NimbusRomNo9L-Regu,False,108.24906158447266,508.00042724609375,0.2,5,H3
sample_3.pdf,14,ODEL,7.970099925994873,NimbusRomNo9L-Regu,False,152.19406127929688,509.51153564453125,1.0,4,P
sample_3.pdf,14,IZE,7.970099925994873,NimbusRomNo9L-Regu,False,183.93505859375,509.51153564453125,1.0,3,P
sample_3.pdf,14,"For all the models used in this paper, the size of a hidden layer",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,527.179443359375,0.015384615384615385,65,H3
sample_3.pdf,14,"is 1000, the word embedding",9.962599754333496,NimbusRomNo9L-Regu,False,380.234619140625,527.179443359375,0.0,27,H3
sample_3.pdf,14,dimensionality,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,538.137451171875,0.0,14,H3
sample_3.pdf,14,is 620 and the size of the maxout hidden layer in the deep output,9.962599754333496,NimbusRomNo9L-Regu,False,179.04222106933594,538.137451171875,0.0,65,H3
sample_3.pdf,14,is 500. The,9.962599754333496,NimbusRomNo9L-Regu,False,453.2709045410156,538.137451171875,0.09090909090909091,11,H3
sample_3.pdf,14,number of hidden units in the alignment model,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,549.096435546875,0.0,45,H3
sample_3.pdf,14,is 1000.,9.962599754333496,NimbusRomNo9L-Regu,False,309.1020812988281,549.096435546875,0.0,8,H3
sample_3.pdf,14,RAINING,9.56410026550293,NimbusRomNo9L-Regu,False,136.72808837890625,578.2276611328125,1.0,7,H3
sample_3.pdf,14,ROCEDURE,9.56410026550293,NimbusRomNo9L-Regu,False,191.4700927734375,578.2276611328125,1.0,8,H3
sample_3.pdf,14,B.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.24909210205078,601.5224609375,0.3333333333333333,3,H3
sample_3.pdf,14,ARAMETER,7.970099925994873,NimbusRomNo9L-Regu,False,139.0430908203125,603.0335693359375,1.0,8,P
sample_3.pdf,14,NITIALIZATION,7.970099925994873,NimbusRomNo9L-Regu,False,193.12008666992188,603.0335693359375,1.0,13,P
sample_3.pdf,14,We initialized the recurrent weight matrices,9.962599754333496,NimbusRomNo9L-Regu,False,108.00008392333984,622.04541015625,0.022727272727272728,44,H3
sample_3.pdf,14,"U, U",9.962599754333496,CMMI10,False,284.1588439941406,621.8148803710938,0.5,4,H3
sample_3.pdf,14,", U",9.962599754333496,CMMI10,False,309.61907958984375,621.8148803710938,0.3333333333333333,3,H3
sample_3.pdf,14,"U ,",9.962599754333496,CMMI10,False,330.72607421875,621.8148803710938,0.3333333333333333,3,H3
sample_3.pdf,14,"U ,",9.962599754333496,CMMI10,False,382.9000549316406,621.8148803710938,0.3333333333333333,3,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,410.0247497558594,622.04541015625,0.0,3,H3
sample_3.pdf,14,as random or-,9.962599754333496,NimbusRomNo9L-Regu,False,444.56414794921875,622.04541015625,0.0,13,H3
sample_3.pdf,14,thogonal matrices. For,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,633.0044555664062,0.045454545454545456,22,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,213.74082946777344,633.0044555664062,0.0,3,H3
sample_3.pdf,14,", we initialized them by sampling each element from the Gaussian",9.962599754333496,NimbusRomNo9L-Regu,False,244.48507690429688,633.0044555664062,0.015625,64,H3
sample_3.pdf,14,distribution of mean,9.962599754333496,NimbusRomNo9L-Regu,False,108.00007629394531,643.9634399414062,0.0,20,H3
sample_3.pdf,14,and variance,9.962599754333496,NimbusRomNo9L-Regu,False,195.86936950683594,643.9634399414062,0.0,12,H3
sample_3.pdf,14,001,9.962599754333496,CMR10,False,258.76007080078125,643.73291015625,0.0,3,H3
sample_3.pdf,14,. All the elements of,9.962599754333496,NimbusRomNo9L-Regu,False,278.174072265625,643.9634399414062,0.047619047619047616,21,H3
sample_3.pdf,14,and all the bias vectors were ini-,9.962599754333496,NimbusRomNo9L-Regu,False,372.1688232421875,643.9634399414062,0.0,34,H3
sample_3.pdf,14,tialized to zero. Any other weight matrix was initialized by sampling from the Gaussian distribution,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,654.9224243164062,0.02,100,H3
sample_3.pdf,14,of mean,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,665.8814697265625,0.0,7,H3
sample_3.pdf,14,and variance,9.962599754333496,NimbusRomNo9L-Regu,False,147.84036254882812,665.8814697265625,0.0,12,H3
sample_3.pdf,14,B.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24906158447266,690.824462890625,0.3333333333333333,3,H3
sample_3.pdf,14,RAINING,7.970099925994873,NimbusRomNo9L-Regu,False,140.40806579589844,692.3355712890625,1.0,7,P
sample_3.pdf,14,"We used the stochastic gradient descent (SGD) algorithm. Adadelta (Zeiler, 2012) was used to",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,711.347412109375,0.06521739130434782,92,H3
sample_3.pdf,14,automatically adapt the learning rate of each parameter (,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,722.3064575195312,0.0,57,H3
sample_3.pdf,14,= 10,9.962599754333496,CMR10,False,342.9928894042969,722.075927734375,0.0,4,H3
sample_3.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,382.80908203125,722.3064575195312,0.0,3,H3
sample_3.pdf,14,= 0,9.962599754333496,CMR10,False,405.5557556152344,722.075927734375,0.0,3,H3
sample_3.pdf,14,). We explicitly,9.962599754333496,NimbusRomNo9L-Regu,False,439.215087890625,722.3064575195312,0.0625,16,H3
sample_3.pdf,15,Published as a conference paper at ICLR 2015,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_3.pdf,15,normalized the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.0,14,H3
sample_3.pdf,15,-norm of the gradient of the cost function each time to be at most a predeﬁned,9.962599754333496,NimbusRomNo9L-Regu,False,182.6439971923828,84.26844787597656,0.0,78,H3
sample_3.pdf,15,threshold of,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,95.22743225097656,0.0,12,H3
sample_3.pdf,15,", when the norm was larger than the threshold (Pascanu",9.962599754333496,NimbusRomNo9L-Regu,False,165.1790008544922,95.22743225097656,0.018518518518518517,54,H3
sample_3.pdf,15,et al.,9.962599754333496,NimbusRomNo9L-ReguItal,False,394.03973388671875,95.05096435546875,0.0,6,H3
sample_3.pdf,15,", 2013b). Each SGD",9.962599754333496,NimbusRomNo9L-Regu,False,418.2909851074219,95.22743225097656,0.2222222222222222,18,H3
sample_3.pdf,15,update direction was computed with a minibatch of 80 sentences.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,106.18641662597656,0.0,63,H3
sample_3.pdf,15,At each update our implementation requires time proportional to the length of the longest sentence in,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,123.12342834472656,0.009900990099009901,101,H3
sample_3.pdf,15,"a minibatch. Hence, to minimize the waste of computation, before every 20-th update, we retrieved",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,134.08241271972656,0.010309278350515464,97,H3
sample_3.pdf,15,"1600 sentence pairs, sorted them according to the lengths and split them into 20 minibatches. The",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,145.04042053222656,0.010309278350515464,97,H3
sample_3.pdf,15,training data was shufﬂed once before training and was traversed sequentially in this manner.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,155.99940490722656,0.0,93,H3
sample_3.pdf,15,In Tables 2 we present the statistics related to training all the models used in the experiments.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,172.93641662597656,0.020618556701030927,97,H3
sample_3.pdf,15,RANSLATIONS OF,9.56410026550293,NimbusRomNo9L-Regu,False,136.72799682617188,201.87461853027344,0.9285714285714286,14,H3
sample_3.pdf,15,ONG,9.56410026550293,NimbusRomNo9L-Regu,False,235.8470001220703,201.87461853027344,1.0,3,H3
sample_3.pdf,15,ENTENCES,9.56410026550293,NimbusRomNo9L-Regu,False,268.5679931640625,201.87461853027344,1.0,8,H3
sample_3.pdf,15,Source,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,227.70498657226562,0.16666666666666666,6,P
sample_3.pdf,15,An admitting privilege is the right of a doctor to admit a patient to a hospital or a medical centre,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,227.70498657226562,0.01,100,P
sample_3.pdf,15,"to carry out a diagnosis or a procedure, based on his status as a health care worker at a hospital.",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,237.66799926757812,0.0,99,P
sample_3.pdf,15,Reference,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,248.02896118164062,0.1111111111111111,9,P
sample_3.pdf,15,"Le privil`ege d’admission est le droit d’un m´edecin, en vertu de son statut de membre soignant",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,247.98397827148438,0.010526315789473684,95,P
sample_3.pdf,15,"d’un hˆopital, d’admettre un patient dans un hˆopital ou un centre m´edical aﬁn d’y d´elivrer un",8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,257.9469909667969,0.0,96,P
sample_3.pdf,15,diagnostic ou un traitement.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18905639648438,267.9539489746094,0.0,28,P
sample_3.pdf,15,RNNenc-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,278.3149719238281,0.3333333333333333,9,P
sample_3.pdf,15,Un privil`ege d’admission est le droit d’un m´edecin de reconnaˆıtre un patient `a l’hˆopital ou un,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,278.2709655761719,0.010101010101010102,99,P
sample_3.pdf,15,centre m´edical d’un diagnostic ou de prendre un diagnostic en fonction de son ´etat de sant´e.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,288.23297119140625,0.0,95,P
sample_3.pdf,15,RNNsearch-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,298.63897705078125,0.25,12,P
sample_3.pdf,15,Un privil`ege d’admission est le droit d’un m´edecin d’admettre un patient `a un hˆopital ou un,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,298.5939636230469,0.010526315789473684,95,P
sample_3.pdf,15,"centre m´edical pour effectuer un diagnostic ou une proc´edure, selon son statut de travailleur des",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,308.5569763183594,0.0,99,P
sample_3.pdf,15,soins de sant´e `a l’hˆopital.,8.966400146484375,NimbusRomNo9L-Regu,False,180.1890106201172,318.5199890136719,0.0,30,P
sample_3.pdf,15,Google,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,328.9259948730469,0.16666666666666666,6,P
sample_3.pdf,15,Translate,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,338.88800048828125,0.1111111111111111,9,P
sample_3.pdf,15,Un privil`ege admettre est le droit d’un m´edecin d’admettre un patient dans un hˆopital ou un,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,328.8809814453125,0.010638297872340425,94,P
sample_3.pdf,15,"centre m´edical pour effectuer un diagnostic ou une proc´edure, fond´ee sur sa situation en tant",8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,338.8429870605469,0.0,96,P
sample_3.pdf,15,que travailleur de soins de sant´e dans un hˆopital.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,348.8059997558594,0.0,52,P
sample_3.pdf,15,Source,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,369.5729675292969,0.16666666666666666,6,P
sample_3.pdf,15,This kind of experience is part of Disney’s efforts to ”extend the lifetime of its series and build,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,369.5729675292969,0.020202020202020204,99,P
sample_3.pdf,15,"new relationships with audiences via digital platforms that are becoming ever more important,”",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,379.5359802246094,0.0,94,P
sample_3.pdf,15,he added.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,389.49798583984375,0.0,9,P
sample_3.pdf,15,Reference,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,399.8599853515625,0.1111111111111111,9,P
sample_3.pdf,15,Ce type d’exp´erience entre dans le cadre des efforts de Disney pour ”´etendre la dur´ee de,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,399.8149719238281,0.02197802197802198,91,P
sample_3.pdf,15,vie de ses s´eries et construire de nouvelles relations avec son public grˆace `a des plateformes,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,409.7769775390625,0.0,97,P
sample_3.pdf,15,"num´eriques qui sont de plus en plus importantes”, a-t-il ajout´e.",8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,419.739990234375,0.0,66,P
sample_3.pdf,15,RNNenc-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,430.14599609375,0.3333333333333333,9,P
sample_3.pdf,15,Ce type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur´ee de vie de,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,430.1009826660156,0.021052631578947368,95,P
sample_3.pdf,15,ses nouvelles et de d´evelopper des liens avec les lecteurs num´eriques qui deviennent plus com-,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,440.0639953613281,0.0,96,P
sample_3.pdf,15,plexes.,8.966400146484375,NimbusRomNo9L-Regu,False,180.1890411376953,450.0710144042969,0.0,7,P
sample_3.pdf,15,RNNsearch-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,460.4319763183594,0.25,12,P
sample_3.pdf,15,Ce genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur´ee de vie de ses,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,460.3879699707031,0.020833333333333332,96,P
sample_3.pdf,15,s´eries et cr´eer de nouvelles relations avec des publics via des plateformes num´eriques de plus,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,470.3499755859375,0.0,97,P
sample_3.pdf,15,"en plus importantes”, a-t-il ajout´e.",8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,480.31298828125,0.0,37,P
sample_3.pdf,15,Google,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,490.718994140625,0.16666666666666666,6,P
sample_3.pdf,15,Translate,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,500.6809997558594,0.1111111111111111,9,P
sample_3.pdf,15,Ce genre d’exp´erience fait partie des efforts de Disney `a “´etendre la dur´ee de vie de sa s´erie et,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,490.6739807128906,0.0196078431372549,102,P
sample_3.pdf,15,construire de nouvelles relations avec le public par le biais des plates-formes num´eriques qui,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,500.6369934082031,0.0,95,P
sample_3.pdf,15,"deviennent de plus en plus important”, at-il ajout´e.",8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,510.5990295410156,0.0,53,P
sample_3.pdf,15,Source,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,531.365966796875,0.16666666666666666,6,P
sample_3.pdf,15,"In a press conference on Thursday, Mr Blair stated that there was nothing in this video that might",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,531.365966796875,0.04081632653061224,98,P
sample_3.pdf,15,constitute a ”reasonable motive” that could lead to criminal charges being brought against the,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,541.3289794921875,0.0,94,P
sample_3.pdf,15,mayor.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,551.2919311523438,0.0,6,P
sample_3.pdf,15,Reference,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,561.6529541015625,0.1111111111111111,9,P
sample_3.pdf,15,"En conf´erence de presse, jeudi, M. Blair a afﬁrm´e qu’il n’y avait rien dans cette vid´eo qui puisse",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,561.6079711914062,0.0297029702970297,101,P
sample_3.pdf,15,constituer des ”motifs raisonnables” pouvant mener au d´epˆot d’une accusation criminelle contre,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,571.5709228515625,0.0,96,P
sample_3.pdf,15,le maire.,8.966400146484375,NimbusRomNo9L-Regu,False,180.1890411376953,581.5779418945312,0.0,9,P
sample_3.pdf,15,RNNenc-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,591.93896484375,0.3333333333333333,9,P
sample_3.pdf,15,"Lors de la conf´erence de presse de jeudi, M. Blair a dit qu’il n’y avait rien dans cette vid´eo qui",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,591.8939208984375,0.03,100,P
sample_3.pdf,15,pourrait constituer une ”motivation raisonnable” pouvant entraˆıner des accusations criminelles,8.966400146484375,NimbusRomNo9L-Regu,False,180.18893432617188,601.85693359375,0.0,95,P
sample_3.pdf,15,port´ees contre le maire.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18893432617188,611.8199462890625,0.0,25,P
sample_3.pdf,15,RNNsearch-50,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,622.2259521484375,0.25,12,P
sample_3.pdf,15,"Lors d’une conf´erence de presse jeudi, M. Blair a d´eclar´e qu’il n’y avait rien dans cette vid´eo qui",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,622.1809692382812,0.02912621359223301,103,P
sample_3.pdf,15,pourrait constituer un ”motif raisonnable” qui pourrait conduire `a des accusations criminelles,8.966400146484375,NimbusRomNo9L-Regu,False,180.18905639648438,632.1429443359375,0.0,95,P
sample_3.pdf,15,contre le maire.,8.966400146484375,NimbusRomNo9L-Regu,False,180.18905639648438,642.1509399414062,0.0,16,P
sample_3.pdf,15,Google,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,652.511962890625,0.16666666666666666,6,P
sample_3.pdf,15,Translate,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,662.4749755859375,0.1111111111111111,9,P
sample_3.pdf,15,"Lors d’une conf´erence de presse jeudi, M. Blair a d´eclar´e qu’il n’y avait rien dans cette vido",8.966400146484375,NimbusRomNo9L-Regu,False,180.18899536132812,652.4669189453125,0.030927835051546393,97,P
sample_3.pdf,15,qui pourrait constituer un ”motif raisonnable” qui pourrait mener `a des accusations criminelles,8.966400146484375,NimbusRomNo9L-Regu,False,180.18902587890625,662.429931640625,0.0,96,P
sample_3.pdf,15,portes contre le maire.,8.966400146484375,NimbusRomNo9L-Regu,False,180.1890411376953,672.4369506835938,0.0,23,P
sample_3.pdf,15,Table 3: The translations generated by RNNenc-50 and RNNsearch-50 from long source sentences,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,692.8224487304688,0.08695652173913043,92,H3
sample_3.pdf,15,"(30 words or more) selected from the test set. For each source sentence, we also show the gold-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,703.7814331054688,0.010526315789473684,95,H3
sample_3.pdf,15,standard translation. The translations by Google Translate were made on 27 August 2014.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,714.740478515625,0.04597701149425287,87,H3
sample_4.pdf,1,Deep Residual Learning for Image Recognition,14.346199989318848,NimbusRomNo9L-Medi,False,153.447998046875,105.9219970703125,0.11363636363636363,44,TITLE
sample_4.pdf,1,Kaiming He,11.9552001953125,NimbusRomNo9L-Regu,False,136.3909912109375,152.38929748535156,0.2,10,H3
sample_4.pdf,1,Xiangyu Zhang,11.9552001953125,NimbusRomNo9L-Regu,False,222.06195068359375,152.38929748535156,0.15384615384615385,13,H3
sample_4.pdf,1,Shaoqing Ren,11.9552001953125,NimbusRomNo9L-Regu,False,323.669189453125,152.38929748535156,0.16666666666666666,12,H3
sample_4.pdf,1,Jian Sun,11.9552001953125,NimbusRomNo9L-Regu,False,417.9837646484375,152.38929748535156,0.25,8,H3
sample_4.pdf,1,Microsoft Research,11.9552001953125,NimbusRomNo9L-Regu,False,249.13998413085938,169.1262969970703,0.1111111111111111,18,H3
sample_4.pdf,1,"kahe, v-xiangz, v-shren, jiansun",9.962599754333496,NimbusRomNo9L-Regu,False,200.47198486328125,184.9834747314453,0.0,32,H3
sample_4.pdf,1,@microsoft.com,9.962599754333496,NimbusRomNo9L-Regu,False,332.7249755859375,184.9834747314453,0.0,14,H3
sample_4.pdf,1,Abstract,11.9552001953125,NimbusRomNo9L-Medi,False,145.99497985839844,225.24615478515625,0.125,8,H3
sample_4.pdf,1,Deeper neural networks are more difﬁcult to train. We,9.962599754333496,NimbusRomNo9L-ReguItal,False,62.066978454589844,246.0460205078125,0.03773584905660377,53,H3
sample_4.pdf,1,present a residual learning framework to ease the training,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,258.00103759765625,0.0,58,H3
sample_4.pdf,1,of networks that are substantially deeper than those used,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,269.9560546875,0.0,57,H3
sample_4.pdf,1,previously. We explicitly reformulate the layers as learn-,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,281.91204833984375,0.017241379310344827,58,H3
sample_4.pdf,1,"ing residual functions with reference to the layer inputs, in-",9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,293.8670349121094,0.0,62,H3
sample_4.pdf,1,stead of learning unreferenced functions. We provide com-,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,305.822021484375,0.017543859649122806,57,H3
sample_4.pdf,1,prehensive empirical evidence showing that these residual,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,317.7770080566406,0.0,57,H3
sample_4.pdf,1,"networks are easier to optimize, and can gain accuracy from",9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,329.73199462890625,0.0,59,H3
sample_4.pdf,1,considerably increased depth. On the ImageNet dataset we,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,341.68798828125,0.05357142857142857,56,H3
sample_4.pdf,1,evaluate residual nets with a depth of up to 152 layers—8,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,353.6429748535156,0.0,57,H3
sample_4.pdf,1,deeper than VGG nets [41] but still having lower complex-,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111968994140625,365.59796142578125,0.05263157894736842,57,H3
sample_4.pdf,1,ity. An ensemble of these residual nets achieves 3.57% error,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111968994140625,377.5529479980469,0.016666666666666666,60,H3
sample_4.pdf,1,on the ImageNet,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111968994140625,389.5079345703125,0.13333333333333333,15,H3
sample_4.pdf,1,test,9.962599754333496,NimbusRomNo9L-Regu,False,114.68954467773438,389.68438720703125,0.0,4,H3
sample_4.pdf,1,set. This result won the 1st place on the,9.962599754333496,NimbusRomNo9L-ReguItal,False,130.6590118408203,389.5079345703125,0.024390243902439025,41,H3
sample_4.pdf,1,ILSVRC 2015 classiﬁcation task. We also present analysis,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,401.4629211425781,0.125,56,H3
sample_4.pdf,1,on CIFAR-10 with 100 and 1000 layers.,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,413.4189147949219,0.13513513513513514,37,H3
sample_4.pdf,1,The depth of representations is of central importance,9.962599754333496,NimbusRomNo9L-ReguItal,False,62.06696319580078,425.8009033203125,0.018867924528301886,53,H3
sample_4.pdf,1,for many visual recognition tasks. Solely due to our ex-,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,437.7558898925781,0.017857142857142856,56,H3
sample_4.pdf,1,"tremely deep representations, we obtain a 28% relative im-",9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,449.71087646484375,0.0,58,H3
sample_4.pdf,1,provement on the COCO object detection dataset. Deep,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,461.6658630371094,0.09615384615384616,52,H3
sample_4.pdf,1,residual nets are foundations of our submissions to ILSVRC,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,473.620849609375,0.10344827586206896,58,H3
sample_4.pdf,1,& COCO 2015 competitions,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,485.5758361816406,0.16666666666666666,24,H3
sample_4.pdf,1,", where we also won the 1st",9.962599754333496,NimbusRomNo9L-ReguItal,False,170.76596069335938,485.5758361816406,0.0,27,H3
sample_4.pdf,1,"places on the tasks of ImageNet detection, ImageNet local-",9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,497.5318298339844,0.06896551724137931,58,H3
sample_4.pdf,1,"ization, COCO detection, and COCO segmentation.",9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111961364746094,509.48681640625,0.1702127659574468,47,H3
sample_4.pdf,1,1. Introduction,11.9552001953125,NimbusRomNo9L-Medi,False,50.111961364746094,535.2259521484375,0.06666666666666667,15,H3
sample_4.pdf,1,"Deep convolutional neural networks [22, 21] have led",9.962599754333496,NimbusRomNo9L-Regu,False,62.06696319580078,556.2022705078125,0.019230769230769232,52,H3
sample_4.pdf,1,"to a series of breakthroughs for image classiﬁcation [21,",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,568.1572875976562,0.0,57,H3
sample_4.pdf,1,"50, 40]. Deep networks naturally integrate low/mid/high-",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,580.11328125,0.017857142857142856,56,H3
sample_4.pdf,1,level features [50] and classiﬁers in an end-to-end multi-,9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,592.0682373046875,0.0,58,H3
sample_4.pdf,1,"layer fashion, and the “levels” of features can be enriched",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,604.0232543945312,0.0,59,H3
sample_4.pdf,1,by the number of stacked layers (depth). Recent evidence,9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,615.978271484375,0.017857142857142856,56,H3
sample_4.pdf,1,"[41, 44] reveals that network depth is of crucial importance,",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,627.9332885742188,0.0,61,H3
sample_4.pdf,1,"and the leading results [41, 44, 13, 16] on the challenging",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,639.8883056640625,0.0,59,H3
sample_4.pdf,1,"ImageNet dataset [36] all exploit “very deep” [41] models,",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,651.84423828125,0.034482758620689655,58,H3
sample_4.pdf,1,with a depth of sixteen [41] to thirty [16]. Many other non-,9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,663.7992553710938,0.016666666666666666,60,H3
sample_4.pdf,1,"trivial visual recognition tasks [8, 12, 7, 32, 27] have also",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,675.7542724609375,0.0,61,H3
sample_4.pdf,1,http://image-net.org/challenges/LSVRC/2015/,7.571599960327148,NimbusMonL-Regu,False,64.45800018310547,696.900146484375,0.11627906976744186,43,P
sample_4.pdf,1,and,7.571599960327148,NimbusRomNo9L-Regu,False,275.4289855957031,697.2877807617188,0.0,3,P
sample_4.pdf,1,http://mscoco.org/dataset/#detections-challenge2015,7.571599960327148,NimbusMonL-Regu,False,50.11198425292969,704.8701171875,0.0,51,P
sample_4.pdf,1,iter. (1e4),6.552039623260498,Times-Roman,False,357.8670654296875,295.64483642578125,0.0,11,P
sample_4.pdf,1,training error (%),6.552039623260498,Times-Roman,False,308.9814758300781,235.5298614501953,0.0,18,P
sample_4.pdf,1,iter. (1e4),6.552039623260498,Times-Roman,False,479.6940612792969,295.64483642578125,0.0,11,P
sample_4.pdf,1,test error (%),6.552039623260498,Times-Roman,False,430.8083801269531,241.29627990722656,0.0,14,P
sample_4.pdf,1,56-layer,6.581333637237549,TT93o00,False,400.2607421875,263.2540283203125,0.0,8,P
sample_4.pdf,1,20-layer,6.581333637237549,TT93o00,False,400.2607421875,278.7020568847656,0.0,8,P
sample_4.pdf,1,56-layer,6.581333637237549,TT93o00,False,521.6488647460938,240.43385314941406,0.0,8,P
sample_4.pdf,1,20-layer,6.581333637237549,TT93o00,False,521.6488647460938,252.37057495117188,0.0,8,P
sample_4.pdf,1,Figure 1. Training error (left) and test error (right) on CIFAR-10,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,304.88897705078125,0.10606060606060606,66,P
sample_4.pdf,1,with 20-layer and 56-layer “plain” networks. The deeper network,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,315.8479919433594,0.015873015873015872,63,P
sample_4.pdf,1,"has higher training error, and thus test error. Similar phenomena",8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,326.8069763183594,0.015384615384615385,65,P
sample_4.pdf,1,on ImageNet is presented in Fig. 4.,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,337.7659606933594,0.08571428571428572,35,P
sample_4.pdf,1,greatly beneﬁted from very deep models.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,362.8054504394531,0.0,39,H3
sample_4.pdf,1,"Driven by the signiﬁcance of depth, a question arises:",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,376.7254638671875,0.018518518518518517,54,H3
sample_4.pdf,1,learning better networks as easy as stacking more layers?,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.86199951171875,388.5039978027344,0.0,57,H3
sample_4.pdf,1,An obstacle to answering this question was the notorious,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,400.63543701171875,0.017857142857142856,56,H3
sample_4.pdf,1,"problem of vanishing/exploding gradients [1, 9], which",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,412.5914306640625,0.0,54,H3
sample_4.pdf,1,hamper convergence from the beginning.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,424.5464172363281,0.0,38,H3
sample_4.pdf,1,"This problem,",9.962599754333496,NimbusRomNo9L-Regu,False,487.4515075683594,424.5464172363281,0.07692307692307693,13,H3
sample_4.pdf,1,"however, has been largely addressed by normalized initial-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,436.50140380859375,0.0,58,H3
sample_4.pdf,1,"ization [23, 9, 37, 13] and intermediate normalization layers",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,448.4563903808594,0.0,61,H3
sample_4.pdf,1,"[16], which enable networks with tens of layers to start con-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,460.411376953125,0.0,61,H3
sample_4.pdf,1,verging for stochastic gradient descent (SGD) with back-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,472.36737060546875,0.05357142857142857,56,H3
sample_4.pdf,1,propagation [22].,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,484.3223571777344,0.0,17,H3
sample_4.pdf,1,"When deeper networks are able to start converging, a",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,498.24237060546875,0.019230769230769232,52,H3
sample_4.pdf,1,degradation,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.86199951171875,510.02093505859375,0.0,11,H3
sample_4.pdf,1,problem has been exposed: with the network,9.962599754333496,NimbusRomNo9L-Regu,False,357.0211486816406,510.1973876953125,0.0,42,H3
sample_4.pdf,1,"depth increasing, accuracy gets saturated (which might be",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,522.15234375,0.0,57,H3
sample_4.pdf,1,unsurprising) and then degrades rapidly.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,534.1073608398438,0.0,40,H3
sample_4.pdf,1,"Unexpectedly,",9.962599754333496,NimbusRomNo9L-Regu,False,488.0889892578125,534.1073608398438,0.07692307692307693,13,H3
sample_4.pdf,1,such degradation is,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,546.0623779296875,0.0,19,H3
sample_4.pdf,1,not caused by overﬁtting,9.962599754333496,NimbusRomNo9L-ReguItal,False,388.0247497558594,545.8859252929688,0.0,24,H3
sample_4.pdf,1,", and adding",9.962599754333496,NimbusRomNo9L-Regu,False,493.4410095214844,546.0623779296875,0.0,12,H3
sample_4.pdf,1,more layers to a suitably deep model leads to,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,558.017333984375,0.0,45,H3
sample_4.pdf,1,higher train-,9.962599754333496,NimbusRomNo9L-ReguItal,False,490.9981689453125,557.8408813476562,0.0,13,H3
sample_4.pdf,1,ing error,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.86199951171875,569.796875,0.0,9,H3
sample_4.pdf,1,", as reported in [11, 42] and thoroughly veriﬁed by",9.962599754333496,NimbusRomNo9L-Regu,False,344.5530090332031,569.9733276367188,0.0,51,H3
sample_4.pdf,1,our experiments. Fig. 1 shows a typical example.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,581.9283447265625,0.020833333333333332,48,H3
sample_4.pdf,1,The degradation (of training accuracy) indicates that not,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,595.8483276367188,0.017543859649122806,57,H3
sample_4.pdf,1,all systems are similarly easy to optimize. Let us consider a,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,607.8033447265625,0.01639344262295082,61,H3
sample_4.pdf,1,shallower architecture and its deeper counterpart that adds,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,619.7583618164062,0.0,59,H3
sample_4.pdf,1,more layers onto it. There exists a solution,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,631.71337890625,0.022727272727272728,44,H3
sample_4.pdf,1,by construction,9.962599754333496,NimbusRomNo9L-ReguItal,False,480.6071472167969,631.5369262695312,0.0,15,H3
sample_4.pdf,1,to the deeper model: the added layers are,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,643.6683349609375,0.0,41,H3
sample_4.pdf,1,identity,9.962599754333496,NimbusRomNo9L-ReguItal,False,472.90606689453125,643.4918823242188,0.0,8,H3
sample_4.pdf,1,"mapping,",9.962599754333496,NimbusRomNo9L-Regu,False,505.2717590332031,643.6683349609375,0.0,8,H3
sample_4.pdf,1,and the other layers are copied from the learned shallower,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,655.6233520507812,0.0,58,H3
sample_4.pdf,1,model. The existence of this constructed solution indicates,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,667.579345703125,0.01694915254237288,59,H3
sample_4.pdf,1,that a deeper model should produce no higher training error,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,679.5343627929688,0.0,59,H3
sample_4.pdf,1,than its shallower counterpart. But experiments show that,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,691.4893798828125,0.017543859649122806,57,H3
sample_4.pdf,1,our current solvers on hand are unable to ﬁnd solutions that,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,703.4443359375,0.0,60,H3
sample_4.pdf,1,arXiv:1512.03385v1  [cs.CV]  10 Dec 2015,20.0,Times-Roman,False,10.940000534057617,208.94000244140625,0.1,40,TITLE
sample_4.pdf,2,identity,8.167912483215332,TT3Bo00,False,205.97393798828125,123.6444320678711,0.0,8,P
sample_4.pdf,2,weight layer,7.2967143058776855,TT3Co00,False,137.34751892089844,95.47470092773438,0.0,12,P
sample_4.pdf,2,weight layer,7.2967143058776855,TT3Co00,False,137.34751892089844,119.98433685302734,0.0,12,P
sample_4.pdf,2,relu,8.167912483215332,TT3Bo00,False,159.1339111328125,106.32432556152344,0.0,4,P
sample_4.pdf,2,relu,8.167912483215332,TT3Bo00,False,159.1339111328125,146.19302368164062,0.0,4,P
sample_4.pdf,2,Figure 2. Residual learning: a building block.,8.966400146484375,NimbusRomNo9L-Regu,False,86.61699676513672,158.15499877929688,0.043478260869565216,46,P
sample_4.pdf,2,are comparably good or better than the constructed solution,9.962599754333496,NimbusRomNo9L-Regu,False,50.111995697021484,182.1535186767578,0.0,59,H3
sample_4.pdf,2,(or unable to do so in feasible time).,9.962599754333496,NimbusRomNo9L-Regu,False,50.111995697021484,194.10853576660156,0.0,38,H3
sample_4.pdf,2,"In this paper, we address the degradation problem by",9.962599754333496,NimbusRomNo9L-Regu,False,62.066993713378906,207.5075225830078,0.019230769230769232,52,H3
sample_4.pdf,2,introducing a,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199188232422,219.46253967285156,0.0,13,H3
sample_4.pdf,2,deep residual learning,9.962599754333496,NimbusRomNo9L-ReguItal,False,106.47041320800781,219.28607177734375,0.0,22,H3
sample_4.pdf,2,framework.,9.962599754333496,NimbusRomNo9L-Regu,False,209.30641174316406,219.46253967285156,0.0,10,H3
sample_4.pdf,2,In-,9.962599754333496,NimbusRomNo9L-Regu,False,274.7478332519531,219.46253967285156,0.3333333333333333,3,H3
sample_4.pdf,2,stead of hoping each few stacked layers directly ﬁt a,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,231.4175567626953,0.0,53,H3
sample_4.pdf,2,"desired underlying mapping, we explicitly let these lay-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,243.37355041503906,0.0,56,H3
sample_4.pdf,2,"ers ﬁt a residual mapping. Formally, denoting the desired",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,255.3285675048828,0.017543859649122806,57,H3
sample_4.pdf,2,underlying mapping as,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,267.2835693359375,0.0,21,H3
sample_4.pdf,2,", we let the stacked nonlinear",9.962599754333496,NimbusRomNo9L-Regu,False,167.69198608398438,267.2835693359375,0.0,30,H3
sample_4.pdf,2,layers ﬁt another mapping of,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,279.2385559082031,0.0,28,H3
sample_4.pdf,2,) :=,9.962599754333496,CMR10,False,184.76197814941406,279.3221435546875,0.0,4,H3
sample_4.pdf,2,. The orig-,9.962599754333496,NimbusRomNo9L-Regu,False,243.7049560546875,279.2385559082031,0.09090909090909091,11,H3
sample_4.pdf,2,inal mapping is recast into,9.962599754333496,NimbusRomNo9L-Regu,False,50.11195373535156,291.19354248046875,0.0,27,H3
sample_4.pdf,2,. We hypothesize that it,9.962599754333496,NimbusRomNo9L-Regu,False,193.45693969726562,291.19354248046875,0.041666666666666664,24,H3
sample_4.pdf,2,is easier to optimize the residual mapping than to optimize,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,303.1485290527344,0.0,59,H3
sample_4.pdf,2,"the original, unreferenced mapping. To the extreme, if an",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,315.1045227050781,0.017543859649122806,57,H3
sample_4.pdf,2,"identity mapping were optimal, it would be easier to push",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,327.05950927734375,0.0,57,H3
sample_4.pdf,2,the residual to zero than to ﬁt an identity mapping by a stack,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,339.0144958496094,0.0,62,H3
sample_4.pdf,2,of nonlinear layers.,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,350.969482421875,0.0,20,H3
sample_4.pdf,2,The formulation of,9.962599754333496,NimbusRomNo9L-Regu,False,62.06694030761719,364.36846923828125,0.05555555555555555,18,H3
sample_4.pdf,2,can be realized by feedfor-,9.962599754333496,NimbusRomNo9L-Regu,False,178.3532257080078,364.36846923828125,0.0,27,H3
sample_4.pdf,2,ward neural networks with “shortcut connections” (Fig. 2).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,376.3234558105469,0.017241379310344827,58,H3
sample_4.pdf,2,"Shortcut connections [2, 34, 49] are those skipping one or",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,388.2784423828125,0.017241379310344827,58,H3
sample_4.pdf,2,"more layers. In our case, the shortcut connections simply",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,400.23443603515625,0.017543859649122806,57,H3
sample_4.pdf,2,perform,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,412.1894226074219,0.0,7,H3
sample_4.pdf,2,identity,9.962599754333496,NimbusRomNo9L-ReguItal,False,82.20145416259766,412.0129699707031,0.0,8,H3
sample_4.pdf,2,"mapping, and their outputs are added to",9.962599754333496,NimbusRomNo9L-Regu,False,115.94871520996094,412.1894226074219,0.0,39,H3
sample_4.pdf,2,the outputs of the stacked layers (Fig. 2). Identity short-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11193084716797,424.1444091796875,0.03389830508474576,59,H3
sample_4.pdf,2,cut connections add neither extra parameter nor computa-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11193084716797,436.0993957519531,0.0,56,H3
sample_4.pdf,2,tional complexity. The entire network can still be trained,9.962599754333496,NimbusRomNo9L-Regu,False,50.11193084716797,448.05438232421875,0.017241379310344827,58,H3
sample_4.pdf,2,"end-to-end by SGD with backpropagation, and can be eas-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11193084716797,460.0093688964844,0.05454545454545454,55,H3
sample_4.pdf,2,ily implemented using common libraries (,9.962599754333496,NimbusRomNo9L-Regu,False,50.11193084716797,471.9653625488281,0.0,40,H3
sample_4.pdf,2,e.g,9.962599754333496,NimbusRomNo9L-ReguItal,False,221.20693969726562,471.7889099121094,0.0,3,H3
sample_4.pdf,2,"., Caffe [19])",9.962599754333496,NimbusRomNo9L-Regu,False,232.95294189453125,471.9653625488281,0.07142857142857142,14,H3
sample_4.pdf,2,without modifying the solvers.,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,483.92034912109375,0.0,30,H3
sample_4.pdf,2,We present comprehensive experiments on ImageNet,9.962599754333496,NimbusRomNo9L-Regu,False,62.06694030761719,497.3193359375,0.0625,48,H3
sample_4.pdf,2,[36] to show the degradation problem and evaluate our,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,509.2742919921875,0.0,53,H3
sample_4.pdf,2,method. We show that: 1) Our extremely deep residual nets,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,521.2293090820312,0.03508771929824561,57,H3
sample_4.pdf,2,"are easy to optimize, but the counterpart “plain” nets (that",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,533.184326171875,0.0,60,H3
sample_4.pdf,2,simply stack layers) exhibit higher training error when the,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,545.1392822265625,0.0,59,H3
sample_4.pdf,2,depth increases; 2) Our deep residual nets can easily enjoy,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,557.0953369140625,0.01694915254237288,59,H3
sample_4.pdf,2,"accuracy gains from greatly increased depth, producing re-",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,569.05029296875,0.0,58,H3
sample_4.pdf,2,sults substantially better than previous networks.,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,581.0053100585938,0.0,50,H3
sample_4.pdf,2,Similar phenomena are also shown on the CIFAR-10 set,9.962599754333496,NimbusRomNo9L-Regu,False,62.06694030761719,594.404296875,0.11538461538461539,52,H3
sample_4.pdf,2,"[20], suggesting that the optimization difﬁculties and the",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,606.3593139648438,0.0,58,H3
sample_4.pdf,2,effects of our method are not just akin to a particular dataset.,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,618.3143310546875,0.0,64,H3
sample_4.pdf,2,We present successfully trained models on this dataset with,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,630.269287109375,0.01694915254237288,59,H3
sample_4.pdf,2,"over 100 layers, and explore models with over 1000 layers.",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,642.225341796875,0.0,58,H3
sample_4.pdf,2,"On the ImageNet classiﬁcation dataset [36], we obtain",9.962599754333496,NimbusRomNo9L-Regu,False,62.06694030761719,655.6243286132812,0.05660377358490566,53,H3
sample_4.pdf,2,excellent results by extremely deep residual nets. Our 152-,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,667.579345703125,0.01694915254237288,59,H3
sample_4.pdf,2,layer residual net is the deepest network ever presented on,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,679.5343017578125,0.0,59,H3
sample_4.pdf,2,"ImageNet, while still having lower complexity than VGG",9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,691.4893188476562,0.09259259259259259,54,H3
sample_4.pdf,2,nets [41].,9.962599754333496,NimbusRomNo9L-Regu,False,50.1119384765625,703.4443359375,0.0,10,H3
sample_4.pdf,2,Our ensemble has,9.962599754333496,NimbusRomNo9L-Regu,False,98.74934387207031,703.4443359375,0.0625,16,H3
sample_4.pdf,2,3.57%,9.962599754333496,NimbusRomNo9L-Medi,False,174.08653259277344,703.3533935546875,0.0,5,H3
sample_4.pdf,2,top-5 error on the,9.962599754333496,NimbusRomNo9L-Regu,False,205.95606994628906,703.4443359375,0.0,18,H3
sample_4.pdf,2,ImageNet,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,74.40736389160156,0.25,8,H3
sample_4.pdf,2,test,9.962599754333496,NimbusRomNo9L-ReguItal,False,348.14447021484375,74.23089599609375,0.0,4,H3
sample_4.pdf,2,"set, and",9.962599754333496,NimbusRomNo9L-Regu,False,365.98797607421875,74.40736389160156,0.0,8,H3
sample_4.pdf,2,won the 1st place in the ILSVRC,9.962599754333496,NimbusRomNo9L-ReguItal,False,402.5015869140625,74.23089599609375,0.1935483870967742,31,H3
sample_4.pdf,2,2015 classiﬁcation competition,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619384765625,86.1859130859375,0.0,30,H3
sample_4.pdf,2,. The extremely deep rep-,9.962599754333496,NimbusRomNo9L-Regu,False,435.5529479980469,86.36238098144531,0.04,25,H3
sample_4.pdf,2,resentations also have excellent generalization performance,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,98.31739807128906,0.0,59,H3
sample_4.pdf,2,"on other recognition tasks, and lead us to further",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,110.27241516113281,0.0,50,H3
sample_4.pdf,2,win the,9.962599754333496,NimbusRomNo9L-ReguItal,False,511.2519226074219,110.095947265625,0.0,7,H3
sample_4.pdf,2,"1st places on: ImageNet detection, ImageNet localization,",9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619384765625,122.05194091796875,0.07017543859649122,57,H3
sample_4.pdf,2,"COCO detection, and COCO segmentation",9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619384765625,134.0069580078125,0.21621621621621623,37,H3
sample_4.pdf,2,in ILSVRC &,9.962599754333496,NimbusRomNo9L-Regu,False,484.293212890625,134.1834259033203,0.5454545454545454,11,H3
sample_4.pdf,2,COCO 2015 competitions. This strong evidence shows that,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,146.13844299316406,0.09090909090909091,55,H3
sample_4.pdf,2,"the residual learning principle is generic, and we expect that",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,158.0934600830078,0.0,62,H3
sample_4.pdf,2,it is applicable in other vision and non-vision problems.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,170.04847717285156,0.0,57,H3
sample_4.pdf,2,2. Related Work,11.9552001953125,NimbusRomNo9L-Medi,False,308.8619384765625,195.0701904296875,0.13333333333333333,15,H3
sample_4.pdf,2,Residual Representations.,9.962599754333496,NimbusRomNo9L-Medi,False,308.8619384765625,216.43853759765625,0.08,25,H3
sample_4.pdf,2,"In image recognition, VLAD",9.962599754333496,NimbusRomNo9L-Regu,False,420.3434753417969,216.5294952392578,0.19230769230769232,26,H3
sample_4.pdf,2,[18] is a representation that encodes by the residual vectors,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,228.48451232910156,0.0,61,H3
sample_4.pdf,2,"with respect to a dictionary, and Fisher Vector [30] can be",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,240.4395294189453,0.03389830508474576,59,H3
sample_4.pdf,2,formulated as a probabilistic version [18] of VLAD. Both,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,252.39454650878906,0.08928571428571429,56,H3
sample_4.pdf,2,of them are powerful shallow representations for image re-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,264.35052490234375,0.0,58,H3
sample_4.pdf,2,"trieval and classiﬁcation [4, 48]. For vector quantization,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,276.3055114746094,0.01694915254237288,59,H3
sample_4.pdf,2,encoding residual vectors [17] is shown to be more effec-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,288.260498046875,0.0,57,H3
sample_4.pdf,2,tive than encoding original vectors.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,300.2154846191406,0.0,36,H3
sample_4.pdf,2,"In low-level vision and computer graphics, for solv-",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169250488281,313.08148193359375,0.019230769230769232,52,H3
sample_4.pdf,2,"ing Partial Differential Equations (PDEs), the widely used",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,325.0364685058594,0.10344827586206896,58,H3
sample_4.pdf,2,Multigrid method [3] reformulates the system as subprob-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,336.991455078125,0.017857142857142856,56,H3
sample_4.pdf,2,"lems at multiple scales, where each subproblem is respon-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,348.9464416503906,0.0,57,H3
sample_4.pdf,2,sible for the residual solution between a coarser and a ﬁner,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,360.90142822265625,0.0,60,H3
sample_4.pdf,2,scale. An alternative to Multigrid is hierarchical basis pre-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,372.857421875,0.03278688524590164,61,H3
sample_4.pdf,2,"conditioning [45, 46], which relies on variables that repre-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,384.8124084472656,0.0,60,H3
sample_4.pdf,2,sent residual vectors between two scales. It has been shown,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,396.76739501953125,0.01694915254237288,59,H3
sample_4.pdf,2,"[3, 45, 46] that these solvers converge much faster than stan-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,408.7223815917969,0.0,62,H3
sample_4.pdf,2,dard solvers that are unaware of the residual nature of the,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,420.6773681640625,0.0,59,H3
sample_4.pdf,2,solutions. These methods suggest that a good reformulation,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,432.6323547363281,0.017241379310344827,58,H3
sample_4.pdf,2,or preconditioning can simplify the optimization.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,444.5883483886719,0.0,49,H3
sample_4.pdf,2,Shortcut Connections.,9.962599754333496,NimbusRomNo9L-Medi,False,308.8619384765625,463.34039306640625,0.09523809523809523,21,H3
sample_4.pdf,2,Practices and theories that lead to,9.962599754333496,NimbusRomNo9L-Regu,False,404.0446472167969,463.43133544921875,0.02857142857142857,35,H3
sample_4.pdf,2,"shortcut connections [2, 34, 49] have been studied for a long",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,475.3863220214844,0.0,61,H3
sample_4.pdf,2,time. An early practice of training multi-layer perceptrons,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,487.34130859375,0.01694915254237288,59,H3
sample_4.pdf,2,(MLPs) is to add a linear layer connected from the network,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,499.2962951660156,0.05172413793103448,58,H3
sample_4.pdf,2,"input to the output [34, 49]. In [44, 24], a few interme-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,511.25128173828125,0.017543859649122806,57,H3
sample_4.pdf,2,diate layers are directly connected to auxiliary classiﬁers,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,523.207275390625,0.0,59,H3
sample_4.pdf,2,for addressing vanishing/exploding gradients. The papers,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,535.1622924804688,0.017857142857142856,56,H3
sample_4.pdf,2,"of [39, 38, 31, 47] propose methods for centering layer re-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,547.1173095703125,0.0,59,H3
sample_4.pdf,2,"sponses, gradients, and propagated errors, implemented by",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,559.072265625,0.0,57,H3
sample_4.pdf,2,"shortcut connections. In [44], an “inception” layer is com-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,571.0272827148438,0.01694915254237288,59,H3
sample_4.pdf,2,posed of a shortcut branch and a few deeper branches.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,582.9822998046875,0.0,53,H3
sample_4.pdf,2,"Concurrent with our work, “highway networks” [42, 43]",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169250488281,595.8482666015625,0.018867924528301886,53,H3
sample_4.pdf,2,present shortcut connections with gating functions [15].,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,607.8032836914062,0.0,56,H3
sample_4.pdf,2,"These gates are data-dependent and have parameters, in",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,619.75830078125,0.018518518518518517,54,H3
sample_4.pdf,2,contrast to our identity shortcuts that are parameter-free.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,631.7132568359375,0.0,59,H3
sample_4.pdf,2,"When a gated shortcut is “closed” (approaching zero), the",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,643.6693115234375,0.017543859649122806,57,H3
sample_4.pdf,2,layers in highway networks represent,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,655.624267578125,0.0,36,H3
sample_4.pdf,2,non-residual,9.962599754333496,NimbusRomNo9L-ReguItal,False,464.86614990234375,655.4478149414062,0.0,12,H3
sample_4.pdf,2,func-,9.962599754333496,NimbusRomNo9L-Regu,False,519.7511596679688,655.624267578125,0.0,5,H3
sample_4.pdf,2,tions.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,667.5792846679688,0.0,6,H3
sample_4.pdf,2,"On the contrary, our formulation always learns",9.962599754333496,NimbusRomNo9L-Regu,False,342.0473327636719,667.5792846679688,0.021739130434782608,46,H3
sample_4.pdf,2,"residual functions; our identity shortcuts are never closed,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,679.5343017578125,0.0,60,H3
sample_4.pdf,2,"and all information is always passed through, with addi-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,691.4892578125,0.0,56,H3
sample_4.pdf,2,"tional residual functions to be learned. In addition, high-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,703.4442749023438,0.01694915254237288,59,H3
sample_4.pdf,3,way networks have not demonstrated accuracy gains with,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,74.40748596191406,0.0,54,H3
sample_4.pdf,3,extremely increased depth (,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,86.36250305175781,0.0,27,H3
sample_4.pdf,3,e.g,9.962599754333496,NimbusRomNo9L-ReguItal,False,160.3470001220703,86.18603515625,0.0,3,H3
sample_4.pdf,3,"., over 100 layers).",9.962599754333496,NimbusRomNo9L-Regu,False,172.09300231933594,86.36250305175781,0.0,20,H3
sample_4.pdf,3,3. Deep Residual Learning,11.9552001953125,NimbusRomNo9L-Medi,False,50.11199951171875,108.96416473388672,0.12,25,H3
sample_4.pdf,3,3.1. Residual Learning,10.958900451660156,NimbusRomNo9L-Medi,False,50.11199951171875,128.76187133789062,0.09090909090909091,22,H3
sample_4.pdf,3,Let us consider,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,147.6535186767578,0.06666666666666667,15,H3
sample_4.pdf,3,as an underlying mapping to be,9.962599754333496,NimbusRomNo9L-Regu,False,151.33143615722656,147.6535186767578,0.0,30,H3
sample_4.pdf,3,"ﬁt by a few stacked layers (not necessarily the entire net),",9.962599754333496,NimbusRomNo9L-Regu,False,50.111976623535156,159.60853576660156,0.0,60,H3
sample_4.pdf,3,with,9.962599754333496,NimbusRomNo9L-Regu,False,50.111976623535156,171.5645294189453,0.0,4,H3
sample_4.pdf,3,denoting the inputs to the ﬁrst of these layers. If one,9.962599754333496,NimbusRomNo9L-Regu,False,76.28427124023438,171.5645294189453,0.01818181818181818,55,H3
sample_4.pdf,3,hypothesizes that multiple nonlinear layers can asymptoti-,9.962599754333496,NimbusRomNo9L-Regu,False,50.111976623535156,183.51954650878906,0.0,58,H3
sample_4.pdf,3,cally approximate complicated functions,9.962599754333496,NimbusRomNo9L-Regu,False,50.111976623535156,195.4745635986328,0.0,39,H3
sample_4.pdf,3,", then it is equiv-",9.962599754333496,NimbusRomNo9L-Regu,False,217.69398498535156,195.4745635986328,0.0,19,H3
sample_4.pdf,3,alent to hypothesize that they can asymptotically approxi-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,207.42958068847656,0.0,58,H3
sample_4.pdf,3,"mate the residual functions,",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,219.3845977783203,0.0,28,H3
sample_4.pdf,3,i.e,9.962599754333496,NimbusRomNo9L-ReguItal,False,161.9321746826172,219.2081298828125,0.0,3,H3
sample_4.pdf,3,(assuming that,9.962599754333496,NimbusRomNo9L-Regu,False,224.35325622558594,219.3845977783203,0.0,14,H3
sample_4.pdf,3,the input and output are of the same dimensions).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11195373535156,231.34059143066406,0.0,49,H3
sample_4.pdf,3,rather than expect stacked layers to approximate,9.962599754333496,NimbusRomNo9L-Regu,False,50.11195373535156,243.2956085205078,0.0,48,H3
sample_4.pdf,3,", we",9.962599754333496,NimbusRomNo9L-Regu,False,269.3779296875,243.2956085205078,0.0,4,H3
sample_4.pdf,3,explicitly let these layers approximate a residual function,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,255.25062561035156,0.0,59,H3
sample_4.pdf,3,) :=,9.962599754333496,CMR10,False,68.18292236328125,267.2892150878906,0.0,4,H3
sample_4.pdf,3,. The original function thus becomes,9.962599754333496,NimbusRomNo9L-Regu,False,133.3289337158203,267.20562744140625,0.027777777777777776,36,H3
sample_4.pdf,3,. Although both forms should be able to asymptot-,9.962599754333496,NimbusRomNo9L-Regu,False,87.41592407226562,279.1606140136719,0.02040816326530612,49,H3
sample_4.pdf,3,"ically approximate the desired functions (as hypothesized),",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,291.1156005859375,0.0,59,H3
sample_4.pdf,3,the ease of learning might be different.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,303.07159423828125,0.0,40,H3
sample_4.pdf,3,This reformulation is motivated by the counterintuitive,9.962599754333496,NimbusRomNo9L-Regu,False,62.066925048828125,315.1305847167969,0.01818181818181818,55,H3
sample_4.pdf,3,"phenomena about the degradation problem (Fig. 1, left). As",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,327.0855712890625,0.034482758620689655,58,H3
sample_4.pdf,3,"we discussed in the introduction, if the added layers can",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,339.0405578613281,0.0,57,H3
sample_4.pdf,3,"be constructed as identity mappings, a deeper model should",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,350.99554443359375,0.0,58,H3
sample_4.pdf,3,have training error no greater than its shallower counter-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,362.9505310058594,0.0,58,H3
sample_4.pdf,3,part.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,374.905517578125,0.0,5,H3
sample_4.pdf,3,The degradation problem suggests that the solvers,9.962599754333496,NimbusRomNo9L-Regu,False,76.4131851196289,374.905517578125,0.02040816326530612,49,H3
sample_4.pdf,3,might have difﬁculties in approximating identity mappings,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,386.86151123046875,0.0,57,H3
sample_4.pdf,3,by multiple nonlinear layers. With the residual learning re-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,398.8164978027344,0.016666666666666666,60,H3
sample_4.pdf,3,"formulation, if identity mappings are optimal, the solvers",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,410.771484375,0.0,58,H3
sample_4.pdf,3,may simply drive the weights of the multiple nonlinear lay-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,422.7264709472656,0.0,59,H3
sample_4.pdf,3,ers toward zero to approach identity mappings.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,434.68145751953125,0.0,46,H3
sample_4.pdf,3,"In real cases, it is unlikely that identity mappings are op-",9.962599754333496,NimbusRomNo9L-Regu,False,62.066925048828125,446.7404479980469,0.016666666666666666,60,H3
sample_4.pdf,3,"timal, but our reformulation may help to precondition the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,458.6964416503906,0.0,57,H3
sample_4.pdf,3,problem. If the optimal function is closer to an identity,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,470.65142822265625,0.017543859649122806,57,H3
sample_4.pdf,3,"mapping than to a zero mapping, it should be easier for the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,482.6064147949219,0.0,59,H3
sample_4.pdf,3,solver to ﬁnd the perturbations with reference to an identity,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,494.5614013671875,0.0,61,H3
sample_4.pdf,3,"mapping, than to learn the function as a new one. We show",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,506.516357421875,0.017543859649122806,57,H3
sample_4.pdf,3,by experiments (Fig. 7) that the learned residual functions in,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,518.4713745117188,0.016129032258064516,62,H3
sample_4.pdf,3,"general have small responses, suggesting that identity map-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,530.4273681640625,0.0,59,H3
sample_4.pdf,3,pings provide reasonable preconditioning.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,542.3823852539062,0.0,41,H3
sample_4.pdf,3,3.2. Identity Mapping by Shortcuts,10.958900451660156,NimbusRomNo9L-Medi,False,50.11192321777344,561.7637329101562,0.08823529411764706,34,H3
sample_4.pdf,3,We adopt residual learning to every few stacked layers.,9.962599754333496,NimbusRomNo9L-Regu,False,62.066925048828125,580.6553955078125,0.01818181818181818,55,H3
sample_4.pdf,3,"A building block is shown in Fig. 2. Formally, in this paper",9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,592.6103515625,0.05,60,H3
sample_4.pdf,3,we consider a building block deﬁned as:,9.962599754333496,NimbusRomNo9L-Regu,False,50.11192321777344,604.5663452148438,0.0,39,H3
sample_4.pdf,3,) +,9.962599754333496,CMR10,False,188.14291381835938,626.7749633789062,0.0,3,H3
sample_4.pdf,3,(1),9.962599754333496,NimbusRomNo9L-Regu,False,274.74591064453125,626.6913452148438,0.0,3,H3
sample_4.pdf,3,Here,9.962599754333496,NimbusRomNo9L-Regu,False,50.111907958984375,648.8173828125,0.25,4,H3
sample_4.pdf,3,and,9.962599754333496,NimbusRomNo9L-Regu,False,78.93220520019531,648.8173828125,0.0,3,H3
sample_4.pdf,3,are the input and output vectors of the lay-,9.962599754333496,NimbusRomNo9L-Regu,False,106.19821166992188,648.8173828125,0.0,44,H3
sample_4.pdf,3,ers considered.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11191177368164,660.7723388671875,0.0,15,H3
sample_4.pdf,3,The function,9.962599754333496,NimbusRomNo9L-Regu,False,119.52133178710938,660.7723388671875,0.08333333333333333,12,H3
sample_4.pdf,3,represents the,9.962599754333496,NimbusRomNo9L-Regu,False,225.53834533691406,660.7723388671875,0.0,14,H3
sample_4.pdf,3,residual mapping to be learned. For the example in Fig. 2,9.962599754333496,NimbusRomNo9L-Regu,False,50.11187744140625,672.7273559570312,0.03508771929824561,57,H3
sample_4.pdf,3,"that has two layers,",9.962599754333496,NimbusRomNo9L-Regu,False,50.11187744140625,684.682373046875,0.0,20,H3
sample_4.pdf,3,in which,9.962599754333496,NimbusRomNo9L-Regu,False,204.68531799316406,684.682373046875,0.0,8,H3
sample_4.pdf,3,denotes,9.962599754333496,NimbusRomNo9L-Regu,False,252.29150390625,684.682373046875,0.0,7,H3
sample_4.pdf,3,"This hypothesis, however, is still an open question. See [28].",7.970099925994873,NimbusRomNo9L-Regu,False,64.45800018310547,704.95556640625,0.03225806451612903,62,P
sample_4.pdf,3,ReLU [29] and the biases are omitted for simplifying no-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,74.40748596191406,0.05357142857142857,56,H3
sample_4.pdf,3,tations. The operation,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,86.36250305175781,0.045454545454545456,22,H3
sample_4.pdf,3,is performed by a shortcut,9.962599754333496,NimbusRomNo9L-Regu,False,432.5703125,86.36250305175781,0.0,26,H3
sample_4.pdf,3,connection and element-wise addition. We adopt the sec-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,98.31752014160156,0.01818181818181818,55,H3
sample_4.pdf,3,ond nonlinearity after the addition (,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,110.27253723144531,0.0,37,H3
sample_4.pdf,3,i.e,9.962599754333496,NimbusRomNo9L-ReguItal,False,450.8079833984375,110.0960693359375,0.0,3,H3
sample_4.pdf,3,", see Fig. 2).",9.962599754333496,NimbusRomNo9L-Regu,False,487.96795654296875,110.27253723144531,0.07142857142857142,14,H3
sample_4.pdf,3,The shortcut connections in Eqn.(1) introduce neither ex-,9.962599754333496,NimbusRomNo9L-Regu,False,320.81695556640625,122.46955871582031,0.03508771929824561,57,H3
sample_4.pdf,3,tra parameter nor computation complexity. This is not only,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,134.42457580566406,0.017241379310344827,58,H3
sample_4.pdf,3,attractive in practice but also important in our comparisons,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,146.3795928955078,0.0,60,H3
sample_4.pdf,3,between plain and residual networks. We can fairly com-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,158.33558654785156,0.01818181818181818,55,H3
sample_4.pdf,3,pare plain/residual networks that simultaneously have the,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,170.2906036376953,0.0,57,H3
sample_4.pdf,3,"same number of parameters, depth, width, and computa-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,182.24562072753906,0.0,53,H3
sample_4.pdf,3,tional cost (except for the negligible element-wise addition).,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,194.2006378173828,0.0,62,H3
sample_4.pdf,3,The dimensions of,9.962599754333496,NimbusRomNo9L-Regu,False,320.81695556640625,206.3976593017578,0.058823529411764705,17,H3
sample_4.pdf,3,and,9.962599754333496,NimbusRomNo9L-Regu,False,406.7762451171875,206.3976593017578,0.0,3,H3
sample_4.pdf,3,must be equal in Eqn.(1).,9.962599754333496,NimbusRomNo9L-Regu,False,435.47906494140625,206.3976593017578,0.04,25,H3
sample_4.pdf,3,If this is not the case (,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,218.35267639160156,0.04,25,H3
sample_4.pdf,3,e.g,9.962599754333496,NimbusRomNo9L-ReguItal,False,398.35992431640625,218.17620849609375,0.0,3,H3
sample_4.pdf,3,"., when changing the input/output",9.962599754333496,NimbusRomNo9L-Regu,False,410.1059265136719,218.35267639160156,0.0,33,H3
sample_4.pdf,3,"channels), we can perform a linear projection",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,230.3076934814453,0.0,45,H3
sample_4.pdf,3,by the,9.962599754333496,NimbusRomNo9L-Regu,False,514.8297729492188,230.3076934814453,0.0,6,H3
sample_4.pdf,3,shortcut connections to match the dimensions:,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,242.26271057128906,0.0,45,H3
sample_4.pdf,3,) +,9.962599754333496,CMR10,False,440.0588684082031,264.7482604980469,0.0,3,H3
sample_4.pdf,3,(2),9.962599754333496,NimbusRomNo9L-Regu,False,533.495849609375,264.6646728515625,0.0,3,H3
sample_4.pdf,3,We can also use a square matrix,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,287.065673828125,0.03225806451612903,31,H3
sample_4.pdf,3,in Eqn.(1). But we will,9.962599754333496,NimbusRomNo9L-Regu,False,450.5827331542969,287.065673828125,0.08695652173913043,23,H3
sample_4.pdf,3,show by experiments that the identity mapping is sufﬁcient,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,299.0206604003906,0.0,58,H3
sample_4.pdf,3,"for addressing the degradation problem and is economical,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,310.97564697265625,0.0,57,H3
sample_4.pdf,3,and thus,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,322.9306335449219,0.0,8,H3
sample_4.pdf,3,is only used when matching dimensions.,9.962599754333496,NimbusRomNo9L-Regu,False,358.0047302246094,322.9306335449219,0.0,38,H3
sample_4.pdf,3,The form of the residual function,9.962599754333496,NimbusRomNo9L-Regu,False,320.81683349609375,335.12762451171875,0.030303030303030304,33,H3
sample_4.pdf,3,is ﬂexible. Exper-,9.962599754333496,NimbusRomNo9L-Regu,False,466.96795654296875,335.12762451171875,0.05555555555555555,18,H3
sample_4.pdf,3,iments in this paper involve a function,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,347.0826110839844,0.0,39,H3
sample_4.pdf,3,that has two or,9.962599754333496,NimbusRomNo9L-Regu,False,478.532958984375,347.0826110839844,0.0,15,H3
sample_4.pdf,3,"three layers (Fig. 5), while more layers are possible. But if",9.962599754333496,NimbusRomNo9L-Regu,False,308.86181640625,359.03759765625,0.03278688524590164,61,H3
sample_4.pdf,3,"has only a single layer, Eqn.(1) is similar to a linear layer:",9.962599754333496,NimbusRomNo9L-Regu,False,316.0249328613281,370.99359130859375,0.016129032258064516,62,H3
sample_4.pdf,3,", for which we have not observed advantages.",9.962599754333496,NimbusRomNo9L-Regu,False,365.2437744140625,382.9485778808594,0.0,44,H3
sample_4.pdf,3,We also note that although the above notations are about,9.962599754333496,NimbusRomNo9L-Regu,False,320.8167724609375,395.14556884765625,0.017857142857142856,56,H3
sample_4.pdf,3,"fully-connected layers for simplicity, they are applicable to",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617858886719,407.1005554199219,0.0,61,H3
sample_4.pdf,3,convolutional layers. The function,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617858886719,419.0555419921875,0.029411764705882353,34,H3
sample_4.pdf,3,can repre-,9.962599754333496,NimbusRomNo9L-Regu,False,501.30718994140625,419.0555419921875,0.0,10,H3
sample_4.pdf,3,sent multiple convolutional layers. The element-wise addi-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,431.0105285644531,0.017241379310344827,58,H3
sample_4.pdf,3,"tion is performed on two feature maps, channel by channel.",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,442.96551513671875,0.0,58,H3
sample_4.pdf,3,3.3. Network Architectures,10.958900451660156,NimbusRomNo9L-Medi,False,308.8617248535156,462.7608947753906,0.07692307692307693,26,H3
sample_4.pdf,3,"We have tested various plain/residual nets, and have ob-",9.962599754333496,NimbusRomNo9L-Regu,False,320.81671142578125,481.79052734375,0.017857142857142856,56,H3
sample_4.pdf,3,served consistent phenomena. To provide instances for dis-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,493.7455139160156,0.017241379310344827,58,H3
sample_4.pdf,3,"cussion, we describe two models for ImageNet as follows.",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,505.70050048828125,0.03571428571428571,56,H3
sample_4.pdf,3,Plain Network.,9.962599754333496,NimbusRomNo9L-Medi,False,308.8617248535156,523.7845458984375,0.14285714285714285,14,H3
sample_4.pdf,3,"Our plain baselines (Fig. 3, middle) are",9.962599754333496,NimbusRomNo9L-Regu,False,374.176513671875,523.87548828125,0.05,40,H3
sample_4.pdf,3,"mainly inspired by the philosophy of VGG nets [41] (Fig. 3,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,535.8305053710938,0.06779661016949153,59,H3
sample_4.pdf,3,left). The convolutional layers mostly have 3,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,547.7855224609375,0.022222222222222223,45,H3
sample_4.pdf,3,3 ﬁlters and,9.962599754333496,NimbusRomNo9L-Regu,False,497.5127258300781,547.7855224609375,0.0,12,H3
sample_4.pdf,3,follow two simple design rules: (i) for the same output,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,559.740478515625,0.0,55,H3
sample_4.pdf,3,"feature map size, the layers have the same number of ﬁl-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,571.6964721679688,0.0,56,H3
sample_4.pdf,3,"ters; and (ii) if the feature map size is halved, the num-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,583.6514892578125,0.0,58,H3
sample_4.pdf,3,ber of ﬁlters is doubled so as to preserve the time com-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,595.6065063476562,0.0,56,H3
sample_4.pdf,3,plexity per layer. We perform downsampling directly by,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,607.5615234375,0.018518518518518517,54,H3
sample_4.pdf,3,convolutional layers that have a stride of 2. The network,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,619.5164794921875,0.017543859649122806,57,H3
sample_4.pdf,3,ends with a global average pooling layer and a 1000-way,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,631.4714965820312,0.0,55,H3
sample_4.pdf,3,fully-connected layer with softmax. The total number of,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,643.427490234375,0.01818181818181818,55,H3
sample_4.pdf,3,weighted layers is 34 in Fig. 3 (middle).,9.962599754333496,NimbusRomNo9L-Regu,False,308.8617248535156,655.3825073242188,0.024390243902439025,41,H3
sample_4.pdf,3,It is worth noticing that our model has,9.962599754333496,NimbusRomNo9L-Regu,False,320.81671142578125,667.5794677734375,0.02564102564102564,39,H3
sample_4.pdf,3,fewer,9.962599754333496,NimbusRomNo9L-ReguItal,False,476.8009338378906,667.4030151367188,0.0,5,H3
sample_4.pdf,3,ﬁlters and,9.962599754333496,NimbusRomNo9L-Regu,False,501.7911682128906,667.5794677734375,0.0,10,H3
sample_4.pdf,3,lower,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8616943359375,679.3580322265625,0.0,5,H3
sample_4.pdf,3,"complexity than VGG nets [41] (Fig. 3, left). Our 34-",9.962599754333496,NimbusRomNo9L-Regu,False,331.5564880371094,679.5344848632812,0.09433962264150944,53,H3
sample_4.pdf,3,"layer baseline has 3.6 billion FLOPs (multiply-adds), which",9.962599754333496,NimbusRomNo9L-Regu,False,308.8616943359375,691.489501953125,0.06779661016949153,59,H3
sample_4.pdf,3,is only 18% of VGG-19 (19.6 billion FLOPs).,9.962599754333496,NimbusRomNo9L-Regu,False,308.8616943359375,703.4445190429688,0.16279069767441862,43,H3
sample_4.pdf,4,"7x7 conv, 64, /2",4.9190778732299805,TT94o00,False,152.88955688476562,154.7363739013672,0.0,16,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,160.85568237304688,167.3884735107422,0.0,8,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.28689575195312,180.1576690673828,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.28689575195312,192.8097381591797,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.28689575195312,205.46180725097656,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.28689575195312,218.11387634277344,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.40402221679688,230.8831024169922,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,156.40402221679688,243.53517150878906,0.0,12,P
sample_4.pdf,4,"3x3 conv, 128, /2",4.9190778732299805,TT94o00,False,151.71807861328125,256.187255859375,0.0,17,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.11538696289062,268.8393249511719,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.2325439453125,281.49139404296875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.2325439453125,294.2606201171875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.2325439453125,306.9126892089844,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.2325439453125,319.5647277832031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.34970092773438,332.2168273925781,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,155.34970092773438,344.98602294921875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256, /2",4.9190778732299805,TT94o00,False,151.83523559570312,357.6380920410156,0.0,17,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.2325439453125,370.2901916503906,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,382.9422302246094,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,395.7114562988281,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,408.3635559082031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,421.0155944824219,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.2325439453125,433.6676940917969,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.2325439453125,446.4368896484375,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,459.0889587402344,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.11538696289062,471.74102783203125,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.2325439453125,484.3930969238281,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,155.2325439453125,497.0451965332031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512, /2",4.9190778732299805,TT94o00,False,151.83523559570312,509.8144226074219,0.0,17,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,155.2325439453125,522.4664306640625,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,155.34970092773438,535.1185302734375,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,155.34970092773438,547.7705688476562,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,155.2325439453125,560.539794921875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,155.2325439453125,573.1918334960938,0.0,13,P
sample_4.pdf,4,avg pool,4.9190778732299805,TT94o00,False,160.2699432373047,585.8439331054688,0.0,8,P
sample_4.pdf,4,fc 1000,4.9190778732299805,TT94o00,False,160.97283935546875,598.4960327148438,0.0,7,P
sample_4.pdf,4,image,4.9190778732299805,TT94o00,False,162.261474609375,91.35890197753906,0.0,5,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.3575210571289,294.2606201171875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,85.411865234375,104.01091003417969,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,85.411865234375,116.66300964355469,0.0,12,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,90.09780883789062,129.43223571777344,0.0,8,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,84.24037170410156,142.0843048095703,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,84.24037170410156,154.7363739013672,0.0,13,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,90.09780883789062,167.3884735107422,0.0,8,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,84.3575210571289,180.1576690673828,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,84.3575210571289,192.8097381591797,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,84.24037170410156,205.46180725097656,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,84.24037170410156,218.11387634277344,0.0,13,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,90.2149658203125,256.187255859375,0.0,8,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.3575210571289,268.8393249511719,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.47467041015625,281.49139404296875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.3575210571289,306.9126892089844,0.0,13,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,90.09780883789062,357.6380920410156,0.0,8,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.24037170410156,370.2901916503906,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.3575210571289,382.9422302246094,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.3575210571289,395.7114562988281,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,84.24037170410156,408.3635559082031,0.0,13,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,90.2149658203125,509.8144226074219,0.0,8,P
sample_4.pdf,4,fc 4096,4.9190778732299805,TT94o00,False,90.91785430908203,585.8439331054688,0.0,7,P
sample_4.pdf,4,fc 4096,4.9190778732299805,TT94o00,False,90.91785430908203,598.4960327148438,0.0,7,P
sample_4.pdf,4,fc 1000,4.9190778732299805,TT94o00,False,90.56640625,611.2651977539062,0.0,7,P
sample_4.pdf,4,image,4.9190778732299805,TT94o00,False,92.08934020996094,91.35890197753906,0.0,5,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,133.64939880371094,0.0,6,P
sample_4.pdf,4,size: 112,4.9190778732299805,TT94o00,False,50.85318374633789,139.50697326660156,0.0,9,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,101.08222961425781,0.0,6,P
sample_4.pdf,4,size: 224,4.9190778732299805,TT94o00,False,50.85318374633789,106.93980407714844,0.0,9,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,171.37147521972656,0.0,6,P
sample_4.pdf,4,size: 56,4.9190778732299805,TT94o00,False,52.14167785644531,177.2290496826172,0.0,8,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,260.28778076171875,0.0,6,P
sample_4.pdf,4,size: 28,4.9190778732299805,TT94o00,False,52.14167785644531,266.14532470703125,0.0,8,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,354.7098388671875,0.0,6,P
sample_4.pdf,4,size: 14,4.9190778732299805,TT94o00,False,52.14167785644531,360.5673828125,0.0,8,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,506.8862609863281,0.0,6,P
sample_4.pdf,4,size: 7,4.9190778732299805,TT94o00,False,53.3131217956543,512.7437744140625,0.0,7,P
sample_4.pdf,4,output,4.9190778732299805,TT94o00,False,52.72739791870117,582.9158935546875,0.0,6,P
sample_4.pdf,4,size: 1,4.9190778732299805,TT94o00,False,53.3131217956543,588.7734375,0.0,7,P
sample_4.pdf,4,VGG-19,7.847163200378418,TT95o00,False,85.88045501708984,77.53533935546875,0.5,6,P
sample_4.pdf,4,34-layer plain,7.847163200378418,TT95o00,False,146.9110565185547,77.53533935546875,0.0,14,P
sample_4.pdf,4,"7x7 conv, 64, /2",4.9190778732299805,TT94o00,False,223.0616912841797,154.7363739013672,0.0,16,P
sample_4.pdf,4,"pool, /2",4.9190778732299805,TT94o00,False,231.02781677246094,167.3884735107422,0.0,8,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.22471618652344,180.1576690673828,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.22471618652344,192.8097381591797,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.22471618652344,205.46180725097656,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.22471618652344,218.11387634277344,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.107666015625,230.8831024169922,0.0,12,P
sample_4.pdf,4,"3x3 conv, 64",4.9190778732299805,TT94o00,False,226.107666015625,243.53517150878906,0.0,12,P
sample_4.pdf,4,"3x3 conv, 128, /2",4.9190778732299805,TT94o00,False,221.65591430664062,256.187255859375,0.0,17,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,225.05323791503906,268.8393249511719,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.9360809326172,281.49139404296875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.9360809326172,294.2606201171875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.9360809326172,306.9126892089844,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.9360809326172,319.5647277832031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.8189239501953,332.2168273925781,0.0,13,P
sample_4.pdf,4,"3x3 conv, 128",4.9190778732299805,TT94o00,False,224.8189239501953,344.98602294921875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256, /2",4.9190778732299805,TT94o00,False,221.53875732421875,357.6380920410156,0.0,17,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,224.9360809326172,370.2901916503906,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,382.9422302246094,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,395.7114562988281,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,408.3635559082031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,421.0155944824219,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,224.9360809326172,433.6676940917969,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,224.9360809326172,446.4368896484375,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,459.0889587402344,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,225.05323791503906,471.74102783203125,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,224.9360809326172,484.3930969238281,0.0,13,P
sample_4.pdf,4,"3x3 conv, 256",4.9190778732299805,TT94o00,False,224.9360809326172,497.0451965332031,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512, /2",4.9190778732299805,TT94o00,False,221.53875732421875,509.8144226074219,0.0,17,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,224.9360809326172,522.4664306640625,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,224.8189239501953,535.1185302734375,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,224.8189239501953,547.7705688476562,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,224.9360809326172,560.539794921875,0.0,13,P
sample_4.pdf,4,"3x3 conv, 512",4.9190778732299805,TT94o00,False,224.9360809326172,573.1918334960938,0.0,13,P
sample_4.pdf,4,avg pool,4.9190778732299805,TT94o00,False,230.0906219482422,585.8439331054688,0.0,8,P
sample_4.pdf,4,fc 1000,4.9190778732299805,TT94o00,False,231.4964141845703,598.4960327148438,0.0,7,P
sample_4.pdf,4,image,4.9190778732299805,TT94o00,False,232.43360900878906,91.35890197753906,0.0,5,P
sample_4.pdf,4,34-layer residual,7.847163200378418,TT95o00,False,212.40115356445312,77.53533935546875,0.0,17,P
sample_4.pdf,4,Figure 3. Example network architectures for ImageNet.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,632.9159545898438,0.07547169811320754,53,P
sample_4.pdf,4,Left,8.966400146484375,NimbusRomNo9L-Medi,False,250.19720458984375,632.8341064453125,0.25,4,P
sample_4.pdf,4,: the,8.966400146484375,NimbusRomNo9L-Regu,False,269.64300537109375,632.9159545898438,0.0,5,P
sample_4.pdf,4,VGG-19 model [41] (19.6 billion FLOPs) as a reference.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,643.8749389648438,0.12962962962962962,54,P
sample_4.pdf,4,Mid-,8.966400146484375,NimbusRomNo9L-Medi,False,261.7907409667969,643.7930908203125,0.25,4,P
sample_4.pdf,4,dle,8.966400146484375,NimbusRomNo9L-Medi,False,50.11201477050781,654.7521362304688,0.0,3,P
sample_4.pdf,4,: a plain network with 34 parameter layers (3.6 billion FLOPs).,8.966400146484375,NimbusRomNo9L-Regu,False,61.571014404296875,654.833984375,0.06349206349206349,63,P
sample_4.pdf,4,Right,8.966400146484375,NimbusRomNo9L-Medi,False,50.11201477050781,665.7111206054688,0.2,5,P
sample_4.pdf,4,: a residual network with 34 parameter layers (3.6 billion,8.966400146484375,NimbusRomNo9L-Regu,False,71.53201293945312,665.79296875,0.0,58,P
sample_4.pdf,4,FLOPs). The dotted shortcuts increase dimensions.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,676.751953125,0.10204081632653061,49,P
sample_4.pdf,4,Table 1,8.966400146484375,NimbusRomNo9L-Medi,False,232.15682983398438,676.6701049804688,0.14285714285714285,7,P
sample_4.pdf,4,shows,8.966400146484375,NimbusRomNo9L-Regu,False,262.2811279296875,676.751953125,0.0,5,P
sample_4.pdf,4,more details and other variants.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,687.7099609375,0.0,32,P
sample_4.pdf,4,Residual Network.,9.962599754333496,NimbusRomNo9L-Medi,False,308.86199951171875,74.31652069091797,0.11764705882352941,17,H3
sample_4.pdf,4,"Based on the above plain network, we",9.962599754333496,NimbusRomNo9L-Regu,False,388.1642761230469,74.40748596191406,0.027777777777777776,36,H3
sample_4.pdf,4,"insert shortcut connections (Fig. 3, right) which turn the",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,86.36250305175781,0.017241379310344827,58,H3
sample_4.pdf,4,network into its counterpart residual version. The identity,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,98.31752014160156,0.01694915254237288,59,H3
sample_4.pdf,4,shortcuts (Eqn.(1)) can be directly used when the input and,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,110.27253723144531,0.01694915254237288,59,H3
sample_4.pdf,4,output are of the same dimensions (solid line shortcuts in,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,122.22755432128906,0.0,58,H3
sample_4.pdf,4,Fig. 3). When the dimensions increase (dotted line shortcuts,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,134.1835479736328,0.03333333333333333,60,H3
sample_4.pdf,4,"in Fig. 3), we consider two options: (A) The shortcut still",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,146.13856506347656,0.05084745762711865,59,H3
sample_4.pdf,4,"performs identity mapping, with extra zero entries padded",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,158.0935821533203,0.0,57,H3
sample_4.pdf,4,for increasing dimensions. This option introduces no extra,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,170.04859924316406,0.017241379310344827,58,H3
sample_4.pdf,4,parameter; (B) The projection shortcut in Eqn.(2) is used to,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,182.0036163330078,0.05,60,H3
sample_4.pdf,4,match dimensions (done by 1,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,193.95863342285156,0.0,27,H3
sample_4.pdf,4,1 convolutions). For both,9.962599754333496,NimbusRomNo9L-Regu,False,438.3979797363281,193.95863342285156,0.04,25,H3
sample_4.pdf,4,"options, when the shortcuts go across feature maps of two",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,205.9146270751953,0.0,57,H3
sample_4.pdf,4,"sizes, they are performed with a stride of 2.",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,217.86964416503906,0.0,45,H3
sample_4.pdf,4,3.4. Implementation,10.958900451660156,NimbusRomNo9L-Medi,False,308.86199951171875,236.13998413085938,0.05263157894736842,19,H3
sample_4.pdf,4,Our implementation for ImageNet follows the practice,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,254.92860412597656,0.057692307692307696,52,H3
sample_4.pdf,4,"in [21, 41]. The image is resized with its shorter side ran-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,266.88360595703125,0.016666666666666666,60,H3
sample_4.pdf,4,domly sampled in,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,278.8385925292969,0.0,16,H3
sample_4.pdf,4,[256,9.962599754333496,CMR10,False,382.4557189941406,278.92218017578125,0.0,4,H3
sample_4.pdf,4,480],9.962599754333496,CMR10,False,406.5306091308594,278.92218017578125,0.0,4,H3
sample_4.pdf,4,for scale augmentation [41].,9.962599754333496,NimbusRomNo9L-Regu,False,425.9024963378906,278.8385925292969,0.0,28,H3
sample_4.pdf,4,A 224,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,290.7935791015625,0.2,5,H3
sample_4.pdf,4,224 crop is randomly sampled from an image or its,9.962599754333496,NimbusRomNo9L-Regu,False,341.23199462890625,290.7935791015625,0.0,49,H3
sample_4.pdf,4,"horizontal ﬂip, with the per-pixel mean subtracted [21]. The",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,302.74957275390625,0.016666666666666666,60,H3
sample_4.pdf,4,standard color augmentation in [21] is used. We adopt batch,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,314.7045593261719,0.01694915254237288,59,H3
sample_4.pdf,4,normalization (BN) [16] right after each convolution and,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,326.6595458984375,0.03571428571428571,56,H3
sample_4.pdf,4,"before activation, following [16]. We initialize the weights",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,338.6145324707031,0.016666666666666666,60,H3
sample_4.pdf,4,as in [13] and train all plain/residual nets from scratch. We,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,350.56951904296875,0.01639344262295082,61,H3
sample_4.pdf,4,use SGD with a mini-batch size of 256. The learning rate,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,362.5245056152344,0.07142857142857142,56,H3
sample_4.pdf,4,"starts from 0.1 and is divided by 10 when the error plateaus,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,374.4804992675781,0.0,61,H3
sample_4.pdf,4,and the models are trained for up to,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,386.43548583984375,0.0,36,H3
sample_4.pdf,4,iterations. We,9.962599754333496,NimbusRomNo9L-Regu,False,489.47998046875,386.43548583984375,0.07142857142857142,14,H3
sample_4.pdf,4,use a weight decay of 0.0001 and a momentum of 0.9. We,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,398.3904724121094,0.018518518518518517,54,H3
sample_4.pdf,4,"do not use dropout [14], following the practice in [16].",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,410.345458984375,0.0,56,H3
sample_4.pdf,4,"In testing, for comparison studies we adopt the standard",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,422.3004455566406,0.017857142857142856,56,H3
sample_4.pdf,4,"10-crop testing [21]. For best results, we adopt the fully-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,434.2564392089844,0.01694915254237288,59,H3
sample_4.pdf,4,"convolutional form as in [41, 13], and average the scores",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,446.21142578125,0.0,57,H3
sample_4.pdf,4,at multiple scales (images are resized such that the shorter,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,458.1664123535156,0.0,60,H3
sample_4.pdf,4,side is in,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,470.12139892578125,0.0,10,H3
sample_4.pdf,4,224,9.962599754333496,CMR10,False,351.760986328125,470.2049865722656,0.0,3,H3
sample_4.pdf,4,256,9.962599754333496,CMR10,False,369.4745788574219,470.2049865722656,0.0,3,H3
sample_4.pdf,4,384,9.962599754333496,CMR10,False,388.8455810546875,470.2049865722656,0.0,3,H3
sample_4.pdf,4,480,9.962599754333496,CMR10,False,408.21759033203125,470.2049865722656,0.0,3,H3
sample_4.pdf,4,640,9.962599754333496,CMR10,False,427.589599609375,470.2049865722656,0.0,3,H3
sample_4.pdf,4,4. Experiments,11.9552001953125,NimbusRomNo9L-Medi,False,308.86199951171875,491.6120910644531,0.07142857142857142,14,H3
sample_4.pdf,4,4.1. ImageNet Classiﬁcation,10.958900451660156,NimbusRomNo9L-Medi,False,308.86199951171875,511.3067321777344,0.1111111111111111,27,H3
sample_4.pdf,4,We evaluate our method on the ImageNet 2012 classiﬁ-,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,530.0943603515625,0.057692307692307696,52,H3
sample_4.pdf,4,cation dataset [36] that consists of 1000 classes. The models,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,542.0493774414062,0.01639344262295082,61,H3
sample_4.pdf,4,"are trained on the 1.28 million training images, and evalu-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,554.00537109375,0.0,59,H3
sample_4.pdf,4,ated on the 50k validation images. We also obtain a ﬁnal,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,565.9603881835938,0.017857142857142856,56,H3
sample_4.pdf,4,"result on the 100k test images, reported by the test server.",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,577.9154052734375,0.0,60,H3
sample_4.pdf,4,We evaluate both top-1 and top-5 error rates.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,589.870361328125,0.022222222222222223,45,H3
sample_4.pdf,4,Plain Networks.,9.962599754333496,NimbusRomNo9L-Medi,False,308.86199951171875,607.7124633789062,0.13333333333333333,15,H3
sample_4.pdf,4,We ﬁrst evaluate 18-layer and 34-layer,9.962599754333496,NimbusRomNo9L-Regu,False,378.0323181152344,607.8034057617188,0.02631578947368421,38,H3
sample_4.pdf,4,plain nets. The 34-layer plain net is in Fig. 3 (middle). The,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,619.7584228515625,0.04918032786885246,61,H3
sample_4.pdf,4,18-layer plain net is of a similar form. See Table 1 for de-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,631.71337890625,0.03333333333333333,60,H3
sample_4.pdf,4,tailed architectures.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,643.6683959960938,0.0,21,H3
sample_4.pdf,4,The results in Table 2 show that the deeper 34-layer plain,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,655.6243896484375,0.034482758620689655,58,H3
sample_4.pdf,4,net has higher validation error than the shallower 18-layer,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,667.5794067382812,0.0,59,H3
sample_4.pdf,4,"plain net. To reveal the reasons, in Fig. 4 (left) we com-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,679.534423828125,0.034482758620689655,58,H3
sample_4.pdf,4,pare their training/validation errors during the training pro-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,691.4893798828125,0.0,62,H3
sample_4.pdf,4,cedure. We have observed the degradation problem - the,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,703.4443969726562,0.018518518518518517,54,H3
sample_4.pdf,5,layer name output size,6.464033603668213,NimbusRomNo9L-Regu,False,127.91358947753906,73.32965087890625,0.0,22,P
sample_4.pdf,5,18-layer,6.464033603668213,NimbusRomNo9L-Regu,False,205.93798828125,73.32965087890625,0.0,8,P
sample_4.pdf,5,34-layer,6.464033603668213,NimbusRomNo9L-Regu,False,257.65753173828125,73.32965087890625,0.0,8,P
sample_4.pdf,5,50-layer,6.464033603668213,NimbusRomNo9L-Regu,False,311.89129638671875,73.32965087890625,0.0,8,P
sample_4.pdf,5,101-layer,6.464033603668213,NimbusRomNo9L-Regu,False,368.63861083984375,73.32965087890625,0.0,9,P
sample_4.pdf,5,152-layer,6.464033603668213,NimbusRomNo9L-Regu,False,427.8099670410156,73.32965087890625,0.0,9,P
sample_4.pdf,5,conv1,6.464033603668213,NimbusRomNo9L-Regu,False,134.4129180908203,82.12066650390625,0.0,5,P
sample_4.pdf,5,112,6.464033603668213,NimbusRomNo9L-Regu,False,162.4735107421875,82.12066650390625,0.0,3,P
sample_4.pdf,5,112,6.464033603668213,NimbusRomNo9L-Regu,False,177.19741821289062,82.12066650390625,0.0,3,P
sample_4.pdf,5,"7, 64, stride 2",6.464033603668213,NimbusRomNo9L-Regu,False,316.55572509765625,82.12066650390625,0.0,15,P
sample_4.pdf,5,conv2 x,6.464033603668213,NimbusRomNo9L-Regu,False,131.63333129882812,103.555419921875,0.0,7,P
sample_4.pdf,5,"3 max pool, stride 2",6.464033603668213,NimbusRomNo9L-Regu,False,308.475830078125,90.91162109375,0.0,20,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,209.43453979492188,104.03424072265625,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,209.43453979492188,111.92010498046875,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,261.15472412109375,104.03424072265625,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,261.15472412109375,111.92010498046875,0.0,5,P
sample_4.pdf,5,"1, 64",6.464033603668213,NimbusRomNo9L-Regu,False,315.3878173828125,100.09063720703125,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,315.3878173828125,107.97720336914062,0.0,5,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,313.77154541015625,115.86306762695312,0.0,6,P
sample_4.pdf,5,"1, 64",6.464033603668213,NimbusRomNo9L-Regu,False,373.7513732910156,100.09063720703125,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,373.7513732910156,107.97720336914062,0.0,5,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351013183594,115.86306762695312,0.0,6,P
sample_4.pdf,5,"1, 64",6.464033603668213,NimbusRomNo9L-Regu,False,433.7305908203125,100.09063720703125,0.0,5,P
sample_4.pdf,5,"3, 64",6.464033603668213,NimbusRomNo9L-Regu,False,433.7306213378906,107.97720336914062,0.0,5,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,432.1143493652344,115.86306762695312,0.0,6,P
sample_4.pdf,5,conv3 x,6.464033603668213,NimbusRomNo9L-Regu,False,131.63333129882812,133.677978515625,0.0,7,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,129.89010620117188,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,137.77664184570312,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384826660156,129.89010620117188,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384521484375,137.77664184570312,0.0,6,P
sample_4.pdf,5,"1, 128",6.464033603668213,NimbusRomNo9L-Regu,False,313.772216796875,125.94717407226562,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,313.772216796875,133.833740234375,0.0,6,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,313.772216796875,141.7196044921875,0.0,6,P
sample_4.pdf,5,"1, 128",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351318359375,125.94717407226562,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351013183594,133.833740234375,0.0,6,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351013183594,141.7196044921875,0.0,6,P
sample_4.pdf,5,"1, 128",6.464033603668213,NimbusRomNo9L-Regu,False,432.1142883300781,125.94717407226562,0.0,6,P
sample_4.pdf,5,"3, 128",6.464033603668213,NimbusRomNo9L-Regu,False,432.1142883300781,133.833740234375,0.0,6,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,432.1142883300781,141.7196044921875,0.0,6,P
sample_4.pdf,5,conv4 x,6.464033603668213,NimbusRomNo9L-Regu,False,131.63333129882812,159.53451538085938,0.0,7,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,155.74664306640625,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,163.63250732421875,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384826660156,155.74664306640625,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384521484375,163.63250732421875,0.0,6,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,313.7722473144531,151.8037109375,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,313.7722473144531,159.6895751953125,0.0,6,P
sample_4.pdf,5,"1, 1024",6.464033603668213,NimbusRomNo9L-Regu,False,312.156005859375,167.57614135742188,0.0,7,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,370.5195617675781,151.8037109375,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,370.5195617675781,159.6895751953125,0.0,6,P
sample_4.pdf,5,"1, 1024",6.464033603668213,NimbusRomNo9L-Regu,False,368.9033203125,167.57614135742188,0.0,7,P
sample_4.pdf,5,"1, 256",6.464033603668213,NimbusRomNo9L-Regu,False,430.4987487792969,151.8037109375,0.0,6,P
sample_4.pdf,5,"3, 256",6.464033603668213,NimbusRomNo9L-Regu,False,430.498779296875,159.6895751953125,0.0,6,P
sample_4.pdf,5,"1, 1024",6.464033603668213,NimbusRomNo9L-Regu,False,428.882568359375,167.57614135742188,0.0,7,P
sample_4.pdf,5,conv5 x,6.464033603668213,NimbusRomNo9L-Regu,False,131.63333129882812,185.39105224609375,0.0,7,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,181.6031494140625,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,207.81893920898438,189.48904418945312,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384826660156,181.6031494140625,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,259.5384521484375,189.48904418945312,0.0,6,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,313.7722473144531,177.66021728515625,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,313.7722473144531,185.54608154296875,0.0,6,P
sample_4.pdf,5,"1, 2048",6.464033603668213,NimbusRomNo9L-Regu,False,312.156005859375,193.43194580078125,0.0,7,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351623535156,177.66021728515625,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,372.1351318359375,185.54608154296875,0.0,6,P
sample_4.pdf,5,"1, 2048",6.464033603668213,NimbusRomNo9L-Regu,False,370.5188903808594,193.43194580078125,0.0,7,P
sample_4.pdf,5,"1, 512",6.464033603668213,NimbusRomNo9L-Regu,False,432.1142883300781,177.66021728515625,0.0,6,P
sample_4.pdf,5,"3, 512",6.464033603668213,NimbusRomNo9L-Regu,False,432.1142883300781,185.54608154296875,0.0,6,P
sample_4.pdf,5,"1, 2048",6.464033603668213,NimbusRomNo9L-Regu,False,430.4987487792969,193.43194580078125,0.0,7,P
sample_4.pdf,5,"average pool, 1000-d fc, softmax",6.464033603668213,NimbusRomNo9L-Regu,False,287.5010986328125,202.86984252929688,0.0,32,P
sample_4.pdf,5,FLOPs,6.464033603668213,NimbusRomNo9L-Regu,False,149.186767578125,211.66085815429688,0.8,5,P
sample_4.pdf,5,1.8,6.464033603668213,NimbusRomNo9L-Regu,False,205.4708251953125,211.66085815429688,0.0,3,P
sample_4.pdf,5,3.6,6.464033603668213,NimbusRomNo9L-Regu,False,257.19036865234375,211.66085815429688,0.0,3,P
sample_4.pdf,5,3.8,6.464033603668213,NimbusRomNo9L-Regu,False,311.42413330078125,211.66085815429688,0.0,3,P
sample_4.pdf,5,7.6,6.464033603668213,NimbusRomNo9L-Regu,False,369.7876892089844,211.66085815429688,0.0,3,P
sample_4.pdf,5,11.3,6.464033603668213,NimbusRomNo9L-Regu,False,427.3427734375,211.66085815429688,0.0,4,P
sample_4.pdf,5,"Table 1. Architectures for ImageNet. Building blocks are shown in brackets (see also Fig. 5), with the numbers of blocks stacked. Down-",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,224.67495727539062,0.05185185185185185,135,P
sample_4.pdf,5,"sampling is performed by conv3 1, conv4 1, and conv5 1 with a stride of 2.",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,235.63394165039062,0.0,74,P
sample_4.pdf,5,iter. (1e4),6.902493953704834,Times-Roman,False,179.81224060058594,382.00335693359375,0.0,11,P
sample_4.pdf,5,error (%),6.902493953704834,Times-Roman,False,86.04337310791016,300.87158203125,0.0,9,P
sample_4.pdf,5,plain-18,8.05297565460205,Times-Roman,False,115.83331298828125,353.14447021484375,0.0,8,P
sample_4.pdf,5,plain-34,8.05297565460205,Times-Roman,False,115.83331298828125,363.0478210449219,0.0,8,P
sample_4.pdf,5,iter. (1e4),6.902493953704834,Times-Roman,False,403.8171081542969,382.00335693359375,0.0,11,P
sample_4.pdf,5,error (%),6.902493953704834,Times-Roman,False,310.0482482910156,300.87158203125,0.0,9,P
sample_4.pdf,5,ResNet-18,8.05297565460205,Times-Roman,False,339.8380432128906,353.14447021484375,0.2222222222222222,9,P
sample_4.pdf,5,ResNet-34,8.05297565460205,Times-Roman,False,339.8380432128906,363.0478210449219,0.2222222222222222,9,P
sample_4.pdf,5,18-layer,7.857985973358154,TT55o00,False,253.06564331054688,347.9715576171875,0.0,8,P
sample_4.pdf,5,34-layer,7.857985973358154,TT55o00,False,253.06564331054688,322.9773254394531,0.0,8,P
sample_4.pdf,5,18-layer,7.857985973358154,TT55o00,False,475.65399169921875,330.3655700683594,0.0,8,P
sample_4.pdf,5,34-layer,7.857985973358154,TT55o00,False,475.65399169921875,362.7480163574219,0.0,8,P
sample_4.pdf,5,Figure 4. Training on,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,392.3709716796875,0.09523809523809523,21,P
sample_4.pdf,5,ImageNet,8.966400146484375,NimbusRomNo9L-Medi,False,126.38916015625,392.2890930175781,0.25,8,P
sample_4.pdf,5,". Thin curves denote training error, and bold curves denote validation error of the center crops. Left: plain",8.966400146484375,NimbusRomNo9L-Regu,False,165.93701171875,392.3709716796875,0.01834862385321101,109,P
sample_4.pdf,5,"networks of 18 and 34 layers. Right: ResNets of 18 and 34 layers. In this plot, the residual networks have no extra parameter compared to",8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,403.3299865722656,0.029197080291970802,137,P
sample_4.pdf,5,their plain counterparts.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,414.2889709472656,0.0,25,P
sample_4.pdf,5,plain,8.966400146484375,NimbusRomNo9L-Regu,False,162.3820037841797,444.9919738769531,0.0,5,P
sample_4.pdf,5,ResNet,8.966400146484375,NimbusRomNo9L-Regu,False,208.60899353027344,444.9919738769531,0.3333333333333333,6,P
sample_4.pdf,5,18 layers,8.966400146484375,NimbusRomNo9L-Regu,False,101.46900177001953,457.44598388671875,0.0,9,P
sample_4.pdf,5,27.94,8.966400146484375,NimbusRomNo9L-Regu,False,161.26100158691406,457.44598388671875,0.0,5,P
sample_4.pdf,5,27.88,8.966400146484375,NimbusRomNo9L-Regu,False,211.72000122070312,457.44598388671875,0.0,5,P
sample_4.pdf,5,34 layers,8.966400146484375,NimbusRomNo9L-Regu,False,101.46900177001953,469.4999694824219,0.0,9,P
sample_4.pdf,5,28.54,8.966400146484375,NimbusRomNo9L-Regu,False,161.26100158691406,469.4999694824219,0.0,5,P
sample_4.pdf,5,25.03,8.966400146484375,NimbusRomNo9L-Medi,False,211.72000122070312,469.4180908203125,0.0,5,P
sample_4.pdf,5,"Table 2. Top-1 error (%, 10-crop testing) on ImageNet validation.",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,485.60797119140625,0.06153846153846154,65,P
sample_4.pdf,5,Here the ResNets have no extra parameter compared to their plain,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,496.5669860839844,0.046875,64,P
sample_4.pdf,5,counterparts. Fig. 4 shows the training procedures.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,507.5259704589844,0.0196078431372549,51,P
sample_4.pdf,5,34-layer plain net has higher,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,544.8844604492188,0.0,29,H3
sample_4.pdf,5,training,9.962599754333496,NimbusRomNo9L-ReguItal,False,166.64451599121094,544.7080078125,0.0,8,H3
sample_4.pdf,5,error throughout the,9.962599754333496,NimbusRomNo9L-Regu,False,201.72801208496094,544.8844604492188,0.0,20,H3
sample_4.pdf,5,"whole training procedure, even though the solution space",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,556.8394775390625,0.0,56,H3
sample_4.pdf,5,of the 18-layer plain network is a subspace of that of the,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,568.79443359375,0.0,58,H3
sample_4.pdf,5,34-layer one.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,580.7504272460938,0.0,13,H3
sample_4.pdf,5,We argue that this optimization difﬁculty is,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,595.847412109375,0.022727272727272728,44,H3
sample_4.pdf,5,unlikely,9.962599754333496,NimbusRomNo9L-ReguItal,False,240.2979278564453,595.6709594726562,0.0,8,H3
sample_4.pdf,5,be caused by vanishing gradients. These plain networks are,9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,607.803466796875,0.017241379310344827,58,H3
sample_4.pdf,5,"trained with BN [16], which ensures forward propagated",9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,619.7584228515625,0.037037037037037035,54,H3
sample_4.pdf,5,signals to have non-zero variances. We also verify that the,9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,631.7134399414062,0.01694915254237288,59,H3
sample_4.pdf,5,backward propagated gradients exhibit healthy norms with,9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,643.66845703125,0.0,56,H3
sample_4.pdf,5,BN. So neither forward nor backward signals vanish. In,9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,655.6234130859375,0.07407407407407407,54,H3
sample_4.pdf,5,"fact, the 34-layer plain net is still able to achieve compet-",9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,667.5794677734375,0.0,61,H3
sample_4.pdf,5,"itive accuracy (Table 3), suggesting that the solver works",9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,679.534423828125,0.017241379310344827,58,H3
sample_4.pdf,5,to some extent. We conjecture that the deep plain nets may,9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,691.4894409179688,0.017241379310344827,58,H3
sample_4.pdf,5,"have exponentially low convergence rates, which impact the",9.962599754333496,NimbusRomNo9L-Regu,False,50.112030029296875,703.4444580078125,0.0,58,H3
sample_4.pdf,5,reducing of the training error,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,445.3624572753906,0.0,30,H3
sample_4.pdf,5,. The reason for such opti-,9.962599754333496,NimbusRomNo9L-Regu,False,432.4510192871094,445.3624572753906,0.037037037037037035,27,H3
sample_4.pdf,5,mization difﬁculties will be studied in the future.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,457.31744384765625,0.0,51,H3
sample_4.pdf,5,Residual Networks.,9.962599754333496,NimbusRomNo9L-Medi,False,308.8620300292969,475.1595153808594,0.1111111111111111,18,H3
sample_4.pdf,5,Next we evaluate 18-layer and 34-,9.962599754333496,NimbusRomNo9L-Regu,False,393.2651672363281,475.2504577636719,0.030303030303030304,33,H3
sample_4.pdf,5,layer residual nets (,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,487.2054443359375,0.0,21,H3
sample_4.pdf,5,ResNets,9.962599754333496,NimbusRomNo9L-ReguItal,False,392.0100402832031,487.02899169921875,0.2857142857142857,7,H3
sample_4.pdf,5,). The baseline architectures,9.962599754333496,NimbusRomNo9L-Regu,False,424.1090393066406,487.2054443359375,0.034482758620689655,29,H3
sample_4.pdf,5,"are the same as the above plain nets, expect that a shortcut",9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,499.1604309082031,0.0,60,H3
sample_4.pdf,5,connection is added to each pair of 3,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,511.11541748046875,0.0,37,H3
sample_4.pdf,5,3 ﬁlters as in Fig. 3,9.962599754333496,NimbusRomNo9L-Regu,False,466.0040283203125,511.11541748046875,0.047619047619047616,21,H3
sample_4.pdf,5,"(right). In the ﬁrst comparison (Table 2 and Fig. 4 right),",9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,523.0714111328125,0.05084745762711865,59,H3
sample_4.pdf,5,we use identity mapping for all shortcuts and zero-padding,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,535.0264282226562,0.0,58,H3
sample_4.pdf,5,for increasing dimensions (option A). So they have,9.962599754333496,NimbusRomNo9L-Regu,False,308.8620300292969,546.9814453125,0.04,50,H3
sample_4.pdf,5,no extra,9.962599754333496,NimbusRomNo9L-ReguItal,False,510.48504638671875,546.8049926757812,0.0,8,H3
sample_4.pdf,5,parameter,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8620300292969,558.7599487304688,0.0,9,H3
sample_4.pdf,5,compared to the plain counterparts.,9.962599754333496,NimbusRomNo9L-Regu,False,350.2167663574219,558.9364013671875,0.0,35,H3
sample_4.pdf,5,We have three major observations from Table 2 and,9.962599754333496,NimbusRomNo9L-Regu,False,320.8170471191406,570.8914184570312,0.04081632653061224,49,H3
sample_4.pdf,5,"Fig. 4. First, the situation is reversed with residual learn-",9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,582.847412109375,0.03278688524590164,61,H3
sample_4.pdf,5,ing – the 34-layer ResNet is better than the 18-layer ResNet,9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,594.8024291992188,0.06666666666666667,60,H3
sample_4.pdf,5,"(by 2.8%). More importantly, the 34-layer ResNet exhibits",9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,606.7574462890625,0.05263157894736842,57,H3
sample_4.pdf,5,considerably lower training error and is generalizable to the,9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,618.71240234375,0.0,61,H3
sample_4.pdf,5,validation data. This indicates that the degradation problem,9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,630.6674194335938,0.016666666666666666,60,H3
sample_4.pdf,5,is well addressed in this setting and we manage to obtain,9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,642.6224365234375,0.0,57,H3
sample_4.pdf,5,accuracy gains from increased depth.,9.962599754333496,NimbusRomNo9L-Regu,False,308.862060546875,654.5784301757812,0.0,36,H3
sample_4.pdf,5,"Second, compared to its plain counterpart, the 34-layer",9.962599754333496,NimbusRomNo9L-Regu,False,320.8170471191406,666.533447265625,0.01818181818181818,55,H3
sample_4.pdf,5,We have experimented with more training iterations (3,7.970099925994873,NimbusRomNo9L-Regu,False,323.2080078125,686.0265502929688,0.018867924528301886,53,P
sample_4.pdf,5,) and still ob-,7.970099925994873,NimbusRomNo9L-Regu,False,502.8230285644531,686.0265502929688,0.0,15,P
sample_4.pdf,5,"served the degradation problem, suggesting that this problem cannot be",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,695.4906005859375,0.0,70,P
sample_4.pdf,5,feasibly addressed by simply using more iterations.,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,704.95556640625,0.0,51,P
sample_4.pdf,6,model,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099975585938,74.79253387451172,0.0,5,P
sample_4.pdf,6,top-1 err.,7.970099925994873,NimbusRomNo9L-Regu,False,165.66700744628906,74.79253387451172,0.0,10,P
sample_4.pdf,6,top-5 err.,7.970099925994873,NimbusRomNo9L-Regu,False,210.8255615234375,74.79253387451172,0.0,10,P
sample_4.pdf,6,VGG-16 [41],7.970099925994873,NimbusRomNo9L-Regu,False,96.43099975585938,87.24553680419922,0.2727272727272727,11,P
sample_4.pdf,6,28.07,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,86.48995971679688,0.0,5,P
sample_4.pdf,6,9.33,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,86.48995971679688,0.0,4,P
sample_4.pdf,6,GoogLeNet [44],7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,99.30052947998047,0.21428571428571427,14,P
sample_4.pdf,6,9.15,8.966400146484375,NimbusRomNo9L-Regu,False,217.58958435058594,98.54495239257812,0.0,4,P
sample_4.pdf,6,PReLU-net [13],7.970099925994873,NimbusRomNo9L-Regu,False,96.4310073852539,111.35552215576172,0.2857142857142857,14,P
sample_4.pdf,6,24.27,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,110.60000610351562,0.0,5,P
sample_4.pdf,6,7.38,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,110.60000610351562,0.0,4,P
sample_4.pdf,6,plain-34,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099975585938,126.19957733154297,0.0,8,P
sample_4.pdf,6,28.54,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,125.44400024414062,0.0,5,P
sample_4.pdf,6,10.02,8.966400146484375,NimbusRomNo9L-Regu,False,215.3437957763672,125.44400024414062,0.0,5,P
sample_4.pdf,6,ResNet-34 A,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,138.25457763671875,0.2727272727272727,11,P
sample_4.pdf,6,25.03,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,137.49899291992188,0.0,5,P
sample_4.pdf,6,7.76,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,137.49899291992188,0.0,4,P
sample_4.pdf,6,ResNet-34 B,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,150.3095703125,0.2727272727272727,11,P
sample_4.pdf,6,24.52,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,149.55398559570312,0.0,5,P
sample_4.pdf,6,7.46,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,149.55398559570312,0.0,4,P
sample_4.pdf,6,ResNet-34 C,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,162.36456298828125,0.2727272727272727,11,P
sample_4.pdf,6,24.19,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,161.60897827148438,0.0,5,P
sample_4.pdf,6,7.40,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,161.60897827148438,0.0,4,P
sample_4.pdf,6,ResNet-50,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099975585938,174.81756591796875,0.2222222222222222,9,P
sample_4.pdf,6,22.85,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,174.06198120117188,0.0,5,P
sample_4.pdf,6,6.71,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,174.06198120117188,0.0,4,P
sample_4.pdf,6,ResNet-101,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,186.87255859375,0.2,10,P
sample_4.pdf,6,21.75,8.966400146484375,NimbusRomNo9L-Regu,False,170.18899536132812,186.11697387695312,0.0,5,P
sample_4.pdf,6,6.05,8.966400146484375,NimbusRomNo9L-Regu,False,217.58538818359375,186.11697387695312,0.0,4,P
sample_4.pdf,6,ResNet-152,7.970099925994873,NimbusRomNo9L-Regu,False,96.43099212646484,198.92755126953125,0.2,10,P
sample_4.pdf,6,21.43,8.966400146484375,NimbusRomNo9L-Medi,False,170.18899536132812,198.09010314941406,0.0,5,P
sample_4.pdf,6,5.71,8.966400146484375,NimbusRomNo9L-Medi,False,217.58538818359375,198.09010314941406,0.0,4,P
sample_4.pdf,6,"Table 3. Error rates (%,",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,214.34201049804688,0.08333333333333333,24,P
sample_4.pdf,6,10-crop,8.966400146484375,NimbusRomNo9L-Medi,False,135.24795532226562,214.26014709472656,0.0,7,P
sample_4.pdf,6,testing) on ImageNet validation.,8.966400146484375,NimbusRomNo9L-Regu,False,167.08949279785156,214.34201049804688,0.0625,32,P
sample_4.pdf,6,VGG-16 is based on our test. ResNet-50/101/152 are of option B,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199188232422,225.30099487304688,0.0967741935483871,62,P
sample_4.pdf,6,that only uses projections for increasing dimensions.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199188232422,236.25997924804688,0.0,53,P
sample_4.pdf,6,method,7.970099925994873,NimbusRomNo9L-Regu,False,67.0999984741211,257.6595458984375,0.0,6,P
sample_4.pdf,6,top-1 err.,7.970099925994873,NimbusRomNo9L-Regu,False,194.9969940185547,257.6595458984375,0.0,10,P
sample_4.pdf,6,top-5 err.,7.970099925994873,NimbusRomNo9L-Regu,False,240.15554809570312,257.6595458984375,0.0,10,P
sample_4.pdf,6,VGG [41] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,67.0999984741211,269.3580017089844,0.45,20,P
sample_4.pdf,6,8.43,8.966400146484375,NimbusRomNo9L-Regu,False,244.95693969726562,269.3580017089844,0.0,4,P
sample_4.pdf,6,GoogLeNet [44] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,281.4119873046875,0.34615384615384615,26,P
sample_4.pdf,6,7.89,8.966400146484375,NimbusRomNo9L-Regu,False,246.9205780029297,281.4119873046875,0.0,4,P
sample_4.pdf,6,VGG [41],8.966400146484375,NimbusRomNo9L-Regu,False,67.0999984741211,293.865966796875,0.375,8,P
sample_4.pdf,6,(v5),7.970099925994873,NimbusRomNo9L-Regu,False,103.56633758544922,294.6215515136719,0.0,4,P
sample_4.pdf,6,24.4,8.966400146484375,NimbusRomNo9L-Regu,False,201.76100158691406,293.865966796875,0.0,4,P
sample_4.pdf,6,7.1,8.966400146484375,NimbusRomNo9L-Regu,False,249.15737915039062,293.865966796875,0.0,3,P
sample_4.pdf,6,PReLU-net [13],8.966400146484375,NimbusRomNo9L-Regu,False,67.10000610351562,305.92095947265625,0.2857142857142857,14,P
sample_4.pdf,6,21.59,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,305.9209899902344,0.0,5,P
sample_4.pdf,6,5.71,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,305.9209899902344,0.0,4,P
sample_4.pdf,6,BN-inception [16],8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,317.9759826660156,0.11764705882352941,17,P
sample_4.pdf,6,21.99,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,317.9749755859375,0.0,5,P
sample_4.pdf,6,5.81,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,317.9749755859375,0.0,4,P
sample_4.pdf,6,ResNet-34 B,8.966400146484375,NimbusRomNo9L-Regu,False,67.0999984741211,330.4289855957031,0.2727272727272727,11,P
sample_4.pdf,6,21.84,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,330.4289855957031,0.0,5,P
sample_4.pdf,6,5.71,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,330.4289855957031,0.0,4,P
sample_4.pdf,6,ResNet-34 C,8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,342.4839782714844,0.2727272727272727,11,P
sample_4.pdf,6,21.53,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,342.4839782714844,0.0,5,P
sample_4.pdf,6,5.60,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,342.4839782714844,0.0,4,P
sample_4.pdf,6,ResNet-50,8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,354.5389709472656,0.2222222222222222,9,P
sample_4.pdf,6,20.74,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,354.5389709472656,0.0,5,P
sample_4.pdf,6,5.25,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,354.5389709472656,0.0,4,P
sample_4.pdf,6,ResNet-101,8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,366.59295654296875,0.2,10,P
sample_4.pdf,6,19.87,8.966400146484375,NimbusRomNo9L-Regu,False,199.5189971923828,366.5929870605469,0.0,5,P
sample_4.pdf,6,4.60,8.966400146484375,NimbusRomNo9L-Regu,False,246.91537475585938,366.5929870605469,0.0,4,P
sample_4.pdf,6,ResNet-152,8.966400146484375,NimbusRomNo9L-Regu,False,67.09999084472656,378.6479797363281,0.2,10,P
sample_4.pdf,6,19.38,8.966400146484375,NimbusRomNo9L-Medi,False,199.5189971923828,378.56610107421875,0.0,5,P
sample_4.pdf,6,4.49,8.966400146484375,NimbusRomNo9L-Medi,False,246.91537475585938,378.56610107421875,0.0,4,P
sample_4.pdf,6,Table 4. Error rates (%) of,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,395.3169860839844,0.07407407407407407,27,P
sample_4.pdf,6,single-model,8.966400146484375,NimbusRomNo9L-Medi,False,146.3214569091797,395.235107421875,0.0,12,P
sample_4.pdf,6,results on the ImageNet,8.966400146484375,NimbusRomNo9L-Regu,False,197.2499237060547,395.3169860839844,0.08695652173913043,23,P
sample_4.pdf,6,validation set (except,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,406.2759704589844,0.0,22,P
sample_4.pdf,6,reported on the test set).,8.966400146484375,NimbusRomNo9L-Regu,False,134.86399841308594,406.2759704589844,0.0,26,P
sample_4.pdf,6,method,7.970099925994873,NimbusRomNo9L-Regu,False,72.77200317382812,428.7685546875,0.0,6,P
sample_4.pdf,6,top-5 err. (,8.966400146484375,NimbusRomNo9L-Regu,False,208.63999938964844,428.0129699707031,0.0,12,P
sample_4.pdf,6,test,8.966400146484375,NimbusRomNo9L-Medi,False,247.2760009765625,427.93109130859375,0.0,4,P
sample_4.pdf,6,VGG [41] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,72.77200317382812,440.4659729003906,0.45,20,P
sample_4.pdf,6,7.32,8.966400146484375,NimbusRomNo9L-Regu,False,228.3249969482422,440.4659729003906,0.0,4,P
sample_4.pdf,6,GoogLeNet [44] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,72.77200317382812,452.5209655761719,0.34615384615384615,26,P
sample_4.pdf,6,6.66,8.966400146484375,NimbusRomNo9L-Regu,False,228.3249969482422,452.52099609375,0.0,4,P
sample_4.pdf,6,VGG [41],8.966400146484375,NimbusRomNo9L-Regu,False,72.77200317382812,464.9739685058594,0.375,8,P
sample_4.pdf,6,(v5),7.970099925994873,NimbusRomNo9L-Regu,False,109.23834228515625,465.72955322265625,0.0,4,P
sample_4.pdf,6,6.8,8.966400146484375,NimbusRomNo9L-Regu,False,230.56700134277344,464.9739685058594,0.0,3,P
sample_4.pdf,6,PReLU-net [13],8.966400146484375,NimbusRomNo9L-Regu,False,72.77200317382812,477.0289611816406,0.2857142857142857,14,P
sample_4.pdf,6,4.94,8.966400146484375,NimbusRomNo9L-Regu,False,228.3249969482422,477.02899169921875,0.0,4,P
sample_4.pdf,6,BN-inception [16],8.966400146484375,NimbusRomNo9L-Regu,False,72.77200317382812,489.083984375,0.11764705882352941,17,P
sample_4.pdf,6,4.82,8.966400146484375,NimbusRomNo9L-Regu,False,228.3249969482422,489.083984375,0.0,4,P
sample_4.pdf,6,ResNet (ILSVRC’15),8.966400146484375,NimbusRomNo9L-Medi,False,72.77200317382812,501.4551086425781,0.4444444444444444,18,P
sample_4.pdf,6,3.57,8.966400146484375,NimbusRomNo9L-Medi,False,228.3249969482422,501.4551086425781,0.0,4,P
sample_4.pdf,6,Table 5. Error rates (%) of,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,518.1429443359375,0.07407407407407407,27,P
sample_4.pdf,6,ensembles,8.966400146484375,NimbusRomNo9L-Medi,False,147.47811889648438,518.0610961914062,0.0,9,P
sample_4.pdf,6,. The top-5 error is on the,8.966400146484375,NimbusRomNo9L-Regu,False,189.1689910888672,518.1429443359375,0.037037037037037035,27,P
sample_4.pdf,6,test set of ImageNet and reported by the test server.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11198425292969,529.1019287109375,0.03773584905660377,53,P
sample_4.pdf,6,"ResNet reduces the top-1 error by 3.5% (Table 2), resulting",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,563.0674438476562,0.05084745762711865,59,H3
sample_4.pdf,6,from the successfully reduced training error (Fig. 4 right,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,575.0224609375,0.017241379310344827,58,H3
sample_4.pdf,6,left). This comparison veriﬁes the effectiveness of residual,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,586.9784545898438,0.016666666666666666,60,H3
sample_4.pdf,6,learning on extremely deep systems.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,598.9334716796875,0.0,35,H3
sample_4.pdf,6,"Last, we also note that the 18-layer plain/residual nets",9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,612.33447265625,0.017857142857142856,56,H3
sample_4.pdf,6,"are comparably accurate (Table 2), but the 18-layer ResNet",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,624.2894287109375,0.05172413793103448,58,H3
sample_4.pdf,6,converges faster (Fig. 4 right,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,636.2444458007812,0.03333333333333333,30,H3
sample_4.pdf,6,. left). When the net is “not,9.962599754333496,NimbusRomNo9L-Regu,False,176.16299438476562,636.2444458007812,0.034482758620689655,29,H3
sample_4.pdf,6,"overly deep” (18 layers here), the current SGD solver is still",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199188232422,648.200439453125,0.04838709677419355,62,H3
sample_4.pdf,6,"able to ﬁnd good solutions to the plain net. In this case, the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199188232422,660.1554565429688,0.016129032258064516,62,H3
sample_4.pdf,6,ResNet eases the optimization by providing faster conver-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199188232422,672.1104736328125,0.03508771929824561,57,H3
sample_4.pdf,6,gence at the early stage.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199188232422,684.0654296875,0.0,25,H3
sample_4.pdf,6,Identity,9.962599754333496,NimbusRomNo9L-Medi,False,50.11199188232422,703.353515625,0.125,8,H3
sample_4.pdf,6,. Projection Shortcuts.,9.962599754333496,NimbusRomNo9L-Medi,False,96.21298217773438,703.353515625,0.08695652173913043,23,H3
sample_4.pdf,6,We have shown that,9.962599754333496,NimbusRomNo9L-Regu,False,194.314697265625,703.4444580078125,0.05555555555555555,18,H3
sample_4.pdf,6,"3x3, 64",6.041206359863281,TT3Do00,False,470.3319091796875,101.60088348388672,0.0,7,P
sample_4.pdf,6,"1x1, 64",6.041206359863281,TT3Do00,False,470.3319091796875,87.25872802734375,0.0,7,P
sample_4.pdf,6,relu,5.458935737609863,TT3Eo00,False,482.41717529296875,93.84010314941406,0.0,4,P
sample_4.pdf,6,"1x1, 256",6.041206359863281,TT3Do00,False,468.80303955078125,115.94303894042969,0.0,8,P
sample_4.pdf,6,relu,5.458935737609863,TT3Eo00,False,482.41717529296875,108.25506591796875,0.0,4,P
sample_4.pdf,6,relu,5.458935737609863,TT3Eo00,False,482.41717529296875,134.82826232910156,0.0,4,P
sample_4.pdf,6,"3x3, 64",6.041206359863281,TT3Do00,False,350.2073669433594,89.22441101074219,0.0,7,P
sample_4.pdf,6,"3x3, 64",6.041206359863281,TT3Do00,False,350.2073669433594,111.35646057128906,0.0,7,P
sample_4.pdf,6,relu,5.458935737609863,TT3Eo00,False,362.2926330566406,134.8280792236328,0.0,4,P
sample_4.pdf,6,relu,5.458935737609863,TT3Eo00,False,362.2926330566406,97.91706848144531,0.0,4,P
sample_4.pdf,6,64-d,5.458935737609863,TT3Eo00,False,365.1317138671875,71.99908447265625,0.0,4,P
sample_4.pdf,6,256-d,5.458935737609863,TT3Eo00,False,483.87677001953125,71.99908447265625,0.0,5,P
sample_4.pdf,6,Figure 5. A deeper residual function,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,157.10397338867188,0.05555555555555555,36,P
sample_4.pdf,6,for ImageNet. Left: a,8.966400146484375,NimbusRomNo9L-Regu,False,455.54327392578125,157.10397338867188,0.14285714285714285,21,P
sample_4.pdf,6,building block (on 56,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,168.06295776367188,0.0,21,P
sample_4.pdf,6,56 feature maps) as in Fig. 3 for ResNet-,8.966400146484375,NimbusRomNo9L-Regu,False,394.7099914550781,168.06295776367188,0.07317073170731707,41,P
sample_4.pdf,6,34. Right: a “bottleneck” building block for ResNet-50/101/152.,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,179.02194213867188,0.047619047619047616,63,P
sample_4.pdf,6,"parameter-free, identity shortcuts help with training. Next",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,205.5364532470703,0.01694915254237288,59,H3
sample_4.pdf,6,we investigate projection shortcuts (Eqn.(2)). In Table 3 we,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,217.49147033691406,0.05,60,H3
sample_4.pdf,6,compare three options: (A) zero-padding shortcuts are used,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,229.4464874267578,0.017241379310344827,58,H3
sample_4.pdf,6,"for increasing dimensions, and all shortcuts are parameter-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,241.40150451660156,0.0,59,H3
sample_4.pdf,6,free (the same as Table 2 and Fig. 4 right); (B) projec-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,253.3565216064453,0.05357142857142857,56,H3
sample_4.pdf,6,"tion shortcuts are used for increasing dimensions, and other",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,265.3125,0.0,60,H3
sample_4.pdf,6,shortcuts are identity; and (C) all shortcuts are projections.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,277.2674865722656,0.016129032258064516,62,H3
sample_4.pdf,6,Table 3 shows that all three options are considerably bet-,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,289.9314880371094,0.017241379310344827,58,H3
sample_4.pdf,6,ter than the plain counterpart. B is slightly better than A. We,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,301.886474609375,0.047619047619047616,63,H3
sample_4.pdf,6,argue that this is because the zero-padded dimensions in A,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,313.84246826171875,0.017241379310344827,58,H3
sample_4.pdf,6,indeed have no residual learning. C is marginally better than,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,325.7974548339844,0.01639344262295082,61,H3
sample_4.pdf,6,"B, and we attribute this to the extra parameters introduced",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,337.75244140625,0.01694915254237288,59,H3
sample_4.pdf,6,by many (thirteen) projection shortcuts. But the small dif-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,349.7074279785156,0.01694915254237288,59,H3
sample_4.pdf,6,ferences among A/B/C indicate that projection shortcuts are,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,361.66241455078125,0.05084745762711865,59,H3
sample_4.pdf,6,not essential for addressing the degradation problem. So we,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,373.6174011230469,0.01694915254237288,59,H3
sample_4.pdf,6,"do not use option C in the rest of this paper, to reduce mem-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,385.5733947753906,0.01639344262295082,61,H3
sample_4.pdf,6,ory/time complexity and model sizes. Identity shortcuts are,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,397.52838134765625,0.01694915254237288,59,H3
sample_4.pdf,6,particularly important for not increasing the complexity of,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,409.4833679199219,0.0,59,H3
sample_4.pdf,6,the bottleneck architectures that are introduced below.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,421.4383544921875,0.0,55,H3
sample_4.pdf,6,Deeper Bottleneck Architectures.,9.962599754333496,NimbusRomNo9L-Medi,False,308.86199951171875,439.9894104003906,0.09375,32,H3
sample_4.pdf,6,Next we describe our,9.962599754333496,NimbusRomNo9L-Regu,False,451.7157897949219,440.0803527832031,0.05,20,H3
sample_4.pdf,6,deeper nets for ImageNet. Because of concerns on the train-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,452.03533935546875,0.05084745762711865,59,H3
sample_4.pdf,6,"ing time that we can afford, we modify the building block",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,463.9903259277344,0.0,57,H3
sample_4.pdf,6,as a,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,475.9463195800781,0.0,4,H3
sample_4.pdf,6,bottleneck,9.962599754333496,NimbusRomNo9L-ReguItal,False,324.80218505859375,475.7698669433594,0.0,10,H3
sample_4.pdf,6,design,9.962599754333496,NimbusRomNo9L-Regu,False,368.7640075683594,475.9463195800781,0.0,6,H3
sample_4.pdf,6,. For each residual function,9.962599754333496,NimbusRomNo9L-Regu,False,402.14697265625,475.9463195800781,0.03571428571428571,28,H3
sample_4.pdf,6,", we",9.962599754333496,NimbusRomNo9L-Regu,False,527.6069946289062,475.9463195800781,0.0,4,H3
sample_4.pdf,6,use a stack of 3 layers instead of 2 (Fig. 5). The three layers,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,487.90130615234375,0.031746031746031744,63,H3
sample_4.pdf,6,are 1,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,499.8562927246094,0.0,5,H3
sample_4.pdf,6,"1, 3",9.962599754333496,NimbusRomNo9L-Regu,False,335.9830017089844,499.8562927246094,0.0,4,H3
sample_4.pdf,6,"3, and 1",9.962599754333496,NimbusRomNo9L-Regu,False,358.4649963378906,499.8562927246094,0.0,8,H3
sample_4.pdf,6,"1 convolutions, where the 1",9.962599754333496,NimbusRomNo9L-Regu,False,397.5589904785156,499.8562927246094,0.0,27,H3
sample_4.pdf,6,1 layers,9.962599754333496,NimbusRomNo9L-Regu,False,514.1129760742188,499.8562927246094,0.0,8,H3
sample_4.pdf,6,are responsible for reducing and then increasing (restoring),9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,511.811279296875,0.0,60,H3
sample_4.pdf,6,"dimensions, leaving the 3",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,523.7662353515625,0.0,25,H3
sample_4.pdf,6,3 layer a bottleneck with smaller,9.962599754333496,NimbusRomNo9L-Regu,False,417.0079650878906,523.7662353515625,0.0,33,H3
sample_4.pdf,6,"input/output dimensions. Fig. 5 shows an example, where",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,535.7222900390625,0.01818181818181818,55,H3
sample_4.pdf,6,both designs have similar time complexity.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,547.67724609375,0.0,42,H3
sample_4.pdf,6,The parameter-free identity shortcuts are particularly im-,9.962599754333496,NimbusRomNo9L-Regu,False,320.81695556640625,560.3412475585938,0.017241379310344827,58,H3
sample_4.pdf,6,portant for the bottleneck architectures. If the identity short-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,572.2962646484375,0.015625,64,H3
sample_4.pdf,6,"cut in Fig. 5 (right) is replaced with projection, one can",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,584.2512817382812,0.017241379310344827,58,H3
sample_4.pdf,6,"show that the time complexity and model size are doubled,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,596.207275390625,0.0,57,H3
sample_4.pdf,6,as the shortcut is connected to the two high-dimensional,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,608.1622314453125,0.0,56,H3
sample_4.pdf,6,ends. So identity shortcuts lead to more efﬁcient models,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,620.1172485351562,0.017857142857142856,56,H3
sample_4.pdf,6,for the bottleneck designs.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,632.072265625,0.0,27,H3
sample_4.pdf,6,50-layer ResNet:,9.962599754333496,NimbusRomNo9L-Medi,False,320.81695556640625,644.6463012695312,0.125,16,H3
sample_4.pdf,6,We replace each 2-layer block in the,9.962599754333496,NimbusRomNo9L-Regu,False,392.35833740234375,644.7372436523438,0.027777777777777776,36,H3
sample_4.pdf,6,Deeper,7.970099925994873,NimbusRomNo9L-Regu,False,323.2080078125,667.0975952148438,0.16666666666666666,6,P
sample_4.pdf,6,non,7.970099925994873,NimbusRomNo9L-ReguItal,False,346.21771240234375,666.9564208984375,0.0,3,P
sample_4.pdf,6,-bottleneck ResNets (,7.970099925994873,NimbusRomNo9L-Regu,False,360.8070068359375,667.0975952148438,0.09523809523809523,21,P
sample_4.pdf,6,e.g,7.970099925994873,NimbusRomNo9L-ReguItal,False,431.1520080566406,666.9564208984375,0.0,3,P
sample_4.pdf,6,"., Fig. 5 left) also gain accuracy",7.970099925994873,NimbusRomNo9L-Regu,False,440.54901123046875,667.0975952148438,0.029411764705882353,34,P
sample_4.pdf,6,"from increased depth (as shown on CIFAR-10), but are not as economical",7.970099925994873,NimbusRomNo9L-Regu,False,308.86199951171875,676.5615844726562,0.07142857142857142,70,P
sample_4.pdf,6,as the bottleneck ResNets. So the usage of bottleneck designs is mainly due,7.970099925994873,NimbusRomNo9L-Regu,False,308.86199951171875,686.0265502929688,0.04,75,P
sample_4.pdf,6,to practical considerations. We further note that the degradation problem,7.970099925994873,NimbusRomNo9L-Regu,False,308.86199951171875,695.4905395507812,0.0136986301369863,73,P
sample_4.pdf,6,of plain nets is also witnessed for the bottleneck designs.,7.970099925994873,NimbusRomNo9L-Regu,False,308.86199951171875,704.95556640625,0.0,59,P
sample_4.pdf,7,"34-layer net with this 3-layer bottleneck block, resulting in",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,74.40748596191406,0.0,61,H3
sample_4.pdf,7,a 50-layer ResNet (Table 1). We use option B for increasing,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,86.36250305175781,0.0847457627118644,59,H3
sample_4.pdf,7,dimensions. This model has 3.8 billion FLOPs.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,98.31752014160156,0.1111111111111111,45,H3
sample_4.pdf,7,101-layer and 152-layer ResNets:,9.962599754333496,NimbusRomNo9L-Medi,False,62.06700134277344,110.64055633544922,0.0625,32,H3
sample_4.pdf,7,We construct 101-,9.962599754333496,NimbusRomNo9L-Regu,False,206.0365447998047,110.73152160644531,0.058823529411764705,17,H3
sample_4.pdf,7,layer and 152-layer ResNets by using more 3-layer blocks,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,122.68653869628906,0.03571428571428571,56,H3
sample_4.pdf,7,"(Table 1). Remarkably, although the depth is signiﬁcantly",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,134.6425323486328,0.03508771929824561,57,H3
sample_4.pdf,7,"increased, the 152-layer ResNet (11.3 billion FLOPs) still",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,146.59754943847656,0.10344827586206896,58,H3
sample_4.pdf,7,has,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,158.5525665283203,0.0,3,H3
sample_4.pdf,7,lower complexity,9.962599754333496,NimbusRomNo9L-ReguItal,False,63.39214324951172,158.3760986328125,0.0,16,H3
sample_4.pdf,7,than VGG-16/19 nets (15.3/19.6 bil-,9.962599754333496,NimbusRomNo9L-Regu,False,135.29879760742188,158.5525665283203,0.08571428571428572,35,H3
sample_4.pdf,7,lion FLOPs).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,170.50758361816406,0.3333333333333333,12,H3
sample_4.pdf,7,The 50/101/152-layer ResNets are more accurate than,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,182.9215850830078,0.058823529411764705,51,H3
sample_4.pdf,7,the 34-layer ones by considerable margins (Table 3 and 4).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,194.87660217285156,0.017241379310344827,58,H3
sample_4.pdf,7,We do not observe the degradation problem and thus en-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,206.8325958251953,0.018518518518518517,54,H3
sample_4.pdf,7,joy signiﬁcant accuracy gains from considerably increased,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,218.78761291503906,0.0,57,H3
sample_4.pdf,7,depth. The beneﬁts of depth are witnessed for all evaluation,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,230.7426300048828,0.016666666666666666,60,H3
sample_4.pdf,7,metrics (Table 3 and 4).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,242.69764709472656,0.041666666666666664,24,H3
sample_4.pdf,7,Comparisons with State-of-the-art Methods.,9.962599754333496,NimbusRomNo9L-Medi,False,50.11199951171875,260.99871826171875,0.07142857142857142,42,H3
sample_4.pdf,7,In Table 4,9.962599754333496,NimbusRomNo9L-Regu,False,240.08883666992188,261.08966064453125,0.2,10,H3
sample_4.pdf,7,we compare with the previous best single-model results.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,273.0446472167969,0.0,55,H3
sample_4.pdf,7,Our baseline 34-layer ResNets have achieved very compet-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,284.9996337890625,0.05357142857142857,56,H3
sample_4.pdf,7,itive accuracy. Our 152-layer ResNet has a single-model,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,296.9546203613281,0.05454545454545454,55,H3
sample_4.pdf,7,top-5 validation error of 4.49%. This single-model result,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,308.9106140136719,0.017543859649122806,57,H3
sample_4.pdf,7,outperforms all previous ensemble results (Table 5). We,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,320.8656005859375,0.03636363636363636,55,H3
sample_4.pdf,7,combine six models of different depth to form an ensemble,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,332.8205871582031,0.0,57,H3
sample_4.pdf,7,(only with two 152-layer ones at the time of submitting).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,344.77557373046875,0.0,57,H3
sample_4.pdf,7,This leads to,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,356.7305603027344,0.07692307692307693,13,H3
sample_4.pdf,7,3.57%,9.962599754333496,NimbusRomNo9L-Medi,False,103.23257446289062,356.6396179199219,0.0,5,H3
sample_4.pdf,7,top-5 error on the test set (Table 5).,9.962599754333496,NimbusRomNo9L-Regu,False,134.2161407470703,356.7305603027344,0.02631578947368421,38,H3
sample_4.pdf,7,This entry won the 1st place in ILSVRC 2015.,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.11199951171875,368.50909423828125,0.1590909090909091,44,H3
sample_4.pdf,7,4.2. CIFAR-10 and Analysis,10.958900451660156,NimbusRomNo9L-Medi,False,50.11199951171875,389.1329345703125,0.23076923076923078,26,H3
sample_4.pdf,7,We conducted more studies on the CIFAR-10 dataset,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,408.38055419921875,0.12244897959183673,49,H3
sample_4.pdf,7,"[20], which consists of 50k training images and 10k test-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,420.3355407714844,0.0,57,H3
sample_4.pdf,7,ing images in 10 classes. We present experiments trained,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,432.29052734375,0.017857142857142856,56,H3
sample_4.pdf,7,on the training set and evaluated on the test set. Our focus,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,444.2455139160156,0.016666666666666666,60,H3
sample_4.pdf,7,"is on the behaviors of extremely deep networks, but not on",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,456.20050048828125,0.0,58,H3
sample_4.pdf,7,"pushing the state-of-the-art results, so we intentionally use",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,468.156494140625,0.0,61,H3
sample_4.pdf,7,simple architectures as follows.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,480.1114807128906,0.0,32,H3
sample_4.pdf,7,The plain/residual architectures follow the form in Fig. 3,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,492.5254821777344,0.034482758620689655,58,H3
sample_4.pdf,7,(middle/right). The network inputs are 32,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,504.48046875,0.024390243902439025,41,H3
sample_4.pdf,7,"32 images, with",9.962599754333496,NimbusRomNo9L-Regu,False,223.23599243164062,504.48046875,0.0,15,H3
sample_4.pdf,7,the per-pixel mean subtracted. The ﬁrst layer is 3,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,516.4354248046875,0.02,50,H3
sample_4.pdf,7,3 convo-,9.962599754333496,NimbusRomNo9L-Regu,False,252.04998779296875,516.4354248046875,0.0,8,H3
sample_4.pdf,7,lutions. Then we use a stack of,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,528.3904418945312,0.03225806451612903,31,H3
sample_4.pdf,7,layers with 3,9.962599754333496,NimbusRomNo9L-Regu,False,189.24354553222656,528.3904418945312,0.0,13,H3
sample_4.pdf,7,3 convo-,9.962599754333496,NimbusRomNo9L-Regu,False,251.60398864746094,528.3904418945312,0.0,8,H3
sample_4.pdf,7,lutions on the feature maps of sizes,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,540.346435546875,0.0,36,H3
sample_4.pdf,7,"respectively,",9.962599754333496,NimbusRomNo9L-Regu,False,234.61326599121094,540.346435546875,0.0,13,H3
sample_4.pdf,7,with 2,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,552.3014526367188,0.0,6,H3
sample_4.pdf,7,layers for each feature map size. The numbers of,9.962599754333496,NimbusRomNo9L-Regu,False,81.90152740478516,552.3014526367188,0.020833333333333332,48,H3
sample_4.pdf,7,ﬁlters are,9.962599754333496,NimbusRomNo9L-Regu,False,50.11196517944336,564.2564697265625,0.0,10,H3
sample_4.pdf,7,respectively. The subsampling is per-,9.962599754333496,NimbusRomNo9L-Regu,False,137.62326049804688,564.2564697265625,0.02702702702702703,37,H3
sample_4.pdf,7,formed by convolutions with a stride of 2. The network ends,9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,576.21142578125,0.01694915254237288,59,H3
sample_4.pdf,7,"with a global average pooling, a 10-way fully-connected",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,588.1664428710938,0.0,55,H3
sample_4.pdf,7,"layer, and softmax. There are totally 6",9.962599754333496,NimbusRomNo9L-Regu,False,50.111961364746094,600.1214599609375,0.02564102564102564,39,H3
sample_4.pdf,7,+2 stacked weighted,9.962599754333496,NimbusRomNo9L-Regu,False,205.59596252441406,600.1214599609375,0.0,19,H3
sample_4.pdf,7,layers. The following table summarizes the architecture:,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,612.0774536132812,0.017857142857142856,56,H3
sample_4.pdf,7,output map size,8.966400146484375,NimbusRomNo9L-Regu,False,82.16999816894531,634.6289672851562,0.0,15,P
sample_4.pdf,7,# layers,8.966400146484375,NimbusRomNo9L-Regu,False,96.49400329589844,647.0819702148438,0.0,8,P
sample_4.pdf,7,1+2,8.966400146484375,NimbusRomNo9L-Regu,False,158.05099487304688,647.0819702148438,0.0,3,P
sample_4.pdf,7,# ﬁlters,8.966400146484375,NimbusRomNo9L-Regu,False,96.98699951171875,659.136962890625,0.0,8,P
sample_4.pdf,7,"When shortcut connections are used, they are connected",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,679.534423828125,0.018518518518518517,54,H3
sample_4.pdf,7,to the pairs of 3,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,691.4894409179688,0.0,17,H3
sample_4.pdf,7,3 layers (totally,9.962599754333496,NimbusRomNo9L-Regu,False,124.91500091552734,691.4894409179688,0.0,17,H3
sample_4.pdf,7,shortcuts). On this,9.962599754333496,NimbusRomNo9L-Regu,False,204.28855895996094,691.4894409179688,0.05263157894736842,19,H3
sample_4.pdf,7,dataset we use identity shortcuts in all cases (,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,703.4444580078125,0.0,48,H3
sample_4.pdf,7,i.e,9.962599754333496,NimbusRomNo9L-ReguItal,False,228.7680206298828,703.2680053710938,0.0,3,H3
sample_4.pdf,7,"., option A),",9.962599754333496,NimbusRomNo9L-Regu,False,238.4520263671875,703.4444580078125,0.07692307692307693,13,H3
sample_4.pdf,7,method,9.314743995666504,NimbusRomNo9L-Regu,False,377.65155029296875,74.71338653564453,0.0,6,H3
sample_4.pdf,7,error (%),9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,74.71338653564453,0.0,9,H3
sample_4.pdf,7,Maxout [10],9.314743995666504,NimbusRomNo9L-Regu,False,368.2115173339844,87.08191680908203,0.09090909090909091,11,H3
sample_4.pdf,7,9.38,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,87.08191680908203,0.0,4,H3
sample_4.pdf,7,NIN [25],9.314743995666504,NimbusRomNo9L-Regu,False,374.423828125,99.03601837158203,0.375,8,H3
sample_4.pdf,7,8.81,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,99.03601837158203,0.0,4,H3
sample_4.pdf,7,DSN [24],9.314743995666504,NimbusRomNo9L-Regu,False,373.38604736328125,110.98896026611328,0.375,8,H3
sample_4.pdf,7,8.22,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,110.98896026611328,0.0,4,H3
sample_4.pdf,7,# layers,9.314743995666504,NimbusRomNo9L-Regu,False,393.0025939941406,123.35755157470703,0.0,8,H3
sample_4.pdf,7,# params,9.314743995666504,NimbusRomNo9L-Regu,False,432.9952087402344,123.35755157470703,0.0,8,H3
sample_4.pdf,7,FitNet [35],9.314743995666504,NimbusRomNo9L-Regu,False,328.4744567871094,135.72503662109375,0.18181818181818182,11,H3
sample_4.pdf,7,2.5M,9.314743995666504,NimbusRomNo9L-Regu,False,439.9762878417969,135.72503662109375,0.25,4,H3
sample_4.pdf,7,8.39,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,135.72503662109375,0.0,4,H3
sample_4.pdf,7,"Highway [42, 43]",9.314743995666504,NimbusRomNo9L-Regu,False,316.3656311035156,147.67913818359375,0.0625,16,H3
sample_4.pdf,7,2.3M,9.314743995666504,NimbusRomNo9L-Regu,False,439.9762878417969,147.6790771484375,0.25,4,H3
sample_4.pdf,7,7.54,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,147.6790771484375,0.0,4,H3
sample_4.pdf,7,(7.72,8.27973747253418,NimbusRomNo9L-Regu,False,493.94683837890625,148.46401977539062,0.0,5,P
sample_4.pdf,7,0.16),8.27973747253418,NimbusRomNo9L-Regu,False,520.3646240234375,148.46401977539062,0.0,5,P
sample_4.pdf,7,"Highway [42, 43]",9.314743995666504,NimbusRomNo9L-Regu,False,316.3656311035156,159.63311767578125,0.0625,16,H3
sample_4.pdf,7,1.25M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,159.63311767578125,0.2,5,H3
sample_4.pdf,7,8.80,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,159.63311767578125,0.0,4,H3
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,172.00067138671875,0.3333333333333333,6,H3
sample_4.pdf,7,0.27M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,172.00067138671875,0.2,5,H3
sample_4.pdf,7,8.75,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,172.00067138671875,0.0,4,H3
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,183.9547119140625,0.3333333333333333,6,H3
sample_4.pdf,7,0.46M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,183.95465087890625,0.2,5,H3
sample_4.pdf,7,7.51,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,183.95465087890625,0.0,4,H3
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,195.90875244140625,0.3333333333333333,6,H3
sample_4.pdf,7,0.66M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,195.90875244140625,0.2,5,H3
sample_4.pdf,7,7.17,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,195.90875244140625,0.0,4,H3
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,207.86279296875,0.3333333333333333,6,H3
sample_4.pdf,7,0.85M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,207.86279296875,0.2,5,H3
sample_4.pdf,7,6.97,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,207.86279296875,0.0,4,H3
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,219.81689453125,0.3333333333333333,6,H3
sample_4.pdf,7,110,9.314743995666504,NimbusRomNo9L-Regu,False,400.6308898925781,219.81683349609375,0.0,3,H3
sample_4.pdf,7,1.7M,9.314743995666504,NimbusRomNo9L-Regu,False,439.9762878417969,219.81683349609375,0.25,4,H3
sample_4.pdf,7,6.43,9.314743995666504,NimbusRomNo9L-Medi,False,477.64605712890625,219.73179626464844,0.0,4,H3
sample_4.pdf,7,(6.61,8.27973747253418,NimbusRomNo9L-Regu,False,493.94683837890625,220.60177612304688,0.0,5,P
sample_4.pdf,7,0.16),8.27973747253418,NimbusRomNo9L-Regu,False,520.3646240234375,220.60177612304688,0.0,5,P
sample_4.pdf,7,ResNet,9.314743995666504,NimbusRomNo9L-Regu,False,335.59161376953125,231.7708740234375,0.3333333333333333,6,H3
sample_4.pdf,7,1202,9.314743995666504,NimbusRomNo9L-Regu,False,398.3028259277344,231.7708740234375,0.0,4,H3
sample_4.pdf,7,19.4M,9.314743995666504,NimbusRomNo9L-Regu,False,437.6482238769531,231.7708740234375,0.2,5,H3
sample_4.pdf,7,7.93,9.314743995666504,NimbusRomNo9L-Regu,False,477.64605712890625,231.7708740234375,0.0,4,H3
sample_4.pdf,7,Table 6. Classiﬁcation error on the,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,253.17098999023438,0.05714285714285714,35,P
sample_4.pdf,7,CIFAR-10,8.966400146484375,NimbusRomNo9L-Medi,False,434.382568359375,253.08912658691406,0.625,8,P
sample_4.pdf,7,test set. All meth-,8.966400146484375,NimbusRomNo9L-Regu,False,476.50390625,253.17098999023438,0.05263157894736842,19,P
sample_4.pdf,7,"ods are with data augmentation. For ResNet-110, we run it 5 times",8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,264.1299743652344,0.046153846153846156,65,P
sample_4.pdf,7,and show “best (mean,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,275.0889587402344,0.0,20,P
sample_4.pdf,7,std)” as in [43].,8.966400146484375,NimbusRomNo9L-Regu,False,395.2380065917969,275.0889587402344,0.0,17,P
sample_4.pdf,7,"so our residual models have exactly the same depth, width,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,305.5094299316406,0.0,58,H3
sample_4.pdf,7,and number of parameters as the plain counterparts.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,317.46441650390625,0.0,51,H3
sample_4.pdf,7,"We use a weight decay of 0.0001 and momentum of 0.9,",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,329.4194030761719,0.019230769230769232,52,H3
sample_4.pdf,7,and adopt the weight initialization in [13] and BN [16] but,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,341.3743896484375,0.03389830508474576,59,H3
sample_4.pdf,7,with no dropout. These models are trained with a mini-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,353.3293762207031,0.018518518518518517,54,H3
sample_4.pdf,7,batch size of 128 on two GPUs. We start with a learning,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,365.28436279296875,0.07272727272727272,55,H3
sample_4.pdf,7,"rate of 0.1, divide it by 10 at 32k and 48k iterations, and",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,377.2403564453125,0.0,59,H3
sample_4.pdf,7,"terminate training at 64k iterations, which is determined on",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,389.1953430175781,0.0,60,H3
sample_4.pdf,7,a 45k/5k train/val split. We follow the simple data augmen-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,401.15032958984375,0.01694915254237288,59,H3
sample_4.pdf,7,"tation in [24] for training: 4 pixels are padded on each side,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,413.1053161621094,0.0,62,H3
sample_4.pdf,7,and a 32,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,425.060302734375,0.0,8,H3
sample_4.pdf,7,32 crop is randomly sampled from the padded,9.962599754333496,NimbusRomNo9L-Regu,False,352.875,425.060302734375,0.0,43,H3
sample_4.pdf,7,"image or its horizontal ﬂip. For testing, we only evaluate",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,437.01629638671875,0.017241379310344827,58,H3
sample_4.pdf,7,the single view of the original 32,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,448.9712829589844,0.0,34,H3
sample_4.pdf,7,32 image.,9.962599754333496,NimbusRomNo9L-Regu,False,448.07598876953125,448.9712829589844,0.0,9,H3
sample_4.pdf,7,We compare,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,460.92626953125,0.1,10,H3
sample_4.pdf,7,", leading to 20, 32, 44, and",9.962599754333496,NimbusRomNo9L-Regu,False,437.04095458984375,460.92626953125,0.0,28,H3
sample_4.pdf,7,56-layer networks. Fig. 6 (left) shows the behaviors of the,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,472.8812561035156,0.01694915254237288,59,H3
sample_4.pdf,7,"plain nets. The deep plain nets suffer from increased depth,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,484.83624267578125,0.016666666666666666,60,H3
sample_4.pdf,7,and exhibit higher training error when going deeper. This,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,496.7912292480469,0.017543859649122806,57,H3
sample_4.pdf,7,"phenomenon is similar to that on ImageNet (Fig. 4, left) and",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,508.7471923828125,0.05,60,H3
sample_4.pdf,7,"on MNIST (see [42]), suggesting that such an optimization",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,520.7022094726562,0.08771929824561403,57,H3
sample_4.pdf,7,difﬁculty is a fundamental problem.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,532.6572265625,0.0,35,H3
sample_4.pdf,7,Fig. 6 (middle) shows the behaviors of ResNets. Also,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169250488281,544.6121826171875,0.07692307692307693,52,H3
sample_4.pdf,7,"similar to the ImageNet cases (Fig. 4, right), our ResNets",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,556.5671997070312,0.08620689655172414,58,H3
sample_4.pdf,7,manage to overcome the optimization difﬁculty and demon-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,568.522216796875,0.0,56,H3
sample_4.pdf,7,strate accuracy gains when the depth increases.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,580.4782104492188,0.0,47,H3
sample_4.pdf,7,We further explore,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169250488281,592.4332275390625,0.05555555555555555,18,H3
sample_4.pdf,7,= 18,9.962599754333496,CMR10,False,409.1344909667969,592.516845703125,0.0,4,H3
sample_4.pdf,7,that leads to a 110-layer,9.962599754333496,NimbusRomNo9L-Regu,False,438.5624084472656,592.4332275390625,0.0,25,H3
sample_4.pdf,7,"ResNet. In this case, we ﬁnd that the initial learning rate",9.962599754333496,NimbusRomNo9L-Regu,False,308.86187744140625,604.38818359375,0.05084745762711865,59,H3
sample_4.pdf,7,of 0.1 is slightly too large to start converging,9.962599754333496,NimbusRomNo9L-Regu,False,308.86187744140625,616.3432006835938,0.0,48,H3
sample_4.pdf,7,. So we use,9.962599754333496,NimbusRomNo9L-Regu,False,496.21185302734375,616.3432006835938,0.09090909090909091,11,H3
sample_4.pdf,7,0.01 to warm up the training until the training error is below,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,628.2982177734375,0.0,62,H3
sample_4.pdf,7,"80% (about 400 iterations), and then go back to 0.1 and con-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,640.2532348632812,0.0,60,H3
sample_4.pdf,7,tinue training. The rest of the learning schedule is as done,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,652.209228515625,0.016666666666666666,60,H3
sample_4.pdf,7,"previously. This 110-layer network converges well (Fig. 6,",9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,664.1641845703125,0.034482758620689655,58,H3
sample_4.pdf,7,middle). It has,9.962599754333496,NimbusRomNo9L-Regu,False,308.8618469238281,676.1192016601562,0.06666666666666667,15,H3
sample_4.pdf,7,fewer,9.962599754333496,NimbusRomNo9L-ReguItal,False,370.2513427734375,675.9427490234375,0.0,5,H3
sample_4.pdf,7,parameters than other deep and thin,9.962599754333496,NimbusRomNo9L-Regu,False,395.46929931640625,676.1192016601562,0.0,35,H3
sample_4.pdf,7,"With an initial learning rate of 0.1, it starts converging (",7.970099925994873,NimbusRomNo9L-Regu,False,323.2080078125,695.4905395507812,0.016666666666666666,60,P
sample_4.pdf,7,90% error),7.970099925994873,NimbusRomNo9L-Regu,False,510.0980224609375,695.4905395507812,0.0,10,P
sample_4.pdf,7,"after several epochs, but still reaches similar accuracy.",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,704.95556640625,0.0,57,P
sample_4.pdf,8,iter. (1e4),5.03141450881958,Times-Roman,False,168.06228637695312,167.45303344726562,0.0,11,P
sample_4.pdf,8,error (%),5.03141450881958,Times-Roman,False,100.28567504882812,109.00904083251953,0.0,9,P
sample_4.pdf,8,plain-20,4.360572338104248,Times-Roman,False,121.34341430664062,140.07138061523438,0.0,8,P
sample_4.pdf,8,plain-32,4.360572338104248,Times-Roman,False,121.34341430664062,145.4664306640625,0.0,8,P
sample_4.pdf,8,plain-44,4.360572338104248,Times-Roman,False,121.34341430664062,150.86148071289062,0.0,8,P
sample_4.pdf,8,plain-56,4.360572338104248,Times-Roman,False,121.34341430664062,156.2565460205078,0.0,8,P
sample_4.pdf,8,iter. (1e4),5.037631988525391,Times-Roman,False,331.6357727050781,167.67787170410156,0.0,11,P
sample_4.pdf,8,error (%),5.037631988525391,Times-Roman,False,263.85443115234375,109.23514556884766,0.0,9,P
sample_4.pdf,8,ResNet-20,4.365976810455322,Times-Roman,False,385.5863037109375,76.81884002685547,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-32,4.365976810455322,Times-Roman,False,385.5863037109375,82.21390533447266,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-44,4.365976810455322,Times-Roman,False,385.5863037109375,87.60895538330078,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-56,4.365976810455322,Times-Roman,False,385.5863037109375,93.00401306152344,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-110,4.365976810455322,Times-Roman,False,385.5863037109375,98.3990707397461,0.2,10,P
sample_4.pdf,8,56-layer,4.81996488571167,TT4Co00,False,223.16073608398438,98.3330078125,0.0,8,P
sample_4.pdf,8,20-layer,4.81996488571167,TT4Co00,False,223.16073608398438,120.37224578857422,0.0,8,P
sample_4.pdf,8,110-layer,4.81996488571167,TT4Co00,False,384.4383544921875,135.4093017578125,0.0,9,P
sample_4.pdf,8,20-layer,4.81996488571167,TT4Co00,False,385.7008972167969,118.19117736816406,0.0,8,P
sample_4.pdf,8,iter. (1e4),5.035862922668457,Times-Roman,False,451.1304931640625,167.67922973632812,0.0,11,P
sample_4.pdf,8,error (%),5.035862922668457,Times-Roman,False,417.4426574707031,109.23709106445312,0.0,9,P
sample_4.pdf,8,residual-110,4.364446640014648,Times-Roman,False,468.3487548828125,76.82000732421875,0.0,12,P
sample_4.pdf,8,residual-1202,4.364446640014648,Times-Roman,False,468.3487548828125,82.44464874267578,0.0,13,P
sample_4.pdf,8,Figure 6. Training on,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,172.57400512695312,0.09523809523809523,21,P
sample_4.pdf,8,CIFAR-10,8.966400146484375,NimbusRomNo9L-Medi,False,127.1781997680664,172.4921417236328,0.625,8,P
sample_4.pdf,8,". Dashed lines denote training error, and bold lines denote testing error.",8.966400146484375,NimbusRomNo9L-Regu,False,169.1719970703125,172.57400512695312,0.013513513513513514,74,P
sample_4.pdf,8,Left,8.966400146484375,NimbusRomNo9L-Medi,False,427.31463623046875,172.4921417236328,0.25,4,P
sample_4.pdf,8,: plain networks. The error,8.966400146484375,NimbusRomNo9L-Regu,False,446.69500732421875,172.57400512695312,0.037037037037037035,27,P
sample_4.pdf,8,of plain-110 is higher than 60% and not displayed.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,183.53298950195312,0.0,50,P
sample_4.pdf,8,Middle,8.966400146484375,NimbusRomNo9L-Medi,False,231.6636962890625,183.4511260986328,0.16666666666666666,6,P
sample_4.pdf,8,: ResNets.,8.966400146484375,NimbusRomNo9L-Regu,False,261.84197998046875,183.53298950195312,0.2,10,P
sample_4.pdf,8,Right,8.966400146484375,NimbusRomNo9L-Medi,False,299.24078369140625,183.4511260986328,0.2,5,P
sample_4.pdf,8,: ResNets with 110 and 1202 layers.,8.966400146484375,NimbusRomNo9L-Regu,False,323.44000244140625,183.53298950195312,0.05714285714285714,35,P
sample_4.pdf,8,100,4.646377086639404,Times-Roman,False,251.96926879882812,317.7090148925781,0.0,3,P
sample_4.pdf,8,layer index (sorted by magnitude),6.040326118469238,Times-Roman,False,131.64498901367188,322.5600280761719,0.0,33,P
sample_4.pdf,8,std,6.040326118469238,Times-Roman,False,61.85755157470703,290.7468566894531,0.0,3,P
sample_4.pdf,8,plain-20,4.646377086639404,Times-Roman,False,238.40016174316406,274.04437255859375,0.0,8,P
sample_4.pdf,8,plain-56,4.646377086639404,Times-Roman,False,238.40016174316406,279.7851257324219,0.0,8,P
sample_4.pdf,8,ResNet-20,4.646377086639404,Times-Roman,False,238.40016174316406,285.4679260253906,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-56,4.646377086639404,Times-Roman,False,238.40016174316406,291.09271240234375,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-110,4.646377086639404,Times-Roman,False,238.40016174316406,296.7755126953125,0.2,10,P
sample_4.pdf,8,100,4.646377086639404,Times-Roman,False,251.96926879882812,259.02557373046875,0.0,3,P
sample_4.pdf,8,layer index (original),6.040326118469238,Times-Roman,False,146.89572143554688,263.8765869140625,0.0,22,P
sample_4.pdf,8,std,6.040326118469238,Times-Roman,False,61.85755157470703,232.0634307861328,0.0,3,P
sample_4.pdf,8,plain-20,4.646377086639404,Times-Roman,False,238.40016174316406,215.3609161376953,0.0,8,P
sample_4.pdf,8,plain-56,4.646377086639404,Times-Roman,False,238.40016174316406,221.1016845703125,0.0,8,P
sample_4.pdf,8,ResNet-20,4.646377086639404,Times-Roman,False,238.40016174316406,226.7844696044922,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-56,4.646377086639404,Times-Roman,False,238.40016174316406,232.40927124023438,0.2222222222222222,9,P
sample_4.pdf,8,ResNet-110,4.646377086639404,Times-Roman,False,238.40016174316406,238.092041015625,0.2,10,P
sample_4.pdf,8,Figure 7. Standard deviations (std) of layer responses on CIFAR-,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,328.3189697265625,0.109375,64,P
sample_4.pdf,8,10. The responses are the outputs of each 3,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,339.2769775390625,0.023255813953488372,43,P
sample_4.pdf,8,"3 layer, after BN and",8.966400146484375,NimbusRomNo9L-Regu,False,211.67800903320312,339.2769775390625,0.09523809523809523,21,P
sample_4.pdf,8,before nonlinearity.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,350.2359924316406,0.0,20,P
sample_4.pdf,8,Top,8.966400146484375,NimbusRomNo9L-Medi,False,121.2603988647461,350.15411376953125,0.3333333333333333,3,P
sample_4.pdf,8,: the layers are shown in their original,8.966400146484375,NimbusRomNo9L-Regu,False,141.7110137939453,350.2359924316406,0.0,40,P
sample_4.pdf,8,order.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,361.1949768066406,0.0,6,P
sample_4.pdf,8,Bottom,8.966400146484375,NimbusRomNo9L-Medi,False,70.7795639038086,361.11309814453125,0.16666666666666666,6,P
sample_4.pdf,8,: the responses are ranked in descending order.,8.966400146484375,NimbusRomNo9L-Regu,False,101.94601440429688,361.1949768066406,0.0,47,P
sample_4.pdf,8,"networks such as FitNet [35] and Highway [42] (Table 6),",9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,392.40545654296875,0.07142857142857142,56,H3
sample_4.pdf,8,"yet is among the state-of-the-art results (6.43%, Table 6).",9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,404.3604431152344,0.01694915254237288,59,H3
sample_4.pdf,8,Analysis of Layer Responses.,9.962599754333496,NimbusRomNo9L-Medi,False,50.11201477050781,422.2705078125,0.10714285714285714,28,H3
sample_4.pdf,8,Fig. 7 shows the standard,9.962599754333496,NimbusRomNo9L-Regu,False,175.99942016601562,422.3614501953125,0.04,25,H3
sample_4.pdf,8,deviations (std) of the layer responses. The responses are,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,434.3164367675781,0.017241379310344827,58,H3
sample_4.pdf,8,the outputs of each 3,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,446.27142333984375,0.0,21,H3
sample_4.pdf,8,"3 layer, after BN and before other",9.962599754333496,NimbusRomNo9L-Regu,False,145.2270050048828,446.27142333984375,0.058823529411764705,34,H3
sample_4.pdf,8,nonlinearity (ReLU/addition).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,458.2274169921875,0.10344827586206896,29,H3
sample_4.pdf,8,"For ResNets, this analy-",9.962599754333496,NimbusRomNo9L-Regu,False,182.38543701171875,458.2274169921875,0.125,24,H3
sample_4.pdf,8,sis reveals the response strength of the residual functions.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,470.1824035644531,0.0,60,H3
sample_4.pdf,8,Fig. 7 shows that ResNets have generally smaller responses,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,482.13739013671875,0.05172413793103448,58,H3
sample_4.pdf,8,than their plain counterparts. These results support our ba-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,494.0923767089844,0.016666666666666666,60,H3
sample_4.pdf,8,sic motivation (Sec.3.1) that the residual functions might,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,506.04736328125,0.017241379310344827,58,H3
sample_4.pdf,8,be generally closer to zero than the non-residual functions.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,518.0023193359375,0.0,60,H3
sample_4.pdf,8,We also notice that the deeper ResNet has smaller magni-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,529.9583740234375,0.05357142857142857,56,H3
sample_4.pdf,8,"tudes of responses, as evidenced by the comparisons among",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,541.913330078125,0.0,57,H3
sample_4.pdf,8,"ResNet-20, 56, and 110 in Fig. 7. When there are more",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,553.8683471679688,0.07547169811320754,53,H3
sample_4.pdf,8,"layers, an individual layer of ResNets tends to modify the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,565.8233642578125,0.034482758620689655,58,H3
sample_4.pdf,8,signal less.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,577.7783203125,0.0,12,H3
sample_4.pdf,8,Exploring Over 1000 layers.,9.962599754333496,NimbusRomNo9L-Medi,False,50.11200714111328,595.6884155273438,0.07407407407407407,27,H3
sample_4.pdf,8,We explore an aggressively,9.962599754333496,NimbusRomNo9L-Regu,False,171.05795288085938,595.7793579101562,0.038461538461538464,26,H3
sample_4.pdf,8,deep model of over 1000 layers.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,607.734375,0.0,31,H3
sample_4.pdf,8,We set,9.962599754333496,NimbusRomNo9L-Regu,False,194.5298309326172,607.734375,0.16666666666666666,6,H3
sample_4.pdf,8,= 200,9.962599754333496,CMR10,False,232.9055633544922,607.8179931640625,0.0,5,H3
sample_4.pdf,8,that,9.962599754333496,NimbusRomNo9L-Regu,False,267.27587890625,607.734375,0.0,4,H3
sample_4.pdf,8,"leads to a 1202-layer network, which is trained as described",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,619.6903686523438,0.0,60,H3
sample_4.pdf,8,above. Our method shows,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,631.6453857421875,0.043478260869565216,23,H3
sample_4.pdf,8,no optimization difﬁculty,9.962599754333496,NimbusRomNo9L-ReguItal,False,160.06919860839844,631.4689331054688,0.0,25,H3
sample_4.pdf,8,", and",9.962599754333496,NimbusRomNo9L-Regu,False,265.52899169921875,631.6453857421875,0.0,5,H3
sample_4.pdf,8,this,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,643.600341796875,0.0,4,H3
sample_4.pdf,8,-layer network is able to achieve,9.962599754333496,NimbusRomNo9L-Regu,False,83.69998168945312,643.600341796875,0.0,33,H3
sample_4.pdf,8,training error,9.962599754333496,NimbusRomNo9L-ReguItal,False,224.30213928222656,643.4238891601562,0.0,14,H3
sample_4.pdf,8,"0.1% (Fig. 6, right).",9.962599754333496,NimbusRomNo9L-Regu,False,57.860984802246094,655.5553588867188,0.047619047619047616,21,H3
sample_4.pdf,8,Its test error is still fairly good,9.962599754333496,NimbusRomNo9L-Regu,False,153.0635528564453,655.5553588867188,0.02857142857142857,35,H3
sample_4.pdf,8,"(7.93%, Table 6).",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,667.5103759765625,0.058823529411764705,17,H3
sample_4.pdf,8,But there are still open problems on such aggressively,9.962599754333496,NimbusRomNo9L-Regu,False,62.066986083984375,679.5343627929688,0.018518518518518517,54,H3
sample_4.pdf,8,deep models. The testing result of this 1202-layer network,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,691.4893798828125,0.017241379310344827,58,H3
sample_4.pdf,8,"is worse than that of our 110-layer network, although both",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,703.4443359375,0.0,58,H3
sample_4.pdf,8,training data,8.966400146484375,NimbusRomNo9L-Regu,False,343.6390075683594,213.85299682617188,0.0,13,P
sample_4.pdf,8,07+12,8.966400146484375,NimbusRomNo9L-Regu,False,415.7919921875,213.85299682617188,0.0,5,P
sample_4.pdf,8,07++12,8.966400146484375,NimbusRomNo9L-Regu,False,474.07501220703125,213.85299682617188,0.0,6,P
sample_4.pdf,8,test data,8.966400146484375,NimbusRomNo9L-Regu,False,351.3590087890625,225.75796508789062,0.0,9,P
sample_4.pdf,8,VOC 07 test,8.966400146484375,NimbusRomNo9L-Regu,False,405.0509948730469,225.75796508789062,0.2727272727272727,11,P
sample_4.pdf,8,VOC 12 test,8.966400146484375,NimbusRomNo9L-Regu,False,465.86199951171875,225.75796508789062,0.2727272727272727,11,P
sample_4.pdf,8,VGG-16,8.966400146484375,NimbusRomNo9L-Regu,False,350.5559997558594,237.66299438476562,0.5,6,P
sample_4.pdf,8,73.2,8.966400146484375,NimbusRomNo9L-Regu,False,419.4419860839844,237.66299438476562,0.0,4,P
sample_4.pdf,8,70.4,8.966400146484375,NimbusRomNo9L-Regu,False,480.25299072265625,237.66299438476562,0.0,4,P
sample_4.pdf,8,ResNet-101,8.966400146484375,NimbusRomNo9L-Regu,False,344.75897216796875,249.17001342773438,0.2,10,P
sample_4.pdf,8,76.4,8.966400146484375,NimbusRomNo9L-Medi,False,419.4419860839844,249.0880889892578,0.0,4,P
sample_4.pdf,8,73.8,8.966400146484375,NimbusRomNo9L-Medi,False,480.25299072265625,249.0880889892578,0.0,4,P
sample_4.pdf,8,Table 7. Object detection mAP (%) on the PASCAL VOC,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,265.1130065917969,0.2549019607843137,51,P
sample_4.pdf,8,2007/2012 test sets using,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,276.0719909667969,0.0,25,P
sample_4.pdf,8,baseline,8.966400146484375,NimbusRomNo9L-Medi,False,402.76702880859375,275.9901123046875,0.0,8,P
sample_4.pdf,8,Faster R-CNN. See also Ta-,8.966400146484375,NimbusRomNo9L-Regu,False,437.0581970214844,276.0719909667969,0.2692307692307692,26,P
sample_4.pdf,8,ble 10 and 11 for better results.,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,287.0309753417969,0.0,33,P
sample_4.pdf,8,metric,8.966400146484375,NimbusRomNo9L-Regu,False,354.197998046875,301.5879821777344,0.0,6,P
sample_4.pdf,8,mAP@.5,8.966400146484375,NimbusRomNo9L-Regu,False,404.15399169921875,301.5879821777344,0.3333333333333333,6,P
sample_4.pdf,8,"mAP@[.5, .95]",8.966400146484375,NimbusRomNo9L-Regu,False,454.6570129394531,301.5879821777344,0.15384615384615385,13,P
sample_4.pdf,8,VGG-16,8.966400146484375,NimbusRomNo9L-Regu,False,350.0329895019531,313.49298095703125,0.5,6,P
sample_4.pdf,8,41.5,8.966400146484375,NimbusRomNo9L-Regu,False,413.0169982910156,313.49298095703125,0.0,4,P
sample_4.pdf,8,21.2,8.966400146484375,NimbusRomNo9L-Regu,False,474.35198974609375,313.49298095703125,0.0,4,P
sample_4.pdf,8,ResNet-101,8.966400146484375,NimbusRomNo9L-Regu,False,344.2359924316406,324.9999694824219,0.2,10,P
sample_4.pdf,8,48.4,8.966400146484375,NimbusRomNo9L-Medi,False,413.0169982910156,324.9180908203125,0.0,4,P
sample_4.pdf,8,27.2,8.966400146484375,NimbusRomNo9L-Medi,False,474.35198974609375,324.9180908203125,0.0,4,P
sample_4.pdf,8,Table 8. Object detection mAP (%) on the COCO validation set,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,340.9429931640625,0.13333333333333333,60,P
sample_4.pdf,8,using,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,351.9020080566406,0.0,5,P
sample_4.pdf,8,baseline,8.966400146484375,NimbusRomNo9L-Medi,False,328.29217529296875,351.82012939453125,0.0,8,P
sample_4.pdf,8,Faster R-CNN. See also Table 9 for better results.,8.966400146484375,NimbusRomNo9L-Regu,False,361.4222106933594,351.9020080566406,0.14,50,P
sample_4.pdf,8,have similar training error. We argue that this is because of,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,378.18548583984375,0.01639344262295082,61,H3
sample_4.pdf,8,overﬁtting. The 1202-layer network may be unnecessarily,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,390.1404724121094,0.01818181818181818,55,H3
sample_4.pdf,8,large (19.4M) for this small dataset. Strong regularization,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,402.095458984375,0.03389830508474576,59,H3
sample_4.pdf,8,such as maxout [10] or dropout [14] is applied to obtain the,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,414.0504455566406,0.0,60,H3
sample_4.pdf,8,"best results ([10, 25, 24, 35]) on this dataset. In this paper,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,426.00543212890625,0.015873015873015872,63,H3
sample_4.pdf,8,we use no maxout/dropout and just simply impose regular-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,437.9604187011719,0.0,56,H3
sample_4.pdf,8,"ization via deep and thin architectures by design, without",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,449.9164123535156,0.0,58,H3
sample_4.pdf,8,distracting from the focus on the difﬁculties of optimiza-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,461.87139892578125,0.0,58,H3
sample_4.pdf,8,tion. But combining with stronger regularization may im-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,473.8263854980469,0.017857142857142856,56,H3
sample_4.pdf,8,"prove results, which we will study in the future.",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,485.7813720703125,0.0,49,H3
sample_4.pdf,8,4.3. Object Detection on PASCAL and MS COCO,10.958900451660156,NimbusRomNo9L-Medi,False,308.86199951171875,505.1377868652344,0.32558139534883723,43,H3
sample_4.pdf,8,Our method has good generalization performance on,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,524.0213623046875,0.02040816326530612,49,H3
sample_4.pdf,8,other recognition tasks. Table 7 and 8 show the object de-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,535.9763793945312,0.017241379310344827,58,H3
sample_4.pdf,8,tection baseline results on PASCAL VOC 2007 and 2012,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,547.931396484375,0.17307692307692307,52,H3
sample_4.pdf,8,[5] and COCO [26]. We adopt,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,559.8873291015625,0.18518518518518517,27,H3
sample_4.pdf,8,Faster R-CNN,9.962599754333496,NimbusRomNo9L-ReguItal,False,427.8851013183594,559.7108764648438,0.4166666666666667,12,H3
sample_4.pdf,8,[32] as the de-,9.962599754333496,NimbusRomNo9L-Regu,False,486.5733337402344,559.8873291015625,0.0,15,H3
sample_4.pdf,8,tection method. Here we are interested in the improvements,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,571.8423461914062,0.017241379310344827,58,H3
sample_4.pdf,8,of replacing VGG-16 [41] with ResNet-101. The detection,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,583.79736328125,0.10909090909090909,55,H3
sample_4.pdf,8,implementation (see appendix) of using both models is the,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,595.7523803710938,0.0,57,H3
sample_4.pdf,8,"same, so the gains can only be attributed to better networks.",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,607.7073974609375,0.0,61,H3
sample_4.pdf,8,"Most remarkably, on the challenging COCO dataset we ob-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,619.662353515625,0.09090909090909091,55,H3
sample_4.pdf,8,"tain a 6.0% increase in COCO’s standard metric (mAP@[.5,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,631.6183471679688,0.10714285714285714,56,H3
sample_4.pdf,8,".95]), which is a 28% relative improvement. This gain is",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,643.5733642578125,0.017857142857142856,56,H3
sample_4.pdf,8,solely due to the learned representations.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,655.5283813476562,0.0,42,H3
sample_4.pdf,8,"Based on deep residual nets, we won the 1st places in",9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,667.579345703125,0.018867924528301886,53,H3
sample_4.pdf,8,several tracks in ILSVRC & COCO 2015 competitions: Im-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,679.5343627929688,0.2037037037037037,54,H3
sample_4.pdf,8,"ageNet detection, ImageNet localization, COCO detection,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,691.4893798828125,0.125,56,H3
sample_4.pdf,8,and COCO segmentation. The details are in the appendix.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,703.4443969726562,0.09090909090909091,55,H3
sample_4.pdf,9,References,11.9552001953125,NimbusRomNo9L-Medi,False,50.11199951171875,72.78716278076172,0.1,10,H3
sample_4.pdf,9,"[1] Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependen-",7.970099925994873,NimbusRomNo9L-Regu,False,54.09700012207031,92.35655975341797,0.09859154929577464,71,P
sample_4.pdf,9,cies with gradient descent is difﬁcult.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,101.82158660888672,0.0,39,P
sample_4.pdf,9,IEEE Transactions on Neural,7.970099925994873,NimbusRomNo9L-ReguItal,False,188.1297149658203,101.680419921875,0.2222222222222222,27,P
sample_4.pdf,9,Networks,7.970099925994873,NimbusRomNo9L-ReguItal,False,68.37100982666016,111.1444091796875,0.125,8,P
sample_4.pdf,9,", 5(2):157–166, 1994.",7.970099925994873,NimbusRomNo9L-Regu,False,98.48200988769531,111.28557586669922,0.0,21,P
sample_4.pdf,9,[2] C. M. Bishop.,7.970099925994873,NimbusRomNo9L-Regu,False,54.09701156616211,121.74254608154297,0.17647058823529413,17,P
sample_4.pdf,9,Neural networks for pattern recognition,7.970099925994873,NimbusRomNo9L-ReguItal,False,122.406005859375,121.60137939453125,0.02564102564102564,39,P
sample_4.pdf,9,Oxford,7.970099925994873,NimbusRomNo9L-Regu,False,263.3454284667969,121.74254608154297,0.16666666666666666,6,P
sample_4.pdf,9,"university press, 1995.",7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,131.20654296875,0.0,23,P
sample_4.pdf,9,"[3] W. L. Briggs, S. F. McCormick, et al.",7.970099925994873,NimbusRomNo9L-Regu,False,54.09700012207031,141.66351318359375,0.17073170731707318,41,P
sample_4.pdf,9,A Multigrid Tutorial,7.970099925994873,NimbusRomNo9L-ReguItal,False,191.07110595703125,141.5223388671875,0.15,20,P
sample_4.pdf,9,". Siam,",7.970099925994873,NimbusRomNo9L-Regu,False,261.57000732421875,141.66351318359375,0.14285714285714285,7,P
sample_4.pdf,9,2000.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,151.1285400390625,0.0,5,P
sample_4.pdf,9,"[4] K. Chatﬁeld, V. Lempitsky, A. Vedaldi, and A. Zisserman. The devil",7.970099925994873,NimbusRomNo9L-Regu,False,54.09700012207031,161.58453369140625,0.12857142857142856,70,P
sample_4.pdf,9,is in the details: an evaluation of recent feature encoding methods.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,171.049560546875,0.0,68,P
sample_4.pdf,9,BMVC,7.970099925994873,NimbusRomNo9L-ReguItal,False,75.01009368896484,180.37237548828125,1.0,4,P
sample_4.pdf,9,", 2011.",7.970099925994873,NimbusRomNo9L-Regu,False,98.69800567626953,180.5135498046875,0.0,7,P
sample_4.pdf,9,"[5] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zis-",7.970099925994873,NimbusRomNo9L-Regu,False,54.09700393676758,190.97052001953125,0.17647058823529413,68,P
sample_4.pdf,9,serman. The Pascal Visual Object Classes (VOC) Challenge.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,200.435546875,0.15789473684210525,57,P
sample_4.pdf,9,IJCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,264.4354248046875,200.29437255859375,1.0,4,P
sample_4.pdf,9,"pages 303–338, 2010.",7.970099925994873,NimbusRomNo9L-Regu,False,68.37098693847656,209.8995361328125,0.0,20,P
sample_4.pdf,9,[6] S. Gidaris and N. Komodakis. Object detection via a multi-region &,7.970099925994873,NimbusRomNo9L-Regu,False,54.09698486328125,220.35650634765625,0.07142857142857142,70,P
sample_4.pdf,9,semantic segmentation-aware cnn model. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37098693847656,229.821533203125,0.024390243902439025,41,P
sample_4.pdf,9,ICCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,209.4815673828125,229.68035888671875,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,229.62899780273438,229.821533203125,0.0,7,P
sample_4.pdf,9,[7] R. Girshick. Fast R-CNN. In,7.970099925994873,NimbusRomNo9L-Regu,False,54.09700012207031,240.27752685546875,0.25806451612903225,31,P
sample_4.pdf,9,ICCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,161.43829345703125,240.1363525390625,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,181.58599853515625,240.27752685546875,0.0,7,P
sample_4.pdf,9,"[8] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hier-",7.970099925994873,NimbusRomNo9L-Regu,False,54.09700012207031,250.7344970703125,0.1232876712328767,73,P
sample_4.pdf,9,archies for accurate object detection and semantic segmentation. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,260.19952392578125,0.014925373134328358,67,P
sample_4.pdf,9,CVPR,7.970099925994873,NimbusRomNo9L-ReguItal,False,68.37100219726562,269.5223388671875,1.0,4,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,88.29700469970703,269.66351318359375,0.0,7,P
sample_4.pdf,9,[9] X. Glorot and Y. Bengio. Understanding the difﬁculty of training,7.970099925994873,NimbusRomNo9L-Regu,False,54.09700393676758,280.1205139160156,0.07352941176470588,68,P
sample_4.pdf,9,deep feedforward neural networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,289.5845031738281,0.027777777777777776,36,P
sample_4.pdf,9,AISTATS,7.970099925994873,NimbusRomNo9L-ReguItal,False,188.8151092529297,289.4433288574219,1.0,7,P
sample_4.pdf,9,", 2010.",7.970099925994873,NimbusRomNo9L-Regu,False,219.3400115966797,289.5845031738281,0.0,7,P
sample_4.pdf,9,"[10] I. J. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, and",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,300.04150390625,0.14925373134328357,67,P
sample_4.pdf,9,Y. Bengio. Maxout networks.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,309.5065002441406,0.1111111111111111,27,P
sample_4.pdf,9,arXiv:1302.4389,7.970099925994873,NimbusRomNo9L-ReguItal,False,162.88839721679688,309.3653259277344,0.06666666666666667,15,P
sample_4.pdf,9,", 2013.",7.970099925994873,NimbusRomNo9L-Regu,False,219.9940185546875,309.5065002441406,0.0,7,P
sample_4.pdf,9,[11] K. He and J. Sun. Convolutional neural networks at constrained time,7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,319.9635009765625,0.06944444444444445,72,P
sample_4.pdf,9,cost. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,329.427490234375,0.125,8,P
sample_4.pdf,9,CVPR,7.970099925994873,NimbusRomNo9L-ReguItal,False,92.71170806884766,329.28631591796875,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,114.63002014160156,329.427490234375,0.0,7,P
sample_4.pdf,9,"[12] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep",7.970099925994873,NimbusRomNo9L-Regu,False,50.112022399902344,339.8844909667969,0.1232876712328767,73,P
sample_4.pdf,9,convolutional networks for visual recognition. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37102508544922,349.3484802246094,0.02040816326530612,49,P
sample_4.pdf,9,ECCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,224.97543334960938,349.2073059082031,1.0,4,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,247.33900451660156,349.3484802246094,0.0,7,P
sample_4.pdf,9,"[13] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectiﬁers:",7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,359.80548095703125,0.12857142857142856,70,P
sample_4.pdf,9,Surpassing human-level performance on imagenet classiﬁcation. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,369.2704772949219,0.03125,64,P
sample_4.pdf,9,ICCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,68.37100219726562,378.5932922363281,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,86.5270004272461,378.7344665527344,0.0,7,P
sample_4.pdf,9,"[14] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and",7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,389.19146728515625,0.13636363636363635,66,P
sample_4.pdf,9,R. R. Salakhutdinov. Improving neural networks by preventing co-,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,398.6564636230469,0.0625,64,P
sample_4.pdf,9,adaptation of feature detectors.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,408.1204528808594,0.0,32,P
sample_4.pdf,9,arXiv:1207.0580,7.970099925994873,NimbusRomNo9L-ReguItal,False,167.08067321777344,407.9792785644531,0.06666666666666667,15,P
sample_4.pdf,9,", 2012.",7.970099925994873,NimbusRomNo9L-Regu,False,224.18600463867188,408.1204528808594,0.0,7,P
sample_4.pdf,9,[15] S. Hochreiter and J. Schmidhuber. Long short-term memory.,7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,418.57745361328125,0.08064516129032258,62,P
sample_4.pdf,9,Neural,7.970099925994873,NimbusRomNo9L-ReguItal,False,261.6703186035156,418.436279296875,0.16666666666666666,6,P
sample_4.pdf,9,computation,7.970099925994873,NimbusRomNo9L-ReguItal,False,68.37100219726562,427.9002685546875,0.0,11,P
sample_4.pdf,9,", 9(8):1735–1780, 1997.",7.970099925994873,NimbusRomNo9L-Regu,False,108.22200012207031,428.04144287109375,0.0,23,P
sample_4.pdf,9,[16] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep,7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,438.4984436035156,0.08823529411764706,68,P
sample_4.pdf,9,network training by reducing internal covariate shift. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,447.96343994140625,0.017543859649122806,57,P
sample_4.pdf,9,ICML,7.970099925994873,NimbusRomNo9L-ReguItal,False,243.90440368652344,447.822265625,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,264.6920166015625,447.96343994140625,0.0,7,P
sample_4.pdf,9,"[17] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,458.41943359375,0.09722222222222222,72,P
sample_4.pdf,9,neighbor search.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,467.8844299316406,0.0,16,P
sample_4.pdf,9,TPAMI,7.970099925994873,NimbusRomNo9L-ReguItal,False,121.04540252685547,467.7432556152344,1.0,5,P
sample_4.pdf,9,", 33, 2011.",7.970099925994873,NimbusRomNo9L-Regu,False,146.6610107421875,467.8844299316406,0.0,11,P
sample_4.pdf,9,"[18] H. Jegou, F. Perronnin, M. Douze, J. Sanchez, P. Perez, and",7.970099925994873,NimbusRomNo9L-Regu,False,50.11200714111328,478.3414306640625,0.15625,64,P
sample_4.pdf,9,C. Schmid. Aggregating local image descriptors into compact codes.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100982666016,487.805419921875,0.045454545454545456,66,P
sample_4.pdf,9,TPAMI,7.970099925994873,NimbusRomNo9L-ReguItal,False,68.37100982666016,497.1292419433594,1.0,5,P
sample_4.pdf,9,", 2012.",7.970099925994873,NimbusRomNo9L-Regu,False,91.11801147460938,497.2704162597656,0.0,7,P
sample_4.pdf,9,"[19] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201095581055,507.7274169921875,0.16666666666666666,72,P
sample_4.pdf,9,"S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for",7.970099925994873,NimbusRomNo9L-Regu,False,68.37100982666016,517.19140625,0.08823529411764706,68,P
sample_4.pdf,9,fast feature embedding.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100982666016,526.6563720703125,0.0,23,P
sample_4.pdf,9,arXiv:1408.5093,7.970099925994873,NimbusRomNo9L-ReguItal,False,143.3218231201172,526.5151977539062,0.06666666666666667,15,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,200.427001953125,526.6563720703125,0.0,7,P
sample_4.pdf,9,[20] A. Krizhevsky. Learning multiple layers of features from tiny im-,7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,537.1124267578125,0.04285714285714286,70,P
sample_4.pdf,9,ages.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,546.577392578125,0.0,5,P
sample_4.pdf,9,Tech Report,7.970099925994873,NimbusRomNo9L-ReguItal,False,84.52639770507812,546.4362182617188,0.18181818181818182,11,P
sample_4.pdf,9,", 2009.",7.970099925994873,NimbusRomNo9L-Regu,False,125.7239990234375,546.577392578125,0.0,7,P
sample_4.pdf,9,"[21] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation",7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,557.034423828125,0.09859154929577464,71,P
sample_4.pdf,9,with deep convolutional neural networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,566.4984130859375,0.023255813953488372,43,P
sample_4.pdf,9,NIPS,7.970099925994873,NimbusRomNo9L-ReguItal,False,209.47357177734375,566.3572387695312,1.0,4,P
sample_4.pdf,9,", 2012.",7.970099925994873,NimbusRomNo9L-Regu,False,228.29100036621094,566.4984130859375,0.0,7,P
sample_4.pdf,9,"[22] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,",7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,576.9553833007812,0.19696969696969696,66,P
sample_4.pdf,9,"W. Hubbard, and L. D. Jackel. Backpropagation applied to hand-",7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,586.42041015625,0.0967741935483871,62,P
sample_4.pdf,9,written zip code recognition.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37100219726562,595.8843994140625,0.0,29,P
sample_4.pdf,9,Neural computation,7.970099925994873,NimbusRomNo9L-ReguItal,False,160.0111846923828,595.7432250976562,0.05555555555555555,18,P
sample_4.pdf,9,", 1989.",7.970099925994873,NimbusRomNo9L-Regu,False,226.74400329589844,595.8843994140625,0.0,7,P
sample_4.pdf,9,"[23] Y. LeCun, L. Bottou, G. B. Orr, and K.-R. M¨uller. Efﬁcient backprop.",7.970099925994873,NimbusRomNo9L-Regu,False,50.11199951171875,606.3013916015625,0.16216216216216217,74,P
sample_4.pdf,9,Neural Networks: Tricks of the Trade,7.970099925994873,NimbusRomNo9L-ReguItal,False,75.01009368896484,615.6642456054688,0.1111111111111111,36,P
sample_4.pdf,9,", pages 9–50. Springer, 1998.",7.970099925994873,NimbusRomNo9L-Regu,False,194.3380126953125,615.805419921875,0.034482758620689655,29,P
sample_4.pdf,9,"[24] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu.",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,626.2623901367188,0.1896551724137931,58,P
sample_4.pdf,9,Deeply-,7.970099925994873,NimbusRomNo9L-Regu,False,260.6900329589844,626.2623901367188,0.14285714285714285,7,P
sample_4.pdf,9,supervised nets.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,635.7274169921875,0.0,16,P
sample_4.pdf,9,arXiv:1409.5185,7.970099925994873,NimbusRomNo9L-ReguItal,False,119.28401947021484,635.5862426757812,0.06666666666666667,15,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,176.3900146484375,635.7274169921875,0.0,7,P
sample_4.pdf,9,"[25] M. Lin, Q. Chen, and S. Yan. Network in network.",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,646.1834106445312,0.1320754716981132,53,P
sample_4.pdf,9,arXiv:1312.4400,7.970099925994873,NimbusRomNo9L-ReguItal,False,227.82127380371094,646.042236328125,0.06666666666666667,15,P
sample_4.pdf,9,2013.,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,655.6483764648438,0.0,5,P
sample_4.pdf,9,"[26] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,666.1054077148438,0.18571428571428572,70,P
sample_4.pdf,9,"P. Doll´ar, and C. L. Zitnick. Microsoft COCO: Common objects in",7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,675.5294189453125,0.171875,64,P
sample_4.pdf,9,context. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,685.034423828125,0.09090909090909091,11,P
sample_4.pdf,9,ECCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,103.21629333496094,684.8932495117188,1.0,4,P
sample_4.pdf,9,. 2014.,7.970099925994873,NimbusRomNo9L-Regu,False,125.58001708984375,685.034423828125,0.0,7,P
sample_4.pdf,9,"[27] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks",7.970099925994873,NimbusRomNo9L-Regu,False,50.11201477050781,695.4913940429688,0.09722222222222222,72,P
sample_4.pdf,9,for semantic segmentation. In,7.970099925994873,NimbusRomNo9L-Regu,False,68.37101745605469,704.9553833007812,0.034482758620689655,29,P
sample_4.pdf,9,CVPR,7.970099925994873,NimbusRomNo9L-ReguItal,False,163.8687286376953,704.814208984375,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,185.78602600097656,704.9553833007812,0.0,7,P
sample_4.pdf,9,"[28] G. Mont´ufar, R. Pascanu, K. Cho, and Y. Bengio. On the number of",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,75.87841033935547,0.12857142857142856,70,P
sample_4.pdf,9,linear regions of deep neural networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,85.38237762451172,0.023809523809523808,42,P
sample_4.pdf,9,NIPS,7.970099925994873,NimbusRomNo9L-ReguItal,False,460.8195495605469,85.2412109375,1.0,4,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,479.6360168457031,85.38237762451172,0.0,7,P
sample_4.pdf,9,[29] V. Nair and G. E. Hinton. Rectiﬁed linear units improve restricted,7.970099925994873,NimbusRomNo9L-Regu,False,308.86199951171875,95.84337615966797,0.08450704225352113,71,P
sample_4.pdf,9,boltzmann machines. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210021972656,105.30840301513672,0.045454545454545456,22,P
sample_4.pdf,9,ICML,7.970099925994873,NimbusRomNo9L-ReguItal,False,404.36724853515625,105.167236328125,1.0,4,P
sample_4.pdf,9,", 2010.",7.970099925994873,NimbusRomNo9L-Regu,False,425.4000244140625,105.30840301513672,0.0,7,P
sample_4.pdf,9,[30] F. Perronnin and C. Dance. Fisher kernels on visual vocabularies for,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,115.76842498779297,0.0684931506849315,73,P
sample_4.pdf,9,image categorization. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,125.23345184326172,0.041666666666666664,24,P
sample_4.pdf,9,CVPR,7.970099925994873,NimbusRomNo9L-ReguItal,False,405.1244812011719,125.09228515625,1.0,4,P
sample_4.pdf,9,", 2007.",7.970099925994873,NimbusRomNo9L-Regu,False,427.0420227050781,125.23345184326172,0.0,7,P
sample_4.pdf,9,"[31] T. Raiko, H. Valpola, and Y. LeCun. Deep learning made easier by",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,135.6944580078125,0.11594202898550725,69,P
sample_4.pdf,9,linear transformations in perceptrons. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,145.158447265625,0.024390243902439025,41,P
sample_4.pdf,9,AISTATS,7.970099925994873,NimbusRomNo9L-ReguItal,False,456.1570739746094,145.01727294921875,1.0,7,P
sample_4.pdf,9,", 2012.",7.970099925994873,NimbusRomNo9L-Regu,False,486.6810607910156,145.158447265625,0.0,7,P
sample_4.pdf,9,"[32] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,155.61944580078125,0.21212121212121213,66,P
sample_4.pdf,9,real-time object detection with region proposal networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,165.08343505859375,0.016666666666666666,60,P
sample_4.pdf,9,NIPS,7.970099925994873,NimbusRomNo9L-ReguItal,False,523.7835083007812,164.9422607421875,1.0,4,P
sample_4.pdf,9,2015.,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,174.5484619140625,0.0,5,P
sample_4.pdf,9,"[33] S. Ren, K. He, R. Girshick, X. Zhang, and J. Sun. Object detection",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,185.00946044921875,0.15492957746478872,71,P
sample_4.pdf,9,networks on convolutional feature maps.,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,194.47344970703125,0.0,39,P
sample_4.pdf,9,arXiv:1504.06066,7.970099925994873,NimbusRomNo9L-ReguItal,False,456.4997253417969,194.332275390625,0.0625,16,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,517.5900268554688,194.47344970703125,0.0,7,P
sample_4.pdf,9,[34] B. D. Ripley.,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,204.9344482421875,0.16666666666666666,18,P
sample_4.pdf,9,Pattern recognition and neural networks,7.970099925994873,NimbusRomNo9L-ReguItal,False,369.4428405761719,204.79327392578125,0.02564102564102564,39,P
sample_4.pdf,9,. Cambridge,7.970099925994873,NimbusRomNo9L-Regu,False,503.76104736328125,204.9344482421875,0.09090909090909091,11,P
sample_4.pdf,9,"university press, 1996.",7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,214.3984375,0.0,23,P
sample_4.pdf,9,"[35] A. Romero, N. Ballas, S. E. Kahou, A. Chassang, C. Gatta, and",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620300292969,224.85943603515625,0.16666666666666666,66,P
sample_4.pdf,9,Y. Bengio. Fitnets: Hints for thin deep nets. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.12103271484375,234.324462890625,0.10416666666666667,48,P
sample_4.pdf,9,ICLR,7.970099925994873,NimbusRomNo9L-ReguItal,False,476.4330139160156,234.18328857421875,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,495.696044921875,234.324462890625,0.0,7,P
sample_4.pdf,9,"[36] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,244.78546142578125,0.1791044776119403,67,P
sample_4.pdf,9,"Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet",7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,254.24945068359375,0.14285714285714285,63,P
sample_4.pdf,9,large scale visual recognition challenge.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,263.7144775390625,0.0,41,P
sample_4.pdf,9,arXiv:1409.0575,7.970099925994873,NimbusRomNo9L-ReguItal,False,454.6905822753906,263.57330322265625,0.06666666666666667,15,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,511.7950744628906,263.7144775390625,0.0,7,P
sample_4.pdf,9,"[37] A. M. Saxe, J. L. McClelland, and S. Ganguli. Exact solutions to",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,274.1744689941406,0.14492753623188406,69,P
sample_4.pdf,9,the nonlinear dynamics of learning in deep linear neural networks.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,283.63946533203125,0.0,66,P
sample_4.pdf,9,arXiv:1312.6120,7.970099925994873,NimbusRomNo9L-ReguItal,False,327.1210632324219,292.9622802734375,0.06666666666666667,15,P
sample_4.pdf,9,", 2013.",7.970099925994873,NimbusRomNo9L-Regu,False,381.3580627441406,293.10345458984375,0.0,7,P
sample_4.pdf,9,[38] N. N. Schraudolph. Accelerated gradient descent by factor-centering,7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,303.564453125,0.05555555555555555,72,P
sample_4.pdf,9,"decomposition. Technical report, 1998.",7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,313.0294494628906,0.02631578947368421,38,P
sample_4.pdf,9,[39] N. N. Schraudolph. Centering neural network gradient factors. In,7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,323.48944091796875,0.07246376811594203,69,P
sample_4.pdf,9,Neural Networks: Tricks of the Trade,7.970099925994873,NimbusRomNo9L-ReguItal,False,327.1210632324219,332.8132629394531,0.1111111111111111,36,P
sample_4.pdf,9,", pages 207–226. Springer,",7.970099925994873,NimbusRomNo9L-Regu,False,455.1050720214844,332.9544372558594,0.038461538461538464,26,P
sample_4.pdf,9,1998.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,342.4184265136719,0.0,5,P
sample_4.pdf,9,"[40] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. Le-",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,352.8794250488281,0.16901408450704225,71,P
sample_4.pdf,9,Cun.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,362.34442138671875,0.25,4,P
sample_4.pdf,9,"Overfeat: Integrated recognition, localization and detection",7.970099925994873,NimbusRomNo9L-Regu,False,348.9989929199219,362.34442138671875,0.03333333333333333,60,P
sample_4.pdf,9,using convolutional networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,371.80841064453125,0.03125,32,P
sample_4.pdf,9,ICLR,7.970099925994873,NimbusRomNo9L-ReguItal,False,432.3742370605469,371.667236328125,1.0,4,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,451.6380615234375,371.80841064453125,0.0,7,P
sample_4.pdf,9,[41] K. Simonyan and A. Zisserman. Very deep convolutional networks,7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,382.2694091796875,0.07462686567164178,67,P
sample_4.pdf,9,for large-scale image recognition. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,391.7333984375,0.02702702702702703,37,P
sample_4.pdf,9,ICLR,7.970099925994873,NimbusRomNo9L-ReguItal,False,444.0505065917969,391.59222412109375,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,463.31304931640625,391.7333984375,0.0,7,P
sample_4.pdf,9,"[42] R. K. Srivastava, K. Greff, and J. Schmidhuber. Highway networks.",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,402.19439697265625,0.11428571428571428,70,P
sample_4.pdf,9,arXiv:1505.00387,7.970099925994873,NimbusRomNo9L-ReguItal,False,327.1210632324219,411.5182189941406,0.0625,16,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,385.34307861328125,411.6593933105469,0.0,7,P
sample_4.pdf,9,"[43] R. K. Srivastava, K. Greff, and J. Schmidhuber. Training very deep",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,422.1203918457031,0.11267605633802817,71,P
sample_4.pdf,9,networks.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,431.5843811035156,0.0,9,P
sample_4.pdf,9,1507.06228,7.970099925994873,NimbusRomNo9L-ReguItal,False,358.2522888183594,431.4432067871094,0.0,10,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,398.9800720214844,431.5843811035156,0.0,7,P
sample_4.pdf,9,"[44] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Er-",7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,442.0453796386719,0.1891891891891892,74,P
sample_4.pdf,9,"han, V. Vanhoucke, and A. Rabinovich. Going deeper with convolu-",7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,451.5093688964844,0.078125,64,P
sample_4.pdf,9,tions. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,460.974365234375,0.1111111111111111,9,P
sample_4.pdf,9,CVPR,7.970099925994873,NimbusRomNo9L-ReguItal,False,354.123779296875,460.83319091796875,1.0,4,P
sample_4.pdf,9,", 2015.",7.970099925994873,NimbusRomNo9L-Regu,False,376.0410461425781,460.974365234375,0.0,7,P
sample_4.pdf,9,[45] R. Szeliski. Fast surface interpolation using hierarchical basis func-,7.970099925994873,NimbusRomNo9L-Regu,False,308.862060546875,471.43536376953125,0.04,75,P
sample_4.pdf,9,tions.,7.970099925994873,NimbusRomNo9L-Regu,False,327.1210632324219,480.89935302734375,0.0,6,P
sample_4.pdf,9,TPAMI,7.970099925994873,NimbusRomNo9L-ReguItal,False,344.6154479980469,480.7581787109375,1.0,5,P
sample_4.pdf,9,", 1990.",7.970099925994873,NimbusRomNo9L-Regu,False,370.2310791015625,480.89935302734375,0.0,7,P
sample_4.pdf,9,[46] R. Szeliski. Locally adapted hierarchical basis preconditioning. In,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620910644531,491.3603515625,0.05555555555555555,72,P
sample_4.pdf,9,SIGGRAPH,7.970099925994873,NimbusRomNo9L-ReguItal,False,327.12109375,500.68316650390625,1.0,8,P
sample_4.pdf,9,", 2006.",7.970099925994873,NimbusRomNo9L-Regu,False,365.6330871582031,500.8243408203125,0.0,7,P
sample_4.pdf,9,"[47] T. Vatanen, T. Raiko, H. Valpola, and Y. LeCun. Pushing stochas-",7.970099925994873,NimbusRomNo9L-Regu,False,308.8620910644531,511.28533935546875,0.14492753623188406,69,P
sample_4.pdf,9,tic gradient towards second-order methods–backpropagation learn-,7.970099925994873,NimbusRomNo9L-Regu,False,327.12109375,520.7503662109375,0.0,64,P
sample_4.pdf,9,ing with transformations in nonlinearities.,7.970099925994873,NimbusRomNo9L-Regu,False,327.12109375,530.21435546875,0.0,43,P
sample_4.pdf,9,Neural Information,7.970099925994873,NimbusRomNo9L-ReguItal,False,478.7524108886719,530.0731811523438,0.1111111111111111,18,P
sample_4.pdf,9,Processing,7.970099925994873,NimbusRomNo9L-ReguItal,False,327.12109375,539.5381469726562,0.1,10,P
sample_4.pdf,9,", 2013.",7.970099925994873,NimbusRomNo9L-Regu,False,362.18109130859375,539.6793212890625,0.0,7,P
sample_4.pdf,9,[48] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620910644531,550.1393432617188,0.11428571428571428,70,P
sample_4.pdf,9,"of computer vision algorithms, 2008.",7.970099925994873,NimbusRomNo9L-Regu,False,327.12109375,559.6043701171875,0.0,36,P
sample_4.pdf,9,[49] W. Venables and B. Ripley. Modern applied statistics with s-plus.,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620910644531,570.0653076171875,0.07142857142857142,70,P
sample_4.pdf,9,1999.,7.970099925994873,NimbusRomNo9L-Regu,False,327.12109375,579.5293579101562,0.0,5,P
sample_4.pdf,9,[50] M. D. Zeiler and R. Fergus. Visualizing and understanding convolu-,7.970099925994873,NimbusRomNo9L-Regu,False,308.8620910644531,589.9903564453125,0.08450704225352113,71,P
sample_4.pdf,9,tional neural networks. In,7.970099925994873,NimbusRomNo9L-Regu,False,327.12109375,599.455322265625,0.038461538461538464,26,P
sample_4.pdf,9,ECCV,7.970099925994873,NimbusRomNo9L-ReguItal,False,409.81890869140625,599.3141479492188,1.0,4,P
sample_4.pdf,9,", 2014.",7.970099925994873,NimbusRomNo9L-Regu,False,432.1820983886719,599.455322265625,0.0,7,P
sample_4.pdf,10,A. Object Detection Baselines,11.9552001953125,NimbusRomNo9L-Medi,False,50.11199951171875,72.78716278076172,0.13793103448275862,29,H3
sample_4.pdf,10,In this section we introduce our detection method based,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,93.67750549316406,0.01818181818181818,55,H3
sample_4.pdf,10,on the baseline Faster R-CNN [32] system. The models are,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,105.63252258300781,0.10714285714285714,56,H3
sample_4.pdf,10,"initialized by the ImageNet classiﬁcation models, and then",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,117.58753967285156,0.034482758620689655,58,H3
sample_4.pdf,10,ﬁne-tuned on the object detection data. We have experi-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,129.5425567626953,0.01818181818181818,55,H3
sample_4.pdf,10,mented with ResNet-50/101 at the time of the ILSVRC &,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,141.49757385253906,0.1509433962264151,53,H3
sample_4.pdf,10,COCO 2015 detection competitions.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,153.4535675048828,0.12121212121212122,33,H3
sample_4.pdf,10,"Unlike VGG-16 used in [32], our ResNet has no hidden",9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,165.7495880126953,0.11538461538461539,52,H3
sample_4.pdf,10,fc layers. We adopt the idea of “Networks on Conv fea-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,177.70460510253906,0.05555555555555555,54,H3
sample_4.pdf,10,ture maps” (NoC) [33] to address this issue. We compute,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,189.6596221923828,0.05454545454545454,55,H3
sample_4.pdf,10,the full-image shared conv feature maps using those lay-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,201.61463928222656,0.0,56,H3
sample_4.pdf,10,ers whose strides on the image are no greater than 16 pixels,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,213.5696563720703,0.0,60,H3
sample_4.pdf,10,i.e,9.962599754333496,NimbusRomNo9L-ReguItal,False,53.42900085449219,225.34918212890625,0.0,3,H3
sample_4.pdf,10,"., conv1, conv2 x, conv3 x, and conv4 x, totally 91 conv",9.962599754333496,NimbusRomNo9L-Regu,False,63.112998962402344,225.5254669189453,0.0,56,H3
sample_4.pdf,10,layers in ResNet-101; Table 1). We consider these layers as,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,237.48048400878906,0.06779661016949153,59,H3
sample_4.pdf,10,"analogous to the 13 conv layers in VGG-16, and by doing",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,249.4355010986328,0.05454545454545454,55,H3
sample_4.pdf,10,"so, both ResNet and VGG-16 have conv feature maps of the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,261.3905029296875,0.08928571428571429,56,H3
sample_4.pdf,10,same total stride (16 pixels). These layers are shared by a,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,273.3454895019531,0.01694915254237288,59,H3
sample_4.pdf,10,"region proposal network (RPN, generating 300 proposals)",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,285.30047607421875,0.05454545454545454,55,H3
sample_4.pdf,10,[32] and a Fast R-CNN detection network [7]. RoI pool-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,297.2564697265625,0.12962962962962962,54,H3
sample_4.pdf,10,ing [7] is performed before conv5 1. On this RoI-pooled,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,309.2114562988281,0.05454545454545454,55,H3
sample_4.pdf,10,"feature, all layers of conv5 x and up are adopted for each",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,321.16644287109375,0.0,58,H3
sample_4.pdf,10,"region, playing the roles of VGG-16’s fc layers. The ﬁnal",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,333.1214294433594,0.07017543859649122,57,H3
sample_4.pdf,10,classiﬁcation layer is replaced by two sibling layers (classi-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,345.076416015625,0.0,62,H3
sample_4.pdf,10,ﬁcation and box regression [7]).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,357.0314025878906,0.0,32,H3
sample_4.pdf,10,"For the usage of BN layers, after pre-training, we com-",9.962599754333496,NimbusRomNo9L-Regu,False,62.06700897216797,369.3283996582031,0.05454545454545454,55,H3
sample_4.pdf,10,pute the BN statistics (means and variances) for each layer,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,381.28338623046875,0.03389830508474576,59,H3
sample_4.pdf,10,on the ImageNet training set. Then the BN layers are ﬁxed,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,393.2383728027344,0.08771929824561403,57,H3
sample_4.pdf,10,"during ﬁne-tuning for object detection. As such, the BN",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,405.193359375,0.05454545454545454,55,H3
sample_4.pdf,10,layers become linear activations with constant offsets and,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,417.1483459472656,0.0,58,H3
sample_4.pdf,10,"scales, and BN statistics are not updated by ﬁne-tuning. We",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,429.1043395996094,0.05084745762711865,59,H3
sample_4.pdf,10,ﬁx the BN layers mainly for reducing memory consumption,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,441.059326171875,0.03636363636363636,55,H3
sample_4.pdf,10,in Faster R-CNN training.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,453.0143127441406,0.2,25,H3
sample_4.pdf,10,PASCAL VOC,9.962599754333496,NimbusRomNo9L-Medi,False,50.11200714111328,470.20037841796875,0.9,10,H3
sample_4.pdf,10,"Following [7, 32], for the PASCAL VOC 2007",9.962599754333496,NimbusRomNo9L-Regu,False,62.06700897216797,482.58831787109375,0.23809523809523808,42,H3
sample_4.pdf,10,test,9.962599754333496,NimbusRomNo9L-ReguItal,False,252.6016845703125,482.411865234375,0.0,4,H3
sample_4.pdf,10,"set,",9.962599754333496,NimbusRomNo9L-Regu,False,269.5340576171875,482.58831787109375,0.0,4,H3
sample_4.pdf,10,we use the 5k,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,494.5433044433594,0.0,13,H3
sample_4.pdf,10,trainval,9.962599754333496,NimbusRomNo9L-ReguItal,False,105.27491760253906,494.3668518066406,0.0,8,H3
sample_4.pdf,10,images in VOC 2007 and 16k,9.962599754333496,NimbusRomNo9L-Regu,False,138.98361206054688,494.5433044433594,0.11538461538461539,26,H3
sample_4.pdf,10,train-,9.962599754333496,NimbusRomNo9L-ReguItal,False,261.10369873046875,494.3668518066406,0.0,6,H3
sample_4.pdf,10,val,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.11201477050781,506.32183837890625,0.0,3,H3
sample_4.pdf,10,images in VOC 2012 for training (“07+12”). For the,9.962599754333496,NimbusRomNo9L-Regu,False,62.286312103271484,506.498291015625,0.08,50,H3
sample_4.pdf,10,PASCAL VOC 2012,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201858520508,518.4532470703125,0.6,15,H3
sample_4.pdf,10,test,9.962599754333496,NimbusRomNo9L-ReguItal,False,134.21629333496094,518.2767944335938,0.0,4,H3
sample_4.pdf,10,"set, we use the 10k",9.962599754333496,NimbusRomNo9L-Regu,False,151.18409729003906,518.4532470703125,0.0,19,H3
sample_4.pdf,10,trainval,9.962599754333496,NimbusRomNo9L-ReguItal,False,232.76219177246094,518.2767944335938,0.0,8,H3
sample_4.pdf,10,test,9.962599754333496,NimbusRomNo9L-ReguItal,False,272.5240173339844,518.2767944335938,0.0,4,H3
sample_4.pdf,10,images in VOC 2007 and 16k,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,530.4082641601562,0.11538461538461539,26,H3
sample_4.pdf,10,trainval,9.962599754333496,NimbusRomNo9L-ReguItal,False,167.39169311523438,530.2318115234375,0.0,8,H3
sample_4.pdf,10,images in VOC 2012,9.962599754333496,NimbusRomNo9L-Regu,False,200.6836395263672,530.4082641601562,0.16666666666666666,18,H3
sample_4.pdf,10,for training (“07++12”). The hyper-parameters for train-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,542.36328125,0.017857142857142856,56,H3
sample_4.pdf,10,ing Faster R-CNN are the same as in [32]. Table 7 shows,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,554.3192749023438,0.10909090909090909,55,H3
sample_4.pdf,10,the results. ResNet-101 improves the mAP by,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,566.2742919921875,0.09302325581395349,43,H3
sample_4.pdf,10,3% over,9.962599754333496,NimbusRomNo9L-Regu,False,252.22401428222656,566.2742919921875,0.0,7,H3
sample_4.pdf,10,VGG-16. This gain is solely because of the improved fea-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,578.229248046875,0.07142857142857142,56,H3
sample_4.pdf,10,tures learned by ResNet.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,590.1842651367188,0.08333333333333333,24,H3
sample_4.pdf,10,MS COCO,9.962599754333496,NimbusRomNo9L-Medi,False,50.11201477050781,607.371337890625,0.8571428571428571,7,H3
sample_4.pdf,10,The MS COCO dataset [26] involves 80 object cate-,9.962599754333496,NimbusRomNo9L-Regu,False,62.0670166015625,619.75830078125,0.14285714285714285,49,H3
sample_4.pdf,10,gories. We evaluate the PASCAL VOC metric (mAP @,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,631.7132568359375,0.25,48,H3
sample_4.pdf,10,IoU = 0.5) and the standard COCO metric (mAP @ IoU =,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,643.6682739257812,0.19230769230769232,52,H3
sample_4.pdf,10,.5:.05:.95). We use the 80k images on the train set for train-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,655.623291015625,0.016129032258064516,62,H3
sample_4.pdf,10,ing and the 40k images on the val set for evaluation. Our,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,667.5792846679688,0.017543859649122806,57,H3
sample_4.pdf,10,detection system for COCO is similar to that for PASCAL,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,679.5343017578125,0.18181818181818182,55,H3
sample_4.pdf,10,VOC. We train the COCO models with an 8-GPU imple-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,691.4893188476562,0.22,50,H3
sample_4.pdf,10,"mentation, and thus the RPN step has a mini-batch size of",9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,703.4442749023438,0.05263157894736842,57,H3
sample_4.pdf,10,8 images (,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,74.40730285644531,0.0,10,H3
sample_4.pdf,10,i.e,9.962599754333496,NimbusRomNo9L-ReguItal,False,351.4209899902344,74.2308349609375,0.0,3,H3
sample_4.pdf,10,"., 1 per GPU) and the Fast R-CNN step has a",9.962599754333496,NimbusRomNo9L-Regu,False,361.10498046875,74.40730285644531,0.18604651162790697,43,H3
sample_4.pdf,10,mini-batch size of 16 images. The RPN step and Fast R-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,86.36231994628906,0.1111111111111111,54,H3
sample_4.pdf,10,CNN step are both trained for 240k iterations with a learn-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,98.31733703613281,0.05084745762711865,59,H3
sample_4.pdf,10,ing rate of 0.001 and then for 80k iterations with 0.0001.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,110.27235412597656,0.0,58,H3
sample_4.pdf,10,Table 8 shows the results on the MS COCO validation,9.962599754333496,NimbusRomNo9L-Regu,False,320.81695556640625,123.26832580566406,0.13725490196078433,51,H3
sample_4.pdf,10,"set. ResNet-101 has a 6% increase of mAP@[.5, .95] over",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,135.2233428955078,0.07272727272727272,55,H3
sample_4.pdf,10,"VGG-16, which is a 28% relative improvement, solely con-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,147.17835998535156,0.05357142857142857,56,H3
sample_4.pdf,10,tributed by the features learned by the better network. Re-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,159.1333770751953,0.01694915254237288,59,H3
sample_4.pdf,10,"markably, the mAP@[.5, .95]’s absolute increase (6.0%) is",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,171.08839416503906,0.03508771929824561,57,H3
sample_4.pdf,10,nearly as big as mAP@.5’s (6.9%). This suggests that a,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,183.0434112548828,0.05555555555555555,54,H3
sample_4.pdf,10,deeper network can improve both recognition and localiza-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,194.99940490722656,0.0,57,H3
sample_4.pdf,10,tion.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,206.9544219970703,0.0,5,H3
sample_4.pdf,10,B. Object Detection Improvements,11.9552001953125,NimbusRomNo9L-Medi,False,308.8619689941406,232.3651123046875,0.125,32,H3
sample_4.pdf,10,"For completeness, we report the improvements made for",9.962599754333496,NimbusRomNo9L-Regu,False,320.81695556640625,253.9544219970703,0.018867924528301886,53,H3
sample_4.pdf,10,the competitions. These improvements are based on deep,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,265.909423828125,0.018518518518518517,54,H3
sample_4.pdf,10,features and thus should beneﬁt from residual learning.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,277.8644104003906,0.0,55,H3
sample_4.pdf,10,MS COCO,9.962599754333496,NimbusRomNo9L-Medi,False,308.8619689941406,295.7504577636719,0.8571428571428571,7,H3
sample_4.pdf,10,Box reﬁnement.,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619689941406,308.6599426269531,0.07142857142857142,14,H3
sample_4.pdf,10,Our box reﬁnement partially follows the it-,9.962599754333496,NimbusRomNo9L-Regu,False,370.8990783691406,308.8363952636719,0.023255813953488372,43,H3
sample_4.pdf,10,"erative localization in [6]. In Faster R-CNN, the ﬁnal output",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,320.7913818359375,0.09836065573770492,61,H3
sample_4.pdf,10,is a regressed box that is different from its proposal box. So,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,332.7463684082031,0.016129032258064516,62,H3
sample_4.pdf,10,"for inference, we pool a new feature from the regressed box",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,344.7023620605469,0.0,59,H3
sample_4.pdf,10,and obtain a new classiﬁcation score and a new regressed,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,356.6573486328125,0.0,56,H3
sample_4.pdf,10,box. We combine these 300 new predictions with the orig-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,368.6123352050781,0.017857142857142856,56,H3
sample_4.pdf,10,inal 300 predictions. Non-maximum suppression (NMS) is,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,380.56732177734375,0.07407407407407407,54,H3
sample_4.pdf,10,applied on the union set of predicted boxes using an IoU,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,392.5223083496094,0.03571428571428571,56,H3
sample_4.pdf,10,"threshold of 0.3 [8], followed by box voting [6]. Box re-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,404.477294921875,0.017543859649122806,57,H3
sample_4.pdf,10,ﬁnement improves mAP by about 2 points (Table 9).,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,416.43328857421875,0.061224489795918366,49,H3
sample_4.pdf,10,Global context.,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619689941406,434.23284912109375,0.06666666666666667,15,H3
sample_4.pdf,10,We combine global context in the Fast,9.962599754333496,NimbusRomNo9L-Regu,False,380.8509521484375,434.4093017578125,0.05405405405405406,37,H3
sample_4.pdf,10,"R-CNN step. Given the full-image conv feature map, we",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,446.3642883300781,0.09433962264150944,53,H3
sample_4.pdf,10,pool a feature by global Spatial Pyramid Pooling [12] (with,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,458.3202819824219,0.05084745762711865,59,H3
sample_4.pdf,10,a “single-level” pyramid) which can be implemented as,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,470.2752685546875,0.0,53,H3
sample_4.pdf,10,“RoI” pooling using the entire image’s bounding box as the,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,482.2302551269531,0.034482758620689655,58,H3
sample_4.pdf,10,RoI. This pooled feature is fed into the post-RoI layers to,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,494.18524169921875,0.0847457627118644,59,H3
sample_4.pdf,10,obtain a global context feature. This global feature is con-,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,506.1402587890625,0.016666666666666666,60,H3
sample_4.pdf,10,"catenated with the original per-region feature, followed by",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,518.09521484375,0.0,59,H3
sample_4.pdf,10,the sibling classiﬁcation and box regression layers. This,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,530.0512084960938,0.017543859649122806,57,H3
sample_4.pdf,10,new structure is trained end-to-end.,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,542.0062255859375,0.0,36,H3
sample_4.pdf,10,Global context im-,9.962599754333496,NimbusRomNo9L-Regu,False,466.2311096191406,542.0062255859375,0.05555555555555555,18,H3
sample_4.pdf,10,proves mAP@.5 by about 1 point (Table 9).,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,553.961181640625,0.07317073170731707,41,H3
sample_4.pdf,10,Multi-scale testing.,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619384765625,571.7617797851562,0.05,20,H3
sample_4.pdf,10,"In the above, all results are obtained by",9.962599754333496,NimbusRomNo9L-Regu,False,385.6535949707031,571.938232421875,0.024390243902439025,41,H3
sample_4.pdf,10,"single-scale training/testing as in [32], where the image’s",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,583.8931884765625,0.0,59,H3
sample_4.pdf,10,shorter side is,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,595.8482055664062,0.0,15,H3
sample_4.pdf,10,= 600,9.962599754333496,CMR10,False,372.8013916015625,595.9318237304688,0.0,5,H3
sample_4.pdf,10,pixels. Multi-scale training/testing,9.962599754333496,NimbusRomNo9L-Regu,False,402.8030090332031,595.8482055664062,0.027777777777777776,36,H3
sample_4.pdf,10,"has been developed in [12, 7] by selecting a scale from a",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,607.80322265625,0.0,57,H3
sample_4.pdf,10,"feature pyramid, and in [33] by using maxout layers. In",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,619.7582397460938,0.01818181818181818,55,H3
sample_4.pdf,10,"our current implementation, we have performed multi-scale",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,631.7132568359375,0.0,57,H3
sample_4.pdf,10,testing,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.8619384765625,643.4927368164062,0.0,7,H3
sample_4.pdf,10,following [33]; we have not performed multi-scale,9.962599754333496,NimbusRomNo9L-Regu,False,335.4321594238281,643.669189453125,0.0,49,H3
sample_4.pdf,10,"training because of limited time. In addition, we have per-",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,655.6242065429688,0.01694915254237288,59,H3
sample_4.pdf,10,formed multi-scale testing only for the Fast R-CNN step,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,667.5792236328125,0.09090909090909091,55,H3
sample_4.pdf,10,"(but not yet for the RPN step). With a trained model, we",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,679.5342407226562,0.07142857142857142,56,H3
sample_4.pdf,10,"compute conv feature maps on an image pyramid, where the",9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,691.4892578125,0.0,56,H3
sample_4.pdf,10,image’s shorter sides are,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619384765625,703.4442138671875,0.0,25,H3
sample_4.pdf,10,200,9.962599754333496,CMR10,False,440.2269287109375,703.52783203125,0.0,3,H3
sample_4.pdf,10,400,9.962599754333496,CMR10,False,457.9405212402344,703.52783203125,0.0,3,H3
sample_4.pdf,10,600,9.962599754333496,CMR10,False,477.3125305175781,703.52783203125,0.0,3,H3
sample_4.pdf,10,800,9.962599754333496,CMR10,False,496.6845397949219,703.52783203125,0.0,3,H3
sample_4.pdf,10,1000,9.962599754333496,CMR10,False,516.0565795898438,703.52783203125,0.0,4,H3
sample_4.pdf,11,training data,8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,73.65298461914062,0.0,13,P
sample_4.pdf,11,COCO train,8.966400146484375,NimbusRomNo9L-Regu,False,304.14599609375,73.65298461914062,0.4,10,P
sample_4.pdf,11,COCO trainval,8.966400146484375,NimbusRomNo9L-Regu,False,385.25799560546875,73.65298461914062,0.3076923076923077,13,P
sample_4.pdf,11,test data,8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,85.55899047851562,0.0,9,P
sample_4.pdf,11,COCO val,8.966400146484375,NimbusRomNo9L-Regu,False,306.99798583984375,85.55899047851562,0.5,8,P
sample_4.pdf,11,COCO test-dev,8.966400146484375,NimbusRomNo9L-Regu,False,384.58099365234375,85.55899047851562,0.3076923076923077,13,P
sample_4.pdf,11,mAP,8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,97.46395874023438,0.6666666666666666,3,P
sample_4.pdf,11,@.5,8.966400146484375,NimbusRomNo9L-Regu,False,295.9410095214844,97.46395874023438,0.0,3,P
sample_4.pdf,11,"@[.5, .95]",8.966400146484375,NimbusRomNo9L-Regu,False,328.25799560546875,97.46395874023438,0.0,10,P
sample_4.pdf,11,@.5,8.966400146484375,NimbusRomNo9L-Regu,False,382.239013671875,97.46395874023438,0.0,3,P
sample_4.pdf,11,"@[.5, .95]",8.966400146484375,NimbusRomNo9L-Regu,False,414.5570068359375,97.46395874023438,0.0,10,P
sample_4.pdf,11,baseline Faster R-CNN (VGG-16),8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,109.36898803710938,0.26666666666666666,30,P
sample_4.pdf,11,41.5,8.966400146484375,NimbusRomNo9L-Regu,False,295.58599853515625,109.36898803710938,0.0,4,P
sample_4.pdf,11,21.2,8.966400146484375,NimbusRomNo9L-Regu,False,338.7359924316406,109.36898803710938,0.0,4,P
sample_4.pdf,11,baseline Faster R-CNN (ResNet-101),8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,120.87600708007812,0.20588235294117646,34,P
sample_4.pdf,11,48.4,8.966400146484375,NimbusRomNo9L-Regu,False,295.58599853515625,120.87600708007812,0.0,4,P
sample_4.pdf,11,27.2,8.966400146484375,NimbusRomNo9L-Regu,False,338.7359924316406,120.87600708007812,0.0,4,P
sample_4.pdf,11,+box reﬁnement,8.966400146484375,NimbusRomNo9L-Regu,False,146.26300048828125,132.38296508789062,0.0,14,P
sample_4.pdf,11,49.9,8.966400146484375,NimbusRomNo9L-Regu,False,295.58599853515625,132.38296508789062,0.0,4,P
sample_4.pdf,11,29.9,8.966400146484375,NimbusRomNo9L-Regu,False,338.7359924316406,132.38296508789062,0.0,4,P
sample_4.pdf,11,+context,8.966400146484375,NimbusRomNo9L-Regu,False,146.26300048828125,143.88998413085938,0.0,8,P
sample_4.pdf,11,51.1,8.966400146484375,NimbusRomNo9L-Regu,False,295.58599853515625,143.88998413085938,0.0,4,P
sample_4.pdf,11,30.0,8.966400146484375,NimbusRomNo9L-Regu,False,338.7359924316406,143.88998413085938,0.0,4,P
sample_4.pdf,11,53.3,8.966400146484375,NimbusRomNo9L-Regu,False,381.885009765625,143.88998413085938,0.0,4,P
sample_4.pdf,11,32.2,8.966400146484375,NimbusRomNo9L-Regu,False,425.03399658203125,143.88998413085938,0.0,4,P
sample_4.pdf,11,+multi-scale testing,8.966400146484375,NimbusRomNo9L-Regu,False,146.26300048828125,155.39700317382812,0.0,20,P
sample_4.pdf,11,53.8,8.966400146484375,NimbusRomNo9L-Regu,False,295.58599853515625,155.39700317382812,0.0,4,P
sample_4.pdf,11,32.5,8.966400146484375,NimbusRomNo9L-Regu,False,338.7359924316406,155.39700317382812,0.0,4,P
sample_4.pdf,11,55.7,8.966400146484375,NimbusRomNo9L-Medi,False,381.885009765625,155.3151397705078,0.0,4,P
sample_4.pdf,11,34.9,8.966400146484375,NimbusRomNo9L-Medi,False,425.03399658203125,155.3151397705078,0.0,4,P
sample_4.pdf,11,ensemble,8.966400146484375,NimbusRomNo9L-Regu,False,144.02200317382812,167.30197143554688,0.0,8,P
sample_4.pdf,11,59.0,8.966400146484375,NimbusRomNo9L-Medi,False,381.885009765625,167.22010803222656,0.0,4,P
sample_4.pdf,11,37.4,8.966400146484375,NimbusRomNo9L-Medi,False,425.03399658203125,167.22010803222656,0.0,4,P
sample_4.pdf,11,Table 9. Object detection improvements on MS COCO using Faster R-CNN and ResNet-101.,8.966400146484375,NimbusRomNo9L-Regu,False,130.0679931640625,183.24496459960938,0.17857142857142858,84,P
sample_4.pdf,11,system,5.406440258026123,NimbusRomNo9L-Regu,False,53.26581573486328,211.37704467773438,0.0,6,P
sample_4.pdf,11,net,7.208556652069092,NimbusRomNo9L-Regu,False,105.76551818847656,210.01034545898438,0.0,3,P
sample_4.pdf,11,data,7.208556652069092,NimbusRomNo9L-Regu,False,149.57888793945312,210.01034545898438,0.0,4,P
sample_4.pdf,11,mAP,7.208556652069092,NimbusRomNo9L-Regu,False,184.57656860351562,210.01034545898438,0.6666666666666666,3,P
sample_4.pdf,11,areo,5.406440258026123,NimbusRomNo9L-Regu,False,206.61712646484375,211.37704467773438,0.0,4,P
sample_4.pdf,11,bike,5.406440258026123,NimbusRomNo9L-Regu,False,223.76095581054688,211.37704467773438,0.0,4,P
sample_4.pdf,11,bird,5.406440258026123,NimbusRomNo9L-Regu,False,241.15347290039062,211.37704467773438,0.0,4,P
sample_4.pdf,11,boat,5.406440258026123,NimbusRomNo9L-Regu,False,257.9783020019531,211.37704467773438,0.0,4,P
sample_4.pdf,11,bottle,5.406440258026123,NimbusRomNo9L-Regu,False,273.59210205078125,211.37704467773438,0.0,6,P
sample_4.pdf,11,bus,5.406440258026123,NimbusRomNo9L-Regu,False,293.1688537597656,211.37704467773438,0.0,3,P
sample_4.pdf,11,car,5.406440258026123,NimbusRomNo9L-Regu,False,310.6911315917969,211.37704467773438,0.0,3,P
sample_4.pdf,11,cat,5.406440258026123,NimbusRomNo9L-Regu,False,327.95928955078125,211.37704467773438,0.0,3,P
sample_4.pdf,11,chair,5.406440258026123,NimbusRomNo9L-Regu,False,342.82696533203125,211.37704467773438,0.0,5,P
sample_4.pdf,11,cow,5.406440258026123,NimbusRomNo9L-Regu,False,360.9169006347656,211.37704467773438,0.0,3,P
sample_4.pdf,11,table,5.406440258026123,NimbusRomNo9L-Regu,False,377.2173156738281,211.37704467773438,0.0,5,P
sample_4.pdf,11,dog,5.406440258026123,NimbusRomNo9L-Regu,False,395.5397644042969,211.37704467773438,0.0,3,P
sample_4.pdf,11,horse,5.406440258026123,NimbusRomNo9L-Regu,False,410.8616027832031,211.37704467773438,0.0,5,P
sample_4.pdf,11,mbike person,5.406440258026123,NimbusRomNo9L-Regu,False,427.1025390625,211.37704467773438,0.0,12,P
sample_4.pdf,11,plant,5.406440258026123,NimbusRomNo9L-Regu,False,462.6715087890625,211.37704467773438,0.0,5,P
sample_4.pdf,11,sheep,5.406440258026123,NimbusRomNo9L-Regu,False,479.042236328125,211.37704467773438,0.0,5,P
sample_4.pdf,11,sofa,5.406440258026123,NimbusRomNo9L-Regu,False,497.8403015136719,211.37704467773438,0.0,4,P
sample_4.pdf,11,train,5.406440258026123,NimbusRomNo9L-Regu,False,514.4813232421875,211.37704467773438,0.0,5,P
sample_4.pdf,11,baseline,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,220.64303588867188,0.0,8,P
sample_4.pdf,11,VGG-16,7.208556652069092,NimbusRomNo9L-Regu,False,97.61190032958984,220.64303588867188,0.5,6,P
sample_4.pdf,11,07+12,7.208556652069092,NimbusRomNo9L-Regu,False,146.34185791015625,220.64303588867188,0.0,5,P
sample_4.pdf,11,73.2,7.208556652069092,NimbusRomNo9L-Regu,False,185.67910766601562,220.64303588867188,0.0,4,P
sample_4.pdf,11,76.5 79.0 70.9 65.5 52.1 83.1 84.7 86.4 52.0 81.9 65.7 84.8 84.6 77.5 76.7 38.8 73.6 73.9 83.0 72.6,7.208556652069092,NimbusRomNo9L-Regu,False,204.96197509765625,220.64303588867188,0.0,99,P
sample_4.pdf,11,baseline,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,230.91574096679688,0.0,8,P
sample_4.pdf,11,ResNet-101,7.208556652069092,NimbusRomNo9L-Regu,False,92.9521713256836,230.91580200195312,0.2,10,P
sample_4.pdf,11,07+12,7.208556652069092,NimbusRomNo9L-Regu,False,146.34185791015625,230.91580200195312,0.0,5,P
sample_4.pdf,11,76.4,7.208556652069092,NimbusRomNo9L-Regu,False,185.67910766601562,230.91580200195312,0.0,4,P
sample_4.pdf,11,79.8 80.7 76.2 68.3 55.9 85.1 85.3,7.208556652069092,NimbusRomNo9L-Regu,False,204.96197509765625,230.91580200195312,0.0,34,P
sample_4.pdf,11,89.8,7.208556652069092,NimbusRomNo9L-Medi,False,320.2988586425781,230.8499755859375,0.0,4,P
sample_4.pdf,11,56.7 87.8 69.4 88.3 88.9 80.9 78.4 41.7 78.6 79.8 85.3 72.0,7.208556652069092,NimbusRomNo9L-Regu,False,337.4192810058594,230.91580200195312,0.0,59,P
sample_4.pdf,11,baseline+++ ResNet-101,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,241.1876220703125,0.09090909090909091,22,P
sample_4.pdf,11,COCO+07+12,7.208556652069092,NimbusRomNo9L-Regu,False,134.29638671875,241.1876220703125,0.4,10,P
sample_4.pdf,11,85.6,7.208556652069092,NimbusRomNo9L-Medi,False,185.67910766601562,241.12179565429688,0.0,4,P
sample_4.pdf,11,90.0 89.6 87.8 80.8 76.1 89.9 89.9,7.208556652069092,NimbusRomNo9L-Medi,False,204.96197509765625,241.12179565429688,0.0,34,P
sample_4.pdf,11,89.6,7.208556652069092,NimbusRomNo9L-Regu,False,320.2988586425781,241.1876220703125,0.0,4,P
sample_4.pdf,11,75.5 90.0 80.7 89.6 90.3 89.1 88.7 65.4 88.1 85.6 89.0 86.8,7.208556652069092,NimbusRomNo9L-Medi,False,337.4192810058594,241.12179565429688,0.0,59,P
sample_4.pdf,11,Table 10. Detection results on the PASCAL VOC 2007 test set. The baseline is the Faster R-CNN system. The system “baseline+++”,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,255.38900756835938,0.14285714285714285,126,P
sample_4.pdf,11,"include box reﬁnement, context, and multi-scale testing in Table 9.",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,266.3479919433594,0.014925373134328358,67,P
sample_4.pdf,11,system,5.406440258026123,NimbusRomNo9L-Regu,False,53.26581573486328,297.0220947265625,0.0,6,P
sample_4.pdf,11,net,7.208556652069092,NimbusRomNo9L-Regu,False,105.76551818847656,295.6553955078125,0.0,3,P
sample_4.pdf,11,data,7.208556652069092,NimbusRomNo9L-Regu,False,149.57888793945312,295.6553955078125,0.0,4,P
sample_4.pdf,11,mAP,7.208556652069092,NimbusRomNo9L-Regu,False,184.57656860351562,295.6553955078125,0.6666666666666666,3,P
sample_4.pdf,11,areo,5.406440258026123,NimbusRomNo9L-Regu,False,206.61712646484375,297.0220947265625,0.0,4,P
sample_4.pdf,11,bike,5.406440258026123,NimbusRomNo9L-Regu,False,223.76095581054688,297.0220947265625,0.0,4,P
sample_4.pdf,11,bird,5.406440258026123,NimbusRomNo9L-Regu,False,241.15347290039062,297.0220947265625,0.0,4,P
sample_4.pdf,11,boat,5.406440258026123,NimbusRomNo9L-Regu,False,257.9783020019531,297.0220947265625,0.0,4,P
sample_4.pdf,11,bottle,5.406440258026123,NimbusRomNo9L-Regu,False,273.59210205078125,297.0220947265625,0.0,6,P
sample_4.pdf,11,bus,5.406440258026123,NimbusRomNo9L-Regu,False,293.1688537597656,297.0220947265625,0.0,3,P
sample_4.pdf,11,car,5.406440258026123,NimbusRomNo9L-Regu,False,310.6911315917969,297.0220947265625,0.0,3,P
sample_4.pdf,11,cat,5.406440258026123,NimbusRomNo9L-Regu,False,327.95928955078125,297.0220947265625,0.0,3,P
sample_4.pdf,11,chair,5.406440258026123,NimbusRomNo9L-Regu,False,342.82696533203125,297.0220947265625,0.0,5,P
sample_4.pdf,11,cow,5.406440258026123,NimbusRomNo9L-Regu,False,360.9169006347656,297.0220947265625,0.0,3,P
sample_4.pdf,11,table,5.406440258026123,NimbusRomNo9L-Regu,False,377.2173156738281,297.0220947265625,0.0,5,P
sample_4.pdf,11,dog,5.406440258026123,NimbusRomNo9L-Regu,False,395.5397644042969,297.0220947265625,0.0,3,P
sample_4.pdf,11,horse,5.406440258026123,NimbusRomNo9L-Regu,False,410.8616027832031,297.0220947265625,0.0,5,P
sample_4.pdf,11,mbike person,5.406440258026123,NimbusRomNo9L-Regu,False,427.1025390625,297.0220947265625,0.0,12,P
sample_4.pdf,11,plant,5.406440258026123,NimbusRomNo9L-Regu,False,462.6715087890625,297.0220947265625,0.0,5,P
sample_4.pdf,11,sheep,5.406440258026123,NimbusRomNo9L-Regu,False,479.042236328125,297.0220947265625,0.0,5,P
sample_4.pdf,11,sofa,5.406440258026123,NimbusRomNo9L-Regu,False,497.8403015136719,297.0220947265625,0.0,4,P
sample_4.pdf,11,train,5.406440258026123,NimbusRomNo9L-Regu,False,514.4813232421875,297.0220947265625,0.0,5,P
sample_4.pdf,11,baseline,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,306.2880859375,0.0,8,P
sample_4.pdf,11,VGG-16,7.208556652069092,NimbusRomNo9L-Regu,False,97.61190032958984,306.2880859375,0.5,6,P
sample_4.pdf,11,07++12,7.208556652069092,NimbusRomNo9L-Regu,False,144.3095703125,306.2880859375,0.0,6,P
sample_4.pdf,11,70.4,7.208556652069092,NimbusRomNo9L-Regu,False,185.67910766601562,306.2880859375,0.0,4,P
sample_4.pdf,11,84.9 79.8 74.3 53.9 49.8 77.5 75.9 88.5 45.6 77.1 55.3 86.9 81.7 80.9 79.6 40.1 72.6 60.9 81.2 61.5,7.208556652069092,NimbusRomNo9L-Regu,False,204.96197509765625,306.2880859375,0.0,99,P
sample_4.pdf,11,baseline,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,316.5599060058594,0.0,8,P
sample_4.pdf,11,ResNet-101,7.208556652069092,NimbusRomNo9L-Regu,False,92.9521713256836,316.5599060058594,0.2,10,P
sample_4.pdf,11,07++12,7.208556652069092,NimbusRomNo9L-Regu,False,144.3095703125,316.5599060058594,0.0,6,P
sample_4.pdf,11,73.8,7.208556652069092,NimbusRomNo9L-Regu,False,185.67910766601562,316.5599060058594,0.0,4,P
sample_4.pdf,11,86.5 81.6 77.2 58.0 51.0 78.6 76.6 93.2 48.6 80.4 59.0 92.1 85.3 84.8 80.7 48.1 77.3 66.5 84.7 65.6,7.208556652069092,NimbusRomNo9L-Regu,False,204.96197509765625,316.5599060058594,0.0,99,P
sample_4.pdf,11,baseline+++ ResNet-101 COCO+07++12,7.208556652069092,NimbusRomNo9L-Regu,False,53.26581573486328,326.8326721191406,0.17647058823529413,34,P
sample_4.pdf,11,83.8,7.208556652069092,NimbusRomNo9L-Medi,False,185.67910766601562,326.766845703125,0.0,4,P
sample_4.pdf,11,92.1 88.4 84.8 75.9 71.4 86.3 87.8 94.2 66.8 89.4 69.2 93.9 91.9 90.9 89.6 67.9 88.2 76.8 90.3 80.0,7.208556652069092,NimbusRomNo9L-Medi,False,204.96197509765625,326.766845703125,0.0,99,P
sample_4.pdf,11,Table 11. Detection results on the PASCAL VOC 2012 test set (,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,341.03399658203125,0.18032786885245902,61,P
sample_4.pdf,11,http://host.robots.ox.ac.uk:8080/leaderboard/,8.966400146484375,NimbusMonL-Regu,False,303.02001953125,340.574951171875,0.0,45,P
sample_4.pdf,11,displaylb.php?challengeid=11&compid=4,8.966400146484375,NimbusMonL-Regu,False,50.11201477050781,351.5339660644531,0.0,37,P
sample_4.pdf,11,). The baseline is the Faster R-CNN system. The system “baseline+++” include,8.966400146484375,NimbusRomNo9L-Regu,False,249.16500854492188,351.9930114746094,0.09210526315789473,76,P
sample_4.pdf,11,"box reﬁnement, context, and multi-scale testing in Table 9.",8.966400146484375,NimbusRomNo9L-Regu,False,50.11201477050781,362.9519958496094,0.01694915254237288,59,P
sample_4.pdf,11,We select two adjacent scales from the pyramid following,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,394.0254821777344,0.017857142857142856,56,H3
sample_4.pdf,11,[33]. RoI pooling and subsequent layers are performed on,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,405.98046875,0.03571428571428571,56,H3
sample_4.pdf,11,"the feature maps of these two scales [33], which are merged",9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,417.9354553222656,0.0,59,H3
sample_4.pdf,11,by maxout as in [33]. Multi-scale testing improves the mAP,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,429.89044189453125,0.05172413793103448,58,H3
sample_4.pdf,11,by over 2 points (Table 9).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11201477050781,441.8454284667969,0.037037037037037035,27,H3
sample_4.pdf,11,Using validation data.,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.11201477050781,459.24798583984375,0.045454545454545456,22,H3
sample_4.pdf,11,Next we use the 80k+40k trainval set,9.962599754333496,NimbusRomNo9L-Regu,False,138.58984375,459.4244384765625,0.027777777777777776,36,H3
sample_4.pdf,11,for training and the 20k test-dev set for evaluation. The test-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,471.38043212890625,0.015873015873015872,63,H3
sample_4.pdf,11,dev set has no publicly available ground truth and the result,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,483.3354187011719,0.0,61,H3
sample_4.pdf,11,"is reported by the evaluation server. Under this setting, the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,495.2904052734375,0.01639344262295082,61,H3
sample_4.pdf,11,"results are an mAP@.5 of 55.7% and an mAP@[.5, .95] of",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,507.245361328125,0.07407407407407407,54,H3
sample_4.pdf,11,34.9% (Table 9). This is our single-model result.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,519.2003784179688,0.04081632653061224,49,H3
sample_4.pdf,11,Ensemble.,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.11200714111328,536.6029052734375,0.1111111111111111,9,H3
sample_4.pdf,11,"In Faster R-CNN, the system is designed to learn",9.962599754333496,NimbusRomNo9L-Regu,False,91.18780517578125,536.7793579101562,0.125,48,H3
sample_4.pdf,11,"region proposals and also object classiﬁers, so an ensemble",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,548.734375,0.0,59,H3
sample_4.pdf,11,can be used to boost both tasks. We use an ensemble for,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,560.6903686523438,0.01818181818181818,55,H3
sample_4.pdf,11,"proposing regions, and the union set of proposals are pro-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,572.6453857421875,0.0,58,H3
sample_4.pdf,11,cessed by an ensemble of per-region classiﬁers. Table 9,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,584.600341796875,0.01818181818181818,55,H3
sample_4.pdf,11,shows our result based on an ensemble of 3 networks. The,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,596.5553588867188,0.017857142857142856,56,H3
sample_4.pdf,11,mAP is 59.0% and 37.4% on the test-dev set.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11200714111328,608.5103759765625,0.046511627906976744,43,H3
sample_4.pdf,11,This result,9.962599754333496,NimbusRomNo9L-ReguItal,False,237.5284423828125,608.3339233398438,0.09090909090909091,11,H3
sample_4.pdf,11,won the 1st place in the detection task in COCO 2015.,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.11199951171875,620.2889404296875,0.07547169811320754,53,H3
sample_4.pdf,11,PASCAL VOC,9.962599754333496,NimbusRomNo9L-Medi,False,50.11199951171875,642.9354248046875,0.9,10,H3
sample_4.pdf,11,We revisit the PASCAL VOC dataset based on the above,9.962599754333496,NimbusRomNo9L-Regu,False,62.06700134277344,655.6234130859375,0.19230769230769232,52,H3
sample_4.pdf,11,model. With the single model on the COCO dataset (55.7%,9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,667.5794067382812,0.09090909090909091,55,H3
sample_4.pdf,11,"mAP@.5 in Table 9), we ﬁne-tune this model on the PAS-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,679.5343627929688,0.1111111111111111,54,H3
sample_4.pdf,11,"CAL VOC sets. The improvements of box reﬁnement, con-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,691.4893798828125,0.1320754716981132,53,H3
sample_4.pdf,11,"text, and multi-scale testing are also adopted. By doing so",9.962599754333496,NimbusRomNo9L-Regu,False,50.11199951171875,703.4443969726562,0.01694915254237288,59,H3
sample_4.pdf,11,val2,8.966400146484375,NimbusRomNo9L-Regu,False,467.6940002441406,394.4219665527344,0.0,4,P
sample_4.pdf,11,test,8.966400146484375,NimbusRomNo9L-Regu,False,505.0899963378906,394.4219665527344,0.0,4,P
sample_4.pdf,11,GoogLeNet [44] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,334.81201171875,407.9709777832031,0.34615384615384615,26,P
sample_4.pdf,11,43.9,8.966400146484375,NimbusRomNo9L-Regu,False,503.47100830078125,407.9709777832031,0.0,4,P
sample_4.pdf,11,our single model (ILSVRC’15),8.966400146484375,NimbusRomNo9L-Regu,False,334.81201171875,421.5199890136719,0.21428571428571427,28,P
sample_4.pdf,11,60.5,8.966400146484375,NimbusRomNo9L-Regu,False,467.45599365234375,421.5199890136719,0.0,4,P
sample_4.pdf,11,58.8,8.966400146484375,NimbusRomNo9L-Regu,False,503.47100830078125,421.5199890136719,0.0,4,P
sample_4.pdf,11,our ensemble (ILSVRC’15),8.966400146484375,NimbusRomNo9L-Regu,False,334.81201171875,434.6709899902344,0.25,24,P
sample_4.pdf,11,63.6,8.966400146484375,NimbusRomNo9L-Medi,False,467.45599365234375,434.589111328125,0.0,4,P
sample_4.pdf,11,62.1,8.966400146484375,NimbusRomNo9L-Medi,False,503.47100830078125,434.589111328125,0.0,4,P
sample_4.pdf,11,"Table 12. Our results (mAP, %) on the ImageNet detection dataset.",8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,451.10699462890625,0.09230769230769231,65,P
sample_4.pdf,11,Our detection system is Faster R-CNN [32] with the improvements,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,462.0660095214844,0.09523809523809523,63,P
sample_4.pdf,11,"in Table 9, using ResNet-101.",8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,473.0249938964844,0.10344827586206896,29,P
sample_4.pdf,11,we achieve 85.6% mAP on PASCAL VOC 2007 (Table 10),9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,499.3694763183594,0.24,50,H3
sample_4.pdf,11,and 83.8% on PASCAL VOC 2012 (Table 11),9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,511.324462890625,0.2564102564102564,39,H3
sample_4.pdf,11,. The result,9.962599754333496,NimbusRomNo9L-Regu,False,498.4219970703125,511.324462890625,0.08333333333333333,12,H3
sample_4.pdf,11,on PASCAL VOC 2012 is 10 points higher than the previ-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,523.2794189453125,0.16666666666666666,54,H3
sample_4.pdf,11,ous state-of-the-art result [6].,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,535.2354736328125,0.0,32,H3
sample_4.pdf,11,ImageNet Detection,9.962599754333496,NimbusRomNo9L-Medi,False,308.86199951171875,557.1884765625,0.16666666666666666,18,H3
sample_4.pdf,11,The ImageNet Detection (DET) task involves 200 object,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,569.3604736328125,0.1320754716981132,53,H3
sample_4.pdf,11,categories. The accuracy is evaluated by mAP@.5. Our,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,581.3154296875,0.07692307692307693,52,H3
sample_4.pdf,11,object detection algorithm for ImageNet DET is the same,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,593.2704467773438,0.09090909090909091,55,H3
sample_4.pdf,11,as that for MS COCO in Table 9. The networks are pre-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,605.2254638671875,0.1509433962264151,53,H3
sample_4.pdf,11,"trained on the 1000-class ImageNet classiﬁcation set, and",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,617.1814575195312,0.03508771929824561,57,H3
sample_4.pdf,11,are ﬁne-tuned on the DET data. We split the validation set,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,629.136474609375,0.06896551724137931,58,H3
sample_4.pdf,11,into two parts (val1/val2) following [8]. We ﬁne-tune the,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,641.0914306640625,0.017543859649122806,57,H3
sample_4.pdf,11,detection models using the DET training set and the val1,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,653.0464477539062,0.05357142857142857,56,H3
sample_4.pdf,11,set. The val2 set is used for validation. We do not use other,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,665.00146484375,0.03278688524590164,61,H3
sample_4.pdf,11,ILSVRC 2015 data. Our single model with ResNet-101 has,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,676.9574584960938,0.16666666666666666,54,H3
sample_4.pdf,11,http://host.robots.ox.ac.uk:8080/anonymous/3OJ4OJ.html,6.4756999015808105,NimbusMonL-Regu,False,323.2080078125,697.7874145507812,0.07407407407407407,54,P
sample_4.pdf,11,submitted on 2015-11-26.,6.4756999015808105,NimbusRomNo9L-Regu,False,308.86199951171875,706.0889282226562,0.0,24,P
sample_4.pdf,12,LOC,7.145503520965576,NimbusRomNo9L-Regu,False,65.22957611083984,74.31365203857422,1.0,3,P
sample_4.pdf,12,method,7.145503520965576,NimbusRomNo9L-Regu,False,61.656982421875,83.48381805419922,0.0,6,P
sample_4.pdf,12,LOC,7.145503520965576,NimbusRomNo9L-Regu,False,104.6787109375,74.31365203857422,1.0,3,P
sample_4.pdf,12,network,7.145503520965576,NimbusRomNo9L-Regu,False,100.15220642089844,83.48381805419922,0.0,7,P
sample_4.pdf,12,testing,7.145503520965576,NimbusRomNo9L-Regu,False,132.38442993164062,78.85131072998047,0.0,7,P
sample_4.pdf,12,LOC error,7.145503520965576,NimbusRomNo9L-Regu,False,156.6275177001953,74.31365203857422,0.3333333333333333,9,P
sample_4.pdf,12,on GT CLS,7.145503520965576,NimbusRomNo9L-Regu,False,154.93406677246094,83.48381805419922,0.5555555555555556,9,P
sample_4.pdf,12,classiﬁcation,7.145503520965576,NimbusRomNo9L-Regu,False,191.77569580078125,74.31365203857422,0.0,13,P
sample_4.pdf,12,network,7.145503520965576,NimbusRomNo9L-Regu,False,198.75990295410156,83.48381805419922,0.0,7,P
sample_4.pdf,12,top-5 LOC error,7.145503520965576,NimbusRomNo9L-Regu,False,234.37185668945312,74.31365203857422,0.2,15,P
sample_4.pdf,12,on predicted CLS,7.145503520965576,NimbusRomNo9L-Regu,False,232.58197021484375,83.48381805419922,0.1875,16,P
sample_4.pdf,12,VGG’s [41],7.145503520965576,NimbusRomNo9L-Regu,False,55.461727142333984,92.97112274169922,0.3,10,P
sample_4.pdf,12,VGG-16,7.145503520965576,NimbusRomNo9L-Regu,False,99.37680053710938,92.97112274169922,0.5,6,P
sample_4.pdf,12,1-crop,7.145503520965576,NimbusRomNo9L-Regu,False,132.587646484375,92.97112274169922,0.0,6,P
sample_4.pdf,12,33.1 [41],7.145503520965576,NimbusRomNo9L-Regu,False,158.51065063476562,92.97112274169922,0.0,9,P
sample_4.pdf,12,RPN,7.145503520965576,NimbusRomNo9L-Regu,False,65.4264144897461,102.14128875732422,1.0,3,P
sample_4.pdf,12,ResNet-101 1-crop,7.145503520965576,NimbusRomNo9L-Regu,False,94.75704956054688,102.14128875732422,0.11764705882352941,17,P
sample_4.pdf,12,13.3,7.145503520965576,NimbusRomNo9L-Regu,False,165.35618591308594,102.14128875732422,0.0,4,P
sample_4.pdf,12,RPN,7.145503520965576,NimbusRomNo9L-Regu,False,65.4264144897461,111.31145477294922,1.0,3,P
sample_4.pdf,12,ResNet-101 dense,7.145503520965576,NimbusRomNo9L-Regu,False,94.75704956054688,111.31145477294922,0.125,16,P
sample_4.pdf,12,11.7,7.145503520965576,NimbusRomNo9L-Regu,False,165.35618591308594,111.31145477294922,0.0,4,P
sample_4.pdf,12,RPN,7.145503520965576,NimbusRomNo9L-Regu,False,65.4264144897461,120.79961395263672,1.0,3,P
sample_4.pdf,12,ResNet-101 dense,7.145503520965576,NimbusRomNo9L-Regu,False,94.75704956054688,120.79961395263672,0.125,16,P
sample_4.pdf,12,ResNet-101,7.145503520965576,NimbusRomNo9L-Regu,False,193.36553955078125,120.79961395263672,0.2,10,P
sample_4.pdf,12,14.4,7.145503520965576,NimbusRomNo9L-Regu,False,251.53512573242188,120.79961395263672,0.0,4,P
sample_4.pdf,12,RPN+RCNN ResNet-101 dense,7.145503520965576,NimbusRomNo9L-Regu,False,53.486167907714844,129.96893310546875,0.36,25,P
sample_4.pdf,12,ResNet-101,7.145503520965576,NimbusRomNo9L-Regu,False,193.36553955078125,129.96893310546875,0.2,10,P
sample_4.pdf,12,10.6,7.145503520965576,NimbusRomNo9L-Medi,False,251.53512573242188,129.9036865234375,0.0,4,P
sample_4.pdf,12,RPN+RCNN,7.145503520965576,NimbusRomNo9L-Regu,False,53.486167907714844,139.13912963867188,0.875,8,P
sample_4.pdf,12,ensemble,7.145503520965576,NimbusRomNo9L-Regu,False,98.3304443359375,139.13912963867188,0.0,8,P
sample_4.pdf,12,dense,7.145503520965576,NimbusRomNo9L-Regu,False,133.77745056152344,139.13912963867188,0.0,5,P
sample_4.pdf,12,ensemble,7.145503520965576,NimbusRomNo9L-Regu,False,196.93814086914062,139.13912963867188,0.0,8,P
sample_4.pdf,12,8.9,7.145503520965576,NimbusRomNo9L-Medi,False,253.32102966308594,139.07388305664062,0.0,3,P
sample_4.pdf,12,Table 13. Localization error (%) on the ImageNet validation. In,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,152.91995239257812,0.07936507936507936,63,P
sample_4.pdf,12,"the column of “LOC error on GT class” ([41]), the ground truth",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,163.87796020507812,0.08064516129032258,62,P
sample_4.pdf,12,"class is used. In the “testing” column, “1-crop” denotes testing",8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,174.83694458007812,0.015625,64,P
sample_4.pdf,12,on a center crop of 224,8.966400146484375,NimbusRomNo9L-Regu,False,50.11199951171875,185.79592895507812,0.0,23,P
sample_4.pdf,12,"224 pixels, “dense” denotes dense (fully",8.966400146484375,NimbusRomNo9L-Regu,False,141.10598754882812,185.79592895507812,0.0,40,P
sample_4.pdf,12,convolutional) and multi-scale testing.,8.966400146484375,NimbusRomNo9L-Regu,False,50.11198425292969,196.75491333007812,0.0,39,P
sample_4.pdf,12,58.8% mAP and our ensemble of 3 models has 62.1% mAP,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,224.4854278564453,0.07692307692307693,52,H3
sample_4.pdf,12,on the DET test set (Table 12).,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,236.44044494628906,0.12903225806451613,31,H3
sample_4.pdf,12,This result won the 1st place,9.962599754333496,NimbusRomNo9L-ReguItal,False,170.7989044189453,236.26397705078125,0.034482758620689655,29,H3
sample_4.pdf,12,in the ImageNet detection task in ILSVRC 2015,9.962599754333496,NimbusRomNo9L-ReguItal,False,50.111976623535156,248.218994140625,0.17777777777777778,45,H3
sample_4.pdf,12,", surpassing",9.962599754333496,NimbusRomNo9L-Regu,False,239.25698852539062,248.3954620361328,0.0,12,H3
sample_4.pdf,12,the second place by,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,260.3514404296875,0.0,19,H3
sample_4.pdf,12,8.5 points,9.962599754333496,NimbusRomNo9L-Medi,False,128.4080352783203,260.260498046875,0.0,10,H3
sample_4.pdf,12,(absolute).,9.962599754333496,NimbusRomNo9L-Regu,False,171.86416625976562,260.3514404296875,0.0,11,H3
sample_4.pdf,12,C. ImageNet Localization,11.9552001953125,NimbusRomNo9L-Medi,False,50.11198425292969,285.09814453125,0.16666666666666666,24,H3
sample_4.pdf,12,The ImageNet Localization (LOC) task [36] requires to,9.962599754333496,NimbusRomNo9L-Regu,False,62.066986083984375,306.4664306640625,0.1320754716981132,53,H3
sample_4.pdf,12,"classify and localize the objects. Following [40, 41], we",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,318.4214172363281,0.017543859649122806,57,H3
sample_4.pdf,12,assume that the image-level classiﬁers are ﬁrst adopted for,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,330.3774108886719,0.0,59,H3
sample_4.pdf,12,"predicting the class labels of an image, and the localiza-",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,342.3323974609375,0.0,58,H3
sample_4.pdf,12,tion algorithm only accounts for predicting bounding boxes,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,354.2873840332031,0.0,58,H3
sample_4.pdf,12,based on the predicted classes. We adopt the “per-class re-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,366.24237060546875,0.01694915254237288,59,H3
sample_4.pdf,12,"gression” (PCR) strategy [40, 41], learning a bounding box",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,378.1973571777344,0.05172413793103448,58,H3
sample_4.pdf,12,regressor for each class. We pre-train the networks for Im-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,390.15234375,0.03389830508474576,59,H3
sample_4.pdf,12,ageNet classiﬁcation and then ﬁne-tune them for localiza-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,402.10833740234375,0.017543859649122806,57,H3
sample_4.pdf,12,tion. We train networks on the provided 1000-class Ima-,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,414.0633239746094,0.03636363636363636,55,H3
sample_4.pdf,12,geNet training set.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,426.018310546875,0.05263157894736842,19,H3
sample_4.pdf,12,Our localization algorithm is based on the RPN frame-,9.962599754333496,NimbusRomNo9L-Regu,False,62.066986083984375,438.79229736328125,0.07547169811320754,53,H3
sample_4.pdf,12,work of [32] with a few modiﬁcations. Unlike the way in,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,450.7472839355469,0.01818181818181818,55,H3
sample_4.pdf,12,"[32] that is category-agnostic, our RPN for localization is",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,462.7032775878906,0.05084745762711865,59,H3
sample_4.pdf,12,designed in a,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,474.65826416015625,0.0,13,H3
sample_4.pdf,12,per-class,9.962599754333496,NimbusRomNo9L-ReguItal,False,103.0333023071289,474.4818115234375,0.0,9,H3
sample_4.pdf,12,form. This RPN ends with two sib-,9.962599754333496,NimbusRomNo9L-Regu,False,142.02862548828125,474.65826416015625,0.12121212121212122,33,H3
sample_4.pdf,12,ling 1,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,486.6132507324219,0.0,6,H3
sample_4.pdf,12,1 convolutional layers for binary classiﬁcation (,9.962599754333496,NimbusRomNo9L-Regu,False,80.95098114013672,486.6132507324219,0.0,49,H3
sample_4.pdf,12,cls,9.962599754333496,NimbusRomNo9L-ReguItal,False,271.9759826660156,486.4367980957031,0.0,3,H3
sample_4.pdf,12,and box regression (,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,498.5682373046875,0.0,20,H3
sample_4.pdf,12,reg,9.962599754333496,NimbusRomNo9L-ReguItal,False,131.95697021484375,498.39178466796875,0.0,3,H3
sample_4.pdf,12,"), as in [32]. The",9.962599754333496,NimbusRomNo9L-Regu,False,144.469970703125,498.5682373046875,0.05555555555555555,18,H3
sample_4.pdf,12,cls,9.962599754333496,NimbusRomNo9L-ReguItal,False,213.40118408203125,498.39178466796875,0.0,3,H3
sample_4.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,227.27244567871094,498.5682373046875,0.0,3,H3
sample_4.pdf,12,reg,9.962599754333496,NimbusRomNo9L-ReguItal,False,244.4579620361328,498.39178466796875,0.0,3,H3
sample_4.pdf,12,layers,9.962599754333496,NimbusRomNo9L-Regu,False,259.7710266113281,498.5682373046875,0.0,6,H3
sample_4.pdf,12,are both in a,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,510.523193359375,0.0,13,H3
sample_4.pdf,12,per-class,9.962599754333496,NimbusRomNo9L-ReguItal,False,102.91375732421875,510.34674072265625,0.0,9,H3
sample_4.pdf,12,"from, in contrast to [32]. Speciﬁ-",9.962599754333496,NimbusRomNo9L-Regu,False,142.82162475585938,510.523193359375,0.029411764705882353,34,H3
sample_4.pdf,12,"cally, the",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,522.4782104492188,0.0,10,H3
sample_4.pdf,12,cls,9.962599754333496,NimbusRomNo9L-ReguItal,False,85.89763641357422,522.3017578125,0.0,3,H3
sample_4.pdf,12,"layer has a 1000-d output, and each dimension",9.962599754333496,NimbusRomNo9L-Regu,False,99.34742736816406,522.4782104492188,0.0,45,H3
sample_4.pdf,12,binary logistic regression,9.962599754333496,NimbusRomNo9L-ReguItal,False,56.75703430175781,534.2577514648438,0.0,26,H3
sample_4.pdf,12,for predicting being or not be-,9.962599754333496,NimbusRomNo9L-Regu,False,161.4406280517578,534.4342041015625,0.0,31,H3
sample_4.pdf,12,ing an object class; the,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,546.3892211914062,0.0,24,H3
sample_4.pdf,12,reg,9.962599754333496,NimbusRomNo9L-ReguItal,False,146.86874389648438,546.2127685546875,0.0,3,H3
sample_4.pdf,12,layer has a 1000,9.962599754333496,NimbusRomNo9L-Regu,False,163.20602416992188,546.3892211914062,0.0,16,H3
sample_4.pdf,12,4-d output,9.962599754333496,NimbusRomNo9L-Regu,False,243.7939910888672,546.3892211914062,0.0,10,H3
sample_4.pdf,12,"consisting of box regressors for 1000 classes. As in [32],",9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,558.34423828125,0.017241379310344827,58,H3
sample_4.pdf,12,our bounding box regression is with reference to multiple,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,570.2991943359375,0.0,57,H3
sample_4.pdf,12,translation-invariant “anchor” boxes at each position.,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,582.2542114257812,0.0,54,H3
sample_4.pdf,12,"As in our ImageNet classiﬁcation training (Sec. 3.4), we",9.962599754333496,NimbusRomNo9L-Regu,False,62.066986083984375,595.0281982421875,0.07142857142857142,56,H3
sample_4.pdf,12,randomly sample 224,9.962599754333496,NimbusRomNo9L-Regu,False,50.11198425292969,606.9841918945312,0.0,19,H3
sample_4.pdf,12,224 crops for data augmentation.,9.962599754333496,NimbusRomNo9L-Regu,False,147.77597045898438,606.9841918945312,0.0,32,H3
sample_4.pdf,12,We use a mini-batch size of 256 images for ﬁne-tuning. To,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,618.939208984375,0.03508771929824561,57,H3
sample_4.pdf,12,"avoid negative samples being dominate, 8 anchors are ran-",9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,630.8942260742188,0.0,57,H3
sample_4.pdf,12,"domly sampled for each image, where the sampled positive",9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,642.8492431640625,0.0,56,H3
sample_4.pdf,12,"and negative anchors have a ratio of 1:1 [32]. For testing,",9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,654.80419921875,0.01694915254237288,59,H3
sample_4.pdf,12,the network is applied on the image fully-convolutionally.,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,666.7601928710938,0.0,58,H3
sample_4.pdf,12,Table 13 compares the localization results. Following,9.962599754333496,NimbusRomNo9L-Regu,False,62.06697082519531,679.5342407226562,0.03773584905660377,53,H3
sample_4.pdf,12,"[41], we ﬁrst perform “oracle” testing using the ground truth",9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,691.4891967773438,0.0,61,H3
sample_4.pdf,12,class as the classiﬁcation prediction. VGG’s paper [41] re-,9.962599754333496,NimbusRomNo9L-Regu,False,50.111968994140625,703.4442138671875,0.05084745762711865,59,H3
sample_4.pdf,12,method,8.966400146484375,NimbusRomNo9L-Regu,False,365.7760009765625,79.29696655273438,0.0,6,P
sample_4.pdf,12,top-5 localization err,8.966400146484375,NimbusRomNo9L-Regu,False,455.3280029296875,73.65298461914062,0.0,22,P
sample_4.pdf,12,val,8.966400146484375,NimbusRomNo9L-Regu,False,457.8080139160156,85.16000366210938,0.0,3,P
sample_4.pdf,12,test,8.966400146484375,NimbusRomNo9L-Regu,False,504.7090148925781,85.16000366210938,0.0,4,P
sample_4.pdf,12,OverFeat [40] (ILSVRC’13),8.966400146484375,NimbusRomNo9L-Regu,False,323.4460144042969,97.06600952148438,0.32,25,P
sample_4.pdf,12,30.0,8.966400146484375,NimbusRomNo9L-Regu,False,455.3280029296875,97.06600952148438,0.0,4,P
sample_4.pdf,12,29.9,8.966400146484375,NimbusRomNo9L-Regu,False,503.0899963378906,97.06600952148438,0.0,4,P
sample_4.pdf,12,GoogLeNet [44] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,323.44598388671875,108.57199096679688,0.34615384615384615,26,P
sample_4.pdf,12,26.7,8.966400146484375,NimbusRomNo9L-Regu,False,503.0899963378906,108.57199096679688,0.0,4,P
sample_4.pdf,12,VGG [41] (ILSVRC’14),8.966400146484375,NimbusRomNo9L-Regu,False,323.44598388671875,120.07901000976562,0.45,20,P
sample_4.pdf,12,26.9,8.966400146484375,NimbusRomNo9L-Regu,False,455.3280029296875,120.07901000976562,0.0,4,P
sample_4.pdf,12,25.3,8.966400146484375,NimbusRomNo9L-Regu,False,503.0899963378906,120.07901000976562,0.0,4,P
sample_4.pdf,12,ours (ILSVRC’15),8.966400146484375,NimbusRomNo9L-Regu,False,323.4460144042969,131.98495483398438,0.375,16,P
sample_4.pdf,12,8.9,8.966400146484375,NimbusRomNo9L-Medi,False,457.57000732421875,131.90309143066406,0.0,3,P
sample_4.pdf,12,9.0,8.966400146484375,NimbusRomNo9L-Medi,False,505.3320007324219,131.90309143066406,0.0,3,P
sample_4.pdf,12,Table 14. Comparisons of localization error (%) on the ImageNet,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,147.92800903320312,0.06349206349206349,63,P
sample_4.pdf,12,dataset with state-of-the-art methods.,8.966400146484375,NimbusRomNo9L-Regu,False,308.86199951171875,158.88699340820312,0.0,38,P
sample_4.pdf,12,ports a center-crop error of 33.1% (Table 13) using ground,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,183.16346740722656,0.017241379310344827,58,H3
sample_4.pdf,12,"truth classes. Under the same setting, our RPN method us-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,195.1184844970703,0.07017543859649122,57,H3
sample_4.pdf,12,ing ResNet-101 net signiﬁcantly reduces the center-crop er-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,207.07350158691406,0.03389830508474576,59,H3
sample_4.pdf,12,ror to 13.3%. This comparison demonstrates the excellent,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,219.0285186767578,0.017857142857142856,56,H3
sample_4.pdf,12,performance of our framework. With dense (fully convolu-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,230.98353576660156,0.017857142857142856,56,H3
sample_4.pdf,12,"tional) and multi-scale testing, our ResNet-101 has an error",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,242.9395294189453,0.03333333333333333,60,H3
sample_4.pdf,12,of 11.7% using ground truth classes. Using ResNet-101 for,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,254.89454650878906,0.05263157894736842,57,H3
sample_4.pdf,12,"predicting classes (4.6% top-5 classiﬁcation error, Table 4),",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,266.84954833984375,0.01639344262295082,61,H3
sample_4.pdf,12,the top-5 localization error is 14.4%.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,278.8045349121094,0.0,38,H3
sample_4.pdf,12,The above results are only based on the,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,290.759521484375,0.02564102564102564,39,H3
sample_4.pdf,12,proposal network,9.962599754333496,NimbusRomNo9L-ReguItal,False,474.141357421875,290.58306884765625,0.0,16,H3
sample_4.pdf,12,(RPN) in Faster R-CNN [32]. One may use the,9.962599754333496,NimbusRomNo9L-Regu,False,308.8619689941406,302.7145080566406,0.20930232558139536,43,H3
sample_4.pdf,12,detection,9.962599754333496,NimbusRomNo9L-ReguItal,False,505.2347412109375,302.5380554199219,0.0,9,H3
sample_4.pdf,12,network,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.86199951171875,314.4940490722656,0.0,7,H3
sample_4.pdf,12,(Fast R-CNN [7]) in Faster R-CNN to improve the,9.962599754333496,NimbusRomNo9L-Regu,False,340.96148681640625,314.6705017089844,0.2127659574468085,47,H3
sample_4.pdf,12,"results. But we notice that on this dataset, one image usually",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,326.62548828125,0.016129032258064516,62,H3
sample_4.pdf,12,"contains a single dominate object, and the proposal regions",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,338.5804748535156,0.0,59,H3
sample_4.pdf,12,highly overlap with each other and thus have very similar,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,350.53546142578125,0.0,57,H3
sample_4.pdf,12,"RoI-pooled features. As a result, the image-centric training",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,362.4904479980469,0.05,60,H3
sample_4.pdf,12,"of Fast R-CNN [7] generates samples of small variations,",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,374.4454345703125,0.08928571428571429,56,H3
sample_4.pdf,12,which may not be desired for stochastic training. Motivated,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,386.40142822265625,0.01694915254237288,59,H3
sample_4.pdf,12,"by this, in our current experiment we use the original R-",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,398.3564147949219,0.017543859649122806,57,H3
sample_4.pdf,12,"CNN [8] that is RoI-centric, in place of Fast R-CNN.",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,410.3114013671875,0.19230769230769232,52,H3
sample_4.pdf,12,Our R-CNN implementation is as follows. We apply the,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,422.2663879394531,0.11538461538461539,52,H3
sample_4.pdf,12,per-class RPN trained as above on the training images to,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,434.22137451171875,0.05357142857142857,56,H3
sample_4.pdf,12,predict bounding boxes for the ground truth class. These,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,446.1773681640625,0.017857142857142856,56,H3
sample_4.pdf,12,predicted boxes play a role of class-dependent proposals.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,458.1323547363281,0.0,57,H3
sample_4.pdf,12,"For each training image, the highest scored 200 proposals",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,470.08734130859375,0.017543859649122806,57,H3
sample_4.pdf,12,are extracted as training samples to train an R-CNN classi-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,482.0423278808594,0.06779661016949153,59,H3
sample_4.pdf,12,"ﬁer. The image region is cropped from a proposal, warped",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,493.997314453125,0.017857142857142856,56,H3
sample_4.pdf,12,to 224,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,505.9522705078125,0.0,6,H3
sample_4.pdf,12,"224 pixels, and fed into the classiﬁcation network",9.962599754333496,NimbusRomNo9L-Regu,False,342.45599365234375,505.9522705078125,0.0,50,H3
sample_4.pdf,12,as in R-CNN [8]. The outputs of this network consist of two,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,517.9083251953125,0.0847457627118644,59,H3
sample_4.pdf,12,sibling fc layers for,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,529.86328125,0.0,21,H3
sample_4.pdf,12,cls,9.962599754333496,NimbusRomNo9L-ReguItal,False,390.0271911621094,529.6868286132812,0.0,3,H3
sample_4.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,404.7304382324219,529.86328125,0.0,3,H3
sample_4.pdf,12,reg,9.962599754333496,NimbusRomNo9L-ReguItal,False,422.7469787597656,529.6868286132812,0.0,3,H3
sample_4.pdf,12,", also in a per-class form.",9.962599754333496,NimbusRomNo9L-Regu,False,438.8909912109375,529.86328125,0.0,27,H3
sample_4.pdf,12,This R-CNN network is ﬁne-tuned on the training set us-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,541.8182983398438,0.09090909090909091,55,H3
sample_4.pdf,12,ing a mini-batch size of 256 in the RoI-centric fashion. For,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,553.7733154296875,0.05,60,H3
sample_4.pdf,12,"testing, the RPN generates the highest scored 200 proposals",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,565.728271484375,0.05084745762711865,59,H3
sample_4.pdf,12,"for each predicted class, and the R-CNN network is used to",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,577.6832885742188,0.06896551724137931,58,H3
sample_4.pdf,12,update these proposals’ scores and box positions.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,589.6392822265625,0.0,49,H3
sample_4.pdf,12,This method reduces the top-5 localization error to,9.962599754333496,NimbusRomNo9L-Regu,False,320.8169860839844,601.5942993164062,0.0196078431372549,51,H3
sample_4.pdf,12,10.6% (Table 13). This is our single-model result on the,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,613.54931640625,0.03571428571428571,56,H3
sample_4.pdf,12,validation set. Using an ensemble of networks for both clas-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,625.5042724609375,0.016666666666666666,60,H3
sample_4.pdf,12,"siﬁcation and localization, we achieve a top-5 localization",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,637.4592895507812,0.0,59,H3
sample_4.pdf,12,error of 9.0% on the test set. This number signiﬁcantly out-,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,649.414306640625,0.016666666666666666,60,H3
sample_4.pdf,12,"performs the ILSVRC 14 results (Table 14), showing a 64%",9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,661.3703002929688,0.125,56,H3
sample_4.pdf,12,relative reduction of error.,9.962599754333496,NimbusRomNo9L-Regu,False,308.86199951171875,673.3253173828125,0.0,28,H3
sample_4.pdf,12,This result won the 1st place in,9.962599754333496,NimbusRomNo9L-ReguItal,False,414.24627685546875,673.1488647460938,0.03125,32,H3
sample_4.pdf,12,the ImageNet localization task in ILSVRC 2015.,9.962599754333496,NimbusRomNo9L-ReguItal,False,308.86199951171875,685.1038818359375,0.17391304347826086,46,H3
sample_5.pdf,1,Faster R-CNN: Towards Real-Time Object,23.91029930114746,NimbusSanL-Regu,False,58.95599365234375,60.32551574707031,0.23684210526315788,38,TITLE
sample_5.pdf,1,Detection with Region Proposal Networks,23.91029930114746,NimbusSanL-Regu,False,61.107994079589844,88.22151184082031,0.10256410256410256,39,TITLE
sample_5.pdf,1,"Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun",10.958900451660156,NimbusSanL-Regu,False,143.3179931640625,126.53060913085938,0.1509433962264151,53,H3
sample_5.pdf,1,Abstract,7.970099925994873,NimbusSanL-Bold,True,56.83399200439453,158.56976318359375,0.125,8,P
sample_5.pdf,1,—State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations.,7.970099925994873,NimbusSanL-Regu,False,89.15998840332031,158.56317138671875,0.008849557522123894,113,P
sample_5.pdf,1,"Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region",7.970099925994873,NimbusSanL-Regu,False,56.833988189697266,168.8741455078125,0.07627118644067797,118,P
sample_5.pdf,1,"proposal computation as a bottleneck. In this work, we introduce a",7.970099925994873,NimbusSanL-Regu,False,56.833988189697266,179.1861572265625,0.015151515151515152,66,P
sample_5.pdf,1,Region Proposal Network,7.970099925994873,NimbusSanL-ReguItal,False,301.1334533691406,179.1861572265625,0.13043478260869565,23,P
sample_5.pdf,1,(RPN) that shares full-image,7.970099925994873,NimbusSanL-Regu,False,397.18817138671875,179.1861572265625,0.10714285714285714,28,P
sample_5.pdf,1,"convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional",7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,189.49713134765625,0.030534351145038167,131,P
sample_5.pdf,1,network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to,7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,199.80810546875,0.032520325203252036,123,P
sample_5.pdf,1,"generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN",7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,210.1201171875,0.11764705882352941,119,P
sample_5.pdf,1,into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with,7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,220.43109130859375,0.0,124,P
sample_5.pdf,1,"“attention” mechanisms, the RPN component tells the uniﬁed network where to look. For the very deep VGG-16 model [3],",7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,230.7420654296875,0.05982905982905983,117,P
sample_5.pdf,1,our detection system has a frame rate of 5fps (,7.970099925994873,NimbusSanL-Regu,False,56.834014892578125,241.05303955078125,0.0,47,P
sample_5.pdf,1,including all steps,7.970099925994873,NimbusSanL-ReguItal,False,226.25601196289062,241.05303955078125,0.0,19,P
sample_5.pdf,1,") on a GPU, while achieving state-of-the-art object detection",7.970099925994873,NimbusSanL-Regu,False,290.4520263671875,241.05303955078125,0.04918032786885246,61,P
sample_5.pdf,1,"accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO",7.970099925994873,NimbusSanL-Regu,False,56.83403015136719,251.36505126953125,0.23853211009174313,109,P
sample_5.pdf,1,"2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been",7.970099925994873,NimbusSanL-Regu,False,56.83403015136719,261.6760559082031,0.072,125,P
sample_5.pdf,1,made publicly available.,7.970099925994873,NimbusSanL-Regu,False,56.83403015136719,271.987060546875,0.0,24,P
sample_5.pdf,1,Index Terms,7.970099925994873,NimbusSanL-Bold,True,56.83403015136719,293.0466613769531,0.18181818181818182,11,P
sample_5.pdf,1,"—Object Detection, Region Proposal, Convolutional Neural Network.",7.970099925994873,NimbusSanL-Regu,False,103.18702697753906,293.0400695800781,0.1076923076923077,65,P
sample_5.pdf,1,NTRODUCTION,9.56410026550293,NimbusSanL-Bold,True,59.41999816894531,356.619140625,1.0,11,H3
sample_5.pdf,1,Recent advances in object detection are driven by,9.962599754333496,URWPalladioL-Roma,False,36.0,373.7564697265625,0.02040816326530612,49,H3
sample_5.pdf,1,the success of region proposal methods (,9.962599754333496,URWPalladioL-Roma,False,36.0,385.7114562988281,0.0,40,H3
sample_5.pdf,1,e.g,9.962599754333496,URWPalladioL-Ital,False,237.5030059814453,385.5415954589844,0.0,3,H3
sample_5.pdf,1,"., [4])",9.962599754333496,URWPalladioL-Roma,False,248.85000610351562,385.7114562988281,0.0,7,H3
sample_5.pdf,1,and region-based convolutional neural networks (R-,9.962599754333496,URWPalladioL-Roma,False,36.0,397.66644287109375,0.02,50,H3
sample_5.pdf,1,CNNs) [5]. Although region-based CNNs were com-,9.962599754333496,URWPalladioL-Roma,False,36.0,409.6214294433594,0.14893617021276595,47,H3
sample_5.pdf,1,"putationally expensive as originally developed in [5],",9.962599754333496,URWPalladioL-Roma,False,36.0,421.5774230957031,0.0,54,H3
sample_5.pdf,1,their cost has been drastically reduced thanks to shar-,9.962599754333496,URWPalladioL-Roma,False,36.0,433.53240966796875,0.0,55,H3
sample_5.pdf,1,"ing convolutions across proposals [1], [2]. The latest",9.962599754333496,URWPalladioL-Roma,False,36.0,445.4873962402344,0.018518518518518517,54,H3
sample_5.pdf,1,"incarnation, Fast R-CNN [2], achieves near real-time",9.962599754333496,URWPalladioL-Roma,False,36.0,457.4423828125,0.09615384615384616,52,H3
sample_5.pdf,1,"rates using very deep networks [3],",9.962599754333496,URWPalladioL-Roma,False,36.0,469.3973693847656,0.0,35,H3
sample_5.pdf,1,when ignoring the,9.962599754333496,URWPalladioL-Ital,False,195.96945190429688,469.2275085449219,0.0,17,H3
sample_5.pdf,1,time spent on region proposals,9.962599754333496,URWPalladioL-Ital,False,36.0,481.1824951171875,0.0,30,H3
sample_5.pdf,1,". Now, proposals are the",9.962599754333496,URWPalladioL-Roma,False,163.37200927734375,481.35235595703125,0.041666666666666664,24,H3
sample_5.pdf,1,test-time computational bottleneck in state-of-the-art,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,493.308349609375,0.0,54,H3
sample_5.pdf,1,detection systems.,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,505.26336669921875,0.0,18,H3
sample_5.pdf,1,Region proposal methods typically rely on inex-,9.962599754333496,URWPalladioL-Roma,False,45.963008880615234,517.5023193359375,0.02127659574468085,47,H3
sample_5.pdf,1,pensive features and economical inference schemes.,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,529.4573364257812,0.0,50,H3
sample_5.pdf,1,"Selective Search [4], one of the most popular meth-",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,541.413330078125,0.0392156862745098,51,H3
sample_5.pdf,1,"ods, greedily merges superpixels based on engineered",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,553.3683471679688,0.0,52,H3
sample_5.pdf,1,low-level features. Yet when compared to efﬁcient,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,565.3233032226562,0.02040816326530612,49,H3
sample_5.pdf,1,"detection networks [2], Selective Search is an order of",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,577.2783203125,0.03636363636363636,55,H3
sample_5.pdf,1,"magnitude slower, at 2 seconds per image in a CPU",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,589.2333374023438,0.061224489795918366,49,H3
sample_5.pdf,1,implementation. EdgeBoxes [6] currently provides the,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,601.1883544921875,0.038461538461538464,52,H3
sample_5.pdf,1,"best tradeoff between proposal quality and speed,",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,613.1443481445312,0.0,49,H3
sample_5.pdf,1,"at 0.2 seconds per image. Nevertheless, the region",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,625.0993041992188,0.02,50,H3
sample_5.pdf,1,proposal step still consumes as much running time,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,637.0543212890625,0.0,49,H3
sample_5.pdf,1,as the detection network.,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,649.0093383789062,0.0,25,H3
sample_5.pdf,1,"S. Ren is with University of Science and Technology of China, Hefei,",7.970099925994873,URWPalladioL-Ital,False,39.81712341308594,673.43603515625,0.10294117647058823,68,P
sample_5.pdf,1,China. This work was done when S. Ren was an intern at Microsoft,7.970099925994873,URWPalladioL-Ital,False,45.7969970703125,682.403076171875,0.078125,64,P
sample_5.pdf,1,Research. Email: sqren@mail.ustc.edu.cn,7.970099925994873,URWPalladioL-Ital,False,45.7969970703125,691.3690795898438,0.05128205128205128,39,P
sample_5.pdf,1,"K. He and J. Sun are with Visual Computing Group, Microsoft",7.970099925994873,URWPalladioL-Ital,False,39.81712341308594,700.3350830078125,0.13559322033898305,59,P
sample_5.pdf,1,Research. E-mail:,7.970099925994873,URWPalladioL-Ital,False,45.7969970703125,709.3020629882812,0.11764705882352941,17,P
sample_5.pdf,1,"kahe,jiansun",7.970099925994873,URWPalladioL-Ital,False,109.63099670410156,709.3020629882812,0.0,12,P
sample_5.pdf,1,@microsoft.com,7.970099925994873,URWPalladioL-Ital,False,154.3839874267578,709.3020629882812,0.0,14,P
sample_5.pdf,1,R. Girshick is with Facebook AI Research. The majority of this work,7.970099925994873,URWPalladioL-Ital,False,39.817108154296875,718.26806640625,0.1044776119402985,67,P
sample_5.pdf,1,was done when R. Girshick was with Microsoft Research. E-mail:,7.970099925994873,URWPalladioL-Ital,False,45.79698181152344,727.2340698242188,0.08064516129032258,62,P
sample_5.pdf,1,rbg@fb.com,7.970099925994873,URWPalladioL-Ital,False,45.79698181152344,736.2010498046875,0.0,10,P
sample_5.pdf,1,One may note that fast region-based CNNs take,9.962599754333496,URWPalladioL-Roma,False,297.02099609375,356.82550048828125,0.08888888888888889,45,H3
sample_5.pdf,1,"advantage of GPUs, while the region proposal meth-",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,368.7804870605469,0.06,50,H3
sample_5.pdf,1,"ods used in research are implemented on the CPU,",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,380.7354736328125,0.0625,48,H3
sample_5.pdf,1,making such runtime comparisons inequitable. An ob-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,392.6904602050781,0.0196078431372549,51,H3
sample_5.pdf,1,vious way to accelerate proposal computation is to re-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,404.64544677734375,0.0,54,H3
sample_5.pdf,1,implement it for the GPU. This may be an effective en-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,416.6004333496094,0.07407407407407407,54,H3
sample_5.pdf,1,"gineering solution, but re-implementation ignores the",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,428.5564270019531,0.0,53,H3
sample_5.pdf,1,down-stream detection network and therefore misses,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,440.51141357421875,0.0,50,H3
sample_5.pdf,1,important opportunities for sharing computation.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,452.4664001464844,0.0,48,H3
sample_5.pdf,1,"In this paper, we show that an algorithmic change—",9.962599754333496,URWPalladioL-Roma,False,297.02099609375,464.42138671875,0.02,50,H3
sample_5.pdf,1,computing proposals with a deep convolutional neu-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,476.3763732910156,0.0,50,H3
sample_5.pdf,1,ral network—leads to an elegant and effective solution,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,488.33135986328125,0.0,54,H3
sample_5.pdf,1,where proposal computation is nearly cost-free given,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,500.287353515625,0.0,52,H3
sample_5.pdf,1,"the detection network’s computation. To this end, we",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,512.2423706054688,0.019230769230769232,52,H3
sample_5.pdf,1,introduce novel,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,524.1973266601562,0.0,15,H3
sample_5.pdf,1,Region Proposal Networks,9.962599754333496,URWPalladioL-Ital,False,357.5942687988281,524.0274658203125,0.125,24,H3
sample_5.pdf,1,(RPNs) that,9.962599754333496,URWPalladioL-Roma,False,469.94268798828125,524.1973266601562,0.2727272727272727,11,H3
sample_5.pdf,1,share convolutional layers with state-of-the-art object,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,536.15234375,0.0,55,H3
sample_5.pdf,1,"detection networks [1], [2]. By sharing convolutions at",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,548.1073608398438,0.01818181818181818,55,H3
sample_5.pdf,1,"test-time, the marginal cost for computing proposals",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,560.0633544921875,0.0,52,H3
sample_5.pdf,1,is small (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,572.0183715820312,0.0,10,H3
sample_5.pdf,1,e.g,9.962599754333496,URWPalladioL-Ital,False,328.2739562988281,571.8485107421875,0.0,3,H3
sample_5.pdf,1,"., 10ms per image).",9.962599754333496,URWPalladioL-Roma,False,339.6209716796875,572.0183715820312,0.0,19,H3
sample_5.pdf,1,Our observation is that the convolutional feature,9.962599754333496,URWPalladioL-Roma,False,297.0209655761719,583.9733276367188,0.02040816326530612,49,H3
sample_5.pdf,1,"maps used by region-based detectors, like Fast R-",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,595.9283447265625,0.04081632653061224,49,H3
sample_5.pdf,1,"CNN, can also be used for generating region pro-",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,607.8833618164062,0.0625,48,H3
sample_5.pdf,1,"posals. On top of these convolutional features, we",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,619.83837890625,0.02,50,H3
sample_5.pdf,1,construct an RPN by adding a few additional con-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,631.7943725585938,0.0625,48,H3
sample_5.pdf,1,volutional layers that simultaneously regress region,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,643.7493286132812,0.0,52,H3
sample_5.pdf,1,bounds and objectness scores at each location on a,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,655.704345703125,0.0,50,H3
sample_5.pdf,1,regular grid. The RPN is thus a kind of fully convo-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,667.6593627929688,0.07692307692307693,52,H3
sample_5.pdf,1,lutional network (FCN) [7] and can be trained end-to-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,679.6143798828125,0.05660377358490566,53,H3
sample_5.pdf,1,end speciﬁcally for the task for generating detection,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,691.5693969726562,0.0,53,H3
sample_5.pdf,1,proposals.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,703.525390625,0.0,10,H3
sample_5.pdf,1,RPNs are designed to efﬁciently predict region pro-,9.962599754333496,URWPalladioL-Roma,False,297.0209655761719,715.4803466796875,0.058823529411764705,51,H3
sample_5.pdf,1,posals with a wide range of scales and aspect ratios. In,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,727.4353637695312,0.017857142857142856,56,H3
sample_5.pdf,1,"contrast to prevalent methods [8], [9], [1], [2] that use",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,739.390380859375,0.0,57,H3
sample_5.pdf,1,arXiv:1506.01497v3  [cs.CV]  6 Jan 2016,20.0,Times-Roman,False,10.940000534057617,201.47998046875,0.10256410256410256,39,TITLE
sample_5.pdf,2,multiple scaled images,7.621291637420654,TT79o00,False,168.58705139160156,124.17349243164062,0.0,22,P
sample_5.pdf,2,multiple filter sizes,7.621291637420654,TT79o00,False,293.5139465332031,66.60272979736328,0.0,21,P
sample_5.pdf,2,multiple references,7.621291637420654,TT79o00,False,464.2936706542969,72.97407531738281,0.0,19,P
sample_5.pdf,2,(a),8.531269073486328,TT7Ao00,False,141.052978515625,140.63209533691406,0.0,3,P
sample_5.pdf,2,(b),8.531269073486328,TT7Ao00,False,326.38397216796875,140.63209533691406,0.0,3,P
sample_5.pdf,2,(c),8.531269073486328,TT7Ao00,False,454.6028747558594,140.63209533691406,0.0,3,P
sample_5.pdf,2,image,4.777487754821777,TT7Bo00,False,79.72726440429688,132.82701110839844,0.0,5,P
sample_5.pdf,2,feature map,4.777487754821777,TT7Bo00,False,83.82347106933594,96.64612579345703,0.0,11,P
sample_5.pdf,2,image,4.777487754821777,TT7Bo00,False,309.556640625,132.82701110839844,0.0,5,P
sample_5.pdf,2,feature map,4.777487754821777,TT7Bo00,False,313.6528625488281,96.64612579345703,0.0,11,P
sample_5.pdf,2,image,4.777487754821777,TT7Bo00,False,440.1726379394531,132.82701110839844,0.0,5,P
sample_5.pdf,2,feature map,4.777487754821777,TT7Bo00,False,444.3825378417969,96.64612579345703,0.0,11,P
sample_5.pdf,2,Figure 1: Different schemes for addressing multiple scales and sizes. (a) Pyramids of images and feature maps,9.962599754333496,URWPalladioL-Roma,False,36.0,159.0384521484375,0.027522935779816515,109,H3
sample_5.pdf,2,"are built, and the classiﬁer is run at all scales. (b) Pyramids of ﬁlters with multiple scales/sizes are run on",9.962599754333496,URWPalladioL-Roma,False,36.0,170.99444580078125,0.009009009009009009,111,H3
sample_5.pdf,2,the feature map. (c) We use pyramids of reference boxes in the regression functions.,9.962599754333496,URWPalladioL-Roma,False,36.0,182.949462890625,0.011904761904761904,84,H3
sample_5.pdf,2,"pyramids of images (Figure 1, a) or pyramids of ﬁlters",9.962599754333496,URWPalladioL-Roma,False,36.0,218.814453125,0.018518518518518517,54,H3
sample_5.pdf,2,"(Figure 1, b), we introduce novel “anchor” boxes",9.962599754333496,URWPalladioL-Roma,False,36.0,230.76947021484375,0.020833333333333332,48,H3
sample_5.pdf,2,that serve as references at multiple scales and aspect,9.962599754333496,URWPalladioL-Roma,False,36.0,242.7254638671875,0.0,54,H3
sample_5.pdf,2,ratios. Our scheme can be thought of as a pyramid,9.962599754333496,URWPalladioL-Roma,False,36.0,254.68048095703125,0.02040816326530612,49,H3
sample_5.pdf,2,"of regression references (Figure 1, c), which avoids",9.962599754333496,URWPalladioL-Roma,False,36.0,266.6354675292969,0.019230769230769232,52,H3
sample_5.pdf,2,enumerating images or ﬁlters of multiple scales or,9.962599754333496,URWPalladioL-Roma,False,36.0,278.5904541015625,0.0,50,H3
sample_5.pdf,2,aspect ratios. This model performs well when trained,9.962599754333496,URWPalladioL-Roma,False,36.0,290.5454406738281,0.019230769230769232,52,H3
sample_5.pdf,2,and tested using single-scale images and thus beneﬁts,9.962599754333496,URWPalladioL-Roma,False,36.0,302.5014343261719,0.0,53,H3
sample_5.pdf,2,running speed.,9.962599754333496,URWPalladioL-Roma,False,36.0,314.4564208984375,0.0,14,H3
sample_5.pdf,2,To unify RPNs with Fast R-CNN [2] object detec-,9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,326.8664245605469,0.19148936170212766,47,H3
sample_5.pdf,2,"tion networks, we propose a training scheme that",9.962599754333496,URWPalladioL-Roma,False,36.0,338.8214111328125,0.0,48,H3
sample_5.pdf,2,alternates between ﬁne-tuning for the region proposal,9.962599754333496,URWPalladioL-Roma,False,36.0,350.7763977050781,0.0,53,H3
sample_5.pdf,2,"task and then ﬁne-tuning for object detection, while",9.962599754333496,URWPalladioL-Roma,False,36.0,362.73138427734375,0.0,52,H3
sample_5.pdf,2,keeping the proposals ﬁxed. This scheme converges,9.962599754333496,URWPalladioL-Roma,False,36.0,374.6873779296875,0.02040816326530612,49,H3
sample_5.pdf,2,quickly and produces a uniﬁed network with convo-,9.962599754333496,URWPalladioL-Roma,False,36.0,386.6423645019531,0.0,49,H3
sample_5.pdf,2,lutional features that are shared between both tasks.,9.962599754333496,URWPalladioL-Roma,False,36.0,398.59735107421875,0.0,53,H3
sample_5.pdf,2,We comprehensively evaluate our method on the,9.962599754333496,URWPalladioL-Roma,False,45.962982177734375,411.0073547363281,0.022222222222222223,45,H3
sample_5.pdf,2,PASCAL VOC detection benchmarks [11] where RPNs,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,422.96234130859375,0.2553191489361702,47,H3
sample_5.pdf,2,with Fast R-CNNs produce detection accuracy bet-,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,434.9183349609375,0.10416666666666667,48,H3
sample_5.pdf,2,ter than the strong baseline of Selective Search with,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,446.8733215332031,0.03773584905660377,53,H3
sample_5.pdf,2,"Fast R-CNNs. Meanwhile, our method waives nearly",9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,458.82830810546875,0.125,48,H3
sample_5.pdf,2,all computational burdens of Selective Search at,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,470.7832946777344,0.041666666666666664,48,H3
sample_5.pdf,2,test-time—the effective running time for proposals,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,482.73828125,0.0,50,H3
sample_5.pdf,2,is just 10 milliseconds. Using the expensive very,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,494.6932678222656,0.02040816326530612,49,H3
sample_5.pdf,2,"deep models of [3], our detection method still has",9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,506.64923095703125,0.0,50,H3
sample_5.pdf,2,a frame rate of 5fps (,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,518.604248046875,0.0,22,H3
sample_5.pdf,2,including all steps,9.962599754333496,URWPalladioL-Ital,False,138.5909881591797,518.4343872070312,0.0,19,H3
sample_5.pdf,2,") on a GPU,",9.962599754333496,URWPalladioL-Roma,False,217.13497924804688,518.604248046875,0.2727272727272727,11,H3
sample_5.pdf,2,and thus is a practical object detection system in,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,530.5592651367188,0.0,50,H3
sample_5.pdf,2,terms of both speed and accuracy. We also report,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,542.5142822265625,0.020833333333333332,48,H3
sample_5.pdf,2,results on the MS COCO dataset [12] and investi-,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,554.4692993164062,0.125,48,H3
sample_5.pdf,2,gate the improvements on PASCAL VOC using the,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,566.4252319335938,0.2,45,H3
sample_5.pdf,2,COCO data. Code has been made publicly available,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,578.3802490234375,0.10416666666666667,48,H3
sample_5.pdf,2,https://github.com/shaoqingren/faster_,9.962599754333496,NimbusMonL-Regu,False,44.22909164428711,589.417236328125,0.0,38,H3
sample_5.pdf,2,rcnn,9.962599754333496,NimbusMonL-Regu,False,35.99998474121094,601.3722534179688,0.0,4,H3
sample_5.pdf,2,(in MATLAB) and,9.962599754333496,URWPalladioL-Roma,False,59.91023254394531,602.290283203125,0.4,15,H3
sample_5.pdf,2,https://github.com/,9.962599754333496,NimbusMonL-Regu,False,154.7880859375,601.3722534179688,0.0,19,H3
sample_5.pdf,2,rbgirshick/py-faster-rcnn,9.962599754333496,NimbusMonL-Regu,False,35.99999237060547,613.3272705078125,0.0,25,H3
sample_5.pdf,2,(in Python).,9.962599754333496,URWPalladioL-Roma,False,186.4352264404297,614.2453002929688,0.08333333333333333,12,H3
sample_5.pdf,2,A preliminary version of this manuscript was pub-,9.962599754333496,URWPalladioL-Roma,False,45.96299743652344,626.6552734375,0.02040816326530612,49,H3
sample_5.pdf,2,"lished previously [10]. Since then, the frameworks of",9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,638.6112670898438,0.018867924528301886,53,H3
sample_5.pdf,2,RPN and Faster R-CNN have been adopted and gen-,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,650.5662841796875,0.1702127659574468,47,H3
sample_5.pdf,2,"eralized to other methods, such as 3D object detection",9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,662.5213012695312,0.018518518518518517,54,H3
sample_5.pdf,2,"[13], part-based detection [14], instance segmentation",9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,674.4762573242188,0.0,54,H3
sample_5.pdf,2,"[15], and image captioning [16]. Our fast and effective",9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,686.4312744140625,0.01818181818181818,55,H3
sample_5.pdf,2,object detection system has also been built in com-,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,698.3872680664062,0.0,51,H3
sample_5.pdf,2,1. Since the publication of the conference version of this paper,7.970099925994873,URWPalladioL-Roma,False,43.96999740600586,722.8867797851562,0.015625,64,P
sample_5.pdf,2,"[10], we have also found that RPNs can be trained jointly with Fast",7.970099925994873,URWPalladioL-Roma,False,35.999996185302734,731.853759765625,0.05970149253731343,67,P
sample_5.pdf,2,R-CNN networks leading to less training time.,7.970099925994873,URWPalladioL-Roma,False,35.999996185302734,740.8197631835938,0.08888888888888889,45,P
sample_5.pdf,2,"mercial systems such as at Pinterests [17], with user",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,218.81524658203125,0.018867924528301886,53,H3
sample_5.pdf,2,engagement improvements reported.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,230.770263671875,0.0,33,H3
sample_5.pdf,2,"In ILSVRC and COCO 2015 competitions, Faster",9.962599754333496,URWPalladioL-Roma,False,297.02099609375,243.11126708984375,0.2727272727272727,44,H3
sample_5.pdf,2,R-CNN and RPN are the basis of several 1st-place,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,255.06625366210938,0.14583333333333334,48,H3
sample_5.pdf,2,"entries [18] in the tracks of ImageNet detection, Ima-",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,267.0222473144531,0.05555555555555555,54,H3
sample_5.pdf,2,"geNet localization, COCO detection, and COCO seg-",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,278.97723388671875,0.1836734693877551,49,H3
sample_5.pdf,2,mentation. RPNs completely learn to propose regions,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,290.9322204589844,0.058823529411764705,51,H3
sample_5.pdf,2,"from data, and thus can easily beneﬁt from deeper",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,302.88720703125,0.0,49,H3
sample_5.pdf,2,and more expressive features (such as the 101-layer,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,314.8421936035156,0.0,51,H3
sample_5.pdf,2,residual nets adopted in [18]). Faster R-CNN and RPN,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,326.7981872558594,0.15384615384615385,52,H3
sample_5.pdf,2,are also used by several other leading entries in these,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,338.753173828125,0.0,55,H3
sample_5.pdf,2,competitions,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,350.7081604003906,0.0,12,H3
sample_5.pdf,2,. These results suggest that our method,9.962599754333496,URWPalladioL-Roma,False,348.2179870605469,350.7081604003906,0.02564102564102564,39,H3
sample_5.pdf,2,"is not only a cost-efﬁcient solution for practical usage,",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,362.66314697265625,0.0,57,H3
sample_5.pdf,2,but also an effective way of improving object detec-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,374.6181335449219,0.0,52,H3
sample_5.pdf,2,tion accuracy.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,386.5731201171875,0.0,14,H3
sample_5.pdf,2,ELATED,9.56410026550293,NimbusSanL-Bold,True,315.7869873046875,418.582763671875,1.0,6,H3
sample_5.pdf,2,ORK,9.56410026550293,NimbusSanL-Bold,True,371.71197509765625,418.582763671875,1.0,3,H3
sample_5.pdf,2,Object Proposals.,9.962599754333496,URWPalladioL-Bold,True,287.0589599609375,436.2398376464844,0.11764705882352941,17,H3
sample_5.pdf,2,There is a large literature on object,9.962599754333496,URWPalladioL-Roma,False,367.5468444824219,436.3341369628906,0.02702702702702703,37,H3
sample_5.pdf,2,proposal methods. Comprehensive surveys and com-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,448.28912353515625,0.020833333333333332,48,H3
sample_5.pdf,2,parisons of object proposal methods can be found in,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,460.2441101074219,0.0,51,H3
sample_5.pdf,2,"[19], [20], [21]. Widely used object proposal methods",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,472.1990966796875,0.018867924528301886,53,H3
sample_5.pdf,2,include those based on grouping super-pixels (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,484.15509033203125,0.0,46,H3
sample_5.pdf,2,e.g,9.962599754333496,URWPalladioL-Ital,False,509.83294677734375,483.9852294921875,0.0,3,H3
sample_5.pdf,2,"Selective Search [4], CPMC [22], MCG [23]) and those",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,496.1100769042969,0.17307692307692307,52,H3
sample_5.pdf,2,based on sliding windows (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,508.0650634765625,0.0,26,H3
sample_5.pdf,2,e.g,9.962599754333496,URWPalladioL-Ital,False,408.1589660644531,507.89520263671875,0.0,3,H3
sample_5.pdf,2,"., objectness in windows",9.962599754333496,URWPalladioL-Roma,False,419.5059814453125,508.0650634765625,0.0,24,H3
sample_5.pdf,2,"[24], EdgeBoxes [6]). Object proposal methods were",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,520.0200805664062,0.06,50,H3
sample_5.pdf,2,adopted as external modules independent of the de-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,531.9750366210938,0.0,50,H3
sample_5.pdf,2,tectors (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,543.9300537109375,0.0,9,H3
sample_5.pdf,2,e.g,9.962599754333496,URWPalladioL-Ital,False,324.323974609375,543.7601928710938,0.0,3,H3
sample_5.pdf,2,"., Selective Search [4] object detectors, R-",9.962599754333496,URWPalladioL-Roma,False,335.6719665527344,543.9300537109375,0.06818181818181818,44,H3
sample_5.pdf,2,"CNN [5], and Fast R-CNN [2]).",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,555.8860473632812,0.27586206896551724,29,H3
sample_5.pdf,2,Deep Networks for Object Detection.,9.962599754333496,URWPalladioL-Bold,True,287.0589599609375,573.11474609375,0.11428571428571428,35,H3
sample_5.pdf,2,The R-CNN,9.962599754333496,URWPalladioL-Roma,False,466.7345886230469,573.2090454101562,0.5555555555555556,9,H3
sample_5.pdf,2,method [5] trains CNNs end-to-end to classify the,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,585.1640625,0.061224489795918366,49,H3
sample_5.pdf,2,proposal regions into object categories or background.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,597.1190795898438,0.0,54,H3
sample_5.pdf,2,"R-CNN mainly plays as a classiﬁer, and it does not",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,609.0740356445312,0.08,50,H3
sample_5.pdf,2,predict object bounds (except for reﬁning by bounding,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,621.029052734375,0.0,53,H3
sample_5.pdf,2,box regression). Its accuracy depends on the perfor-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,632.9840698242188,0.019230769230769232,52,H3
sample_5.pdf,2,mance of the region proposal module (see compar-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,644.9400634765625,0.0,48,H3
sample_5.pdf,2,isons in [20]). Several papers have proposed ways of,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,656.8950805664062,0.019230769230769232,52,H3
sample_5.pdf,2,using deep networks for predicting object bounding,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,668.85009765625,0.0,50,H3
sample_5.pdf,2,"boxes [25], [9], [26], [27]. In the OverFeat method [9],",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,680.8050537109375,0.05357142857142857,56,H3
sample_5.pdf,2,a fully-connected layer is trained to predict the box,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,692.7600708007812,0.0,53,H3
sample_5.pdf,2,coordinates for the localization task that assumes a,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,704.716064453125,0.0,52,H3
sample_5.pdf,2,single object. The fully-connected layer is then turned,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,716.6710815429688,0.01818181818181818,55,H3
sample_5.pdf,2,2. http://image-net.org/challenges/LSVRC/2015/results,7.970099925994873,URWPalladioL-Roma,False,295.0289611816406,740.819580078125,0.09433962264150944,53,P
sample_5.pdf,3,image,6.516932964324951,Times-Bold,True,146.77099609375,271.60162353515625,0.0,5,P
sample_5.pdf,3,conv layers,6.516932964324951,Times-Roman,False,142.75762939453125,238.61309814453125,0.0,11,P
sample_5.pdf,3,feature maps,9.302041053771973,Times-Roman,False,221.018310546875,174.50357055664062,0.0,12,H3
sample_5.pdf,3,Region Proposal Network,9.302041053771973,Times-Bold,True,42.42351150512695,160.52978515625,0.13043478260869565,23,H3
sample_5.pdf,3,proposals,9.302041053771973,Times-Roman,False,49.335418701171875,122.49703979492188,0.0,9,H3
sample_5.pdf,3,classifier,9.302041053771973,Times-Roman,False,182.9470672607422,52.76479721069336,0.0,10,H3
sample_5.pdf,3,RoI pooling,9.302041053771973,Times-Roman,False,212.5456085205078,85.76358032226562,0.18181818181818182,11,H3
sample_5.pdf,3,"Figure 2: Faster R-CNN is a single, uniﬁed network",9.962599754333496,URWPalladioL-Roma,False,36.0,291.79547119140625,0.12,50,H3
sample_5.pdf,3,for object detection. The RPN module serves as the,9.962599754333496,URWPalladioL-Roma,False,36.0,303.7504577636719,0.08,50,H3
sample_5.pdf,3,‘attention’ of this uniﬁed network.,9.962599754333496,URWPalladioL-Roma,False,36.0,315.7064514160156,0.0,35,H3
sample_5.pdf,3,into a convolutional layer for detecting multiple class-,9.962599754333496,URWPalladioL-Roma,False,36.0,350.8204345703125,0.0,56,H3
sample_5.pdf,3,"speciﬁc objects. The MultiBox methods [26], [27] gen-",9.962599754333496,URWPalladioL-Roma,False,36.0,362.7754211425781,0.05660377358490566,53,H3
sample_5.pdf,3,erate region proposals from a network whose last,9.962599754333496,URWPalladioL-Roma,False,36.0,374.73040771484375,0.0,48,H3
sample_5.pdf,3,fully-connected layer simultaneously predicts mul-,9.962599754333496,URWPalladioL-Roma,False,36.0,386.6864013671875,0.0,50,H3
sample_5.pdf,3,"tiple class-agnostic boxes, generalizing the “single-",9.962599754333496,URWPalladioL-Roma,False,36.0,398.6413879394531,0.0,53,H3
sample_5.pdf,3,box” fashion of OverFeat. These class-agnostic boxes,9.962599754333496,URWPalladioL-Roma,False,36.0,410.59637451171875,0.057692307692307696,52,H3
sample_5.pdf,3,are used as proposals for R-CNN [5]. The MultiBox,9.962599754333496,URWPalladioL-Roma,False,36.0,422.5513610839844,0.14285714285714285,49,H3
sample_5.pdf,3,proposal network is applied on a single image crop or,9.962599754333496,URWPalladioL-Roma,False,36.0,434.50634765625,0.0,53,H3
sample_5.pdf,3,multiple large image crops (,9.962599754333496,URWPalladioL-Roma,False,36.0,446.46234130859375,0.0,28,H3
sample_5.pdf,3,e.g,9.962599754333496,URWPalladioL-Ital,False,162.01699829101562,446.29248046875,0.0,3,H3
sample_5.pdf,3,"., 224",9.962599754333496,URWPalladioL-Roma,False,173.36399841308594,446.46234130859375,0.0,6,H3
sample_5.pdf,3,"224), in contrast",9.962599754333496,URWPalladioL-Roma,False,204.14498901367188,446.46234130859375,0.0,17,H3
sample_5.pdf,3,to our fully convolutional scheme. MultiBox does not,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,458.4173278808594,0.038461538461538464,52,H3
sample_5.pdf,3,share features between the proposal and detection,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,470.372314453125,0.0,49,H3
sample_5.pdf,3,networks. We discuss OverFeat and MultiBox in more,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,482.3273010253906,0.1,50,H3
sample_5.pdf,3,depth later in context with our method. Concurrent,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,494.28228759765625,0.02,50,H3
sample_5.pdf,3,"with our work, the DeepMask method [28] is devel-",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,506.23724365234375,0.04081632653061224,49,H3
sample_5.pdf,3,oped for learning segmentation proposals.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,518.1932983398438,0.0,41,H3
sample_5.pdf,3,"Shared computation of convolutions [9], [1], [29],",9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,530.0742797851562,0.02,50,H3
sample_5.pdf,3,"[7], [2] has been attracting increasing attention for ef-",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,542.0302734375,0.0,57,H3
sample_5.pdf,3,"ﬁcient, yet accurate, visual recognition. The OverFeat",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,553.9852905273438,0.05555555555555555,54,H3
sample_5.pdf,3,paper [9] computes convolutional features from an,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,565.9402465820312,0.0,49,H3
sample_5.pdf,3,"image pyramid for classiﬁcation, localization, and de-",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,577.895263671875,0.0,54,H3
sample_5.pdf,3,tection. Adaptively-sized pooling (SPP) [1] on shared,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,589.8502807617188,0.07547169811320754,53,H3
sample_5.pdf,3,convolutional feature maps is developed for efﬁcient,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,601.8052368164062,0.0,52,H3
sample_5.pdf,3,"region-based object detection [1], [30] and semantic",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,613.7612915039062,0.0,52,H3
sample_5.pdf,3,segmentation [29]. Fast R-CNN [2] enables end-to-end,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,625.7162475585938,0.09615384615384616,52,H3
sample_5.pdf,3,detector training on shared convolutional features and,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,637.6712646484375,0.0,54,H3
sample_5.pdf,3,shows compelling accuracy and speed.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,649.6262817382812,0.0,36,H3
sample_5.pdf,3,ASTER,9.56410026550293,NimbusSanL-Bold,True,62.53998565673828,676.2109375,1.0,5,H3
sample_5.pdf,3,R-CNN,11.9552001953125,NimbusSanL-Bold,True,97.31505584716797,674.3724365234375,0.8,5,H2
sample_5.pdf,3,"Our object detection system, called Faster R-CNN, is",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,691.5692749023438,0.11538461538461539,52,H3
sample_5.pdf,3,composed of two modules. The ﬁrst module is a deep,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,703.5252685546875,0.02,50,H3
sample_5.pdf,3,"fully convolutional network that proposes regions,",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,715.4802856445312,0.0,50,H3
sample_5.pdf,3,and the second module is the Fast R-CNN detector [2],9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,727.4352416992188,0.09615384615384616,52,H3
sample_5.pdf,3,that uses the proposed regions. The entire system is a,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,739.3902587890625,0.018518518518518517,54,H3
sample_5.pdf,3,"single, uniﬁed network for object detection (Figure 2).",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,57.94629669189453,0.01818181818181818,55,H3
sample_5.pdf,3,Using the recently popular terminology of neural,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,69.90131378173828,0.020833333333333332,48,H3
sample_5.pdf,3,"networks with ‘attention’ [31] mechanisms, the RPN",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,81.85633087158203,0.06,50,H3
sample_5.pdf,3,module tells the Fast R-CNN module where to look.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,93.81134796142578,0.10204081632653061,49,H3
sample_5.pdf,3,In Section 3.1 we introduce the designs and properties,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,105.76636505126953,0.037037037037037035,54,H3
sample_5.pdf,3,of the network for region proposal. In Section 3.2 we,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,117.72138214111328,0.03773584905660377,53,H3
sample_5.pdf,3,develop algorithms for training both modules with,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,129.6773681640625,0.0,49,H3
sample_5.pdf,3,features shared.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,141.63238525390625,0.0,16,H3
sample_5.pdf,3,3.1,9.962599754333496,NimbusSanL-Bold,True,287.0589904785156,163.88665771484375,0.0,3,H3
sample_5.pdf,3,Region Proposal Networks,9.962599754333496,NimbusSanL-Bold,True,310.8695983886719,163.88665771484375,0.125,24,H3
sample_5.pdf,3,A Region Proposal Network (RPN) takes an image,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,179.2794189453125,0.15217391304347827,46,H3
sample_5.pdf,3,(of any size) as input and outputs a set of rectangular,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,191.23443603515625,0.0,55,H3
sample_5.pdf,3,"object proposals, each with an objectness score.",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,203.189453125,0.0,48,H3
sample_5.pdf,3,model this process with a fully convolutional network,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,215.14447021484375,0.0,53,H3
sample_5.pdf,3,"[7], which we describe in this section. Because our ulti-",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,227.0994873046875,0.017543859649122806,57,H3
sample_5.pdf,3,mate goal is to share computation with a Fast R-CNN,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,239.05548095703125,0.09803921568627451,51,H3
sample_5.pdf,3,"object detection network [2], we assume that both nets",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,251.010498046875,0.0,54,H3
sample_5.pdf,3,share a common set of convolutional layers. In our ex-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,262.9654846191406,0.018518518518518517,54,H3
sample_5.pdf,3,"periments, we investigate the Zeiler and Fergus model",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,274.92047119140625,0.03773584905660377,53,H3
sample_5.pdf,3,"[32] (ZF), which has 5 shareable convolutional layers",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,286.8754577636719,0.03773584905660377,53,H3
sample_5.pdf,3,"and the Simonyan and Zisserman model [3] (VGG-16),",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,298.8314514160156,0.1,50,H3
sample_5.pdf,3,which has 13 shareable convolutional layers.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,310.78643798828125,0.0,44,H3
sample_5.pdf,3,"To generate region proposals, we slide a small",9.962599754333496,URWPalladioL-Roma,False,297.02099609375,322.39544677734375,0.021739130434782608,46,H3
sample_5.pdf,3,network over the convolutional feature map output,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,334.3504333496094,0.0,49,H3
sample_5.pdf,3,by the last shared convolutional layer. This small,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,346.305419921875,0.02,50,H3
sample_5.pdf,3,network takes as input an,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,358.2604064941406,0.0,25,H3
sample_5.pdf,3,spatial window of,9.962599754333496,URWPalladioL-Roma,False,438.1835632324219,358.2604064941406,0.0,17,H3
sample_5.pdf,3,the input convolutional feature map. Each sliding,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,370.21539306640625,0.02040816326530612,49,H3
sample_5.pdf,3,window is mapped to a lower-dimensional feature,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,382.1703796386719,0.0,47,H3
sample_5.pdf,3,"(256-d for ZF and 512-d for VGG, with ReLU [33]",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,394.1263732910156,0.1702127659574468,47,H3
sample_5.pdf,3,following). This feature is fed into two sibling fully-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,406.08135986328125,0.01818181818181818,55,H3
sample_5.pdf,3,connected layers—a box-regression layer (,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,418.0363464355469,0.0,41,H3
sample_5.pdf,3,reg,9.962599754333496,URWPalladioL-Ital,False,480.010986328125,417.8664855957031,0.0,3,H3
sample_5.pdf,3,) and a,9.962599754333496,URWPalladioL-Roma,False,492.5639953613281,418.0363464355469,0.0,7,H3
sample_5.pdf,3,box-classiﬁcation layer (,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,429.9913330078125,0.0,25,H3
sample_5.pdf,3,cls,9.962599754333496,URWPalladioL-Ital,False,398.88897705078125,429.82147216796875,0.0,3,H3
sample_5.pdf,3,). We use,9.962599754333496,URWPalladioL-Roma,False,409.5889892578125,429.9913330078125,0.1111111111111111,9,H3
sample_5.pdf,3,= 3,9.962599754333496,CMR10,False,465.9645690917969,429.352783203125,0.0,3,H3
sample_5.pdf,3,in this,9.962599754333496,URWPalladioL-Roma,False,490.7895202636719,429.9913330078125,0.0,7,H3
sample_5.pdf,3,"paper, noting that the effective receptive ﬁeld on the",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,441.9463195800781,0.0,54,H3
sample_5.pdf,3,input image is large (171 and 228 pixels for ZF and,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,453.90130615234375,0.0392156862745098,51,H3
sample_5.pdf,3,"VGG, respectively). This mini-network is illustrated",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,465.8572998046875,0.07692307692307693,52,H3
sample_5.pdf,3,at a single position in Figure 3 (left). Note that be-,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,477.8122863769531,0.037037037037037035,54,H3
sample_5.pdf,3,cause the mini-network operates in a sliding-window,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,489.76727294921875,0.0,51,H3
sample_5.pdf,3,"fashion, the fully-connected layers are shared across",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,501.7222595214844,0.0,53,H3
sample_5.pdf,3,all spatial locations. This architecture is naturally im-,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,513.67724609375,0.017543859649122806,57,H3
sample_5.pdf,3,plemented with an,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,525.6322631835938,0.0,17,H3
sample_5.pdf,3,convolutional layer followed,9.962599754333496,URWPalladioL-Roma,False,395.4595642089844,525.6322631835938,0.0,28,H3
sample_5.pdf,3,by two sibling,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,537.5882568359375,0.0,14,H3
sample_5.pdf,3,convolutional layers (for,9.962599754333496,URWPalladioL-Roma,False,376.6552734375,537.5882568359375,0.0,25,H3
sample_5.pdf,3,reg,9.962599754333496,URWPalladioL-Ital,False,490.00714111328125,537.4183959960938,0.0,3,H3
sample_5.pdf,3,and,9.962599754333496,URWPalladioL-Roma,False,505.92987060546875,537.5882568359375,0.0,3,H3
sample_5.pdf,3,cls,9.962599754333496,URWPalladioL-Ital,False,287.0589904785156,549.3734130859375,0.0,3,H3
sample_5.pdf,3,", respectively).",9.962599754333496,URWPalladioL-Roma,False,297.75799560546875,549.5432739257812,0.0,16,H3
sample_5.pdf,3,3.1.1,9.962599754333496,NimbusSanL-ReguItal,False,287.0589904785156,568.8492431640625,0.0,5,H3
sample_5.pdf,3,Anchors,9.962599754333496,NimbusSanL-ReguItal,False,319.17840576171875,568.8492431640625,0.14285714285714285,7,H3
sample_5.pdf,3,"At each sliding-window location, we simultaneously",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,583.3152465820312,0.02,50,H3
sample_5.pdf,3,"predict multiple region proposals, where the number",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,595.270263671875,0.0,51,H3
sample_5.pdf,3,of maximum possible proposals for each location is,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,607.2252807617188,0.0,50,H3
sample_5.pdf,3,denoted as,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,619.1802368164062,0.0,10,H3
sample_5.pdf,3,. So the,9.962599754333496,URWPalladioL-Roma,False,343.19500732421875,619.1802368164062,0.125,8,H3
sample_5.pdf,3,reg,9.962599754333496,URWPalladioL-Ital,False,375.40411376953125,619.0103759765625,0.0,3,H3
sample_5.pdf,3,layer has,9.962599754333496,URWPalladioL-Roma,False,390.5658874511719,619.1802368164062,0.0,9,H3
sample_5.pdf,3,outputs encoding,9.962599754333496,URWPalladioL-Roma,False,445.70751953125,619.1802368164062,0.0,16,H3
sample_5.pdf,3,the coordinates of,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,631.13525390625,0.0,18,H3
sample_5.pdf,3,"boxes, and the",9.962599754333496,URWPalladioL-Roma,False,377.4625549316406,631.13525390625,0.0,14,H3
sample_5.pdf,3,cls,9.962599754333496,URWPalladioL-Ital,False,447.60137939453125,630.9653930664062,0.0,3,H3
sample_5.pdf,3,layer outputs,9.962599754333496,URWPalladioL-Roma,False,462.1608581542969,631.13525390625,0.0,13,H3
sample_5.pdf,3,scores that estimate probability of object or not,9.962599754333496,URWPalladioL-Roma,False,297.23052978515625,643.0902709960938,0.0,49,H3
sample_5.pdf,3,object for each proposal,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,655.0462646484375,0.0,24,H3
sample_5.pdf,3,. The,9.962599754333496,URWPalladioL-Roma,False,397.4850158691406,655.0462646484375,0.2,5,H3
sample_5.pdf,3,proposals are param-,9.962599754333496,URWPalladioL-Roma,False,428.0675354003906,655.0462646484375,0.0,20,H3
sample_5.pdf,3,eterized,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,667.0012817382812,0.0,8,H3
sample_5.pdf,3,relative,9.962599754333496,URWPalladioL-Ital,False,322.5259094238281,666.8314208984375,0.0,8,H3
sample_5.pdf,3,"reference boxes, which we call",9.962599754333496,URWPalladioL-Roma,False,379.8035583496094,667.0012817382812,0.0,30,H3
sample_5.pdf,3,3. “Region” is a generic term and in this paper we only consider,7.970099925994873,URWPalladioL-Roma,False,295.029052734375,686.124755859375,0.015625,64,P
sample_5.pdf,3,rectangular,7.970099925994873,URWPalladioL-Ital,False,287.0590515136719,694.9558715820312,0.0,11,P
sample_5.pdf,3,"regions, as is common for many methods (",7.970099925994873,URWPalladioL-Roma,False,324.2555236816406,695.091796875,0.0,40,P
sample_5.pdf,3,e.g,7.970099925994873,URWPalladioL-Ital,False,481.19403076171875,694.9558715820312,0.0,3,P
sample_5.pdf,3,"., [27], [4],",7.970099925994873,URWPalladioL-Roma,False,490.27203369140625,695.091796875,0.0,13,P
sample_5.pdf,3,[6]). “Objectness” measures membership to a set of object classes,7.970099925994873,URWPalladioL-Roma,False,287.05902099609375,704.0577392578125,0.015384615384615385,65,P
sample_5.pdf,3,. background.,7.970099925994873,URWPalladioL-Roma,False,294.1440124511719,713.0247802734375,0.0,13,P
sample_5.pdf,3,4. For simplicity we implement the,7.970099925994873,URWPalladioL-Roma,False,295.0290222167969,722.8877563476562,0.029411764705882353,34,P
sample_5.pdf,3,cls,7.970099925994873,URWPalladioL-Ital,False,430.688232421875,722.7518310546875,0.0,3,P
sample_5.pdf,3,layer as a two-class,7.970099925994873,URWPalladioL-Roma,False,444.2479248046875,722.8877563476562,0.0,20,P
sample_5.pdf,3,"softmax layer. Alternatively, one may use logistic regression to",7.970099925994873,URWPalladioL-Roma,False,287.05902099609375,731.853759765625,0.015625,64,P
sample_5.pdf,3,produce,7.970099925994873,URWPalladioL-Roma,False,287.05902099609375,740.8197631835938,0.0,7,P
sample_5.pdf,3,scores.,7.970099925994873,URWPalladioL-Roma,False,323.4335021972656,740.8197631835938,0.0,7,P
sample_5.pdf,4,car : 1.000,2.9808242321014404,Helvetica,False,323.14215087890625,72.90020751953125,0.0,11,P
sample_5.pdf,4,dog : 0.997,2.9808242321014404,Helvetica,False,349.21258544921875,92.65542602539062,0.0,11,P
sample_5.pdf,4,person : 0.992,2.9808242321014404,Helvetica,False,373.17791748046875,55.573917388916016,0.0,14,P
sample_5.pdf,4,person : 0.979,2.9808242321014404,Helvetica,False,398.7625732421875,91.19807434082031,0.0,14,P
sample_5.pdf,4,horse : 0.993,2.9808242321014404,Helvetica,False,361.19525146484375,64.80380249023438,0.0,13,P
sample_5.pdf,4,conv feature map,8.289027214050293,Times-Roman,False,149.23147583007812,195.8401641845703,0.0,16,P
sample_5.pdf,4,intermediate layer,8.289027214050293,Times-Roman,False,126.2376708984375,113.41861724853516,0.0,18,P
sample_5.pdf,4,256-d,8.289027214050293,Times-Roman,False,104.37742614746094,100.4645767211914,0.0,5,P
sample_5.pdf,4,scores,8.289027214050293,Times-Roman,False,69.84209442138672,57.229801177978516,0.0,6,P
sample_5.pdf,4,coordinates,8.289027214050293,Times-Roman,False,136.55642700195312,57.229801177978516,0.0,11,P
sample_5.pdf,4,sliding window,8.289027214050293,Times-Roman,False,92.23222351074219,179.64764404296875,0.0,14,P
sample_5.pdf,4,reg,8.289027214050293,Times-Italic,False,161.53775024414062,71.3953628540039,0.0,3,P
sample_5.pdf,4,layer,8.289027214050293,Times-Roman,False,172.48306274414062,71.47932434082031,0.0,5,P
sample_5.pdf,4,cls,8.289027214050293,Times-Italic,False,43.49127197265625,71.3953628540039,0.0,3,P
sample_5.pdf,4,layer,8.289027214050293,Times-Roman,False,52.70686721801758,71.47932434082031,0.0,5,P
sample_5.pdf,4,anchor boxes,8.289027214050293,Times-Roman,False,251.84942626953125,55.28665542602539,0.0,12,P
sample_5.pdf,4,bus : 0.996,2.9738075733184814,Helvetica,False,342.41156005859375,137.83877563476562,0.0,11,P
sample_5.pdf,4,person : 0.736,2.9738075733184814,Helvetica,False,346.6217041015625,148.84988403320312,0.0,14,P
sample_5.pdf,4,boat : 0.970,2.964024305343628,Helvetica,False,433.09130859375,139.78952026367188,0.0,12,P
sample_5.pdf,4,person : 0.989,2.964024305343628,Helvetica,False,497.86248779296875,167.64114379882812,0.0,14,P
sample_5.pdf,4,person : 0.983 person : 0.983,2.964024305343628,Helvetica,False,448.3125,147.07627868652344,0.0,29,P
sample_5.pdf,4,person : 0.925,2.964024305343628,Helvetica,False,481.02197265625,154.20111083984375,0.0,14,P
sample_5.pdf,4,cat : 0.982,2.9602463245391846,Helvetica,False,470.0108642578125,74.37353515625,0.0,11,P
sample_5.pdf,4,dog : 0.994,2.9602463245391846,Helvetica,False,424.50909423828125,61.09544372558594,0.0,11,P
sample_5.pdf,4,Figure 3:,9.962599754333496,URWPalladioL-Roma,False,36.0,214.81048583984375,0.1111111111111111,9,H3
sample_5.pdf,4,Left,9.962599754333496,URWPalladioL-Bold,True,75.12313079833984,214.71620178222656,0.25,4,H3
sample_5.pdf,4,: Region Proposal Network (RPN).,9.962599754333496,URWPalladioL-Roma,False,96.51499938964844,214.81048583984375,0.1875,32,H3
sample_5.pdf,4,Right,9.962599754333496,URWPalladioL-Bold,True,250.9850311279297,214.71620178222656,0.2,5,H3
sample_5.pdf,4,: Example detections using RPN proposals on PASCAL,9.962599754333496,URWPalladioL-Roma,False,279.5769958496094,214.81048583984375,0.2,50,H3
sample_5.pdf,4,VOC 2007 test. Our method detects objects in a wide range of scales and aspect ratios.,9.962599754333496,URWPalladioL-Roma,False,36.0,226.7655029296875,0.046511627906976744,86,H3
sample_5.pdf,4,anchors,9.962599754333496,URWPalladioL-Ital,False,36.0,262.4616394042969,0.0,7,H3
sample_5.pdf,4,. An anchor is centered at the sliding window,9.962599754333496,URWPalladioL-Roma,False,67.17300415039062,262.6315002441406,0.022222222222222223,45,H3
sample_5.pdf,4,"in question, and is associated with a scale and aspect",9.962599754333496,URWPalladioL-Roma,False,36.000003814697266,274.58648681640625,0.0,54,H3
sample_5.pdf,4,"ratio (Figure 3, left). By default we use 3 scales and",9.962599754333496,URWPalladioL-Roma,False,36.000003814697266,286.5414733886719,0.037037037037037035,54,H3
sample_5.pdf,4,"3 aspect ratios, yielding",9.962599754333496,URWPalladioL-Roma,False,36.000003814697266,298.4964599609375,0.0,25,H3
sample_5.pdf,4,= 9,9.962599754333496,CMR10,False,150.41851806640625,297.85791015625,0.0,3,H3
sample_5.pdf,4,anchors at each sliding,9.962599754333496,URWPalladioL-Roma,False,168.997802734375,298.4964599609375,0.0,23,H3
sample_5.pdf,4,position. For a convolutional feature map of a size,9.962599754333496,URWPalladioL-Roma,False,36.0,310.45245361328125,0.0196078431372549,51,H3
sample_5.pdf,4,(typically,9.962599754333496,URWPalladioL-Roma,False,67.31692504882812,322.4074401855469,0.0,10,H3
sample_5.pdf,4,"2,400), there are",9.962599754333496,URWPalladioL-Roma,False,124.677001953125,322.4074401855469,0.0,17,H3
sample_5.pdf,4,WHk,9.962599754333496,CMMI10,False,195.81988525390625,321.7688903808594,0.6666666666666666,3,H3
sample_5.pdf,4,anchors in,9.962599754333496,URWPalladioL-Roma,False,224.42190551757812,322.4074401855469,0.0,10,H3
sample_5.pdf,4,total.,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,334.3624267578125,0.0,6,H3
sample_5.pdf,4,Translation-Invariant Anchors,9.962599754333496,URWPalladioL-Bold,True,36.00001525878906,352.8601379394531,0.10344827586206896,29,H3
sample_5.pdf,4,An important property of our approach is that it,9.962599754333496,URWPalladioL-Roma,False,45.963016510009766,366.5644226074219,0.020833333333333332,48,H3
sample_5.pdf,4,translation invariant,9.962599754333496,URWPalladioL-Ital,False,43.12327575683594,378.34954833984375,0.0,21,H3
sample_5.pdf,4,", both in terms of the anchors",9.962599754333496,URWPalladioL-Roma,False,134.218017578125,378.5194091796875,0.0,30,H3
sample_5.pdf,4,and the functions that compute proposals relative to,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,390.47540283203125,0.0,52,H3
sample_5.pdf,4,"the anchors. If one translates an object in an image,",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,402.4303894042969,0.018867924528301886,53,H3
sample_5.pdf,4,the proposal should translate and the same function,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,414.3853759765625,0.0,51,H3
sample_5.pdf,4,should be able to predict the proposal in either lo-,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,426.3403625488281,0.0,52,H3
sample_5.pdf,4,cation. This translation-invariant property is guaran-,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,438.29534912109375,0.018518518518518517,54,H3
sample_5.pdf,4,teed by our method,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,450.2503356933594,0.0,18,H3
sample_5.pdf,4,". As a comparison, the MultiBox",9.962599754333496,URWPalladioL-Roma,False,129.50201416015625,450.2503356933594,0.0967741935483871,31,H3
sample_5.pdf,4,"method [27] uses k-means to generate 800 anchors,",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,462.2063293457031,0.0,49,H3
sample_5.pdf,4,which are,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,474.16131591796875,0.0,9,H3
sample_5.pdf,4,not,9.962599754333496,URWPalladioL-Ital,False,79.97492980957031,473.991455078125,0.0,3,H3
sample_5.pdf,4,translation invariant. So MultiBox does,9.962599754333496,URWPalladioL-Roma,False,96.48516082763672,474.16131591796875,0.07692307692307693,39,H3
sample_5.pdf,4,not guarantee that the same proposal is generated if,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,486.1163024902344,0.0,52,H3
sample_5.pdf,4,an object is translated.,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,498.0712890625,0.0,24,H3
sample_5.pdf,4,The translation-invariant property also reduces the,9.962599754333496,URWPalladioL-Roma,False,45.963016510009766,511.68231201171875,0.0196078431372549,51,H3
sample_5.pdf,4,model size. MultiBox has a,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,523.6372680664062,0.07692307692307693,26,H3
sample_5.pdf,4,(4 + 1),9.962599754333496,CMR10,False,157.8824462890625,522.9987182617188,0.0,7,H3
sample_5.pdf,4,800,9.962599754333496,CMR10,False,200.29591369628906,522.9987182617188,0.0,3,H3
sample_5.pdf,4,-dimensional,9.962599754333496,URWPalladioL-Roma,False,217.19100952148438,523.6372680664062,0.0,12,H3
sample_5.pdf,4,"fully-connected output layer, whereas our method has",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,535.59228515625,0.0,52,H3
sample_5.pdf,4,(4 + 2),9.962599754333496,CMR10,False,40.98131561279297,546.9087524414062,0.0,7,H3
sample_5.pdf,4,-dimensional convolutional output layer,9.962599754333496,URWPalladioL-Roma,False,92.79601287841797,547.5473022460938,0.0,39,H3
sample_5.pdf,4,in the case of,9.962599754333496,URWPalladioL-Roma,False,36.0000114440918,559.5022583007812,0.0,14,H3
sample_5.pdf,4,= 9,9.962599754333496,CMR10,False,105.98851776123047,558.8637084960938,0.0,3,H3
sample_5.pdf,4,"anchors. As a result, our output",9.962599754333496,URWPalladioL-Roma,False,125.65079498291016,559.5022583007812,0.03125,32,H3
sample_5.pdf,4,layer has,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,571.457275390625,0.0,9,H3
sample_5.pdf,4,parameters (,9.962599754333496,URWPalladioL-Roma,False,132.6680145263672,571.457275390625,0.0,12,H3
sample_5.pdf,4,512,9.962599754333496,CMR10,False,191.27902221679688,570.8187255859375,0.0,3,H3
sample_5.pdf,4,(4 + 2),9.962599754333496,CMR10,False,217.7979278564453,570.8187255859375,0.0,7,H3
sample_5.pdf,4,"for VGG-16), two orders of magnitude fewer than",9.962599754333496,URWPalladioL-Roma,False,36.00004577636719,583.4132690429688,0.06382978723404255,47,H3
sample_5.pdf,4,MultiBox’s output layer that has,9.962599754333496,URWPalladioL-Roma,False,36.00004577636719,595.3682861328125,0.0625,32,H3
sample_5.pdf,4,parameters,9.962599754333496,URWPalladioL-Roma,False,225.47003173828125,595.3682861328125,0.0,10,H3
sample_5.pdf,4,1536,9.962599754333496,CMR10,False,39.318031311035156,606.6847534179688,0.0,4,H3
sample_5.pdf,4,(4 + 1),9.962599754333496,CMR10,False,69.37393188476562,606.6847534179688,0.0,7,H3
sample_5.pdf,4,800,9.962599754333496,CMR10,False,112.1029281616211,606.6847534179688,0.0,3,H3
sample_5.pdf,4,for GoogleNet [34] in MultiBox,9.962599754333496,URWPalladioL-Roma,False,129.4249267578125,607.3233032226562,0.13333333333333333,30,H3
sample_5.pdf,4,"[27]). If considering the feature projection layers, our",9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,619.2782592773438,0.017857142857142856,56,H3
sample_5.pdf,4,proposal layers still have an order of magnitude fewer,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,631.2332763671875,0.0,54,H3
sample_5.pdf,4,parameters than MultiBox,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,643.1882934570312,0.08333333333333333,24,H3
sample_5.pdf,4,. We expect our method,9.962599754333496,URWPalladioL-Roma,False,160.70204162597656,643.1882934570312,0.045454545454545456,22,H3
sample_5.pdf,4,"to have less risk of overﬁtting on small datasets, like",9.962599754333496,URWPalladioL-Roma,False,36.000038146972656,655.144287109375,0.0,55,H3
sample_5.pdf,4,PASCAL VOC.,9.962599754333496,URWPalladioL-Roma,False,36.000038146972656,667.0993041992188,0.8181818181818182,11,H3
sample_5.pdf,4,"5. As is the case of FCNs [7], our network is translation invariant",7.970099925994873,URWPalladioL-Roma,False,43.97003936767578,695.091796875,0.05970149253731343,67,P
sample_5.pdf,4,up to the network’s total stride.,7.970099925994873,URWPalladioL-Roma,False,36.000038146972656,704.0578002929688,0.0,33,P
sample_5.pdf,4,"6. Considering the feature projection layers, our proposal layers’",7.970099925994873,URWPalladioL-Roma,False,43.97003936767578,713.9207763671875,0.015151515151515152,66,P
sample_5.pdf,4,parameter count is,7.970099925994873,URWPalladioL-Roma,False,36.000038146972656,722.8867797851562,0.0,18,P
sample_5.pdf,4,512,7.970099925994873,CMR8,False,134.9723358154297,722.3759155273438,0.0,3,P
sample_5.pdf,4,512 + 512,7.970099925994873,CMR8,False,158.42433166503906,722.3759155273438,0.0,9,P
sample_5.pdf,4,9 = 2,7.970099925994873,CMR8,False,220.31231689453125,722.3759155273438,0.0,5,P
sample_5.pdf,4,MultiBox’s proposal layers’ parameter count is,7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,731.8538208007812,0.043478260869565216,46,P
sample_5.pdf,4,(64 + 96 +,7.970099925994873,CMR8,False,234.4043426513672,731.3429565429688,0.0,10,P
sample_5.pdf,4,64 + 64),7.970099925994873,CMR8,False,36.00004577636719,740.3089599609375,0.0,8,P
sample_5.pdf,4,1536 + 1536,7.970099925994873,CMR8,False,75.04535675048828,740.3089599609375,0.0,11,P
sample_5.pdf,4,800 = 27,7.970099925994873,CMR8,False,144.20335388183594,740.3089599609375,0.0,8,P
sample_5.pdf,4,Multi-Scale Anchors as Regression References,9.962599754333496,URWPalladioL-Bold,True,287.0590515136719,262.5369873046875,0.11363636363636363,44,H3
sample_5.pdf,4,Our design of anchors presents a novel scheme,9.962599754333496,URWPalladioL-Roma,False,297.02105712890625,274.352294921875,0.022222222222222223,45,H3
sample_5.pdf,4,for addressing multiple scales (and aspect ratios). As,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,286.3072814941406,0.018518518518518517,54,H3
sample_5.pdf,4,"shown in Figure 1, there have been two popular ways",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,298.2632751464844,0.0196078431372549,51,H3
sample_5.pdf,4,for multi-scale predictions. The ﬁrst way is based on,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,310.21826171875,0.018867924528301886,53,H3
sample_5.pdf,4,"image/feature pyramids,",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,322.1732482910156,0.0,23,H3
sample_5.pdf,4,e.g,9.962599754333496,URWPalladioL-Ital,False,399.686279296875,322.0033874511719,0.0,3,H3
sample_5.pdf,4,"., in DPM [8] and CNN-",9.962599754333496,URWPalladioL-Roma,False,414.85003662109375,322.1732482910156,0.2727272727272727,22,H3
sample_5.pdf,4,"based methods [9], [1], [2]. The images are resized at",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,334.12823486328125,0.018518518518518517,54,H3
sample_5.pdf,4,"multiple scales, and feature maps (HOG [8] or deep",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,346.0832214355469,0.06,50,H3
sample_5.pdf,4,"convolutional features [9], [1], [2]) are computed for",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,358.0382080078125,0.0,54,H3
sample_5.pdf,4,each scale (Figure 1(a)). This way is often useful but,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,369.99420166015625,0.037037037037037035,54,H3
sample_5.pdf,4,is time-consuming. The second way is to use sliding,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,381.9491882324219,0.0196078431372549,51,H3
sample_5.pdf,4,windows of multiple scales (and/or aspect ratios) on,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,393.9041748046875,0.0,52,H3
sample_5.pdf,4,"the feature maps. For example, in DPM [8], models",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,405.8591613769531,0.08163265306122448,49,H3
sample_5.pdf,4,of different aspect ratios are trained separately using,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,417.81414794921875,0.0,55,H3
sample_5.pdf,4,different ﬁlter sizes (such as 5,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,429.7691345214844,0.0,32,H3
sample_5.pdf,4,7 and 7,9.962599754333496,URWPalladioL-Roma,False,425.8280334472656,429.7691345214844,0.0,7,H3
sample_5.pdf,4,5). If this way,9.962599754333496,URWPalladioL-Roma,False,465.7230224609375,429.7691345214844,0.06666666666666667,15,H3
sample_5.pdf,4,"is used to address multiple scales, it can be thought",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,441.7251281738281,0.0,53,H3
sample_5.pdf,4,of as a “pyramid of ﬁlters” (Figure 1(b)). The second,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,453.68011474609375,0.03773584905660377,53,H3
sample_5.pdf,4,way is usually adopted jointly with the ﬁrst way [8].,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,465.6351013183594,0.0,53,H3
sample_5.pdf,4,"As a comparison, our anchor-based method is built",9.962599754333496,URWPalladioL-Roma,False,297.0210266113281,477.3561096191406,0.02040816326530612,49,H3
sample_5.pdf,4,a pyramid of anchors,9.962599754333496,URWPalladioL-Ital,False,298.29681396484375,489.1412353515625,0.0,20,H3
sample_5.pdf,4,", which is more cost-efﬁcient.",9.962599754333496,URWPalladioL-Roma,False,391.592041015625,489.31109619140625,0.0,30,H3
sample_5.pdf,4,Our method classiﬁes and regresses bounding boxes,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,501.26708984375,0.02040816326530612,49,H3
sample_5.pdf,4,with reference to anchor boxes of multiple scales and,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,513.2221069335938,0.0,53,H3
sample_5.pdf,4,aspect ratios. It only relies on images and feature,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,525.1770629882812,0.0196078431372549,51,H3
sample_5.pdf,4,"maps of a single scale, and uses ﬁlters (sliding win-",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,537.132080078125,0.0,53,H3
sample_5.pdf,4,dows on the feature map) of a single size. We show by,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,549.0870971679688,0.018867924528301886,53,H3
sample_5.pdf,4,experiments the effects of this scheme for addressing,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,561.0421142578125,0.0,53,H3
sample_5.pdf,4,multiple scales and sizes (Table 8).,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,572.9981079101562,0.027777777777777776,36,H3
sample_5.pdf,4,"Because of this multi-scale design based on anchors,",9.962599754333496,URWPalladioL-Roma,False,297.02105712890625,584.7190551757812,0.019230769230769232,52,H3
sample_5.pdf,4,we can simply use the convolutional features com-,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,596.674072265625,0.0,49,H3
sample_5.pdf,4,"puted on a single-scale image, as is also done by",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,608.6290893554688,0.0,49,H3
sample_5.pdf,4,the Fast R-CNN detector [2]. The design of multi-,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,620.5841064453125,0.12244897959183673,49,H3
sample_5.pdf,4,scale anchors is a key component for sharing features,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,632.5391235351562,0.0,53,H3
sample_5.pdf,4,without extra cost for addressing scales.,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,644.4951171875,0.0,41,H3
sample_5.pdf,4,3.1.2,9.962599754333496,NimbusSanL-ReguItal,False,287.0590515136719,665.0360717773438,0.0,5,H3
sample_5.pdf,4,Loss Function,9.962599754333496,NimbusSanL-ReguItal,False,319.178466796875,665.0360717773438,0.15384615384615385,13,H3
sample_5.pdf,4,"For training RPNs, we assign a binary class label",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,679.6140747070312,0.08163265306122448,49,H3
sample_5.pdf,4,(of being an object or not) to each anchor. We as-,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,691.5701293945312,0.02,50,H3
sample_5.pdf,4,sign a positive label to two kinds of anchors: (i) the,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,703.5250854492188,0.0,54,H3
sample_5.pdf,4,anchor/anchors with the highest Intersection-over-,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,715.4801025390625,0.02,50,H3
sample_5.pdf,4,"Union (IoU) overlap with a ground-truth box,",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,727.4351196289062,0.06818181818181818,44,H3
sample_5.pdf,4,(ii) an,9.962599754333496,URWPalladioL-Roma,False,498.24591064453125,727.4351196289062,0.0,7,H3
sample_5.pdf,4,anchor that has an IoU overlap higher than 0.7 with,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,739.3900756835938,0.0392156862745098,51,H3
sample_5.pdf,5,any ground-truth box. Note that a single ground-truth,9.962599754333496,URWPalladioL-Roma,False,36.0,57.94550323486328,0.018867924528301886,53,H3
sample_5.pdf,5,box may assign positive labels to multiple anchors.,9.962599754333496,URWPalladioL-Roma,False,36.0,69.90149688720703,0.0,51,H3
sample_5.pdf,5,Usually the second condition is sufﬁcient to determine,9.962599754333496,URWPalladioL-Roma,False,36.0,81.85651397705078,0.018518518518518517,54,H3
sample_5.pdf,5,the positive samples; but we still adopt the ﬁrst,9.962599754333496,URWPalladioL-Roma,False,36.0,93.81153106689453,0.0,49,H3
sample_5.pdf,5,condition for the reason that in some rare cases the,9.962599754333496,URWPalladioL-Roma,False,36.0,105.76654815673828,0.0,52,H3
sample_5.pdf,5,second condition may ﬁnd no positive sample. We,9.962599754333496,URWPalladioL-Roma,False,36.0,117.72156524658203,0.02127659574468085,47,H3
sample_5.pdf,5,assign a negative label to a non-positive anchor if its,9.962599754333496,URWPalladioL-Roma,False,36.0,129.67657470703125,0.0,55,H3
sample_5.pdf,5,IoU ratio is lower than 0.3 for all ground-truth boxes.,9.962599754333496,URWPalladioL-Roma,False,36.0,141.632568359375,0.03636363636363636,55,H3
sample_5.pdf,5,Anchors that are neither positive nor negative do not,9.962599754333496,URWPalladioL-Roma,False,36.0,153.58758544921875,0.018867924528301886,53,H3
sample_5.pdf,5,contribute to the training objective.,9.962599754333496,URWPalladioL-Roma,False,36.0,165.5426025390625,0.0,37,H3
sample_5.pdf,5,"With these deﬁnitions, we minimize an objective",9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,177.8345947265625,0.02127659574468085,47,H3
sample_5.pdf,5,function following the multi-task loss in Fast R-CNN,9.962599754333496,URWPalladioL-Roma,False,36.0,189.78961181640625,0.09615384615384616,52,H3
sample_5.pdf,5,[2]. Our loss function for an image is deﬁned as:,9.962599754333496,URWPalladioL-Roma,False,36.0,201.74560546875,0.02040816326530612,49,H3
sample_5.pdf,5,) =,9.962599754333496,CMR10,False,130.04901123046875,225.52305603027344,0.0,3,H3
sample_5.pdf,5,cls,6.973800182342529,CMTI7,False,156.40699768066406,236.18678283691406,0.0,3,P
sample_5.pdf,5,cls,6.973800182342529,CMTI7,False,192.48098754882812,229.3527374267578,0.0,3,P
sample_5.pdf,5,", p",9.962599754333496,CMMI10,False,215.0709686279297,225.5228729248047,0.0,3,H3
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,144.93099975585938,265.08673095703125,0.0,3,P
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,191.5699920654297,258.25274658203125,0.0,3,P
sample_5.pdf,5,", t",9.962599754333496,CMMI10,False,213.718994140625,254.4219207763672,0.0,3,H3
sample_5.pdf,5,(1),9.962599754333496,URWPalladioL-Roma,False,263.48699951171875,242.896484375,0.0,3,H3
sample_5.pdf,5,"Here,",9.962599754333496,URWPalladioL-Roma,False,36.0,283.5154724121094,0.2,5,H3
sample_5.pdf,5,is the index of an anchor in a mini-batch and,9.962599754333496,URWPalladioL-Roma,False,66.95509338378906,283.5154724121094,0.0,45,H3
sample_5.pdf,5,is the predicted probability of anchor,9.962599754333496,URWPalladioL-Roma,False,43.82941818237305,295.4714660644531,0.0,38,H3
sample_5.pdf,5,being an,9.962599754333496,URWPalladioL-Roma,False,230.63909912109375,295.4714660644531,0.0,8,H3
sample_5.pdf,5,object. The ground-truth label,9.962599754333496,URWPalladioL-Roma,False,36.0,307.42645263671875,0.03333333333333333,30,H3
sample_5.pdf,5,is 1 if the anchor,9.962599754333496,URWPalladioL-Roma,False,193.5030059814453,307.4264831542969,0.0,18,H3
sample_5.pdf,5,"is positive, and is 0 if the anchor is negative.",9.962599754333496,URWPalladioL-Roma,False,36.0,319.3814697265625,0.0,48,H3
sample_5.pdf,5,is a,9.962599754333496,URWPalladioL-Roma,False,254.3764190673828,319.3814697265625,0.0,4,H3
sample_5.pdf,5,vector representing the 4 parameterized coordinates,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,331.3364562988281,0.0,51,H3
sample_5.pdf,5,"of the predicted bounding box, and",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,343.29144287109375,0.0,34,H3
sample_5.pdf,5,is that of the,9.962599754333496,URWPalladioL-Roma,False,215.88401794433594,343.2914733886719,0.0,14,H3
sample_5.pdf,5,ground-truth box associated with a positive anchor.,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,355.2464599609375,0.0,51,H3
sample_5.pdf,5,The classiﬁcation loss,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,367.20245361328125,0.045454545454545456,22,H3
sample_5.pdf,5,cls,6.973800182342529,CMTI7,False,141.9440155029297,370.3937072753906,0.0,3,P
sample_5.pdf,5,is log loss over two classes,9.962599754333496,URWPalladioL-Roma,False,151.29588317871094,367.20245361328125,0.0,28,H3
sample_5.pdf,5,(object,9.962599754333496,URWPalladioL-Roma,False,36.000022888183594,379.1574401855469,0.0,7,H3
sample_5.pdf,5,". not object). For the regression loss, we use",9.962599754333496,URWPalladioL-Roma,False,77.38903045654297,379.1574401855469,0.021739130434782608,46,H3
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,42.780029296875,394.3036804199219,0.0,3,P
sample_5.pdf,5,", t",9.962599754333496,CMMI10,False,64.92903137207031,390.473876953125,0.0,3,H3
sample_5.pdf,5,) =,9.962599754333496,CMR10,False,77.5340347290039,390.4739074707031,0.0,3,H3
sample_5.pdf,5,where,9.962599754333496,URWPalladioL-Roma,False,144.70948791503906,391.11248779296875,0.0,5,H3
sample_5.pdf,5,is the robust loss,9.962599754333496,URWPalladioL-Roma,False,189.4886474609375,391.11248779296875,0.0,18,H3
sample_5.pdf,5,function (smooth L,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,403.0674743652344,0.05555555555555555,18,H3
sample_5.pdf,5,) deﬁned in [2]. The term,9.962599754333496,URWPalladioL-Roma,False,127.38203430175781,403.0674743652344,0.04,25,H3
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,263.7440185546875,406.259765625,0.0,3,P
sample_5.pdf,5,means the regression loss is activated only for positive,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,415.0224914550781,0.0,56,H3
sample_5.pdf,5,anchors (,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,426.9784851074219,0.0,9,H3
sample_5.pdf,5,= 1,9.962599754333496,CMR10,False,91.30901336669922,426.3399658203125,0.0,3,H3
sample_5.pdf,5,) and is disabled otherwise (,9.962599754333496,URWPalladioL-Roma,False,107.80901336669922,426.978515625,0.0,29,H3
sample_5.pdf,5,= 0,9.962599754333496,CMR10,False,252.79501342773438,426.3399963378906,0.0,3,H3
sample_5.pdf,5,The outputs of the,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,438.93353271484375,0.05555555555555555,18,H3
sample_5.pdf,5,cls,9.962599754333496,URWPalladioL-Ital,False,121.98723602294922,438.763671875,0.0,3,H3
sample_5.pdf,5,and,9.962599754333496,URWPalladioL-Roma,False,136.8788604736328,438.93353271484375,0.0,3,H3
sample_5.pdf,5,reg,9.962599754333496,URWPalladioL-Ital,False,157.9366912841797,438.763671875,0.0,3,H3
sample_5.pdf,5,layers consist of,9.962599754333496,URWPalladioL-Roma,False,174.68191528320312,438.93353271484375,0.0,17,H3
sample_5.pdf,5,and,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,450.8885192871094,0.0,3,H3
sample_5.pdf,5,respectively.,9.962599754333496,URWPalladioL-Roma,False,73.23031616210938,450.8885192871094,0.0,13,H3
sample_5.pdf,5,The two terms are normalized by,9.962599754333496,URWPalladioL-Roma,False,45.96302032470703,463.1805114746094,0.03225806451612903,31,H3
sample_5.pdf,5,cls,6.973800182342529,CMTI7,False,218.30502319335938,466.3727722167969,0.0,3,P
sample_5.pdf,5,and,9.962599754333496,URWPalladioL-Roma,False,227.65689086914062,463.1805114746094,0.0,3,H3
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,263.7440185546875,466.3727722167969,0.0,3,P
sample_5.pdf,5,and weighted by a balancing parameter,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,475.135498046875,0.0,37,H3
sample_5.pdf,5,. In our,9.962599754333496,URWPalladioL-Roma,False,237.14901733398438,475.135498046875,0.125,8,H3
sample_5.pdf,5,"current implementation (as in the released code), the",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,487.09149169921875,0.0,53,H3
sample_5.pdf,5,cls,9.962599754333496,CMMI10,False,36.00001525878906,498.4079284667969,0.0,3,H3
sample_5.pdf,5,term in Eqn.(1) is normalized by the mini-batch,9.962599754333496,URWPalladioL-Roma,False,48.154388427734375,499.0464782714844,0.02127659574468085,47,H3
sample_5.pdf,5,size (,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,511.00146484375,0.0,6,H3
sample_5.pdf,5,i.e,9.962599754333496,URWPalladioL-Ital,False,59.962013244628906,510.83160400390625,0.0,3,H3
sample_5.pdf,5,cls,6.973800182342529,CMTI7,False,85.85201263427734,514.1927490234375,0.0,3,P
sample_5.pdf,5,= 256,9.962599754333496,CMR10,False,95.2038803100586,510.3629150390625,0.0,5,H3
sample_5.pdf,5,) and the,9.962599754333496,URWPalladioL-Roma,False,125.50801849365234,511.00146484375,0.0,9,H3
sample_5.pdf,5,reg,9.962599754333496,CMMI10,False,167.04208374023438,510.3629150390625,0.0,3,H3
sample_5.pdf,5,term is normalized,9.962599754333496,URWPalladioL-Roma,False,184.98085021972656,511.00146484375,0.0,18,H3
sample_5.pdf,5,by the number of anchor locations (,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,522.9564819335938,0.0,35,H3
sample_5.pdf,5,i.e,9.962599754333496,URWPalladioL-Ital,False,195.22201538085938,522.78662109375,0.0,3,H3
sample_5.pdf,5,reg,6.973800182342529,CMTI7,False,220.29901123046875,526.1477661132812,0.0,3,P
sample_5.pdf,5,400,9.962599754333496,CMR10,False,252.692626953125,522.3179321289062,0.0,3,H3
sample_5.pdf,5,By default we set,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,534.9114990234375,0.058823529411764705,17,H3
sample_5.pdf,5,= 10,9.962599754333496,CMR10,False,131.6402130126953,534.27294921875,0.0,4,H3
sample_5.pdf,5,", and thus both",9.962599754333496,URWPalladioL-Roma,False,161.94601440429688,534.9114990234375,0.0,15,H3
sample_5.pdf,5,cls,9.962599754333496,URWPalladioL-Ital,False,236.75515747070312,534.7416381835938,0.0,3,H3
sample_5.pdf,5,and,9.962599754333496,URWPalladioL-Roma,False,252.84486389160156,534.9114990234375,0.0,3,H3
sample_5.pdf,5,reg,9.962599754333496,URWPalladioL-Ital,False,36.000030517578125,546.6966552734375,0.0,3,H3
sample_5.pdf,5,terms are roughly equally weighted. We show,9.962599754333496,URWPalladioL-Roma,False,48.55290603637695,546.8665161132812,0.023255813953488372,43,H3
sample_5.pdf,5,by experiments that the results are insensitive to the,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,558.8224487304688,0.0,54,H3
sample_5.pdf,5,values of,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,570.7774658203125,0.0,9,H3
sample_5.pdf,5,in a wide range (Table 9). We also note,9.962599754333496,URWPalladioL-Roma,False,87.65422821044922,570.7774658203125,0.05128205128205128,39,H3
sample_5.pdf,5,that the normalization as above is not required and,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,582.7324829101562,0.0,51,H3
sample_5.pdf,5,could be simpliﬁed.,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,594.6875,0.0,19,H3
sample_5.pdf,5,"For bounding box regression, we adopt the param-",9.962599754333496,URWPalladioL-Roma,False,45.96303176879883,606.9794921875,0.020833333333333332,48,H3
sample_5.pdf,5,eterizations of the 4 coordinates following [5]:,9.962599754333496,URWPalladioL-Roma,False,36.000030517578125,618.9354858398438,0.0,48,H3
sample_5.pdf,5,= (,9.962599754333496,CMR10,False,80.23851013183594,637.9209594726562,0.0,3,H3
sample_5.pdf,5,= (,9.962599754333496,CMR10,False,167.28245544433594,637.9209594726562,0.0,3,H3
sample_5.pdf,5,= log(,9.962599754333496,CMR10,False,80.23817443847656,652.8649291992188,0.0,6,H3
sample_5.pdf,5,w/w,9.962599754333496,CMMI10,False,110.76303100585938,652.8649291992188,0.0,3,H3
sample_5.pdf,5,= log(,9.962599754333496,CMR10,False,160.18377685546875,652.8649291992188,0.0,6,H3
sample_5.pdf,5,h/h,9.962599754333496,CMMI10,False,190.70803833007812,652.8649291992188,0.0,3,H3
sample_5.pdf,5,= (,9.962599754333496,CMR10,False,83.50403594970703,667.8089599609375,0.0,3,H3
sample_5.pdf,5,= (,9.962599754333496,CMR10,False,175.33203125,667.8089599609375,0.0,3,H3
sample_5.pdf,5,= log(,9.962599754333496,CMR10,False,83.50404357910156,683.595947265625,0.0,6,H3
sample_5.pdf,5,= log(,9.962599754333496,CMR10,False,168.05206298828125,683.595947265625,0.0,6,H3
sample_5.pdf,5,(2),9.962599754333496,URWPalladioL-Roma,False,263.487060546875,661.4965209960938,0.0,3,H3
sample_5.pdf,5,where,9.962599754333496,URWPalladioL-Roma,False,36.00006103515625,703.5255126953125,0.0,5,H3
sample_5.pdf,5,", and",9.962599754333496,URWPalladioL-Roma,False,98.1110610961914,703.5255126953125,0.0,5,H3
sample_5.pdf,5,denote the box’s center coordi-,9.962599754333496,URWPalladioL-Roma,False,130.79751586914062,703.5255126953125,0.0,31,H3
sample_5.pdf,5,nates and its width and height. Variables,9.962599754333496,URWPalladioL-Roma,False,36.00005340576172,715.4805297851562,0.024390243902439025,41,H3
sample_5.pdf,5,", and",9.962599754333496,URWPalladioL-Roma,False,251.591064453125,715.4805297851562,0.0,5,H3
sample_5.pdf,5,"are for the predicted box, anchor box, and ground-",9.962599754333496,URWPalladioL-Roma,False,49.2110595703125,727.4354858398438,0.0,50,H3
sample_5.pdf,5,truth box respectively (likewise for,9.962599754333496,URWPalladioL-Roma,False,36.00006103515625,739.3905029296875,0.0,36,H3
sample_5.pdf,5,"y, w, h",9.962599754333496,CMMI10,False,195.6805877685547,738.751953125,0.0,7,H3
sample_5.pdf,5,). This can,9.962599754333496,URWPalladioL-Roma,False,226.9680633544922,739.3905029296875,0.09090909090909091,11,H3
sample_5.pdf,5,be thought of as bounding-box regression from an,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,57.94654083251953,0.0,48,H3
sample_5.pdf,5,anchor box to a nearby ground-truth box.,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,69.90155792236328,0.0,40,H3
sample_5.pdf,5,"Nevertheless, our method achieves bounding-box",9.962599754333496,URWPalladioL-Roma,False,297.02105712890625,81.94757843017578,0.021739130434782608,46,H3
sample_5.pdf,5,regression by a different manner from previous RoI-,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,93.90259552001953,0.0392156862745098,51,H3
sample_5.pdf,5,"based (Region of Interest) methods [1], [2]. In [1],",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,105.85761260986328,0.057692307692307696,52,H3
sample_5.pdf,5,"[2], bounding-box regression is performed on features",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,117.81262969970703,0.0,53,H3
sample_5.pdf,5,pooled from,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,129.76763916015625,0.0,11,H3
sample_5.pdf,5,arbitrarily,9.962599754333496,URWPalladioL-Ital,False,342.490966796875,129.59776306152344,0.0,11,H3
sample_5.pdf,5,"sized RoIs, and the regression",9.962599754333496,URWPalladioL-Roma,False,387.6814880371094,129.76763916015625,0.06666666666666667,30,H3
sample_5.pdf,5,weights are,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,141.7236328125,0.0,11,H3
sample_5.pdf,5,shared,9.962599754333496,URWPalladioL-Ital,False,338.4859924316406,141.5537567138672,0.0,6,H3
sample_5.pdf,5,by all region sizes. In our formula-,9.962599754333496,URWPalladioL-Roma,False,367.43804931640625,141.7236328125,0.027777777777777776,36,H3
sample_5.pdf,5,"tion, the features used for regression are of the",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,153.67864990234375,0.0,49,H3
sample_5.pdf,5,same,9.962599754333496,URWPalladioL-Ital,False,502.31109619140625,153.50877380371094,0.0,4,H3
sample_5.pdf,5,spatial size (,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,165.6336669921875,0.0,14,H3
sample_5.pdf,5,) on the feature maps. To account,9.962599754333496,URWPalladioL-Roma,False,368.8890075683594,165.6336669921875,0.030303030303030304,33,H3
sample_5.pdf,5,"for varying sizes, a set of",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,177.58868408203125,0.0,27,H3
sample_5.pdf,5,bounding-box regressors,9.962599754333496,URWPalladioL-Roma,False,411.2525329589844,177.58868408203125,0.0,23,H3
sample_5.pdf,5,are learned. Each regressor is responsible for one scale,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,189.543701171875,0.017857142857142856,56,H3
sample_5.pdf,5,"and one aspect ratio, and the",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,201.49871826171875,0.0,29,H3
sample_5.pdf,5,regressors do,9.962599754333496,URWPalladioL-Roma,False,422.2985534667969,201.49871826171875,0.0,13,H3
sample_5.pdf,5,not,9.962599754333496,URWPalladioL-Ital,False,484.0613708496094,201.32884216308594,0.0,3,H3
sample_5.pdf,5,share,9.962599754333496,URWPalladioL-Roma,False,499.9871826171875,201.49871826171875,0.0,5,H3
sample_5.pdf,5,"weights. As such, it is still possible to predict boxes of",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,213.4547119140625,0.017241379310344827,58,H3
sample_5.pdf,5,various sizes even though the features are of a ﬁxed,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,225.40972900390625,0.0,52,H3
sample_5.pdf,5,"size/scale, thanks to the design of anchors.",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,237.36474609375,0.0,44,H3
sample_5.pdf,5,3.1.3,9.962599754333496,NimbusSanL-ReguItal,False,287.05902099609375,261.0247497558594,0.0,5,H3
sample_5.pdf,5,Training RPNs,9.962599754333496,NimbusSanL-ReguItal,False,319.1784362792969,261.0247497558594,0.3076923076923077,13,H3
sample_5.pdf,5,The,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,276.1547546386719,0.3333333333333333,3,H3
sample_5.pdf,5,RPN,9.962599754333496,URWPalladioL-Roma,False,312.423828125,276.1547546386719,1.0,3,H3
sample_5.pdf,5,can,9.962599754333496,URWPalladioL-Roma,False,342.0625915527344,276.1547546386719,0.0,3,H3
sample_5.pdf,5,trained,9.962599754333496,URWPalladioL-Roma,False,384.9216613769531,276.1547546386719,0.0,7,H3
sample_5.pdf,5,end-to-end,9.962599754333496,URWPalladioL-Roma,False,425.3299560546875,276.1547546386719,0.0,10,H3
sample_5.pdf,5,back-,9.962599754333496,URWPalladioL-Roma,False,502.390625,276.1547546386719,0.0,5,H3
sample_5.pdf,5,propagation and stochastic gradient descent (SGD),9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,288.1097412109375,0.061224489795918366,49,H3
sample_5.pdf,5,[35]. We follow the “image-centric” sampling strategy,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,300.0647277832031,0.018867924528301886,53,H3
sample_5.pdf,5,from [2] to train this network. Each mini-batch arises,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,312.0207214355469,0.018518518518518517,54,H3
sample_5.pdf,5,from a single image that contains many positive and,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,323.9757080078125,0.0,51,H3
sample_5.pdf,5,negative example anchors. It is possible to optimize,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,335.9306945800781,0.019230769230769232,52,H3
sample_5.pdf,5,"for the loss functions of all anchors, but this will",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,347.88568115234375,0.0,52,H3
sample_5.pdf,5,bias towards negative samples as they are dominate.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,359.8406677246094,0.0,51,H3
sample_5.pdf,5,"Instead, we randomly sample 256 anchors in an image",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,371.795654296875,0.0196078431372549,51,H3
sample_5.pdf,5,"to compute the loss function of a mini-batch, where",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,383.75164794921875,0.0,51,H3
sample_5.pdf,5,the sampled positive and negative anchors have a,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,395.7066345214844,0.0,48,H3
sample_5.pdf,5,ratio of,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,407.66162109375,0.0,8,H3
sample_5.pdf,5,up to,9.962599754333496,URWPalladioL-Ital,False,319.87579345703125,407.49176025390625,0.0,5,H3
sample_5.pdf,5,1:1. If there are fewer than 128 positive,9.962599754333496,URWPalladioL-Roma,False,345.2521057128906,407.66162109375,0.024390243902439025,41,H3
sample_5.pdf,5,"samples in an image, we pad the mini-batch with",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,419.6166076660156,0.0,47,H3
sample_5.pdf,5,negative ones.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,431.57159423828125,0.0,14,H3
sample_5.pdf,5,We randomly initialize all new layers by drawing,9.962599754333496,URWPalladioL-Roma,False,297.0210266113281,443.6175842285156,0.020833333333333332,48,H3
sample_5.pdf,5,weights from a zero-mean Gaussian distribution with,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,455.57257080078125,0.0196078431372549,51,H3
sample_5.pdf,5,standard deviation 0.01. All other layers (,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,467.528564453125,0.023255813953488372,43,H3
sample_5.pdf,5,i.e,9.962599754333496,URWPalladioL-Ital,False,491.9530029296875,467.35870361328125,0.0,3,H3
sample_5.pdf,5,"., the",9.962599754333496,URWPalladioL-Roma,False,501.0889892578125,467.528564453125,0.0,6,H3
sample_5.pdf,5,shared convolutional layers) are initialized by pre-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,479.4835510253906,0.0,52,H3
sample_5.pdf,5,"training a model for ImageNet classiﬁcation [36], as",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,491.43853759765625,0.038461538461538464,52,H3
sample_5.pdf,5,is standard practice [5]. We tune all layers of the,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,503.3935241699219,0.0196078431372549,51,H3
sample_5.pdf,5,"ZF net, and conv3",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,515.3485107421875,0.11764705882352941,17,H3
sample_5.pdf,5,and up for the VGG net to,9.962599754333496,URWPalladioL-Roma,False,385.8222961425781,515.3484497070312,0.12,25,H3
sample_5.pdf,5,conserve memory [2]. We use a learning rate of 0.001,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,527.303466796875,0.019230769230769232,52,H3
sample_5.pdf,5,"for 60k mini-batches, and 0.0001 for the next 20k",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,539.2584838867188,0.0,49,H3
sample_5.pdf,5,mini-batches on the PASCAL VOC dataset. We use a,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,551.2135009765625,0.20833333333333334,48,H3
sample_5.pdf,5,momentum of 0.9 and a weight decay of 0.0005 [37].,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,563.1694946289062,0.0,50,H3
sample_5.pdf,5,Our implementation uses Caffe [38].,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,575.1244506835938,0.05714285714285714,35,H3
sample_5.pdf,5,3.2,9.962599754333496,NimbusSanL-Bold,True,287.0589904785156,603.6917114257812,0.0,3,H3
sample_5.pdf,5,Sharing Features for RPN and Fast R-CNN,9.962599754333496,NimbusSanL-Bold,True,310.8695983886719,603.6917114257812,0.2564102564102564,39,H3
sample_5.pdf,5,Thus far we have described how to train a network,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,619.7484741210938,0.02040816326530612,49,H3
sample_5.pdf,5,"for region proposal generation, without considering",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,631.7034912109375,0.0,51,H3
sample_5.pdf,5,the region-based object detection CNN that will utilize,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,643.6585083007812,0.05454545454545454,55,H3
sample_5.pdf,5,"these proposals. For the detection network, we adopt",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,655.6134643554688,0.019230769230769232,52,H3
sample_5.pdf,5,Fast R-CNN [2]. Next we describe algorithms that,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,667.5684814453125,0.125,48,H3
sample_5.pdf,5,learn a uniﬁed network composed of RPN and Fast,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,679.5234985351562,0.0851063829787234,47,H3
sample_5.pdf,5,R-CNN with shared convolutional layers (Figure 2).,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,691.4794921875,0.1,50,H3
sample_5.pdf,5,"Both RPN and Fast R-CNN, trained independently,",9.962599754333496,URWPalladioL-Roma,False,297.02099609375,703.5255126953125,0.19148936170212766,47,H3
sample_5.pdf,5,will modify their convolutional layers in different,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,715.4805297851562,0.0,51,H3
sample_5.pdf,5,ways. We therefore need to develop a technique that,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,727.4354858398438,0.0196078431372549,51,H3
sample_5.pdf,5,allows for sharing convolutional layers between the,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,739.3905029296875,0.0,51,H3
sample_5.pdf,6,Table 1: the learned average proposal size for each anchor using the ZF net (numbers for,9.962599754333496,URWPalladioL-Roma,False,58.59698486328125,54.35950469970703,0.03409090909090909,88,H3
sample_5.pdf,6,= 600,9.962599754333496,CMR10,False,469.5324401855469,53.72093200683594,0.0,5,H3
sample_5.pdf,6,anchor,8.966400146484375,URWPalladioL-Roma,False,78.03500366210938,66.33220672607422,0.0,6,P
sample_5.pdf,6,128,8.966400146484375,CMR9,False,117.89299774169922,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 2:1",8.966400146484375,URWPalladioL-Roma,False,135.86700439453125,66.33220672607422,0.0,5,P
sample_5.pdf,6,128,8.966400146484375,CMR9,False,152.45484924316406,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:1",8.966400146484375,URWPalladioL-Roma,False,176.80499267578125,66.33220672607422,0.0,5,P
sample_5.pdf,6,128,8.966400146484375,CMR9,False,193.39283752441406,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:2",8.966400146484375,URWPalladioL-Roma,False,217.7429962158203,66.33220672607422,0.0,5,P
sample_5.pdf,6,256,8.966400146484375,CMR9,False,243.09800720214844,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 2:1",8.966400146484375,URWPalladioL-Roma,False,261.072021484375,66.33220672607422,0.0,5,P
sample_5.pdf,6,256,8.966400146484375,CMR9,False,277.65985107421875,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:1",8.966400146484375,URWPalladioL-Roma,False,302.010009765625,66.33220672607422,0.0,5,P
sample_5.pdf,6,256,8.966400146484375,CMR9,False,318.59783935546875,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:2",8.966400146484375,URWPalladioL-Roma,False,342.947998046875,66.33220672607422,0.0,5,P
sample_5.pdf,6,512,8.966400146484375,CMR9,False,368.3030090332031,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 2:1",8.966400146484375,URWPalladioL-Roma,False,386.2770080566406,66.33220672607422,0.0,5,P
sample_5.pdf,6,512,8.966400146484375,CMR9,False,402.8648681640625,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:1",8.966400146484375,URWPalladioL-Roma,False,427.2149963378906,66.33220672607422,0.0,5,P
sample_5.pdf,6,512,8.966400146484375,CMR9,False,443.8028564453125,65.75749206542969,0.0,3,P
sample_5.pdf,6,", 1:2",8.966400146484375,URWPalladioL-Roma,False,468.1529846191406,66.33220672607422,0.0,5,P
sample_5.pdf,6,proposal,8.966400146484375,URWPalladioL-Roma,False,74.28299713134766,77.68920135498047,0.0,8,P
sample_5.pdf,6,188,8.966400146484375,URWPalladioL-Roma,False,118.13999938964844,77.68920135498047,0.0,3,P
sample_5.pdf,6,111 113,8.966400146484375,URWPalladioL-Roma,False,138.75698852539062,77.68920135498047,0.0,7,P
sample_5.pdf,6,114,8.966400146484375,URWPalladioL-Roma,False,179.69500732421875,77.68920135498047,0.0,3,P
sample_5.pdf,6,416,8.966400146484375,URWPalladioL-Roma,False,243.34500122070312,77.68920135498047,0.0,3,P
sample_5.pdf,6,229 261,8.966400146484375,URWPalladioL-Roma,False,263.9630126953125,77.68920135498047,0.0,7,P
sample_5.pdf,6,284 174,8.966400146484375,URWPalladioL-Roma,False,304.9010009765625,77.68920135498047,0.0,7,P
sample_5.pdf,6,332,8.966400146484375,URWPalladioL-Roma,False,345.8389892578125,77.68920135498047,0.0,3,P
sample_5.pdf,6,768,8.966400146484375,URWPalladioL-Roma,False,368.5509948730469,77.68920135498047,0.0,3,P
sample_5.pdf,6,437 499,8.966400146484375,URWPalladioL-Roma,False,389.1679992675781,77.68920135498047,0.0,7,P
sample_5.pdf,6,501 355,8.966400146484375,URWPalladioL-Roma,False,430.10601806640625,77.68920135498047,0.0,7,P
sample_5.pdf,6,715,8.966400146484375,URWPalladioL-Roma,False,471.04400634765625,77.68920135498047,0.0,3,P
sample_5.pdf,6,"two networks, rather than learning two separate net-",9.962599754333496,URWPalladioL-Roma,False,36.0,118.51850128173828,0.0,52,H3
sample_5.pdf,6,works. We discuss three ways for training networks,9.962599754333496,URWPalladioL-Roma,False,36.0,130.4735107421875,0.02,50,H3
sample_5.pdf,6,with features shared:,9.962599754333496,URWPalladioL-Roma,False,36.0,142.42950439453125,0.0,21,H3
sample_5.pdf,6,(i),9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,155.92852783203125,0.0,3,H3
sample_5.pdf,6,Alternating training,9.962599754333496,URWPalladioL-Ital,False,55.49721145629883,155.75865173339844,0.05,20,H3
sample_5.pdf,6,". In this solution, we ﬁrst train",9.962599754333496,URWPalladioL-Roma,False,141.6009979248047,155.92852783203125,0.030303030303030304,33,H3
sample_5.pdf,6,"RPN, and use the proposals to train Fast R-CNN.",9.962599754333496,URWPalladioL-Roma,False,36.0,167.883544921875,0.1702127659574468,47,H3
sample_5.pdf,6,The network tuned by Fast R-CNN is then used to,9.962599754333496,URWPalladioL-Roma,False,36.0,179.83856201171875,0.1276595744680851,47,H3
sample_5.pdf,6,"initialize RPN, and this process is iterated. This is the",9.962599754333496,URWPalladioL-Roma,False,36.0,191.7945556640625,0.07017543859649122,57,H3
sample_5.pdf,6,solution that is used in all experiments in this paper.,9.962599754333496,URWPalladioL-Roma,False,36.0,203.74957275390625,0.0,55,H3
sample_5.pdf,6,(ii),9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,217.24859619140625,0.0,4,H3
sample_5.pdf,6,Approximate joint training,9.962599754333496,URWPalladioL-Ital,False,58.39632797241211,217.07872009277344,0.038461538461538464,26,H3
sample_5.pdf,6,". In this solution, the",9.962599754333496,URWPalladioL-Roma,False,176.62399291992188,217.24859619140625,0.043478260869565216,23,H3
sample_5.pdf,6,RPN and Fast R-CNN networks are merged into one,9.962599754333496,URWPalladioL-Roma,False,36.0,229.20361328125,0.1702127659574468,47,H3
sample_5.pdf,6,network during training as in Figure 2. In each SGD,9.962599754333496,URWPalladioL-Roma,False,36.0,241.15863037109375,0.09803921568627451,51,H3
sample_5.pdf,6,"iteration, the forward pass generates region propos-",9.962599754333496,URWPalladioL-Roma,False,36.0,253.1146240234375,0.0,52,H3
sample_5.pdf,6,"als which are treated just like ﬁxed, pre-computed",9.962599754333496,URWPalladioL-Roma,False,36.0,265.0696105957031,0.0,50,H3
sample_5.pdf,6,proposals when training a Fast R-CNN detector. The,9.962599754333496,URWPalladioL-Roma,False,36.0,277.02459716796875,0.12,50,H3
sample_5.pdf,6,"backward propagation takes place as usual, where for",9.962599754333496,URWPalladioL-Roma,False,36.0,288.9795837402344,0.0,52,H3
sample_5.pdf,6,the shared layers the backward propagated signals,9.962599754333496,URWPalladioL-Roma,False,36.0,300.9345703125,0.0,49,H3
sample_5.pdf,6,from both the RPN loss and the Fast R-CNN loss,9.962599754333496,URWPalladioL-Roma,False,36.0,312.8895568847656,0.17391304347826086,46,H3
sample_5.pdf,6,are combined. This solution is easy to implement. But,9.962599754333496,URWPalladioL-Roma,False,36.0,324.8455505371094,0.03773584905660377,53,H3
sample_5.pdf,6,this solution ignores the derivative w.r.t. the proposal,9.962599754333496,URWPalladioL-Roma,False,36.0,336.800537109375,0.0,56,H3
sample_5.pdf,6,"boxes’ coordinates that are also network responses,",9.962599754333496,URWPalladioL-Roma,False,36.0,348.7555236816406,0.0,51,H3
sample_5.pdf,6,"so is approximate. In our experiments, we have em-",9.962599754333496,URWPalladioL-Roma,False,36.0,360.71051025390625,0.02,50,H3
sample_5.pdf,6,"pirically found this solver produces close results, yet",9.962599754333496,URWPalladioL-Roma,False,36.0,372.6654968261719,0.0,55,H3
sample_5.pdf,6,reduces the training time by about 25-50% comparing,9.962599754333496,URWPalladioL-Roma,False,36.0,384.6204833984375,0.0,51,H3
sample_5.pdf,6,with alternating training. This solver is included in,9.962599754333496,URWPalladioL-Roma,False,36.0,396.57647705078125,0.018867924528301886,53,H3
sample_5.pdf,6,our released Python code.,9.962599754333496,URWPalladioL-Roma,False,36.0,408.5314636230469,0.04,25,H3
sample_5.pdf,6,(iii),9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,422.03045654296875,0.0,5,H3
sample_5.pdf,6,Non-approximate joint training,9.962599754333496,URWPalladioL-Ital,False,61.29544448852539,421.860595703125,0.03333333333333333,30,H3
sample_5.pdf,6,. As discussed,9.962599754333496,URWPalladioL-Roma,False,204.20700073242188,422.03045654296875,0.07142857142857142,14,H3
sample_5.pdf,6,"above, the bounding boxes predicted by RPN are",9.962599754333496,URWPalladioL-Roma,False,36.0,433.9854431152344,0.06521739130434782,46,H3
sample_5.pdf,6,also functions of the input. The RoI pooling layer,9.962599754333496,URWPalladioL-Roma,False,36.0,445.9414367675781,0.06,50,H3
sample_5.pdf,6,[2] in Fast R-CNN accepts the convolutional features,9.962599754333496,URWPalladioL-Roma,False,36.0,457.89642333984375,0.09615384615384616,52,H3
sample_5.pdf,6,"and also the predicted bounding boxes as input, so",9.962599754333496,URWPalladioL-Roma,False,36.0,469.8514099121094,0.0,50,H3
sample_5.pdf,6,a theoretically valid backpropagation solver should,9.962599754333496,URWPalladioL-Roma,False,36.0,481.806396484375,0.0,51,H3
sample_5.pdf,6,also involve gradients w.r.t. the box coordinates. These,9.962599754333496,URWPalladioL-Roma,False,36.0,493.7613830566406,0.017857142857142856,56,H3
sample_5.pdf,6,gradients are ignored in the above approximate joint,9.962599754333496,URWPalladioL-Roma,False,36.0,505.71636962890625,0.0,52,H3
sample_5.pdf,6,"training. In a non-approximate joint training solution,",9.962599754333496,URWPalladioL-Roma,False,36.0,517.67236328125,0.01818181818181818,55,H3
sample_5.pdf,6,we need an RoI pooling layer that is differentiable,9.962599754333496,URWPalladioL-Roma,False,36.0,529.6273803710938,0.0392156862745098,51,H3
sample_5.pdf,6,w.r.t. the box coordinates. This is a nontrivial problem,9.962599754333496,URWPalladioL-Roma,False,36.0,541.5823364257812,0.017857142857142856,56,H3
sample_5.pdf,6,and a solution can be given by an “RoI warping” layer,9.962599754333496,URWPalladioL-Roma,False,36.0,553.537353515625,0.03773584905660377,53,H3
sample_5.pdf,6,"as developed in [15], which is beyond the scope of this",9.962599754333496,URWPalladioL-Roma,False,36.0,565.4923706054688,0.0,55,H3
sample_5.pdf,6,paper.,9.962599754333496,URWPalladioL-Roma,False,36.0,577.4473876953125,0.0,6,H3
sample_5.pdf,6,4-Step Alternating Training,9.962599754333496,URWPalladioL-Bold,True,36.0,595.8341064453125,0.1111111111111111,27,H3
sample_5.pdf,6,". In this paper, we adopt",9.962599754333496,URWPalladioL-Roma,False,163.57699584960938,595.9284057617188,0.04,25,H3
sample_5.pdf,6,a pragmatic 4-step training algorithm to learn shared,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,607.8833618164062,0.0,53,H3
sample_5.pdf,6,"features via alternating optimization. In the ﬁrst step,",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,619.83837890625,0.017857142857142856,56,H3
sample_5.pdf,6,we train the RPN as described in Section 3.1.3. This,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,631.7943725585938,0.09615384615384616,52,H3
sample_5.pdf,6,network is initialized with an ImageNet-pre-trained,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,643.7493896484375,0.0392156862745098,51,H3
sample_5.pdf,6,model and ﬁne-tuned end-to-end for the region pro-,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,655.7044067382812,0.0,50,H3
sample_5.pdf,6,"posal task. In the second step, we train a separate",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,667.6593627929688,0.0196078431372549,51,H3
sample_5.pdf,6,detection network by Fast R-CNN using the proposals,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,679.6143798828125,0.09803921568627451,51,H3
sample_5.pdf,6,generated by the step-1 RPN. This detection net-,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,691.5703735351562,0.08333333333333333,48,H3
sample_5.pdf,6,work is also initialized by the ImageNet-pre-trained,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,703.525390625,0.038461538461538464,52,H3
sample_5.pdf,6,model. At this point the two networks do not share,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,715.4804077148438,0.02,50,H3
sample_5.pdf,6,"convolutional layers. In the third step, we use the",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,727.4353637695312,0.0196078431372549,51,H3
sample_5.pdf,6,"detector network to initialize RPN training, but we",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,739.390380859375,0.058823529411764705,51,H3
sample_5.pdf,6,ﬁx the shared convolutional layers and only ﬁne-tune,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,118.51941680908203,0.0,52,H3
sample_5.pdf,6,the layers unique to RPN. Now the two networks,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,130.47442626953125,0.08695652173913043,46,H3
sample_5.pdf,6,"share convolutional layers. Finally, keeping the shared",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,142.429443359375,0.01818181818181818,55,H3
sample_5.pdf,6,"convolutional layers ﬁxed, we ﬁne-tune the unique",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,154.38446044921875,0.0,49,H3
sample_5.pdf,6,"layers of Fast R-CNN. As such, both networks share",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,166.3394775390625,0.12,50,H3
sample_5.pdf,6,the same convolutional layers and form a uniﬁed,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,178.29449462890625,0.0,47,H3
sample_5.pdf,6,network. A similar alternating training can be run,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,190.25048828125,0.02,50,H3
sample_5.pdf,6,"for more iterations, but we have observed negligible",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,202.20550537109375,0.0,52,H3
sample_5.pdf,6,improvements.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,214.1605224609375,0.0,13,H3
sample_5.pdf,6,3.3,9.962599754333496,NimbusSanL-Bold,True,287.0589904785156,234.8267822265625,0.0,3,H3
sample_5.pdf,6,Implementation Details,9.962599754333496,NimbusSanL-Bold,True,310.8695983886719,234.8267822265625,0.09090909090909091,22,H3
sample_5.pdf,6,We train and test both region proposal and object,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,250.12054443359375,0.02040816326530612,49,H3
sample_5.pdf,6,"detection networks on images of a single scale [1], [2].",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,262.0755310058594,0.0,56,H3
sample_5.pdf,6,We re-scale the images such that their shorter side,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,274.030517578125,0.0196078431372549,51,H3
sample_5.pdf,6,= 600,9.962599754333496,CMR10,False,303.814453125,285.3469543457031,0.0,5,H3
sample_5.pdf,6,pixels [2]. Multi-scale feature extraction,9.962599754333496,URWPalladioL-Roma,False,337.50213623046875,285.9855041503906,0.023809523809523808,42,H3
sample_5.pdf,6,(using an image pyramid) may improve accuracy but,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,297.94049072265625,0.0,49,H3
sample_5.pdf,6,does not exhibit a good speed-accuracy trade-off [2].,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,309.8954772949219,0.0,53,H3
sample_5.pdf,6,"On the re-scaled images, the total stride for both ZF",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,321.8514709472656,0.05660377358490566,53,H3
sample_5.pdf,6,and VGG nets on the last convolutional layer is 16,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,333.80645751953125,0.06,50,H3
sample_5.pdf,6,"pixels, and thus is",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,345.7614440917969,0.0,19,H3
sample_5.pdf,6,10 pixels on a typical PASCAL,9.962599754333496,URWPalladioL-Roma,False,383.6469421386719,345.7614440917969,0.20689655172413793,29,H3
sample_5.pdf,6,image before resizing (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,357.7164306640625,0.0,23,H3
sample_5.pdf,6,500,9.962599754333496,URWPalladioL-Roma,False,398.4769592285156,357.7164306640625,0.0,3,H3
sample_5.pdf,6,375). Even such a large,9.962599754333496,URWPalladioL-Roma,False,421.1699523925781,357.7164306640625,0.043478260869565216,23,H3
sample_5.pdf,6,"stride provides good results, though accuracy may be",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,369.6714172363281,0.0,52,H3
sample_5.pdf,6,further improved with a smaller stride.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,381.6274108886719,0.0,39,H3
sample_5.pdf,6,"For anchors, we use 3 scales with box areas of",9.962599754333496,URWPalladioL-Roma,False,297.0209655761719,393.13641357421875,0.021739130434782608,46,H3
sample_5.pdf,6,128,9.962599754333496,CMR10,False,501.37384033203125,392.49786376953125,0.0,3,H3
sample_5.pdf,6,256,9.962599754333496,CMR10,False,287.0589599609375,404.4528503417969,0.0,3,H3
sample_5.pdf,6,", and",9.962599754333496,URWPalladioL-Roma,False,306.4719543457031,405.0914001464844,0.0,5,H3
sample_5.pdf,6,512,9.962599754333496,CMR10,False,329.79443359375,404.4528503417969,0.0,3,H3
sample_5.pdf,6,"pixels, and 3 aspect ratios of 1:1, 1:2,",9.962599754333496,URWPalladioL-Roma,False,357.137939453125,405.0914001464844,0.0,40,H3
sample_5.pdf,6,and 2:1. These hyper-parameters are,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,417.04638671875,0.02857142857142857,35,H3
sample_5.pdf,6,not,9.962599754333496,URWPalladioL-Ital,False,447.3971252441406,416.87652587890625,0.0,3,H3
sample_5.pdf,6,carefully cho-,9.962599754333496,URWPalladioL-Roma,False,463.31610107421875,417.04638671875,0.0,14,H3
sample_5.pdf,6,"sen for a particular dataset, and we provide ablation",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,429.00238037109375,0.0,53,H3
sample_5.pdf,6,experiments on their effects in the next section. As dis-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,440.9573669433594,0.017543859649122806,57,H3
sample_5.pdf,6,"cussed, our solution does not need an image pyramid",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,452.912353515625,0.0,51,H3
sample_5.pdf,6,"or ﬁlter pyramid to predict regions of multiple scales,",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,464.8673400878906,0.0,55,H3
sample_5.pdf,6,saving considerable running time. Figure 3 (right),9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,476.82232666015625,0.02,50,H3
sample_5.pdf,6,shows the capability of our method for a wide range,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,488.7773132324219,0.0,51,H3
sample_5.pdf,6,of scales and aspect ratios. Table 1 shows the learned,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,500.7333068847656,0.018518518518518517,54,H3
sample_5.pdf,6,average proposal size for each anchor using the ZF,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,512.6882934570312,0.04,50,H3
sample_5.pdf,6,net. We note that our algorithm allows predictions,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,524.643310546875,0.02,50,H3
sample_5.pdf,6,that are larger than the underlying receptive ﬁeld.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,536.5983276367188,0.0,51,H3
sample_5.pdf,6,Such predictions are not impossible—one may still,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,548.5532836914062,0.02040816326530612,49,H3
sample_5.pdf,6,roughly infer the extent of an object if only the middle,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,560.5093383789062,0.0,56,H3
sample_5.pdf,6,of the object is visible.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,572.4642944335938,0.0,25,H3
sample_5.pdf,6,The anchor boxes that cross image boundaries need,9.962599754333496,URWPalladioL-Roma,False,297.0209655761719,583.9733276367188,0.02040816326530612,49,H3
sample_5.pdf,6,"to be handled with care. During training, we ignore",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,595.9282836914062,0.0196078431372549,51,H3
sample_5.pdf,6,all cross-boundary anchors so they do not contribute,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,607.8843383789062,0.0,52,H3
sample_5.pdf,6,to the loss. For a typical,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,619.8392944335938,0.038461538461538464,26,H3
sample_5.pdf,6,1000,9.962599754333496,CMR10,False,407.0585632324219,619.2007446289062,0.0,4,H3
sample_5.pdf,6,600,9.962599754333496,CMR10,False,444.2288818359375,619.2007446289062,0.0,3,H3
sample_5.pdf,6,"image, there",9.962599754333496,URWPalladioL-Roma,False,462.9998474121094,619.8392944335938,0.0,12,H3
sample_5.pdf,6,will be roughly 20000 (,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,631.7943115234375,0.0,23,H3
sample_5.pdf,6,) anchors in,9.962599754333496,URWPalladioL-Roma,False,468.6339111328125,631.7943115234375,0.0,12,H3
sample_5.pdf,6,"total. With the cross-boundary anchors ignored, there",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,643.7493286132812,0.018867924528301886,53,H3
sample_5.pdf,6,are about 6000 anchors per image for training. If the,9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,655.7042846679688,0.018867924528301886,53,H3
sample_5.pdf,6,"boundary-crossing outliers are not ignored in training,",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,667.6593017578125,0.0,55,H3
sample_5.pdf,6,"they introduce large, difﬁcult to correct error terms in",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,679.6152954101562,0.0,56,H3
sample_5.pdf,6,"the objective, and training does not converge. During",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,691.5703125,0.018867924528301886,53,H3
sample_5.pdf,6,"testing, however, we still apply the fully convolutional",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,703.5253295898438,0.0,56,H3
sample_5.pdf,6,RPN to the entire image. This may generate cross-,9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,715.4803466796875,0.08163265306122448,49,H3
sample_5.pdf,6,"boundary proposal boxes, which we clip to the image",9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,727.435302734375,0.0,51,H3
sample_5.pdf,6,boundary.,9.962599754333496,URWPalladioL-Roma,False,287.05889892578125,739.3912963867188,0.0,9,H3
sample_5.pdf,7,Table 2: Detection results on,9.962599754333496,URWPalladioL-Roma,False,36.0,54.35950469970703,0.06896551724137931,29,H3
sample_5.pdf,7,PASCAL VOC 2007 test set,9.962599754333496,URWPalladioL-Bold,True,164.6769256591797,54.26521301269531,0.375,24,H3
sample_5.pdf,7,(trained on VOC 2007 trainval). The detectors are,9.962599754333496,URWPalladioL-Roma,False,297.0034484863281,54.35950469970703,0.08163265306122448,49,H3
sample_5.pdf,7,"Fast R-CNN with ZF, but using various proposal methods for training and testing.",9.962599754333496,URWPalladioL-Roma,False,36.0,66.31452178955078,0.0875,80,H3
sample_5.pdf,7,train-time region proposals,8.966400146484375,URWPalladioL-Bold,True,117.56099700927734,78.20236206054688,0.0,27,P
sample_5.pdf,7,test-time region proposals,8.966400146484375,URWPalladioL-Bold,True,268.239990234375,78.20230102539062,0.0,26,P
sample_5.pdf,7,method,8.966400146484375,URWPalladioL-Roma,False,136.0330047607422,89.24620819091797,0.0,6,P
sample_5.pdf,7,# boxes,8.966400146484375,URWPalladioL-Roma,False,205.8812713623047,89.24620819091797,0.0,7,P
sample_5.pdf,7,method,8.966400146484375,URWPalladioL-Roma,False,276.18499755859375,89.24620819091797,0.0,6,P
sample_5.pdf,7,# proposals,8.966400146484375,URWPalladioL-Roma,False,346.6160583496094,89.24620819091797,0.0,11,P
sample_5.pdf,7,mAP (%),8.966400146484375,URWPalladioL-Roma,False,409.2229919433594,89.24620819091797,0.2857142857142857,7,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,102.99419403076172,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,360.7879333496094,102.99419403076172,0.0,4,P
sample_5.pdf,7,58.7,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,102.99419403076172,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01829528808594,113.95317840576172,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,360.7880554199219,113.95317840576172,0.0,4,P
sample_5.pdf,7,58.6,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,113.95317840576172,0.0,4,P
sample_5.pdf,7,"RPN+ZF, shared",8.966400146484375,URWPalladioL-Roma,False,118.16299438476562,124.91216278076172,0.35714285714285715,14,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.0143280029297,124.91216278076172,0.0,4,P
sample_5.pdf,7,"RPN+ZF, shared",8.966400146484375,URWPalladioL-Roma,False,258.31500244140625,124.91216278076172,0.35714285714285715,14,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.02459716796875,124.91216278076172,0.0,3,P
sample_5.pdf,7,59.9,8.966400146484375,URWPalladioL-Bold,True,419.8529968261719,124.82730102539062,0.0,4,P
sample_5.pdf,7,ablation experiments follow below,8.966400146484375,URWPalladioL-Ital,False,112.8499984741211,138.50830078125,0.0,33,P
sample_5.pdf,7,"RPN+ZF, unshared",8.966400146484375,URWPalladioL-Roma,False,112.8499984741211,152.4091796875,0.3125,16,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01840209960938,152.4091796875,0.0,4,P
sample_5.pdf,7,"RPN+ZF, unshared",8.966400146484375,URWPalladioL-Roma,False,253.0030059814453,152.4091796875,0.3125,16,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.0296630859375,152.4091796875,0.0,3,P
sample_5.pdf,7,58.7,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,152.4091796875,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,163.7672119140625,0.0,4,P
sample_5.pdf,7,RPN+ZF,8.966400146484375,URWPalladioL-Roma,False,273.9209899902344,163.7672119140625,0.8333333333333334,6,P
sample_5.pdf,7,100,8.966400146484375,URWPalladioL-Roma,False,363.0290832519531,163.7672119140625,0.0,3,P
sample_5.pdf,7,55.1,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,163.7672119140625,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,174.7252197265625,0.0,4,P
sample_5.pdf,7,RPN+ZF,8.966400146484375,URWPalladioL-Roma,False,273.9209899902344,174.7252197265625,0.8333333333333334,6,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.0290832519531,174.7252197265625,0.0,3,P
sample_5.pdf,7,56.8,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,174.7252197265625,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,185.6842041015625,0.0,4,P
sample_5.pdf,7,RPN+ZF,8.966400146484375,URWPalladioL-Roma,False,273.9209899902344,185.6842041015625,0.8333333333333334,6,P
sample_5.pdf,7,1000,8.966400146484375,URWPalladioL-Roma,False,360.7874755859375,185.6842041015625,0.0,4,P
sample_5.pdf,7,56.3,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,185.6842041015625,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,196.6431884765625,0.0,4,P
sample_5.pdf,7,RPN+ZF (no NMS),8.966400146484375,URWPalladioL-Roma,False,252.4199981689453,196.6431884765625,0.5333333333333333,15,P
sample_5.pdf,7,6000,8.966400146484375,URWPalladioL-Roma,False,360.78790283203125,196.6431884765625,0.0,4,P
sample_5.pdf,7,55.2,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,196.6431884765625,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,208.001220703125,0.0,4,P
sample_5.pdf,7,RPN+ZF (no,8.966400146484375,URWPalladioL-Roma,False,257.9259948730469,208.001220703125,0.5,10,P
sample_5.pdf,7,cls,8.966400146484375,URWPalladioL-Ital,False,309.4200439453125,207.84832763671875,0.0,3,P
sample_5.pdf,7,100,8.966400146484375,URWPalladioL-Roma,False,363.0289611816406,208.001220703125,0.0,3,P
sample_5.pdf,7,44.6,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,208.001220703125,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,218.960205078125,0.0,4,P
sample_5.pdf,7,RPN+ZF (no,8.966400146484375,URWPalladioL-Roma,False,257.9259948730469,218.960205078125,0.5,10,P
sample_5.pdf,7,cls,8.966400146484375,URWPalladioL-Ital,False,309.4200439453125,218.80731201171875,0.0,3,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.0289611816406,218.960205078125,0.0,3,P
sample_5.pdf,7,51.4,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,218.960205078125,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,229.919189453125,0.0,4,P
sample_5.pdf,7,RPN+ZF (no,8.966400146484375,URWPalladioL-Roma,False,257.9259948730469,229.919189453125,0.5,10,P
sample_5.pdf,7,cls,8.966400146484375,URWPalladioL-Ital,False,309.4200439453125,229.76629638671875,0.0,3,P
sample_5.pdf,7,1000,8.966400146484375,URWPalladioL-Roma,False,360.787353515625,229.919189453125,0.0,4,P
sample_5.pdf,7,55.8,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,229.919189453125,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,241.27618408203125,0.0,4,P
sample_5.pdf,7,RPN+ZF (no,8.966400146484375,URWPalladioL-Roma,False,257.0920104980469,241.27618408203125,0.5,10,P
sample_5.pdf,7,reg,8.966400146484375,URWPalladioL-Ital,False,308.5860595703125,241.123291015625,0.0,3,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.02911376953125,241.27618408203125,0.0,3,P
sample_5.pdf,7,52.1,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,241.27618408203125,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,252.23516845703125,0.0,4,P
sample_5.pdf,7,RPN+ZF (no,8.966400146484375,URWPalladioL-Roma,False,257.0920104980469,252.2352294921875,0.5,10,P
sample_5.pdf,7,reg,8.966400146484375,URWPalladioL-Ital,False,308.5860595703125,252.08233642578125,0.0,3,P
sample_5.pdf,7,1000,8.966400146484375,URWPalladioL-Roma,False,360.7875061035156,252.2352294921875,0.0,4,P
sample_5.pdf,7,51.3,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,252.2352294921875,0.0,4,P
sample_5.pdf,7,2000,8.966400146484375,URWPalladioL-Roma,False,212.01820373535156,263.59320068359375,0.0,4,P
sample_5.pdf,7,RPN+VGG,8.966400146484375,URWPalladioL-Roma,False,269.32598876953125,263.59320068359375,0.8571428571428571,7,P
sample_5.pdf,7,300,8.966400146484375,URWPalladioL-Roma,False,363.02490234375,263.59320068359375,0.0,3,P
sample_5.pdf,7,59.2,8.966400146484375,URWPalladioL-Roma,False,419.8529968261719,263.59320068359375,0.0,4,P
sample_5.pdf,7,Some RPN proposals highly overlap with each,9.962599754333496,URWPalladioL-Roma,False,45.962982177734375,304.4224853515625,0.09302325581395349,43,H3
sample_5.pdf,7,"other. To reduce redundancy, we adopt non-maximum",9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,316.3774719238281,0.02040816326530612,49,H3
sample_5.pdf,7,suppression (NMS) on the proposal regions based on,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,328.33245849609375,0.06,50,H3
sample_5.pdf,7,their,9.962599754333496,URWPalladioL-Roma,False,35.99998092651367,340.2874450683594,0.0,5,H3
sample_5.pdf,7,cls,9.962599754333496,URWPalladioL-Ital,False,56.65245056152344,340.1175842285156,0.0,3,H3
sample_5.pdf,7,scores. We ﬁx the IoU threshold for NMS,9.962599754333496,URWPalladioL-Roma,False,72.39881134033203,340.2874450683594,0.15384615384615385,39,H3
sample_5.pdf,7,"at 0.7, which leaves us about 2000 proposal regions",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,352.242431640625,0.0,51,H3
sample_5.pdf,7,"per image. As we will show, NMS does not harm the",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,364.19842529296875,0.08163265306122448,49,H3
sample_5.pdf,7,"ultimate detection accuracy, but substantially reduces",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,376.1534118652344,0.0,54,H3
sample_5.pdf,7,"the number of proposals. After NMS, we use the",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,388.1083984375,0.08695652173913043,46,H3
sample_5.pdf,7,top-,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,400.0633850097656,0.0,4,H3
sample_5.pdf,7,ranked proposal regions for detection. In the,9.962599754333496,URWPalladioL-Roma,False,62.001914978027344,400.0633850097656,0.022222222222222223,45,H3
sample_5.pdf,7,"following, we train Fast R-CNN using 2000 RPN pro-",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,412.01837158203125,0.16,50,H3
sample_5.pdf,7,"posals, but evaluate different numbers of proposals at",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,423.974365234375,0.0,54,H3
sample_5.pdf,7,test-time.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,435.9293518066406,0.0,10,H3
sample_5.pdf,7,XPERIMENTS,9.56410026550293,NimbusSanL-Bold,True,64.07098388671875,461.79998779296875,1.0,10,H3
sample_5.pdf,7,4.1,9.962599754333496,NimbusSanL-Bold,True,35.99998474121094,476.6015930175781,0.0,3,H3
sample_5.pdf,7,Experiments on PASCAL VOC,9.962599754333496,NimbusSanL-Bold,True,59.810604095458984,476.6015930175781,0.4,25,H3
sample_5.pdf,7,We comprehensively evaluate our method on the,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,492.22235107421875,0.022222222222222223,45,H3
sample_5.pdf,7,PASCAL VOC 2007 detection benchmark [11]. This,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,504.1773376464844,0.21739130434782608,46,H3
sample_5.pdf,7,dataset consists of about 5k trainval images and 5k,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,516.13232421875,0.0,51,H3
sample_5.pdf,7,test images over 20 object categories. We also provide,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,528.0873413085938,0.018518518518518517,54,H3
sample_5.pdf,7,results on the PASCAL VOC 2012 benchmark for a,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,540.0423583984375,0.1956521739130435,46,H3
sample_5.pdf,7,"few models. For the ImageNet pre-trained network,",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,551.9973754882812,0.061224489795918366,49,H3
sample_5.pdf,7,we use the “fast” version of ZF net [32] that has,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,563.9533081054688,0.04081632653061224,49,H3
sample_5.pdf,7,"5 convolutional layers and 3 fully-connected layers,",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,575.9083251953125,0.0,52,H3
sample_5.pdf,7,and the public VGG-16 model,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,587.8633422851562,0.1111111111111111,27,H3
sample_5.pdf,7,[3] that has 13 con-,9.962599754333496,URWPalladioL-Roma,False,184.3999786376953,587.8633422851562,0.0,20,H3
sample_5.pdf,7,volutional layers and 3 fully-connected layers. We,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,599.818359375,0.02,50,H3
sample_5.pdf,7,primarily evaluate detection mean Average Precision,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,611.7733764648438,0.0392156862745098,51,H3
sample_5.pdf,7,"(mAP), because this is the actual metric for object",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,623.7283325195312,0.0392156862745098,51,H3
sample_5.pdf,7,detection (rather than focusing on object proposal,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,635.684326171875,0.0,50,H3
sample_5.pdf,7,proxy metrics).,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,647.6393432617188,0.0,15,H3
sample_5.pdf,7,Table 2 (top) shows Fast R-CNN results when,9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,659.476318359375,0.13953488372093023,43,H3
sample_5.pdf,7,trained and tested using various region proposal,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,671.4313354492188,0.0,48,H3
sample_5.pdf,7,methods. These results use the ZF net. For Selective,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,683.3863525390625,0.09615384615384616,52,H3
sample_5.pdf,7,"Search (SS) [4], we generate about 2000 proposals by",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,695.3423461914062,0.057692307692307696,52,H3
sample_5.pdf,7,"the “fast” mode. For EdgeBoxes (EB) [6], we generate",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,707.29736328125,0.09615384615384616,52,H3
sample_5.pdf,7,the proposals by the default EB setting tuned for 0.7,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,719.2523803710938,0.03773584905660377,53,H3
sample_5.pdf,7,7. www.robots.ox.ac.uk/,7.970099925994873,URWPalladioL-Roma,False,43.96998596191406,740.81982421875,0.0,23,P
sample_5.pdf,7,vgg/research/very deep/,7.970099925994873,URWPalladioL-Roma,False,137.81898498535156,740.81982421875,0.0,23,P
sample_5.pdf,7,IoU. SS has an mAP of 58.7% and EB has an mAP,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,304.4224853515625,0.2222222222222222,45,H3
sample_5.pdf,7,of 58.6% under the Fast R-CNN framework. RPN,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,316.3774719238281,0.18181818181818182,44,H3
sample_5.pdf,7,"with Fast R-CNN achieves competitive results, with",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,328.33245849609375,0.1,50,H3
sample_5.pdf,7,an mAP of 59.9% while using,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,340.2874450683594,0.07407407407407407,27,H3
sample_5.pdf,7,up to,9.962599754333496,URWPalladioL-Ital,False,426.0173645019531,340.1175842285156,0.0,5,H3
sample_5.pdf,7,300 proposals,9.962599754333496,URWPalladioL-Roma,False,453.0419616699219,340.2874450683594,0.0,13,H3
sample_5.pdf,7,Using RPN yields a much faster detection system than,9.962599754333496,URWPalladioL-Roma,False,287.0579528808594,352.242431640625,0.07692307692307693,52,H3
sample_5.pdf,7,using either SS or EB because of shared convolutional,9.962599754333496,URWPalladioL-Roma,False,287.0579528808594,364.19842529296875,0.07547169811320754,53,H3
sample_5.pdf,7,computations; the fewer proposals also reduce the,9.962599754333496,URWPalladioL-Roma,False,287.0579528808594,376.1534118652344,0.0,49,H3
sample_5.pdf,7,region-wise fully-connected layers’ cost (Table 5).,9.962599754333496,URWPalladioL-Roma,False,287.0579528808594,388.1083984375,0.0196078431372549,51,H3
sample_5.pdf,7,Ablation Experiments on RPN.,9.962599754333496,URWPalladioL-Bold,True,287.0579528808594,404.5990905761719,0.17857142857142858,28,H3
sample_5.pdf,7,To investigate the be-,9.962599754333496,URWPalladioL-Roma,False,428.8855895996094,404.6933898925781,0.045454545454545456,22,H3
sample_5.pdf,7,"havior of RPNs as a proposal method, we conducted",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,416.64837646484375,0.061224489795918366,49,H3
sample_5.pdf,7,"several ablation studies. First, we show the effect of",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,428.6033630371094,0.018518518518518517,54,H3
sample_5.pdf,7,sharing convolutional layers between the RPN and,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,440.558349609375,0.0625,48,H3
sample_5.pdf,7,"Fast R-CNN detection network. To do this, we stop",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,452.5133361816406,0.12244897959183673,49,H3
sample_5.pdf,7,after the second step in the 4-step training process.,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,464.46832275390625,0.0,53,H3
sample_5.pdf,7,Using separate networks reduces the result slightly to,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,476.42431640625,0.018518518518518517,54,H3
sample_5.pdf,7,"58.7% (RPN+ZF, unshared, Table 2). We observe that",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,488.3793029785156,0.14,50,H3
sample_5.pdf,7,this is because in the third step when the detector-,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,500.33428955078125,0.0,52,H3
sample_5.pdf,7,"tuned features are used to ﬁne-tune the RPN, the",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,512.289306640625,0.0625,48,H3
sample_5.pdf,7,proposal quality is improved.,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,524.2443237304688,0.0,29,H3
sample_5.pdf,7,"Next, we disentangle the RPN’s inﬂuence on train-",9.962599754333496,URWPalladioL-Roma,False,297.02093505859375,535.8483276367188,0.08163265306122448,49,H3
sample_5.pdf,7,ing the Fast R-CNN detection network. For this pur-,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,547.8032836914062,0.11764705882352941,51,H3
sample_5.pdf,7,"pose, we train a Fast R-CNN model by using the",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,559.75830078125,0.10869565217391304,46,H3
sample_5.pdf,7,2000 SS proposals and ZF net. We ﬁx this detector,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,571.7133178710938,0.10204081632653061,49,H3
sample_5.pdf,7,and evaluate the detection mAP by changing the,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,583.6682739257812,0.043478260869565216,46,H3
sample_5.pdf,7,proposal regions used at test-time. In these ablation,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,595.623291015625,0.018867924528301886,53,H3
sample_5.pdf,7,"experiments, the RPN does not share features with",9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,607.5792846679688,0.061224489795918366,49,H3
sample_5.pdf,7,the detector.,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,619.5343017578125,0.0,13,H3
sample_5.pdf,7,Replacing SS with 300 RPN proposals at test-time,9.962599754333496,URWPalladioL-Roma,False,297.02093505859375,631.1372680664062,0.125,48,H3
sample_5.pdf,7,leads to an mAP of 56.8%. The loss in mAP is because,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,643.09228515625,0.09615384615384616,52,H3
sample_5.pdf,7,of the inconsistency between the training/testing pro-,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,655.0473022460938,0.0,54,H3
sample_5.pdf,7,posals. This result serves as the baseline for the fol-,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,667.0032958984375,0.01818181818181818,55,H3
sample_5.pdf,7,lowing comparisons.,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,678.9583129882812,0.0,19,H3
sample_5.pdf,7,"Somewhat surprisingly, the RPN still leads to a",9.962599754333496,URWPalladioL-Roma,False,297.02093505859375,690.561279296875,0.0851063829787234,47,H3
sample_5.pdf,7,competitive result (55.1%) when using the top-ranked,9.962599754333496,URWPalladioL-Roma,False,287.05792236328125,702.5162963867188,0.0,52,H3
sample_5.pdf,7,"8. For RPN, the number of proposals (",7.970099925994873,URWPalladioL-Roma,False,295.0289306640625,722.8868408203125,0.10810810810810811,37,P
sample_5.pdf,7,e.g,7.970099925994873,URWPalladioL-Ital,False,434.200927734375,722.7509155273438,0.0,3,P
sample_5.pdf,7,"., 300) is the maximum",7.970099925994873,URWPalladioL-Roma,False,443.2789306640625,722.8868408203125,0.0,22,P
sample_5.pdf,7,number for an image. RPN may produce fewer proposals after,7.970099925994873,URWPalladioL-Roma,False,287.05792236328125,731.8538208007812,0.05172413793103448,58,P
sample_5.pdf,7,"NMS, and thus the average number of proposals is smaller.",7.970099925994873,URWPalladioL-Roma,False,287.05792236328125,740.81982421875,0.05263157894736842,57,P
sample_5.pdf,8,Table 3: Detection results on,9.962599754333496,URWPalladioL-Roma,False,36.0,54.35950469970703,0.06896551724137931,29,H3
sample_5.pdf,8,PASCAL VOC 2007 test set,9.962599754333496,URWPalladioL-Bold,True,163.08291625976562,54.26521301269531,0.375,24,H3
sample_5.pdf,8,. The detector is Fast R-CNN and VGG-16. Training,9.962599754333496,URWPalladioL-Roma,False,293.114990234375,54.35950469970703,0.20408163265306123,49,H3
sample_5.pdf,8,"data: “07”: VOC 2007 trainval, “07+12”: union set of VOC 2007 trainval and VOC 2012 trainval. For RPN,",9.962599754333496,URWPalladioL-Roma,False,36.0,66.31452178955078,0.12745098039215685,102,H3
sample_5.pdf,8,the train-time proposals for Fast R-CNN are 2000.,9.962599754333496,URWPalladioL-Roma,False,36.0,78.26953887939453,0.10204081632653061,49,H3
sample_5.pdf,8,: this number was reported in [2]; using the repository,9.962599754333496,URWPalladioL-Roma,False,273.8699951171875,78.26953887939453,0.0,55,H3
sample_5.pdf,8,"provided by this paper, this result is higher (68.1).",9.962599754333496,URWPalladioL-Roma,False,36.0,90.22455596923828,0.0,53,H3
sample_5.pdf,8,method,8.966400146484375,URWPalladioL-Roma,False,164.44900512695312,102.19725799560547,0.0,6,P
sample_5.pdf,8,# proposals,8.966400146484375,URWPalladioL-Roma,False,243.2905731201172,102.19725799560547,0.0,11,P
sample_5.pdf,8,data,8.966400146484375,URWPalladioL-Roma,False,329.00201416015625,102.19719696044922,0.0,4,P
sample_5.pdf,8,mAP (%),8.966400146484375,URWPalladioL-Roma,False,385.81500244140625,102.19719696044922,0.2857142857142857,7,P
sample_5.pdf,8,2000,8.966400146484375,URWPalladioL-Roma,False,257.4613952636719,116.23418426513672,0.0,4,P
sample_5.pdf,8,66.9,8.966400146484375,URWPalladioL-Roma,False,394.47900390625,116.23418426513672,0.0,4,P
sample_5.pdf,8,2000,8.966400146484375,URWPalladioL-Roma,False,257.46142578125,127.19316864013672,0.0,4,P
sample_5.pdf,8,07+12,8.966400146484375,URWPalladioL-Roma,False,326.00299072265625,127.19316864013672,0.0,5,P
sample_5.pdf,8,70.0,8.966400146484375,URWPalladioL-Roma,False,396.4440002441406,127.19316864013672,0.0,4,P
sample_5.pdf,8,"RPN+VGG, unshared",8.966400146484375,URWPalladioL-Roma,False,136.25900268554688,138.55120849609375,0.35294117647058826,17,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,259.6994934082031,138.55120849609375,0.0,3,P
sample_5.pdf,8,68.5,8.966400146484375,URWPalladioL-Roma,False,396.4440002441406,138.55120849609375,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,141.5709991455078,149.51019287109375,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,259.703369140625,149.51019287109375,0.0,3,P
sample_5.pdf,8,69.9,8.966400146484375,URWPalladioL-Roma,False,396.4440002441406,149.51019287109375,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,141.5709991455078,160.46917724609375,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,259.703369140625,160.46917724609375,0.0,3,P
sample_5.pdf,8,07+12,8.966400146484375,URWPalladioL-Roma,False,326.00299072265625,160.46917724609375,0.0,5,P
sample_5.pdf,8,73.2,8.966400146484375,URWPalladioL-Bold,True,396.4440002441406,160.38430786132812,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,141.5709991455078,171.826171875,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,259.703369140625,171.826171875,0.0,3,P
sample_5.pdf,8,COCO+07+12,8.966400146484375,URWPalladioL-Roma,False,309.8819885253906,171.826171875,0.4,10,P
sample_5.pdf,8,78.8,8.966400146484375,URWPalladioL-Bold,True,396.4440002441406,171.74130249023438,0.0,4,P
sample_5.pdf,8,Table 4: Detection results on,9.962599754333496,URWPalladioL-Roma,False,36.0,200.700439453125,0.06896551724137931,29,H3
sample_5.pdf,8,PASCAL VOC 2012 test set,9.962599754333496,URWPalladioL-Bold,True,163.08291625976562,200.6061553955078,0.375,24,H3
sample_5.pdf,8,. The detector is Fast R-CNN and VGG-16. Training,9.962599754333496,URWPalladioL-Roma,False,293.114990234375,200.700439453125,0.20408163265306123,49,H3
sample_5.pdf,8,"data: “07”: VOC 2007 trainval, “07++12”: union set of VOC 2007 trainval+test and VOC 2012 trainval. For",9.962599754333496,URWPalladioL-Roma,False,36.0,210.7674560546875,0.0970873786407767,103,H3
sample_5.pdf,8,"RPN, the train-time proposals for Fast R-CNN are 2000.",9.962599754333496,URWPalladioL-Roma,False,36.0,220.73046875,0.14814814814814814,54,H3
sample_5.pdf,8,: http://host.robots.ox.ac.uk:8080/anonymous/HZJTQA.html.,7.970099925994873,URWPalladioL-Roma,False,294.57598876953125,222.1599578857422,0.10526315789473684,57,P
sample_5.pdf,8,http://host.robots.ox.ac.uk:8080/anonymous/YNPLXB.html.,7.970099925994873,URWPalladioL-Roma,False,36.0,232.1229705810547,0.10909090909090909,55,P
sample_5.pdf,8,: http://host.robots.ox.ac.uk:8080/anonymous/XEDH10.html.,7.970099925994873,URWPalladioL-Roma,False,260.85101318359375,232.1229705810547,0.07017543859649122,57,P
sample_5.pdf,8,method,8.966400146484375,URWPalladioL-Roma,False,161.7320098876953,242.06817626953125,0.0,6,P
sample_5.pdf,8,# proposals,8.966400146484375,URWPalladioL-Roma,False,237.22911071777344,242.06817626953125,0.0,11,P
sample_5.pdf,8,data,8.966400146484375,URWPalladioL-Roma,False,325.6549987792969,242.06817626953125,0.0,4,P
sample_5.pdf,8,mAP (%),8.966400146484375,URWPalladioL-Roma,False,385.1839904785156,242.06817626953125,0.2857142857142857,7,P
sample_5.pdf,8,2000,8.966400146484375,URWPalladioL-Roma,False,251.3919677734375,255.81619262695312,0.0,4,P
sample_5.pdf,8,65.7,8.966400146484375,URWPalladioL-Roma,False,395.81298828125,255.81619262695312,0.0,4,P
sample_5.pdf,8,2000,8.966400146484375,URWPalladioL-Roma,False,251.3919677734375,266.77520751953125,0.0,4,P
sample_5.pdf,8,07++12,8.966400146484375,URWPalladioL-Roma,False,319.9389953613281,266.77520751953125,0.0,6,P
sample_5.pdf,8,68.4,8.966400146484375,URWPalladioL-Roma,False,395.81298828125,266.77520751953125,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,136.88999938964844,278.42120361328125,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,253.63601684570312,278.42120361328125,0.0,3,P
sample_5.pdf,8,67.0,8.966400146484375,URWPalladioL-Roma,False,395.81298828125,278.42120361328125,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,136.88998413085938,289.669189453125,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,253.635986328125,289.669189453125,0.0,3,P
sample_5.pdf,8,07++12,8.966400146484375,URWPalladioL-Roma,False,319.9389953613281,289.669189453125,0.0,6,P
sample_5.pdf,8,70.4,8.966400146484375,URWPalladioL-Bold,True,395.81298828125,289.5843200683594,0.0,4,P
sample_5.pdf,8,"RPN+VGG, shared",8.966400146484375,URWPalladioL-Roma,False,136.88999938964844,301.3161926269531,0.4,15,P
sample_5.pdf,8,300,8.966400146484375,URWPalladioL-Roma,False,253.63601684570312,301.3161926269531,0.0,3,P
sample_5.pdf,8,COCO+07++12,8.966400146484375,URWPalladioL-Roma,False,303.8169860839844,301.3161926269531,0.36363636363636365,11,P
sample_5.pdf,8,75.9,8.966400146484375,URWPalladioL-Bold,True,395.81298828125,301.2313232421875,0.0,4,P
sample_5.pdf,8,Table 5:,9.962599754333496,URWPalladioL-Roma,False,36.0,330.1904602050781,0.125,8,H3
sample_5.pdf,8,Timing,9.962599754333496,URWPalladioL-Bold,True,69.99238586425781,330.0961608886719,0.16666666666666666,6,H3
sample_5.pdf,8,"(ms) on a K40 GPU, except SS proposal is evaluated in a CPU. “Region-wise” includes NMS,",9.962599754333496,URWPalladioL-Roma,False,106.37830352783203,330.1904602050781,0.14772727272727273,88,H3
sample_5.pdf,8,"pooling, fully-connected, and softmax layers. See our released code for the proﬁling of running time.",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,342.14544677734375,0.009900990099009901,101,H3
sample_5.pdf,8,model,8.966400146484375,URWPalladioL-Roma,False,93.76899719238281,354.1181640625,0.0,5,P
sample_5.pdf,8,system,8.966400146484375,URWPalladioL-Roma,False,165.4929962158203,354.1181945800781,0.0,6,P
sample_5.pdf,8,conv,8.966400146484375,URWPalladioL-Roma,False,239.74400329589844,354.1181945800781,0.0,4,P
sample_5.pdf,8,proposal,8.966400146484375,URWPalladioL-Roma,False,278.82855224609375,354.1181945800781,0.0,8,P
sample_5.pdf,8,region-wise,8.966400146484375,URWPalladioL-Roma,False,333.5953063964844,354.1181945800781,0.0,11,P
sample_5.pdf,8,total,8.966400146484375,URWPalladioL-Roma,False,400.5249938964844,354.1181945800781,0.0,5,P
sample_5.pdf,8,rate,8.966400146484375,URWPalladioL-Roma,False,444.37200927734375,354.1181945800781,0.0,4,P
sample_5.pdf,8,VGG,8.966400146484375,URWPalladioL-Roma,False,96.28900146484375,367.8662109375,1.0,3,P
sample_5.pdf,8,SS + Fast R-CNN,8.966400146484375,URWPalladioL-Roma,False,144.00900268554688,367.8662109375,0.4666666666666667,15,P
sample_5.pdf,8,146,8.966400146484375,URWPalladioL-Roma,False,242.60000610351562,367.8662109375,0.0,3,P
sample_5.pdf,8,1510,8.966400146484375,URWPalladioL-Roma,False,287.28857421875,367.8662109375,0.0,4,P
sample_5.pdf,8,174,8.966400146484375,URWPalladioL-Roma,False,350.1520690917969,367.8662109375,0.0,3,P
sample_5.pdf,8,1830,8.966400146484375,URWPalladioL-Roma,False,400.4750061035156,367.8662109375,0.0,4,P
sample_5.pdf,8,0.5 fps,8.966400146484375,URWPalladioL-Roma,False,438.73199462890625,367.8662109375,0.0,7,P
sample_5.pdf,8,VGG,8.966400146484375,URWPalladioL-Roma,False,96.28900146484375,378.8251953125,1.0,3,P
sample_5.pdf,8,RPN + Fast R-CNN,8.966400146484375,URWPalladioL-Roma,False,139.28799438476562,378.8251953125,0.5,16,P
sample_5.pdf,8,141,8.966400146484375,URWPalladioL-Roma,False,242.60000610351562,378.8251953125,0.0,3,P
sample_5.pdf,8,198,8.966400146484375,URWPalladioL-Bold,True,402.7170104980469,378.7403259277344,0.0,3,P
sample_5.pdf,8,5 fps,8.966400146484375,URWPalladioL-Bold,True,441.59698486328125,378.7403259277344,0.0,5,P
sample_5.pdf,8,RPN + Fast R-CNN,8.966400146484375,URWPalladioL-Roma,False,139.28799438476562,390.1831970214844,0.5,16,P
sample_5.pdf,8,17 fps,8.966400146484375,URWPalladioL-Bold,True,439.3550109863281,390.09832763671875,0.0,6,P
sample_5.pdf,8,"100 proposals at test-time, indicating that the top-",9.962599754333496,URWPalladioL-Roma,False,36.0,431.0124816894531,0.0,52,H3
sample_5.pdf,8,ranked RPN proposals are accurate. On the other,9.962599754333496,URWPalladioL-Roma,False,36.0,442.96746826171875,0.0851063829787234,47,H3
sample_5.pdf,8,"extreme, using the top-ranked 6000 RPN proposals",9.962599754333496,URWPalladioL-Roma,False,36.0,454.9224548339844,0.0625,48,H3
sample_5.pdf,8,"(without NMS) has a comparable mAP (55.2%), sug-",9.962599754333496,URWPalladioL-Roma,False,36.0,466.87744140625,0.10416666666666667,48,H3
sample_5.pdf,8,gesting NMS does not harm the detection mAP and,9.962599754333496,URWPalladioL-Roma,False,36.0,478.8324279785156,0.10638297872340426,47,H3
sample_5.pdf,8,may reduce false alarms.,9.962599754333496,URWPalladioL-Roma,False,36.0,490.7884216308594,0.0,24,H3
sample_5.pdf,8,"Next, we separately investigate the roles of RPN’s",9.962599754333496,URWPalladioL-Roma,False,45.9630012512207,505.909423828125,0.08,50,H3
sample_5.pdf,8,cls,9.962599754333496,URWPalladioL-Ital,False,36.0,517.694580078125,0.0,3,H3
sample_5.pdf,8,and,9.962599754333496,URWPalladioL-Roma,False,46.699832916259766,517.8644409179688,0.0,3,H3
sample_5.pdf,8,reg,9.962599754333496,URWPalladioL-Ital,False,69.32868194580078,517.694580078125,0.0,3,H3
sample_5.pdf,8,outputs by turning off either of them,9.962599754333496,URWPalladioL-Roma,False,87.64286804199219,517.8644409179688,0.0,37,H3
sample_5.pdf,8,at test-time. When the,9.962599754333496,URWPalladioL-Roma,False,36.0,529.8193969726562,0.045454545454545456,22,H3
sample_5.pdf,8,cls,9.962599754333496,URWPalladioL-Ital,False,139.88002014160156,529.6495361328125,0.0,3,H3
sample_5.pdf,8,layer is removed at test-,9.962599754333496,URWPalladioL-Roma,False,155.412841796875,529.8193969726562,0.0,25,H3
sample_5.pdf,8,"time (thus no NMS/ranking is used), we randomly",9.962599754333496,URWPalladioL-Roma,False,36.0,541.7754516601562,0.06382978723404255,47,H3
sample_5.pdf,8,sample,9.962599754333496,URWPalladioL-Roma,False,36.0,553.7304077148438,0.0,6,H3
sample_5.pdf,8,proposals from the unscored regions. The,9.962599754333496,URWPalladioL-Roma,False,79.69692993164062,553.7304077148438,0.025,40,H3
sample_5.pdf,8,mAP is nearly unchanged with,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,565.6854248046875,0.07142857142857142,28,H3
sample_5.pdf,8,= 1000,9.962599754333496,CMR10,False,185.39491271972656,565.046875,0.0,6,H3
sample_5.pdf,8,"(55.8%), but",9.962599754333496,URWPalladioL-Roma,False,219.68865966796875,565.6854248046875,0.0,12,H3
sample_5.pdf,8,degrades considerably to 44.6% when,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,577.6404418945312,0.0,35,H3
sample_5.pdf,8,= 100,9.962599754333496,CMR10,False,219.20291137695312,577.0018920898438,0.0,5,H3
sample_5.pdf,8,. This,9.962599754333496,URWPalladioL-Roma,False,249.75997924804688,577.6404418945312,0.16666666666666666,6,H3
sample_5.pdf,8,shows that the,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,589.5953979492188,0.0,14,H3
sample_5.pdf,8,cls,9.962599754333496,URWPalladioL-Ital,False,102.67967987060547,589.425537109375,0.0,3,H3
sample_5.pdf,8,scores account for the accuracy of,9.962599754333496,URWPalladioL-Roma,False,117.1788101196289,589.5953979492188,0.0,34,H3
sample_5.pdf,8,the highest ranked proposals.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,601.5514526367188,0.0,29,H3
sample_5.pdf,8,"On the other hand, when the",9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,616.6724243164062,0.037037037037037035,27,H3
sample_5.pdf,8,reg,9.962599754333496,URWPalladioL-Ital,False,179.02346801757812,616.5025634765625,0.0,3,H3
sample_5.pdf,8,layer is removed,9.962599754333496,URWPalladioL-Roma,False,195.33587646484375,616.6724243164062,0.0,16,H3
sample_5.pdf,8,"at test-time (so the proposals become anchor boxes),",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,628.62744140625,0.0,52,H3
sample_5.pdf,8,the mAP drops to 52.1%. This suggests that the high-,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,640.5824584960938,0.057692307692307696,52,H3
sample_5.pdf,8,quality proposals are mainly due to the regressed box,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,652.5384521484375,0.0,53,H3
sample_5.pdf,8,"bounds. The anchor boxes, though having multiple",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,664.493408203125,0.020833333333333332,48,H3
sample_5.pdf,8,"scales and aspect ratios, are not sufﬁcient for accurate",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,676.4484252929688,0.0,56,H3
sample_5.pdf,8,detection.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,688.4034423828125,0.0,10,H3
sample_5.pdf,8,We also evaluate the effects of more powerful net-,9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,703.5254516601562,0.02,50,H3
sample_5.pdf,8,works on the proposal quality of RPN alone. We use,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,715.4804077148438,0.08,50,H3
sample_5.pdf,8,"VGG-16 to train the RPN, and still use the above",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,727.4354248046875,0.125,48,H3
sample_5.pdf,8,detector of SS+ZF. The mAP improves from 56.8%,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,739.3904418945312,0.15217391304347827,46,H3
sample_5.pdf,8,(using RPN+ZF) to 59.2% (using RPN+VGG). This is a,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,431.012451171875,0.24,50,H3
sample_5.pdf,8,"promising result, because it suggests that the proposal",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,442.9674377441406,0.0,55,H3
sample_5.pdf,8,quality of RPN+VGG is better than that of RPN+ZF.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,454.92242431640625,0.22448979591836735,49,H3
sample_5.pdf,8,Because proposals of RPN+ZF are competitive with,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,466.8774108886719,0.125,48,H3
sample_5.pdf,8,SS (both are 58.7% when consistently used for training,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,478.8334045410156,0.037037037037037035,54,H3
sample_5.pdf,8,"and testing), we may expect RPN+VGG to be better",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,490.78839111328125,0.125,48,H3
sample_5.pdf,8,than SS. The following experiments justify this hy-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,502.7433776855469,0.058823529411764705,51,H3
sample_5.pdf,8,pothesis.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,514.6983642578125,0.0,9,H3
sample_5.pdf,8,Performance of VGG-16.,9.962599754333496,URWPalladioL-Bold,True,287.0589904785156,536.05810546875,0.18181818181818182,22,H3
sample_5.pdf,8,Table 3 shows the results,9.962599754333496,URWPalladioL-Roma,False,404.1195983886719,536.1524047851562,0.04,25,H3
sample_5.pdf,8,of VGG-16 for both proposal and detection. Using,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,548.1073608398438,0.08333333333333333,48,H3
sample_5.pdf,8,"RPN+VGG, the result is 68.5% for",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,560.0633544921875,0.1875,32,H3
sample_5.pdf,8,unshared,9.962599754333496,URWPalladioL-Ital,False,443.5615234375,559.8934936523438,0.0,8,H3
sample_5.pdf,8,"features,",9.962599754333496,URWPalladioL-Roma,False,484.53546142578125,560.0633544921875,0.0,9,H3
sample_5.pdf,8,"slightly higher than the SS baseline. As shown above,",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,572.0183715820312,0.05660377358490566,53,H3
sample_5.pdf,8,this is because the proposals generated by RPN+VGG,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,583.973388671875,0.12,50,H3
sample_5.pdf,8,are more accurate than SS. Unlike SS that is pre-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,595.9284057617188,0.10204081632653061,49,H3
sample_5.pdf,8,"deﬁned, the RPN is actively trained and beneﬁts from",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,607.8833618164062,0.057692307692307696,52,H3
sample_5.pdf,8,better networks. For the feature-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,619.83935546875,0.030303030303030304,33,H3
sample_5.pdf,8,shared,9.962599754333496,URWPalladioL-Ital,False,441.4329833984375,619.6694946289062,0.0,6,H3
sample_5.pdf,8,"variant, the",9.962599754333496,URWPalladioL-Roma,False,467.2660217285156,619.83935546875,0.0,12,H3
sample_5.pdf,8,"result is 69.9%—better than the strong SS baseline, yet",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,631.7943725585938,0.03636363636363636,55,H3
sample_5.pdf,8,with nearly cost-free proposals. We further train the,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,643.7493896484375,0.018867924528301886,53,H3
sample_5.pdf,8,RPN and detection network on the union set of PAS-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,655.7044067382812,0.12,50,H3
sample_5.pdf,8,CAL VOC 2007 trainval and 2012 trainval. The mAP,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,667.6593627929688,0.1875,48,H3
sample_5.pdf,8,73.2%,9.962599754333496,URWPalladioL-Bold,True,294.1822204589844,679.5200805664062,0.0,5,H3
sample_5.pdf,8,. Figure 5 shows some results on the PASCAL,9.962599754333496,URWPalladioL-Roma,False,323.28497314453125,679.6143798828125,0.16279069767441862,43,H3
sample_5.pdf,8,VOC 2007 test set. On the PASCAL VOC 2012 test set,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,691.5703735351562,0.26,50,H3
sample_5.pdf,8,"(Table 4), our method has an mAP of",9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,703.525390625,0.08571428571428572,35,H3
sample_5.pdf,8,70.4%,9.962599754333496,URWPalladioL-Bold,True,459.9299621582031,703.4310913085938,0.0,5,H3
sample_5.pdf,8,trained,9.962599754333496,URWPalladioL-Roma,False,490.3302307128906,703.525390625,0.0,7,H3
sample_5.pdf,8,on the union set of VOC 2007 trainval+test and VOC,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,715.4804077148438,0.12,50,H3
sample_5.pdf,8,2012 trainval. Table 6 and Table 7 show the detailed,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,727.4353637695312,0.038461538461538464,52,H3
sample_5.pdf,8,numbers.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,739.390380859375,0.0,8,H3
sample_5.pdf,9,"Table 6: Results on PASCAL VOC 2007 test set with Fast R-CNN detectors and VGG-16. For RPN, the train-time",9.962599754333496,URWPalladioL-Roma,False,36.0,54.35950469970703,0.2169811320754717,106,H3
sample_5.pdf,9,proposals for Fast R-CNN are 2000. RPN,9.962599754333496,URWPalladioL-Roma,False,36.0,66.31452178955078,0.21052631578947367,38,H3
sample_5.pdf,9,denotes the unsharing feature version.,9.962599754333496,URWPalladioL-Roma,False,229.08200073242188,66.31452178955078,0.0,38,H3
sample_5.pdf,9,method,5.347509860992432,URWPalladioL-Roma,False,41.466522216796875,79.70220947265625,0.0,6,P
sample_5.pdf,9,# box,6.8754353523254395,URWPalladioL-Roma,False,66.9066390991211,78.60601806640625,0.0,5,P
sample_5.pdf,9,data,6.8754353523254395,URWPalladioL-Roma,False,104.93225860595703,78.60601806640625,0.0,4,P
sample_5.pdf,9,mAP,6.8754353523254395,URWPalladioL-Roma,False,138.63465881347656,78.60601806640625,0.6666666666666666,3,P
sample_5.pdf,9,areo,5.347509860992432,URWPalladioL-Roma,False,161.35646057128906,79.70220947265625,0.0,4,P
sample_5.pdf,9,bike,5.347509860992432,URWPalladioL-Roma,False,179.75189208984375,79.70220947265625,0.0,4,P
sample_5.pdf,9,bird,5.347509860992432,URWPalladioL-Roma,False,198.21148681640625,79.70220947265625,0.0,4,P
sample_5.pdf,9,boat,5.347509860992432,URWPalladioL-Roma,False,216.2967529296875,79.70220947265625,0.0,4,P
sample_5.pdf,9,bottle,5.347509860992432,URWPalladioL-Roma,False,233.6708221435547,79.70220947265625,0.0,6,P
sample_5.pdf,9,bus,5.347509860992432,URWPalladioL-Roma,False,253.88980102539062,79.70220947265625,0.0,3,P
sample_5.pdf,9,car,5.347509860992432,URWPalladioL-Roma,False,272.86810302734375,79.70220947265625,0.0,3,P
sample_5.pdf,9,cat,5.347509860992432,URWPalladioL-Roma,False,291.3865051269531,79.70220947265625,0.0,3,P
sample_5.pdf,9,chair,5.347509860992432,URWPalladioL-Roma,False,307.2044982910156,79.70220947265625,0.0,5,P
sample_5.pdf,9,cow,5.347509860992432,URWPalladioL-Roma,False,326.57318115234375,79.70220947265625,0.0,3,P
sample_5.pdf,9,table,5.347509860992432,URWPalladioL-Roma,False,344.0381774902344,79.70220947265625,0.0,5,P
sample_5.pdf,9,dog,5.347509860992432,URWPalladioL-Roma,False,363.5405578613281,79.70220947265625,0.0,3,P
sample_5.pdf,9,horse,5.347509860992432,URWPalladioL-Roma,False,380.3424377441406,79.70220947265625,0.0,5,P
sample_5.pdf,9,mbike person plant,5.347509860992432,URWPalladioL-Roma,False,398.6790466308594,79.70220947265625,0.0,18,P
sample_5.pdf,9,sheep,5.347509860992432,URWPalladioL-Roma,False,453.6835021972656,79.70220947265625,0.0,5,P
sample_5.pdf,9,sofa,5.347509860992432,URWPalladioL-Roma,False,473.3089294433594,79.70220947265625,0.0,4,P
sample_5.pdf,9,train,5.347509860992432,URWPalladioL-Roma,False,490.8647766113281,79.70220947265625,0.0,5,P
sample_5.pdf,9,2000,6.8754353523254395,URWPalladioL-Roma,False,68.50541687011719,91.43994140625,0.0,4,P
sample_5.pdf,9,66.9,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,91.43994140625,0.0,4,P
sample_5.pdf,9,74.5,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,91.43994140625,0.0,4,P
sample_5.pdf,9,78.3,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,91.43994140625,0.0,4,P
sample_5.pdf,9,69.2,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,91.43994140625,0.0,4,P
sample_5.pdf,9,53.2,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,91.43994140625,0.0,4,P
sample_5.pdf,9,36.6,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,91.43994140625,0.0,4,P
sample_5.pdf,9,77.3,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,91.43994140625,0.0,4,P
sample_5.pdf,9,78.2,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,91.43994140625,0.0,4,P
sample_5.pdf,9,82.0,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,91.43994140625,0.0,4,P
sample_5.pdf,9,40.7,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,91.43994140625,0.0,4,P
sample_5.pdf,9,72.7,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,91.43994140625,0.0,4,P
sample_5.pdf,9,67.9,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,91.43994140625,0.0,4,P
sample_5.pdf,9,79.6,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,91.43994140625,0.0,4,P
sample_5.pdf,9,79.2,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,91.43994140625,0.0,4,P
sample_5.pdf,9,73.0,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,91.43994140625,0.0,4,P
sample_5.pdf,9,69.0,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,91.43994140625,0.0,4,P
sample_5.pdf,9,30.1,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,91.43994140625,0.0,4,P
sample_5.pdf,9,65.4,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,91.43994140625,0.0,4,P
sample_5.pdf,9,70.2,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,91.43994140625,0.0,4,P
sample_5.pdf,9,75.8,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,91.43994140625,0.0,4,P
sample_5.pdf,9,65.8,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,91.43994140625,0.0,4,P
sample_5.pdf,9,2000,6.8754353523254395,URWPalladioL-Roma,False,68.50541687011719,102.13531494140625,0.0,4,P
sample_5.pdf,9,07+12,6.8754353523254395,URWPalladioL-Roma,False,102.63262176513672,102.13531494140625,0.0,5,P
sample_5.pdf,9,70.0,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,102.13531494140625,0.0,4,P
sample_5.pdf,9,77.0,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,102.13531494140625,0.0,4,P
sample_5.pdf,9,78.1,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,102.13531494140625,0.0,4,P
sample_5.pdf,9,69.3,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,102.13531494140625,0.0,4,P
sample_5.pdf,9,59.4,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,102.13531494140625,0.0,4,P
sample_5.pdf,9,38.3,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,102.13531494140625,0.0,4,P
sample_5.pdf,9,81.6,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,102.13531494140625,0.0,4,P
sample_5.pdf,9,78.6,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,102.13531494140625,0.0,4,P
sample_5.pdf,9,86.7,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,102.13531494140625,0.0,4,P
sample_5.pdf,9,42.8,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,102.13531494140625,0.0,4,P
sample_5.pdf,9,78.8,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,102.13531494140625,0.0,4,P
sample_5.pdf,9,68.9,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,102.13531494140625,0.0,4,P
sample_5.pdf,9,84.7,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,102.13531494140625,0.0,4,P
sample_5.pdf,9,82.0,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,102.13531494140625,0.0,4,P
sample_5.pdf,9,76.6,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,102.13531494140625,0.0,4,P
sample_5.pdf,9,69.9,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,102.13531494140625,0.0,4,P
sample_5.pdf,9,31.8,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,102.13531494140625,0.0,4,P
sample_5.pdf,9,70.1,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,102.13531494140625,0.0,4,P
sample_5.pdf,9,74.8,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,102.13531494140625,0.0,4,P
sample_5.pdf,9,80.4,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,102.13531494140625,0.0,4,P
sample_5.pdf,9,70.4,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,102.13531494140625,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,41.74486541748047,113.13580322265625,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,113.13580322265625,0.0,3,P
sample_5.pdf,9,68.5,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,113.13580322265625,0.0,4,P
sample_5.pdf,9,74.1,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,113.13580322265625,0.0,4,P
sample_5.pdf,9,77.2,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,113.13580322265625,0.0,4,P
sample_5.pdf,9,67.7,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,113.13580322265625,0.0,4,P
sample_5.pdf,9,53.9,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,113.13580322265625,0.0,4,P
sample_5.pdf,9,51.0,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,113.13580322265625,0.0,4,P
sample_5.pdf,9,75.1,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,113.13580322265625,0.0,4,P
sample_5.pdf,9,79.2,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,113.13580322265625,0.0,4,P
sample_5.pdf,9,78.9,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,113.13580322265625,0.0,4,P
sample_5.pdf,9,50.7,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,113.13580322265625,0.0,4,P
sample_5.pdf,9,78.0,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,113.13580322265625,0.0,4,P
sample_5.pdf,9,61.1,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,113.13580322265625,0.0,4,P
sample_5.pdf,9,79.1,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,113.13580322265625,0.0,4,P
sample_5.pdf,9,81.9,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,113.13580322265625,0.0,4,P
sample_5.pdf,9,72.2,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,113.13580322265625,0.0,4,P
sample_5.pdf,9,75.9,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,113.13580322265625,0.0,4,P
sample_5.pdf,9,37.2,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,113.13580322265625,0.0,4,P
sample_5.pdf,9,71.4,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,113.13580322265625,0.0,4,P
sample_5.pdf,9,62.5,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,113.13580322265625,0.0,4,P
sample_5.pdf,9,77.4,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,113.13580322265625,0.0,4,P
sample_5.pdf,9,66.4,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,113.13580322265625,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.39961242675781,123.83114624023438,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,123.83114624023438,0.0,3,P
sample_5.pdf,9,69.9,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,123.83114624023438,0.0,4,P
sample_5.pdf,9,70.0,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,123.83114624023438,0.0,4,P
sample_5.pdf,9,80.6,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,123.83114624023438,0.0,4,P
sample_5.pdf,9,70.1,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,123.83114624023438,0.0,4,P
sample_5.pdf,9,57.3,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,123.83114624023438,0.0,4,P
sample_5.pdf,9,49.9,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,123.83114624023438,0.0,4,P
sample_5.pdf,9,78.2,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,123.83114624023438,0.0,4,P
sample_5.pdf,9,80.4,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,123.83114624023438,0.0,4,P
sample_5.pdf,9,82.0,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,123.83114624023438,0.0,4,P
sample_5.pdf,9,52.2,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,123.83114624023438,0.0,4,P
sample_5.pdf,9,75.3,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,123.83114624023438,0.0,4,P
sample_5.pdf,9,67.2,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,123.83114624023438,0.0,4,P
sample_5.pdf,9,80.3,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,123.83114624023438,0.0,4,P
sample_5.pdf,9,79.8,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,123.83114624023438,0.0,4,P
sample_5.pdf,9,75.0,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,123.83114624023438,0.0,4,P
sample_5.pdf,9,76.3,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,123.83114624023438,0.0,4,P
sample_5.pdf,9,39.1,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,123.83114624023438,0.0,4,P
sample_5.pdf,9,68.3,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,123.83114624023438,0.0,4,P
sample_5.pdf,9,67.3,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,123.83114624023438,0.0,4,P
sample_5.pdf,9,81.1,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,123.83114624023438,0.0,4,P
sample_5.pdf,9,67.6,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,123.83114624023438,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.39961242675781,134.52572631835938,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,134.52572631835938,0.0,3,P
sample_5.pdf,9,07+12,6.8754353523254395,URWPalladioL-Roma,False,102.63262176513672,134.52572631835938,0.0,5,P
sample_5.pdf,9,73.2,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,134.52572631835938,0.0,4,P
sample_5.pdf,9,76.5,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,134.52572631835938,0.0,4,P
sample_5.pdf,9,79.0,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,134.52572631835938,0.0,4,P
sample_5.pdf,9,70.9,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,134.52572631835938,0.0,4,P
sample_5.pdf,9,65.5,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,134.52572631835938,0.0,4,P
sample_5.pdf,9,52.1,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,134.52572631835938,0.0,4,P
sample_5.pdf,9,83.1,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,134.52572631835938,0.0,4,P
sample_5.pdf,9,84.7,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,134.52572631835938,0.0,4,P
sample_5.pdf,9,86.4,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,134.52572631835938,0.0,4,P
sample_5.pdf,9,52.0,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,134.52572631835938,0.0,4,P
sample_5.pdf,9,81.9,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,134.52572631835938,0.0,4,P
sample_5.pdf,9,65.7,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,134.52572631835938,0.0,4,P
sample_5.pdf,9,84.8,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,134.52572631835938,0.0,4,P
sample_5.pdf,9,84.6,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,134.52572631835938,0.0,4,P
sample_5.pdf,9,77.5,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,134.52572631835938,0.0,4,P
sample_5.pdf,9,76.7,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,134.52572631835938,0.0,4,P
sample_5.pdf,9,38.8,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,134.52572631835938,0.0,4,P
sample_5.pdf,9,73.6,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,134.52572631835938,0.0,4,P
sample_5.pdf,9,73.9,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,134.52572631835938,0.0,4,P
sample_5.pdf,9,83.0,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,134.52572631835938,0.0,4,P
sample_5.pdf,9,72.6,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,134.52572631835938,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.39961242675781,145.22103881835938,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,145.22103881835938,0.0,3,P
sample_5.pdf,9,COCO+07+12,6.1114726066589355,URWPalladioL-Roma,False,92.63967895507812,145.76913452148438,0.4,10,P
sample_5.pdf,9,78.8,6.8754353523254395,URWPalladioL-Bold,True,140.25796508789062,145.1559600830078,0.0,4,P
sample_5.pdf,9,84.3,6.8754353523254395,URWPalladioL-Bold,True,160.42633056640625,145.1559600830078,0.0,4,P
sample_5.pdf,9,82.0,6.8754353523254395,URWPalladioL-Bold,True,178.76052856445312,145.1559600830078,0.0,4,P
sample_5.pdf,9,77.7,6.8754353523254395,URWPalladioL-Bold,True,197.09471130371094,145.1559600830078,0.0,4,P
sample_5.pdf,9,68.9,6.8754353523254395,URWPalladioL-Bold,True,215.42965698242188,145.1559600830078,0.0,4,P
sample_5.pdf,9,65.7,6.8754353523254395,URWPalladioL-Bold,True,233.7638397216797,145.1559600830078,0.0,4,P
sample_5.pdf,9,88.1,6.8754353523254395,URWPalladioL-Bold,True,252.09803771972656,145.1559600830078,0.0,4,P
sample_5.pdf,9,88.4,6.8754353523254395,URWPalladioL-Bold,True,270.4329833984375,145.1559600830078,0.0,4,P
sample_5.pdf,9,88.9,6.8754353523254395,URWPalladioL-Bold,True,288.7671813964844,145.1559600830078,0.0,4,P
sample_5.pdf,9,63.6,6.8754353523254395,URWPalladioL-Bold,True,307.10137939453125,145.1559600830078,0.0,4,P
sample_5.pdf,9,86.3,6.8754353523254395,URWPalladioL-Bold,True,325.4363098144531,145.1559600830078,0.0,4,P
sample_5.pdf,9,70.8,6.8754353523254395,URWPalladioL-Bold,True,343.7705078125,145.1559600830078,0.0,4,P
sample_5.pdf,9,85.9,6.8754353523254395,URWPalladioL-Bold,True,362.1047058105469,145.1559600830078,0.0,4,P
sample_5.pdf,9,87.6,6.8754353523254395,URWPalladioL-Bold,True,380.4396667480469,145.1559600830078,0.0,4,P
sample_5.pdf,9,80.1,6.8754353523254395,URWPalladioL-Bold,True,398.77386474609375,145.1559600830078,0.0,4,P
sample_5.pdf,9,82.3,6.8754353523254395,URWPalladioL-Bold,True,417.1080322265625,145.1559600830078,0.0,4,P
sample_5.pdf,9,53.6,6.8754353523254395,URWPalladioL-Bold,True,435.4429931640625,145.1559600830078,0.0,4,P
sample_5.pdf,9,80.4,6.8754353523254395,URWPalladioL-Bold,True,453.77716064453125,145.1559600830078,0.0,4,P
sample_5.pdf,9,75.8,6.8754353523254395,URWPalladioL-Bold,True,472.1113586425781,145.1559600830078,0.0,4,P
sample_5.pdf,9,86.6,6.8754353523254395,URWPalladioL-Bold,True,490.4463195800781,145.1559600830078,0.0,4,P
sample_5.pdf,9,78.9,6.8754353523254395,URWPalladioL-Bold,True,508.68463134765625,145.1559600830078,0.0,4,P
sample_5.pdf,9,"Table 7: Results on PASCAL VOC 2012 test set with Fast R-CNN detectors and VGG-16. For RPN, the train-time",9.962599754333496,URWPalladioL-Roma,False,36.0,172.5155029296875,0.2169811320754717,106,H3
sample_5.pdf,9,proposals for Fast R-CNN are 2000.,9.962599754333496,URWPalladioL-Roma,False,36.0,184.47149658203125,0.14705882352941177,34,H3
sample_5.pdf,9,method,5.347509860992432,URWPalladioL-Roma,False,41.466522216796875,197.85891723632812,0.0,6,P
sample_5.pdf,9,# box,6.8754353523254395,URWPalladioL-Roma,False,66.9066390991211,196.76272583007812,0.0,5,P
sample_5.pdf,9,data,6.8754353523254395,URWPalladioL-Roma,False,104.93225860595703,196.76272583007812,0.0,4,P
sample_5.pdf,9,mAP,6.8754353523254395,URWPalladioL-Roma,False,138.63465881347656,196.76272583007812,0.6666666666666666,3,P
sample_5.pdf,9,areo,5.347509860992432,URWPalladioL-Roma,False,161.35646057128906,197.85891723632812,0.0,4,P
sample_5.pdf,9,bike,5.347509860992432,URWPalladioL-Roma,False,179.75189208984375,197.85891723632812,0.0,4,P
sample_5.pdf,9,bird,5.347509860992432,URWPalladioL-Roma,False,198.21148681640625,197.85891723632812,0.0,4,P
sample_5.pdf,9,boat,5.347509860992432,URWPalladioL-Roma,False,216.2967529296875,197.85891723632812,0.0,4,P
sample_5.pdf,9,bottle,5.347509860992432,URWPalladioL-Roma,False,233.6708221435547,197.85891723632812,0.0,6,P
sample_5.pdf,9,bus,5.347509860992432,URWPalladioL-Roma,False,253.88980102539062,197.85891723632812,0.0,3,P
sample_5.pdf,9,car,5.347509860992432,URWPalladioL-Roma,False,272.86810302734375,197.85891723632812,0.0,3,P
sample_5.pdf,9,cat,5.347509860992432,URWPalladioL-Roma,False,291.3865051269531,197.85891723632812,0.0,3,P
sample_5.pdf,9,chair,5.347509860992432,URWPalladioL-Roma,False,307.2044982910156,197.85891723632812,0.0,5,P
sample_5.pdf,9,cow,5.347509860992432,URWPalladioL-Roma,False,326.57318115234375,197.85891723632812,0.0,3,P
sample_5.pdf,9,table,5.347509860992432,URWPalladioL-Roma,False,344.0381774902344,197.85891723632812,0.0,5,P
sample_5.pdf,9,dog,5.347509860992432,URWPalladioL-Roma,False,363.5405578613281,197.85891723632812,0.0,3,P
sample_5.pdf,9,horse,5.347509860992432,URWPalladioL-Roma,False,380.3424377441406,197.85891723632812,0.0,5,P
sample_5.pdf,9,mbike person plant,5.347509860992432,URWPalladioL-Roma,False,398.6790466308594,197.85891723632812,0.0,18,P
sample_5.pdf,9,sheep,5.347509860992432,URWPalladioL-Roma,False,453.6835021972656,197.85891723632812,0.0,5,P
sample_5.pdf,9,sofa,5.347509860992432,URWPalladioL-Roma,False,473.3089294433594,197.85891723632812,0.0,4,P
sample_5.pdf,9,train,5.347509860992432,URWPalladioL-Roma,False,490.8647766113281,197.85891723632812,0.0,5,P
sample_5.pdf,9,2000,6.8754353523254395,URWPalladioL-Roma,False,68.50541687011719,209.59664916992188,0.0,4,P
sample_5.pdf,9,65.7,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,209.59664916992188,0.0,4,P
sample_5.pdf,9,80.3,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,209.59664916992188,0.0,4,P
sample_5.pdf,9,74.7,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,209.59664916992188,0.0,4,P
sample_5.pdf,9,66.9,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,209.59664916992188,0.0,4,P
sample_5.pdf,9,46.9,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,209.59664916992188,0.0,4,P
sample_5.pdf,9,37.7,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,209.59664916992188,0.0,4,P
sample_5.pdf,9,73.9,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,209.59664916992188,0.0,4,P
sample_5.pdf,9,68.6,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,209.59664916992188,0.0,4,P
sample_5.pdf,9,87.7,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,209.59664916992188,0.0,4,P
sample_5.pdf,9,41.7,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,209.59664916992188,0.0,4,P
sample_5.pdf,9,71.1,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,209.59664916992188,0.0,4,P
sample_5.pdf,9,51.1,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,209.59664916992188,0.0,4,P
sample_5.pdf,9,86.0,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,209.59664916992188,0.0,4,P
sample_5.pdf,9,77.8,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,209.59664916992188,0.0,4,P
sample_5.pdf,9,79.8,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,209.59664916992188,0.0,4,P
sample_5.pdf,9,69.8,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,209.59664916992188,0.0,4,P
sample_5.pdf,9,32.1,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,209.59664916992188,0.0,4,P
sample_5.pdf,9,65.5,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,209.59664916992188,0.0,4,P
sample_5.pdf,9,63.8,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,209.59664916992188,0.0,4,P
sample_5.pdf,9,76.4,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,209.59664916992188,0.0,4,P
sample_5.pdf,9,61.7,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,209.59664916992188,0.0,4,P
sample_5.pdf,9,2000,6.8754353523254395,URWPalladioL-Roma,False,68.50541687011719,220.2919921875,0.0,4,P
sample_5.pdf,9,07++12,6.8754353523254395,URWPalladioL-Roma,False,100.54922485351562,220.2919921875,0.0,6,P
sample_5.pdf,9,68.4,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,220.2919921875,0.0,4,P
sample_5.pdf,9,82.3,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,220.2919921875,0.0,4,P
sample_5.pdf,9,78.4,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,220.2919921875,0.0,4,P
sample_5.pdf,9,70.8,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,220.2919921875,0.0,4,P
sample_5.pdf,9,52.3,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,220.2919921875,0.0,4,P
sample_5.pdf,9,38.7,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,220.2919921875,0.0,4,P
sample_5.pdf,9,77.8,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,220.2919921875,0.0,4,P
sample_5.pdf,9,71.6,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,220.2919921875,0.0,4,P
sample_5.pdf,9,89.3,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,220.2919921875,0.0,4,P
sample_5.pdf,9,44.2,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,220.2919921875,0.0,4,P
sample_5.pdf,9,73.0,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,220.2919921875,0.0,4,P
sample_5.pdf,9,55.0,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,220.2919921875,0.0,4,P
sample_5.pdf,9,87.5,6.8754353523254395,URWPalladioL-Bold,True,362.1047058105469,220.22691345214844,0.0,4,P
sample_5.pdf,9,80.5,6.8754353523254395,URWPalladioL-Roma,False,380.4396667480469,220.2919921875,0.0,4,P
sample_5.pdf,9,80.8,6.8754353523254395,URWPalladioL-Roma,False,398.7764587402344,220.2919921875,0.0,4,P
sample_5.pdf,9,72.0,6.8754353523254395,URWPalladioL-Roma,False,417.1063232421875,220.2919921875,0.0,4,P
sample_5.pdf,9,35.1,6.8754353523254395,URWPalladioL-Roma,False,435.443115234375,220.2919921875,0.0,4,P
sample_5.pdf,9,68.3,6.8754353523254395,URWPalladioL-Roma,False,453.7799072265625,220.2919921875,0.0,4,P
sample_5.pdf,9,65.7,6.8754353523254395,URWPalladioL-Bold,True,472.1113586425781,220.22691345214844,0.0,4,P
sample_5.pdf,9,80.4,6.8754353523254395,URWPalladioL-Roma,False,490.4463195800781,220.2919921875,0.0,4,P
sample_5.pdf,9,64.2,6.8754353523254395,URWPalladioL-Roma,False,508.6868896484375,220.2919921875,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.399620056152344,231.29251098632812,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,231.29251098632812,0.0,3,P
sample_5.pdf,9,67.0,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,231.29251098632812,0.0,4,P
sample_5.pdf,9,82.3,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,231.29251098632812,0.0,4,P
sample_5.pdf,9,76.4,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,231.29251098632812,0.0,4,P
sample_5.pdf,9,71.0,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,231.29251098632812,0.0,4,P
sample_5.pdf,9,48.4,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,231.29251098632812,0.0,4,P
sample_5.pdf,9,45.2,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,231.29251098632812,0.0,4,P
sample_5.pdf,9,72.1,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,231.29251098632812,0.0,4,P
sample_5.pdf,9,72.3,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,231.29251098632812,0.0,4,P
sample_5.pdf,9,87.3,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,231.29251098632812,0.0,4,P
sample_5.pdf,9,42.2,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,231.29251098632812,0.0,4,P
sample_5.pdf,9,73.7,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,231.29251098632812,0.0,4,P
sample_5.pdf,9,50.0,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,231.29251098632812,0.0,4,P
sample_5.pdf,9,86.8,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,231.29251098632812,0.0,4,P
sample_5.pdf,9,78.7,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,231.29251098632812,0.0,4,P
sample_5.pdf,9,78.4,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,231.29251098632812,0.0,4,P
sample_5.pdf,9,77.4,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,231.29251098632812,0.0,4,P
sample_5.pdf,9,34.5,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,231.29251098632812,0.0,4,P
sample_5.pdf,9,70.1,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,231.29251098632812,0.0,4,P
sample_5.pdf,9,57.1,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,231.29251098632812,0.0,4,P
sample_5.pdf,9,77.1,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,231.29251098632812,0.0,4,P
sample_5.pdf,9,58.9,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,231.29251098632812,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.39961242675781,241.98709106445312,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,241.98703002929688,0.0,3,P
sample_5.pdf,9,07++12,6.8754353523254395,URWPalladioL-Roma,False,100.54922485351562,241.98703002929688,0.0,6,P
sample_5.pdf,9,70.4,6.8754353523254395,URWPalladioL-Roma,False,140.25796508789062,241.98703002929688,0.0,4,P
sample_5.pdf,9,84.9,6.8754353523254395,URWPalladioL-Roma,False,160.42633056640625,241.98703002929688,0.0,4,P
sample_5.pdf,9,79.8,6.8754353523254395,URWPalladioL-Roma,False,178.76312255859375,241.98703002929688,0.0,4,P
sample_5.pdf,9,74.3,6.8754353523254395,URWPalladioL-Roma,False,197.09304809570312,241.98703002929688,0.0,4,P
sample_5.pdf,9,53.9,6.8754353523254395,URWPalladioL-Roma,False,215.42982482910156,241.98703002929688,0.0,4,P
sample_5.pdf,9,49.8,6.8754353523254395,URWPalladioL-Roma,False,233.7666015625,241.98703002929688,0.0,4,P
sample_5.pdf,9,77.5,6.8754353523254395,URWPalladioL-Roma,False,252.0965118408203,241.98703002929688,0.0,4,P
sample_5.pdf,9,75.9,6.8754353523254395,URWPalladioL-Roma,False,270.43328857421875,241.98703002929688,0.0,4,P
sample_5.pdf,9,88.5,6.8754353523254395,URWPalladioL-Roma,False,288.77008056640625,241.98703002929688,0.0,4,P
sample_5.pdf,9,45.6,6.8754353523254395,URWPalladioL-Roma,False,307.1000061035156,241.98703002929688,0.0,4,P
sample_5.pdf,9,77.1,6.8754353523254395,URWPalladioL-Roma,False,325.4367980957031,241.98703002929688,0.0,4,P
sample_5.pdf,9,55.3,6.8754353523254395,URWPalladioL-Roma,False,343.7735595703125,241.98703002929688,0.0,4,P
sample_5.pdf,9,86.9,6.8754353523254395,URWPalladioL-Roma,False,362.1034851074219,241.98703002929688,0.0,4,P
sample_5.pdf,9,81.7,6.8754353523254395,URWPalladioL-Roma,False,380.4402770996094,241.98703002929688,0.0,4,P
sample_5.pdf,9,80.9,6.8754353523254395,URWPalladioL-Roma,False,398.7770690917969,241.98703002929688,0.0,4,P
sample_5.pdf,9,79.6,6.8754353523254395,URWPalladioL-Roma,False,417.10693359375,241.98703002929688,0.0,4,P
sample_5.pdf,9,40.1,6.8754353523254395,URWPalladioL-Roma,False,435.4437255859375,241.98703002929688,0.0,4,P
sample_5.pdf,9,72.6,6.8754353523254395,URWPalladioL-Roma,False,453.780517578125,241.98703002929688,0.0,4,P
sample_5.pdf,9,60.9,6.8754353523254395,URWPalladioL-Roma,False,472.11041259765625,241.98703002929688,0.0,4,P
sample_5.pdf,9,81.2,6.8754353523254395,URWPalladioL-Roma,False,490.44720458984375,241.98703002929688,0.0,4,P
sample_5.pdf,9,61.5,6.8754353523254395,URWPalladioL-Roma,False,508.6877746582031,241.98703002929688,0.0,4,P
sample_5.pdf,9,RPN,6.8754353523254395,URWPalladioL-Roma,False,43.39961242675781,252.68234252929688,1.0,3,P
sample_5.pdf,9,300,6.8754353523254395,URWPalladioL-Roma,False,70.2245864868164,252.682373046875,0.0,3,P
sample_5.pdf,9,COCO+07++12,6.1114726066589355,URWPalladioL-Roma,False,90.9649887084961,253.23046875,0.36363636363636365,11,P
sample_5.pdf,9,75.9,6.8754353523254395,URWPalladioL-Bold,True,140.25796508789062,252.61729431152344,0.0,4,P
sample_5.pdf,9,87.4,6.8754353523254395,URWPalladioL-Bold,True,160.42633056640625,252.61729431152344,0.0,4,P
sample_5.pdf,9,83.6,6.8754353523254395,URWPalladioL-Bold,True,178.76052856445312,252.61729431152344,0.0,4,P
sample_5.pdf,9,76.8,6.8754353523254395,URWPalladioL-Bold,True,197.09471130371094,252.61729431152344,0.0,4,P
sample_5.pdf,9,62.9,6.8754353523254395,URWPalladioL-Bold,True,215.42965698242188,252.61729431152344,0.0,4,P
sample_5.pdf,9,59.6,6.8754353523254395,URWPalladioL-Bold,True,233.7638397216797,252.61729431152344,0.0,4,P
sample_5.pdf,9,81.9,6.8754353523254395,URWPalladioL-Bold,True,252.09803771972656,252.61729431152344,0.0,4,P
sample_5.pdf,9,82.0,6.8754353523254395,URWPalladioL-Bold,True,270.4329833984375,252.61729431152344,0.0,4,P
sample_5.pdf,9,91.3,6.8754353523254395,URWPalladioL-Bold,True,288.7671813964844,252.61729431152344,0.0,4,P
sample_5.pdf,9,54.9,6.8754353523254395,URWPalladioL-Bold,True,307.10137939453125,252.61729431152344,0.0,4,P
sample_5.pdf,9,82.6,6.8754353523254395,URWPalladioL-Bold,True,325.4363098144531,252.61729431152344,0.0,4,P
sample_5.pdf,9,59.0,6.8754353523254395,URWPalladioL-Bold,True,343.7705078125,252.61729431152344,0.0,4,P
sample_5.pdf,9,89.0,6.8754353523254395,URWPalladioL-Bold,True,362.1047058105469,252.61729431152344,0.0,4,P
sample_5.pdf,9,85.5,6.8754353523254395,URWPalladioL-Bold,True,380.4396667480469,252.61729431152344,0.0,4,P
sample_5.pdf,9,84.7,6.8754353523254395,URWPalladioL-Bold,True,398.77386474609375,252.61729431152344,0.0,4,P
sample_5.pdf,9,84.1,6.8754353523254395,URWPalladioL-Bold,True,417.1080322265625,252.61729431152344,0.0,4,P
sample_5.pdf,9,52.2,6.8754353523254395,URWPalladioL-Bold,True,435.4429931640625,252.61729431152344,0.0,4,P
sample_5.pdf,9,78.9,6.8754353523254395,URWPalladioL-Bold,True,453.77716064453125,252.61729431152344,0.0,4,P
sample_5.pdf,9,65.5,6.8754353523254395,URWPalladioL-Roma,False,472.1113586425781,252.682373046875,0.0,4,P
sample_5.pdf,9,85.4,6.8754353523254395,URWPalladioL-Bold,True,490.4463195800781,252.61729431152344,0.0,4,P
sample_5.pdf,9,70.2,6.8754353523254395,URWPalladioL-Bold,True,508.68463134765625,252.61729431152344,0.0,4,P
sample_5.pdf,9,Table 8: Detection results of Faster R-CNN on PAS-,9.962599754333496,URWPalladioL-Roma,False,36.0,288.3464660644531,0.2,50,H3
sample_5.pdf,9,CAL VOC 2007 test set using,9.962599754333496,URWPalladioL-Roma,False,36.0,300.30145263671875,0.2222222222222222,27,H3
sample_5.pdf,9,different settings of,9.962599754333496,URWPalladioL-Bold,True,174.87863159179688,300.2071533203125,0.0,21,H3
sample_5.pdf,9,anchors,9.962599754333496,URWPalladioL-Bold,True,36.0,312.1621398925781,0.0,7,H3
sample_5.pdf,9,. The network is VGG-16. The training data,9.962599754333496,URWPalladioL-Roma,False,71.41699981689453,312.2564392089844,0.11904761904761904,42,H3
sample_5.pdf,9,is VOC 2007 trainval. The default setting of using 3,9.962599754333496,URWPalladioL-Roma,False,36.0,324.21142578125,0.07692307692307693,52,H3
sample_5.pdf,9,scales and 3 aspect ratios (69.9%) is the same as that,9.962599754333496,URWPalladioL-Roma,False,36.0,336.1664123535156,0.0,54,H3
sample_5.pdf,9,in Table 3.,9.962599754333496,URWPalladioL-Roma,False,36.0,348.12139892578125,0.09090909090909091,11,H3
sample_5.pdf,9,settings,8.966400146484375,URWPalladioL-Roma,False,55.63800048828125,360.0941162109375,0.0,8,P
sample_5.pdf,9,anchor scales,8.966400146484375,URWPalladioL-Roma,False,114.77899932861328,360.0942077636719,0.0,13,P
sample_5.pdf,9,aspect ratios mAP (%),8.966400146484375,URWPalladioL-Roma,False,180.83200073242188,360.0942077636719,0.09523809523809523,21,P
sample_5.pdf,9,"1 scale, 1 ratio",8.966400146484375,URWPalladioL-Roma,False,41.79399871826172,379.1231994628906,0.0,16,P
sample_5.pdf,9,128,7.970099925994873,CMR8,False,133.0760040283203,374.047119140625,0.0,3,P
sample_5.pdf,9,1:1,8.966400146484375,URWPalladioL-Roma,False,200.36000061035156,373.84320068359375,0.0,3,P
sample_5.pdf,9,65.8,8.966400146484375,URWPalladioL-Roma,False,247.77699279785156,373.84320068359375,0.0,4,P
sample_5.pdf,9,256,7.970099925994873,CMR8,False,133.0760040283203,385.006103515625,0.0,3,P
sample_5.pdf,9,1:1,8.966400146484375,URWPalladioL-Roma,False,200.36000061035156,384.80218505859375,0.0,3,P
sample_5.pdf,9,66.7,8.966400146484375,URWPalladioL-Roma,False,247.77699279785156,384.80218505859375,0.0,4,P
sample_5.pdf,9,"1 scale, 3 ratios",8.966400146484375,URWPalladioL-Roma,False,39.893001556396484,401.439208984375,0.0,17,P
sample_5.pdf,9,128,7.970099925994873,CMR8,False,133.0760040283203,396.3631286621094,0.0,3,P
sample_5.pdf,9,"2:1, 1:1, 1:2",8.966400146484375,URWPalladioL-Roma,False,183.7729949951172,396.1592102050781,0.0,13,P
sample_5.pdf,9,68.8,8.966400146484375,URWPalladioL-Roma,False,247.77699279785156,396.1592102050781,0.0,4,P
sample_5.pdf,9,256,7.970099925994873,CMR8,False,133.0760040283203,407.3221130371094,0.0,3,P
sample_5.pdf,9,"2:1, 1:1, 1:2",8.966400146484375,URWPalladioL-Roma,False,183.7729949951172,407.1181945800781,0.0,13,P
sample_5.pdf,9,67.9,8.966400146484375,URWPalladioL-Roma,False,247.77699279785156,407.1181945800781,0.0,4,P
sample_5.pdf,9,"3 scales, 1 ratio",8.966400146484375,URWPalladioL-Roma,False,39.893001556396484,418.2762145996094,0.0,17,P
sample_5.pdf,9,128,7.970099925994873,CMR8,False,112.45899963378906,418.68011474609375,0.0,3,P
sample_5.pdf,9,256,7.970099925994873,CMR8,False,131.6641845703125,418.68011474609375,0.0,3,P
sample_5.pdf,9,512,7.970099925994873,CMR8,False,152.28118896484375,418.68011474609375,0.0,3,P
sample_5.pdf,9,1:1,8.966400146484375,URWPalladioL-Roma,False,200.36000061035156,418.4761962890625,0.0,3,P
sample_5.pdf,9,69.8,8.966400146484375,URWPalladioL-Bold,True,247.77699279785156,418.3913269042969,0.0,4,P
sample_5.pdf,9,"3 scales, 3 ratios",8.966400146484375,URWPalladioL-Roma,False,37.99300003051758,429.6341857910156,0.0,18,P
sample_5.pdf,9,128,7.970099925994873,CMR8,False,112.45899963378906,430.037109375,0.0,3,P
sample_5.pdf,9,256,7.970099925994873,CMR8,False,131.6641845703125,430.037109375,0.0,3,P
sample_5.pdf,9,512,7.970099925994873,CMR8,False,152.28118896484375,430.037109375,0.0,3,P
sample_5.pdf,9,"2:1, 1:1, 1:2",8.966400146484375,URWPalladioL-Roma,False,183.7729949951172,429.83319091796875,0.0,13,P
sample_5.pdf,9,69.9,8.966400146484375,URWPalladioL-Bold,True,247.77699279785156,429.7483215332031,0.0,4,P
sample_5.pdf,9,Table 9: Detection results of Faster R-CNN on PAS-,9.962599754333496,URWPalladioL-Roma,False,36.0,462.18048095703125,0.2,50,H3
sample_5.pdf,9,CAL VOC 2007 test set using,9.962599754333496,URWPalladioL-Roma,False,36.0,474.136474609375,0.2222222222222222,27,H3
sample_5.pdf,9,different values of,9.962599754333496,URWPalladioL-Bold,True,172.27838134765625,474.04217529296875,0.0,19,H3
sample_5.pdf,9,in Equation (1). The network is VGG-16. The training,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,486.0914611816406,0.11538461538461539,52,H3
sample_5.pdf,9,data is VOC 2007 trainval. The default setting of using,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,498.04644775390625,0.07272727272727272,55,H3
sample_5.pdf,9,= 10,9.962599754333496,CMR10,False,41.80818176269531,509.36285400390625,0.0,4,H3
sample_5.pdf,9,(69.9%) is the same as that in Table 3.,9.962599754333496,URWPalladioL-Roma,False,65.06209564208984,510.00140380859375,0.02564102564102564,39,H3
sample_5.pdf,9,0.1,8.966400146484375,URWPalladioL-Roma,False,123.59100341796875,521.9741821289062,0.0,3,P
sample_5.pdf,9,100,8.966400146484375,URWPalladioL-Roma,False,229.32278442382812,521.9741821289062,0.0,3,P
sample_5.pdf,9,mAP (%),8.966400146484375,URWPalladioL-Roma,False,64.07499694824219,533.3312377929688,0.2857142857142857,7,P
sample_5.pdf,9,67.2,8.966400146484375,URWPalladioL-Roma,False,121.3489990234375,533.3312377929688,0.0,4,P
sample_5.pdf,9,68.9,8.966400146484375,URWPalladioL-Roma,False,156.9635467529297,533.3312377929688,0.0,4,P
sample_5.pdf,9,69.9,8.966400146484375,URWPalladioL-Roma,False,192.5780792236328,533.3312377929688,0.0,4,P
sample_5.pdf,9,69.1,8.966400146484375,URWPalladioL-Roma,False,228.2015838623047,533.3312377929688,0.0,4,P
sample_5.pdf,9,In Table 5 we summarize the running time of the,9.962599754333496,URWPalladioL-Roma,False,45.96299743652344,577.6344604492188,0.0425531914893617,47,H3
sample_5.pdf,9,entire object detection system. SS takes 1-2 seconds,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,589.5894775390625,0.038461538461538464,52,H3
sample_5.pdf,9,"depending on content (on average about 1.5s), and",9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,601.5444946289062,0.0,49,H3
sample_5.pdf,9,Fast R-CNN with VGG-16 takes 320ms on 2000 SS,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,613.49951171875,0.2222222222222222,45,H3
sample_5.pdf,9,proposals (or 223ms if using SVD on fully-connected,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,625.4555053710938,0.058823529411764705,51,H3
sample_5.pdf,9,layers [2]). Our system with VGG-16 takes in total,9.962599754333496,URWPalladioL-Roma,False,35.999996185302734,637.4104614257812,0.08,50,H3
sample_5.pdf,9,198ms,9.962599754333496,URWPalladioL-Bold,True,35.999996185302734,649.2711791992188,0.0,5,H3
sample_5.pdf,9,for both proposal and detection. With the con-,9.962599754333496,URWPalladioL-Roma,False,64.22404479980469,649.365478515625,0.021739130434782608,46,H3
sample_5.pdf,9,"volutional features shared, the RPN alone only takes",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,661.3204956054688,0.057692307692307696,52,H3
sample_5.pdf,9,10ms computing the additional layers. Our region-,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,673.2755126953125,0.02040816326530612,49,H3
sample_5.pdf,9,"wise computation is also lower, thanks to fewer pro-",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,685.2315063476562,0.0,52,H3
sample_5.pdf,9,posals (300 per image). Our system has a frame-rate,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,697.1865234375,0.0196078431372549,51,H3
sample_5.pdf,9,of 17 fps with the ZF net.,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,709.1414794921875,0.07692307692307693,26,H3
sample_5.pdf,9,Sensitivities to Hyper-parameters.,9.962599754333496,URWPalladioL-Bold,True,35.99999237060547,727.3411865234375,0.058823529411764705,34,H3
sample_5.pdf,9,In Table 8 we,9.962599754333496,URWPalladioL-Roma,False,199.81500244140625,727.4354858398438,0.15384615384615385,13,H3
sample_5.pdf,9,investigate the settings of anchors. By default we use,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,739.3905029296875,0.018518518518518517,54,H3
sample_5.pdf,9,3 scales and 3 aspect ratios (69.9% mAP in Table 8).,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,291.9324951171875,0.057692307692307696,52,H3
sample_5.pdf,9,"If using just one anchor at each position, the mAP",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,303.8874816894531,0.06,50,H3
sample_5.pdf,9,drops by a considerable margin of 3-4%. The mAP,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,315.8434753417969,0.06382978723404255,47,H3
sample_5.pdf,9,is higher if using 3 scales (with 1 aspect ratio) or 3,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,327.7984619140625,0.0,54,H3
sample_5.pdf,9,"aspect ratios (with 1 scale), demonstrating that using",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,339.7534484863281,0.0,54,H3
sample_5.pdf,9,anchors of multiple sizes as the regression references,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,351.70843505859375,0.0,54,H3
sample_5.pdf,9,is an effective solution. Using just 3 scales with 1,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,363.6634216308594,0.019230769230769232,52,H3
sample_5.pdf,9,aspect ratio (69.8%) is as good as using 3 scales with,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,375.618408203125,0.0,54,H3
sample_5.pdf,9,"3 aspect ratios on this dataset, suggesting that scales",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,387.57440185546875,0.0,55,H3
sample_5.pdf,9,and aspect ratios are not disentangled dimensions for,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,399.5293884277344,0.0,53,H3
sample_5.pdf,9,the detection accuracy. But we still adopt these two,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,411.484375,0.019230769230769232,52,H3
sample_5.pdf,9,dimensions in our designs to keep our system ﬂexible.,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,423.4393615722656,0.0,53,H3
sample_5.pdf,9,In Table 9 we compare different values of,9.962599754333496,URWPalladioL-Roma,False,297.02099609375,435.4393615722656,0.04878048780487805,41,H3
sample_5.pdf,9,in Equa-,9.962599754333496,URWPalladioL-Roma,False,486.5141906738281,435.4393615722656,0.125,8,H3
sample_5.pdf,9,tion (1). By default we use,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,447.3953552246094,0.037037037037037035,27,H3
sample_5.pdf,9,= 10,9.962599754333496,CMR10,False,419.50921630859375,446.7568054199219,0.0,4,H3
sample_5.pdf,9,which makes the,9.962599754333496,URWPalladioL-Roma,False,444.7394104003906,447.3953552246094,0.0,15,H3
sample_5.pdf,9,two terms in Equation (1) roughly equally weighted,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,459.350341796875,0.02,50,H3
sample_5.pdf,9,after normalization. Table 9 shows that our result is,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,471.3053283691406,0.018867924528301886,53,H3
sample_5.pdf,9,impacted just marginally (by,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,483.26031494140625,0.0,28,H3
sample_5.pdf,9,) when,9.962599754333496,URWPalladioL-Roma,False,443.29998779296875,483.26031494140625,0.0,6,H3
sample_5.pdf,9,is within,9.962599754333496,URWPalladioL-Roma,False,483.59417724609375,483.26031494140625,0.0,9,H3
sample_5.pdf,9,a scale of about two orders of magnitude (1 to 100).,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,495.2153015136719,0.0,52,H3
sample_5.pdf,9,This demonstrates that the result is insensitive to,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,507.1702880859375,0.0196078431372549,51,H3
sample_5.pdf,9,a wide range.,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,519.1262817382812,0.0,13,H3
sample_5.pdf,9,Analysis of Recall-to-IoU.,9.962599754333496,URWPalladioL-Bold,True,287.0589599609375,536.0130004882812,0.15384615384615385,26,H3
sample_5.pdf,9,Next we compute the,9.962599754333496,URWPalladioL-Roma,False,413.80316162109375,536.1072998046875,0.05263157894736842,19,H3
sample_5.pdf,9,recall of proposals at different IoU ratios with ground-,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,548.0623168945312,0.03571428571428571,56,H3
sample_5.pdf,9,truth boxes. It is noteworthy that the Recall-to-IoU,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,560.0182495117188,0.07692307692307693,52,H3
sample_5.pdf,9,metric is just,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,571.9732666015625,0.0,14,H3
sample_5.pdf,9,loosely,9.962599754333496,URWPalladioL-Ital,False,349.8831481933594,571.8034057617188,0.0,7,H3
sample_5.pdf,9,"[19], [20], [21] related to the",9.962599754333496,URWPalladioL-Roma,False,382.9121398925781,571.9732666015625,0.0,31,H3
sample_5.pdf,9,ultimate detection accuracy. It is more appropriate to,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,583.9282836914062,0.018518518518518517,54,H3
sample_5.pdf,9,use this metric to,9.962599754333496,URWPalladioL-Roma,False,287.0589599609375,595.88330078125,0.0,18,H3
sample_5.pdf,9,diagnose,9.962599754333496,URWPalladioL-Ital,False,366.1719970703125,595.7134399414062,0.0,8,H3
sample_5.pdf,9,the proposal method than,9.962599754333496,URWPalladioL-Roma,False,404.7620544433594,595.88330078125,0.0,24,H3
sample_5.pdf,9,to evaluate it.,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,607.8383178710938,0.0,15,H3
sample_5.pdf,9,"In Figure 4, we show the results of using 300, 1000,",9.962599754333496,URWPalladioL-Roma,False,297.02093505859375,619.8383178710938,0.038461538461538464,52,H3
sample_5.pdf,9,"and 2000 proposals. We compare with SS and EB, and",9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,631.7942504882812,0.1,50,H3
sample_5.pdf,9,the,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,643.749267578125,0.0,3,H3
sample_5.pdf,9,proposals are the top-,9.962599754333496,URWPalladioL-Roma,False,312.29583740234375,643.749267578125,0.0,22,H3
sample_5.pdf,9,ranked ones based on,9.962599754333496,URWPalladioL-Roma,False,423.2838439941406,643.749267578125,0.0,20,H3
sample_5.pdf,9,the conﬁdence generated by these methods. The plots,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,655.7042846679688,0.0196078431372549,51,H3
sample_5.pdf,9,show that the RPN method behaves gracefully when,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,667.6593017578125,0.0625,48,H3
sample_5.pdf,9,the number of proposals drops from 2000 to 300. This,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,679.6143188476562,0.019230769230769232,52,H3
sample_5.pdf,9,explains why the RPN has a good ultimate detection,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,691.5703125,0.06,50,H3
sample_5.pdf,9,mAP when using as few as 300 proposals. As we,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,703.5252685546875,0.06666666666666667,45,H3
sample_5.pdf,9,"analyzed before, this property is mainly attributed to",9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,715.4802856445312,0.0,54,H3
sample_5.pdf,9,the,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,727.435302734375,0.0,3,H3
sample_5.pdf,9,cls,9.962599754333496,URWPalladioL-Ital,False,300.8770751953125,727.2654418945312,0.0,3,H3
sample_5.pdf,9,term of the RPN. The recall of SS and EB drops,9.962599754333496,URWPalladioL-Roma,False,314.3807678222656,727.435302734375,0.17391304347826086,46,H3
sample_5.pdf,9,more quickly than RPN when the proposals are fewer.,9.962599754333496,URWPalladioL-Roma,False,287.0589294433594,739.3903198242188,0.058823529411764705,51,H3
sample_5.pdf,10,Figure 4: Recall,9.962599754333496,URWPalladioL-Roma,False,117.9489974975586,157.75048828125,0.125,16,H3
sample_5.pdf,10,. IoU overlap ratio on the PASCAL VOC 2007 test set.,9.962599754333496,URWPalladioL-Roma,False,199.8809814453125,157.75048828125,0.21153846153846154,52,H3
sample_5.pdf,10,Table 10:,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,181.66046142578125,0.1111111111111111,9,H3
sample_5.pdf,10,One-Stage Detection,9.962599754333496,URWPalladioL-Bold,True,75.97989654541016,181.56617736816406,0.15789473684210525,19,H3
sample_5.pdf,10,. Two-Stage Proposal + Detection,9.962599754333496,URWPalladioL-Bold,True,191.04298400878906,181.56617736816406,0.125,32,H3
sample_5.pdf,10,. Detection results are on the PASCAL,9.962599754333496,URWPalladioL-Roma,False,349.6419677734375,181.66046142578125,0.1891891891891892,37,H3
sample_5.pdf,10,VOC 2007 test set using the ZF model and Fast R-CNN. RPN uses unshared features.,9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,193.616455078125,0.1625,80,H3
sample_5.pdf,10,proposals,8.966400146484375,URWPalladioL-Roma,False,202.56399536132812,205.58819580078125,0.0,9,P
sample_5.pdf,10,detector,8.966400146484375,URWPalladioL-Roma,False,350.1180114746094,205.58819580078125,0.0,8,P
sample_5.pdf,10,mAP (%),8.966400146484375,URWPalladioL-Roma,False,432.3320007324219,205.58819580078125,0.2857142857142857,7,P
sample_5.pdf,10,Two-Stage,8.966400146484375,URWPalladioL-Roma,False,89.74099731445312,219.33721923828125,0.2222222222222222,9,P
sample_5.pdf,10,"RPN + ZF, unshared",8.966400146484375,URWPalladioL-Roma,False,163.01600646972656,219.33721923828125,0.2777777777777778,18,P
sample_5.pdf,10,300,8.966400146484375,URWPalladioL-Roma,False,282.3050231933594,219.33721923828125,0.0,3,P
sample_5.pdf,10,"Fast R-CNN + ZF, 1 scale",8.966400146484375,URWPalladioL-Roma,False,314.489990234375,219.33721923828125,0.2916666666666667,24,P
sample_5.pdf,10,58.7,8.966400146484375,URWPalladioL-Roma,False,442.9620056152344,219.33721923828125,0.0,4,P
sample_5.pdf,10,One-Stage,8.966400146484375,URWPalladioL-Roma,False,89.99199676513672,230.6942138671875,0.2222222222222222,9,P
sample_5.pdf,10,"dense, 3 scales, 3 aspect ratios",8.966400146484375,URWPalladioL-Roma,False,143.53700256347656,230.6942138671875,0.0,32,P
sample_5.pdf,10,20000,8.966400146484375,URWPalladioL-Roma,False,277.81787109375,230.6942138671875,0.0,5,P
sample_5.pdf,10,"Fast R-CNN + ZF, 1 scale",8.966400146484375,URWPalladioL-Roma,False,314.489990234375,230.6942138671875,0.2916666666666667,24,P
sample_5.pdf,10,53.8,8.966400146484375,URWPalladioL-Roma,False,442.9620056152344,230.6942138671875,0.0,4,P
sample_5.pdf,10,One-Stage,8.966400146484375,URWPalladioL-Roma,False,89.99200439453125,241.6531982421875,0.2222222222222222,9,P
sample_5.pdf,10,"dense, 3 scales, 3 aspect ratios",8.966400146484375,URWPalladioL-Roma,False,143.53700256347656,241.6531982421875,0.0,32,P
sample_5.pdf,10,20000,8.966400146484375,URWPalladioL-Roma,False,277.81787109375,241.6531982421875,0.0,5,P
sample_5.pdf,10,"Fast R-CNN + ZF, 5 scales",8.966400146484375,URWPalladioL-Roma,False,312.5889892578125,241.6531982421875,0.28,25,P
sample_5.pdf,10,53.9,8.966400146484375,URWPalladioL-Roma,False,442.9620056152344,241.6531982421875,0.0,4,P
sample_5.pdf,10,One-Stage Detection,9.962599754333496,URWPalladioL-Bold,True,36.0,282.38818359375,0.15789473684210525,19,H3
sample_5.pdf,10,. Two-Stage Proposal + De-,9.962599754333496,URWPalladioL-Bold,True,145.9840087890625,282.38818359375,0.15384615384615385,26,H3
sample_5.pdf,10,tection.,9.962599754333496,URWPalladioL-Bold,True,36.00000762939453,294.34417724609375,0.0,8,H3
sample_5.pdf,10,The OverFeat paper [9] proposes a detection,9.962599754333496,URWPalladioL-Roma,False,69.4743423461914,294.4384765625,0.06976744186046512,43,H3
sample_5.pdf,10,method that uses regressors and classiﬁers on sliding,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,306.3934631347656,0.0,53,H3
sample_5.pdf,10,windows over convolutional feature maps. OverFeat,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,318.34844970703125,0.04081632653061224,49,H3
sample_5.pdf,10,is a,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,330.3034362792969,0.0,4,H3
sample_5.pdf,10,one-stage,9.962599754333496,URWPalladioL-Ital,False,50.963836669921875,330.1335754394531,0.0,9,H3
sample_5.pdf,10,class-speciﬁc,9.962599754333496,URWPalladioL-Ital,False,93.94564819335938,330.1335754394531,0.0,13,H3
sample_5.pdf,10,"detection pipeline, and ours",9.962599754333496,URWPalladioL-Roma,False,147.99484252929688,330.3034362792969,0.0,28,H3
sample_5.pdf,10,is a,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,342.2584228515625,0.0,4,H3
sample_5.pdf,10,two-stage cascade,9.962599754333496,URWPalladioL-Ital,False,51.85049057006836,342.08856201171875,0.0,17,H3
sample_5.pdf,10,consisting of class-agnostic pro-,9.962599754333496,URWPalladioL-Roma,False,127.75309753417969,342.2584228515625,0.0,33,H3
sample_5.pdf,10,"posals and class-speciﬁc detections. In OverFeat, the",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,354.2134094238281,0.05660377358490566,53,H3
sample_5.pdf,10,region-wise features come from a sliding window of,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,366.1694030761719,0.0,50,H3
sample_5.pdf,10,one aspect ratio over a scale pyramid. These features,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,378.1243896484375,0.018867924528301886,53,H3
sample_5.pdf,10,are used to simultaneously determine the location and,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,390.0793762207031,0.0,53,H3
sample_5.pdf,10,"category of objects. In RPN, the features are from",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,402.03436279296875,0.08,50,H3
sample_5.pdf,10,square (3,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,413.9893493652344,0.0,9,H3
sample_5.pdf,10,3) sliding windows and predict proposals,9.962599754333496,URWPalladioL-Roma,False,85.20899200439453,413.9893493652344,0.0,40,H3
sample_5.pdf,10,relative to anchors with different scales and aspect,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,425.9453430175781,0.0,52,H3
sample_5.pdf,10,"ratios. Though both methods use sliding windows, the",9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,437.90032958984375,0.019230769230769232,52,H3
sample_5.pdf,10,region proposal task is only the ﬁrst stage of Faster R-,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,449.8553161621094,0.03571428571428571,56,H3
sample_5.pdf,10,CNN—the downstream Fast R-CNN detector,9.962599754333496,URWPalladioL-Roma,False,35.99999237060547,461.810302734375,0.21052631578947367,38,H3
sample_5.pdf,10,attends,9.962599754333496,URWPalladioL-Ital,False,241.8870086669922,461.64044189453125,0.0,7,H3
sample_5.pdf,10,to the proposals to reﬁne them. In the second stage of,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,473.7652893066406,0.018518518518518517,54,H3
sample_5.pdf,10,"our cascade, the region-wise features are adaptively",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,485.72027587890625,0.0,52,H3
sample_5.pdf,10,"pooled [1], [2] from proposal boxes that more faith-",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,497.67626953125,0.0,52,H3
sample_5.pdf,10,fully cover the features of the regions. We believe,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,509.63128662109375,0.0196078431372549,51,H3
sample_5.pdf,10,these features lead to more accurate detections.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,521.5862426757812,0.0,48,H3
sample_5.pdf,10,"To compare the one-stage and two-stage systems,",9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,534.8472290039062,0.02127659574468085,47,H3
sample_5.pdf,10,emulate,9.962599754333496,URWPalladioL-Ital,False,49.08087921142578,546.6323852539062,0.0,7,H3
sample_5.pdf,10,the OverFeat system (and thus also circum-,9.962599754333496,URWPalladioL-Roma,False,82.946533203125,546.80224609375,0.047619047619047616,42,H3
sample_5.pdf,10,vent other differences of implementation details) by,9.962599754333496,URWPalladioL-Roma,False,35.9999885559082,558.7572631835938,0.0,52,H3
sample_5.pdf,10,one-stage,9.962599754333496,URWPalladioL-Ital,False,35.9999885559082,570.5424194335938,0.0,9,H3
sample_5.pdf,10,"Fast R-CNN. In this system, the “proposals”",9.962599754333496,URWPalladioL-Roma,False,73.62873077392578,570.7122802734375,0.13953488372093023,43,H3
sample_5.pdf,10,"are dense sliding windows of 3 scales (128, 256, 512)",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,582.6672973632812,0.0,53,H3
sample_5.pdf,10,"and 3 aspect ratios (1:1, 1:2, 2:1). Fast R-CNN is",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,594.6232299804688,0.1,50,H3
sample_5.pdf,10,trained to predict class-speciﬁc scores and regress box,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,606.5782470703125,0.0,55,H3
sample_5.pdf,10,locations from these sliding windows. Because the,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,618.5332641601562,0.02040816326530612,49,H3
sample_5.pdf,10,"OverFeat system adopts an image pyramid, we also",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,630.48828125,0.041666666666666664,48,H3
sample_5.pdf,10,evaluate using convolutional features extracted from,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,642.4432983398438,0.0,52,H3
sample_5.pdf,10,"5 scales. We use those 5 scales as in [1], [2].",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,654.3982543945312,0.02127659574468085,47,H3
sample_5.pdf,10,Table 10 compares the two-stage system and two,9.962599754333496,URWPalladioL-Roma,False,45.96298599243164,667.6592407226562,0.021739130434782608,46,H3
sample_5.pdf,10,"variants of the one-stage system. Using the ZF model,",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,679.6142578125,0.05660377358490566,53,H3
sample_5.pdf,10,the one-stage system has an mAP of 53.9%. This is,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,691.5692749023438,0.061224489795918366,49,H3
sample_5.pdf,10,lower than the two-stage system (58.7%) by 4.8%.,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,703.5252685546875,0.0,48,H3
sample_5.pdf,10,This experiment justiﬁes the effectiveness of cascaded,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,715.4802856445312,0.018518518518518517,54,H3
sample_5.pdf,10,region proposals and object detection. Similar obser-,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,727.435302734375,0.018867924528301886,53,H3
sample_5.pdf,10,"vations are reported in [2], [39], where replacing SS",9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,739.3902587890625,0.03773584905660377,53,H3
sample_5.pdf,10,region proposals with sliding windows leads to,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,282.4832763671875,0.0,46,H3
sample_5.pdf,10,degradation in both papers. We also note that the one-,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,294.4382629394531,0.018518518518518517,54,H3
sample_5.pdf,10,stage system is slower as it has considerably more,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,306.39324951171875,0.0,50,H3
sample_5.pdf,10,proposals to process.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,318.3482360839844,0.0,21,H3
sample_5.pdf,10,4.2,9.962599754333496,NimbusSanL-Bold,True,287.05902099609375,350.65447998046875,0.0,3,H3
sample_5.pdf,10,Experiments on MS COCO,9.962599754333496,NimbusSanL-Bold,True,310.86962890625,350.65447998046875,0.3181818181818182,22,H3
sample_5.pdf,10,We present more results on the Microsoft COCO,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,368.2492370605469,0.13333333333333333,45,H3
sample_5.pdf,10,object detection dataset [12]. This dataset involves 80,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,380.2052307128906,0.01818181818181818,55,H3
sample_5.pdf,10,object categories. We experiment with the 80k images,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,392.16021728515625,0.019230769230769232,52,H3
sample_5.pdf,10,"on the training set, 40k images on the validation set,",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,404.1152038574219,0.0,54,H3
sample_5.pdf,10,and 20k images on the test-dev set. We evaluate the,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,416.0701904296875,0.0196078431372549,51,H3
sample_5.pdf,10,mAP averaged for IoU,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,428.0251770019531,0.2,20,H3
sample_5.pdf,10,5 : 0,9.962599754333496,CMR10,False,417.2770080566406,427.3866271972656,0.0,5,H3
sample_5.pdf,10,05 : 0,9.962599754333496,CMR10,False,440.74200439453125,427.3866271972656,0.0,6,H3
sample_5.pdf,10,95],9.962599754333496,CMR10,False,469.18902587890625,427.3866271972656,0.0,3,H3
sample_5.pdf,10,(COCO’s,9.962599754333496,URWPalladioL-Roma,False,481.92120361328125,428.0251770019531,0.5714285714285714,7,H3
sample_5.pdf,10,"standard metric, simply denoted as mAP@[.5, .95])",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,439.98016357421875,0.04081632653061224,49,H3
sample_5.pdf,10,and mAP@0.5 (PASCAL VOC’s metric).,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,451.9361572265625,0.3235294117647059,34,H3
sample_5.pdf,10,There are a few minor changes of our system made,9.962599754333496,URWPalladioL-Roma,False,297.0210266113281,464.421142578125,0.020833333333333332,48,H3
sample_5.pdf,10,for this dataset. We train our models on an 8-GPU,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,476.37713623046875,0.08163265306122448,49,H3
sample_5.pdf,10,"implementation, and the effective mini-batch size be-",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,488.3321228027344,0.0,53,H3
sample_5.pdf,10,comes 8 for RPN (1 per GPU) and 16 for Fast R-CNN,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,500.287109375,0.22448979591836735,49,H3
sample_5.pdf,10,(2 per GPU). The RPN step and Fast R-CNN step are,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,512.2421264648438,0.24489795918367346,49,H3
sample_5.pdf,10,both trained for 240k iterations with a learning rate,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,524.1970825195312,0.0,53,H3
sample_5.pdf,10,of 0.003 and then for 80k iterations with 0.0003. We,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,536.152099609375,0.019230769230769232,52,H3
sample_5.pdf,10,modify the learning rates (starting with 0.003 instead,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,548.1080932617188,0.0,54,H3
sample_5.pdf,10,of 0.001) because the mini-batch size is changed. For,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,560.0631103515625,0.018867924528301886,53,H3
sample_5.pdf,10,"the anchors, we use 3 aspect ratios and 4 scales",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,572.0181274414062,0.0,48,H3
sample_5.pdf,10,(adding,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,583.9730834960938,0.0,7,H3
sample_5.pdf,10,"), mainly motivated by handling small",9.962599754333496,URWPalladioL-Roma,False,341.78204345703125,583.9730834960938,0.0,37,H3
sample_5.pdf,10,"objects on this dataset. In addition, in our Fast R-CNN",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,595.9281005859375,0.10909090909090909,55,H3
sample_5.pdf,10,"step, the negative samples are deﬁned as those with",9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,607.8831176757812,0.0,51,H3
sample_5.pdf,10,a maximum IoU with ground truth in the interval of,9.962599754333496,URWPalladioL-Roma,False,287.0590515136719,619.839111328125,0.04,50,H3
sample_5.pdf,10,", instead of",9.962599754333496,URWPalladioL-Roma,False,315.84002685546875,631.7941284179688,0.0,12,H3
sample_5.pdf,10,"used in [1], [2]. We note",9.962599754333496,URWPalladioL-Roma,False,408.78076171875,631.7941284179688,0.04,25,H3
sample_5.pdf,10,"that in the SPPnet system [1], the negative samples",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,643.7490844726562,0.058823529411764705,51,H3
sample_5.pdf,10,"are used for network ﬁne-tuning, but the",9.962599754333496,URWPalladioL-Roma,False,335.94476318359375,655.7041015625,0.0,40,H3
sample_5.pdf,10,negative samples in,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,667.6591186523438,0.0,19,H3
sample_5.pdf,10,are still visited in the SVM,9.962599754333496,URWPalladioL-Roma,False,406.1617431640625,667.6591186523438,0.10714285714285714,28,H3
sample_5.pdf,10,step with hard-negative mining. But the Fast R-CNN,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,679.6151123046875,0.12,50,H3
sample_5.pdf,10,"system [2] abandons the SVM step, so the negative",9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,691.5701293945312,0.061224489795918366,49,H3
sample_5.pdf,10,samples in,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,703.525146484375,0.0,10,H3
sample_5.pdf,10,are never visited. Including these,9.962599754333496,URWPalladioL-Roma,False,368.8377380371094,703.525146484375,0.029411764705882353,34,H3
sample_5.pdf,10,samples improves mAP@0.5 on the COCO,9.962599754333496,URWPalladioL-Roma,False,315.8407287597656,715.4801025390625,0.16666666666666666,36,H3
sample_5.pdf,10,dataset for both Fast R-CNN and Faster R-CNN sys-,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,727.4351196289062,0.20408163265306123,49,H3
sample_5.pdf,10,tems (but the impact is negligible on PASCAL VOC).,9.962599754333496,URWPalladioL-Roma,False,287.0589904785156,739.39013671875,0.18,50,H3
sample_5.pdf,11,Table 11: Object detection results (%) on the,9.962599754333496,URWPalladioL-Roma,False,84.135986328125,54.35950469970703,0.044444444444444446,45,H3
sample_5.pdf,11,MS COCO,9.962599754333496,URWPalladioL-Bold,True,282.3419189453125,54.26521301269531,0.8571428571428571,7,H3
sample_5.pdf,11,dataset. The model is VGG-16.,9.962599754333496,URWPalladioL-Roma,False,336.597412109375,54.35950469970703,0.13793103448275862,29,H3
sample_5.pdf,11,COCO val,8.966400146484375,URWPalladioL-Roma,False,318.6189880371094,66.33220672607422,0.5,8,P
sample_5.pdf,11,COCO test-dev,8.966400146484375,URWPalladioL-Roma,False,426.4330139160156,66.33220672607422,0.3076923076923077,13,P
sample_5.pdf,11,method,8.966400146484375,URWPalladioL-Roma,False,45.1150016784668,77.29119110107422,0.0,6,P
sample_5.pdf,11,proposals,8.966400146484375,URWPalladioL-Roma,False,174.76199340820312,77.29119110107422,0.0,9,P
sample_5.pdf,11,training data,8.966400146484375,URWPalladioL-Roma,False,222.18299865722656,77.29119110107422,0.0,13,P
sample_5.pdf,11,mAP@.5,8.966400146484375,URWPalladioL-Roma,False,292.4700012207031,77.29119110107422,0.3333333333333333,6,P
sample_5.pdf,11,"mAP@[.5, .95]",8.966400146484375,URWPalladioL-Roma,False,339.9989929199219,77.29119110107422,0.15384615384615385,13,P
sample_5.pdf,11,mAP@.5,8.966400146484375,URWPalladioL-Roma,False,410.0880126953125,77.29119110107422,0.3333333333333333,6,P
sample_5.pdf,11,"mAP@[.5, .95]",8.966400146484375,URWPalladioL-Roma,False,457.6180114746094,77.29119110107422,0.15384615384615385,13,P
sample_5.pdf,11,Fast R-CNN [2],8.966400146484375,URWPalladioL-Roma,False,45.1150016784668,91.03917694091797,0.35714285714285715,14,P
sample_5.pdf,11,"SS, 2000",8.966400146484375,URWPalladioL-Roma,False,177.72000122070312,91.03917694091797,0.25,8,P
sample_5.pdf,11,COCO train,8.966400146484375,URWPalladioL-Roma,False,223.86900329589844,91.03917694091797,0.4,10,P
sample_5.pdf,11,35.9,8.966400146484375,URWPalladioL-Roma,False,419.1080017089844,91.03917694091797,0.0,4,P
sample_5.pdf,11,19.7,8.966400146484375,URWPalladioL-Roma,False,477.9179992675781,91.03917694091797,0.0,4,P
sample_5.pdf,11,Fast R-CNN,8.966400146484375,URWPalladioL-Roma,False,45.114990234375,101.99816131591797,0.5,10,P
sample_5.pdf,11,[impl. in this paper],7.970099925994873,URWPalladioL-Roma,False,94.6812515258789,102.71294403076172,0.0,21,P
sample_5.pdf,11,"SS, 2000",8.966400146484375,URWPalladioL-Roma,False,177.72000122070312,101.99822235107422,0.25,8,P
sample_5.pdf,11,COCO train,8.966400146484375,URWPalladioL-Roma,False,223.86900329589844,101.99822235107422,0.4,10,P
sample_5.pdf,11,38.6,8.966400146484375,URWPalladioL-Roma,False,301.489990234375,101.99822235107422,0.0,4,P
sample_5.pdf,11,18.9,8.966400146484375,URWPalladioL-Roma,False,360.29901123046875,101.99822235107422,0.0,4,P
sample_5.pdf,11,39.3,8.966400146484375,URWPalladioL-Roma,False,419.1080017089844,101.99822235107422,0.0,4,P
sample_5.pdf,11,19.3,8.966400146484375,URWPalladioL-Roma,False,477.9179992675781,101.99822235107422,0.0,4,P
sample_5.pdf,11,Faster R-CNN,8.966400146484375,URWPalladioL-Roma,False,45.1150016784668,113.35521697998047,0.4166666666666667,12,P
sample_5.pdf,11,"RPN, 300",8.966400146484375,URWPalladioL-Roma,False,175.24099731445312,113.35521697998047,0.375,8,P
sample_5.pdf,11,COCO train,8.966400146484375,URWPalladioL-Roma,False,223.86900329589844,113.35521697998047,0.4,10,P
sample_5.pdf,11,41.5,8.966400146484375,URWPalladioL-Roma,False,301.489990234375,113.35521697998047,0.0,4,P
sample_5.pdf,11,21.2,8.966400146484375,URWPalladioL-Roma,False,360.29901123046875,113.35521697998047,0.0,4,P
sample_5.pdf,11,42.1,8.966400146484375,URWPalladioL-Roma,False,419.1080017089844,113.35521697998047,0.0,4,P
sample_5.pdf,11,21.5,8.966400146484375,URWPalladioL-Roma,False,477.9179992675781,113.35521697998047,0.0,4,P
sample_5.pdf,11,Faster R-CNN,8.966400146484375,URWPalladioL-Roma,False,45.114990234375,124.31420135498047,0.4166666666666667,12,P
sample_5.pdf,11,"RPN, 300 COCO trainval",8.966400146484375,URWPalladioL-Roma,False,175.24099731445312,124.31420135498047,0.3181818181818182,22,P
sample_5.pdf,11,42.7,8.966400146484375,URWPalladioL-Bold,True,419.1080017089844,124.22933959960938,0.0,4,P
sample_5.pdf,11,21.9,8.966400146484375,URWPalladioL-Bold,True,477.9179992675781,124.22933959960938,0.0,4,P
sample_5.pdf,11,The rest of the implementation details are the same,9.962599754333496,URWPalladioL-Roma,False,45.9630126953125,165.14447021484375,0.0196078431372549,51,H3
sample_5.pdf,11,"as on PASCAL VOC. In particular, we keep using",9.962599754333496,URWPalladioL-Roma,False,36.0000114440918,177.0994873046875,0.21739130434782608,46,H3
sample_5.pdf,11,300 proposals and single-scale (,9.962599754333496,URWPalladioL-Roma,False,36.0000114440918,189.05450439453125,0.0,32,H3
sample_5.pdf,11,= 600,9.962599754333496,CMR10,False,185.1904754638672,188.4159393310547,0.0,5,H3
sample_5.pdf,11,) testing. The,9.962599754333496,URWPalladioL-Roma,False,215.0390167236328,189.05450439453125,0.07142857142857142,14,H3
sample_5.pdf,11,testing time is still about 200ms per image on the,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,201.009521484375,0.0,50,H3
sample_5.pdf,11,COCO dataset.,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,212.96453857421875,0.3076923076923077,13,H3
sample_5.pdf,11,In Table 11 we ﬁrst report the results of the Fast,9.962599754333496,URWPalladioL-Roma,False,45.963016510009766,231.362548828125,0.06,50,H3
sample_5.pdf,11,R-CNN system [2] using the implementation in this,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,243.31756591796875,0.08163265306122448,49,H3
sample_5.pdf,11,paper. Our Fast R-CNN baseline has 39.3% mAP@0.5,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,255.27255249023438,0.16666666666666666,48,H3
sample_5.pdf,11,"on the test-dev set, higher than that reported in [2].",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,267.2275390625,0.0,54,H3
sample_5.pdf,11,We conjecture that the reason for this gap is mainly,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,279.18353271484375,0.019230769230769232,52,H3
sample_5.pdf,11,due to the deﬁnition of the negative samples and also,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,291.1385192871094,0.0,53,H3
sample_5.pdf,11,the changes of the mini-batch sizes. We also note that,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,303.093505859375,0.018518518518518517,54,H3
sample_5.pdf,11,"the mAP@[.5, .95] is just comparable.",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,315.0484924316406,0.05405405405405406,37,H3
sample_5.pdf,11,Next we evaluate our Faster R-CNN system. Using,9.962599754333496,URWPalladioL-Roma,False,45.963016510009766,333.4465026855469,0.14893617021276595,47,H3
sample_5.pdf,11,"the COCO training set to train, Faster R-CNN has",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,345.4014892578125,0.1875,48,H3
sample_5.pdf,11,"42.1% mAP@0.5 and 21.5% mAP@[.5, .95] on the",9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,357.3564758300781,0.09090909090909091,44,H3
sample_5.pdf,11,COCO test-dev set. This is 2.8% higher for mAP@0.5,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,369.31146240234375,0.14,50,H3
sample_5.pdf,11,and,9.962599754333496,URWPalladioL-Roma,False,36.00001525878906,381.2664489746094,0.0,3,H3
sample_5.pdf,11,"2.2% higher for mAP@[.5, .95]",9.962599754333496,URWPalladioL-Bold,True,52.86669921875,381.1721496582031,0.06896551724137931,29,H3
sample_5.pdf,11,than the Fast R-,9.962599754333496,URWPalladioL-Roma,False,197.65830993652344,381.2664489746094,0.125,16,H3
sample_5.pdf,11,CNN counterpart under the same protocol (Table 11).,9.962599754333496,URWPalladioL-Roma,False,36.0,393.2224426269531,0.0784313725490196,51,H3
sample_5.pdf,11,This indicates that RPN performs excellent for im-,9.962599754333496,URWPalladioL-Roma,False,36.0,405.17742919921875,0.08,50,H3
sample_5.pdf,11,proving the localization accuracy at higher IoU thresh-,9.962599754333496,URWPalladioL-Roma,False,36.0,417.1324157714844,0.03636363636363636,55,H3
sample_5.pdf,11,"olds. Using the COCO trainval set to train, Faster R-",9.962599754333496,URWPalladioL-Roma,False,36.0,429.08740234375,0.1320754716981132,53,H3
sample_5.pdf,11,"CNN has 42.7% mAP@0.5 and 21.9% mAP@[.5, .95] on",9.962599754333496,URWPalladioL-Roma,False,36.0,441.0423889160156,0.14583333333333334,48,H3
sample_5.pdf,11,the COCO test-dev set. Figure 6 shows some results,9.962599754333496,URWPalladioL-Roma,False,36.0,452.99737548828125,0.1,50,H3
sample_5.pdf,11,on the MS COCO test-dev set.,9.962599754333496,URWPalladioL-Roma,False,36.0,464.953369140625,0.21428571428571427,28,H3
sample_5.pdf,11,Faster R-CNN in ILSVRC & COCO 2015 compe-,9.962599754333496,URWPalladioL-Bold,True,36.0,488.2380676269531,0.36585365853658536,41,H3
sample_5.pdf,11,titions,9.962599754333496,URWPalladioL-Bold,True,36.0,500.19305419921875,0.0,7,H3
sample_5.pdf,11,We have demonstrated that Faster R-CNN,9.962599754333496,URWPalladioL-Roma,False,65.31993865966797,500.287353515625,0.15789473684210525,38,H3
sample_5.pdf,11,"beneﬁts more from better features, thanks to the fact",9.962599754333496,URWPalladioL-Roma,False,36.0,512.2423706054688,0.0,53,H3
sample_5.pdf,11,that the RPN completely learns to propose regions by,9.962599754333496,URWPalladioL-Roma,False,36.0,524.1973266601562,0.057692307692307696,52,H3
sample_5.pdf,11,neural networks. This observation is still valid even,9.962599754333496,URWPalladioL-Roma,False,36.0,536.15234375,0.018867924528301886,53,H3
sample_5.pdf,11,when one increases the depth substantially to over,9.962599754333496,URWPalladioL-Roma,False,36.0,548.1073608398438,0.0,50,H3
sample_5.pdf,11,100 layers [18]. Only by replacing VGG-16 with a 101-,9.962599754333496,URWPalladioL-Roma,False,36.0,560.0633544921875,0.07547169811320754,53,H3
sample_5.pdf,11,"layer residual net (ResNet-101) [18], the Faster R-CNN",9.962599754333496,URWPalladioL-Roma,False,36.0,572.0183715820312,0.12962962962962962,54,H3
sample_5.pdf,11,system increases the mAP from 41.5%/21.2% (VGG-,9.962599754333496,URWPalladioL-Roma,False,36.0,583.9733276367188,0.10638297872340426,47,H3
sample_5.pdf,11,16) to 48.4%/27.2% (ResNet-101) on the COCO val,9.962599754333496,URWPalladioL-Roma,False,36.0,595.9283447265625,0.1276595744680851,47,H3
sample_5.pdf,11,set. With other improvements orthogonal to Faster R-,9.962599754333496,URWPalladioL-Roma,False,36.0,607.8833618164062,0.057692307692307696,52,H3
sample_5.pdf,11,"CNN, He",9.962599754333496,URWPalladioL-Roma,False,36.0,619.83935546875,0.5714285714285714,7,H3
sample_5.pdf,11,et al,9.962599754333496,URWPalladioL-Ital,False,78.68975067138672,619.6694946289062,0.0,5,H3
sample_5.pdf,11,. [18] obtained a single-model result of,9.962599754333496,URWPalladioL-Roma,False,100.1030044555664,619.83935546875,0.0,40,H3
sample_5.pdf,11,55.7%/34.9% and an ensemble result of 59.0%/37.4%,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,631.7943725585938,0.0,49,H3
sample_5.pdf,11,"on the COCO test-dev set, which won the 1st place",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,643.7493286132812,0.08163265306122448,49,H3
sample_5.pdf,11,in the COCO 2015 object detection competition. The,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,655.704345703125,0.1,50,H3
sample_5.pdf,11,same system [18] also won the 1st place in the ILSVRC,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,667.6593627929688,0.11320754716981132,53,H3
sample_5.pdf,11,"2015 object detection competition, surpassing the sec-",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,679.6143798828125,0.0,54,H3
sample_5.pdf,11,ond place by absolute 8.5%. RPN is also a building,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,691.5703735351562,0.06,50,H3
sample_5.pdf,11,block of the 1st-place winning entries in ILSVRC 2015,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,703.525390625,0.11320754716981132,53,H3
sample_5.pdf,11,localization and COCO 2015 segmentation competi-,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,715.4803466796875,0.08333333333333333,48,H3
sample_5.pdf,11,"tions, for which the details are available in [18] and",9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,727.4353637695312,0.0,54,H3
sample_5.pdf,11,[15] respectively.,9.962599754333496,URWPalladioL-Roma,False,36.00000762939453,739.390380859375,0.0,18,H3
sample_5.pdf,11,Table 12: Detection mAP (%) of Faster R-CNN on,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,161.557373046875,0.1956521739130435,46,H3
sample_5.pdf,11,PASCAL VOC 2007 test set and 2012 test set us-,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,173.51239013671875,0.1956521739130435,46,H3
sample_5.pdf,11,ing different training data. The model is VGG-16.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,185.4683837890625,0.08163265306122448,49,H3
sample_5.pdf,11,“COCO” denotes that the COCO trainval set is used,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,197.42340087890625,0.16326530612244897,49,H3
sample_5.pdf,11,for training. See also Table 6 and Table 7.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,209.37841796875,0.06976744186046512,43,H3
sample_5.pdf,11,training data,8.966400146484375,URWPalladioL-Roma,False,313.22802734375,221.35113525390625,0.0,13,P
sample_5.pdf,11,2007 test,8.966400146484375,URWPalladioL-Roma,False,410.4880065917969,221.3511962890625,0.0,9,P
sample_5.pdf,11,2012 test,8.966400146484375,URWPalladioL-Roma,False,461.8399963378906,221.3511962890625,0.0,9,P
sample_5.pdf,11,VOC07,8.966400146484375,URWPalladioL-Roma,False,313.2279968261719,235.09918212890625,0.6,5,P
sample_5.pdf,11,69.9,8.966400146484375,URWPalladioL-Roma,False,420.14898681640625,235.09918212890625,0.0,4,P
sample_5.pdf,11,67.0,8.966400146484375,URWPalladioL-Roma,False,471.50201416015625,235.09918212890625,0.0,4,P
sample_5.pdf,11,VOC07+12,8.966400146484375,URWPalladioL-Roma,False,313.22802734375,246.05816650390625,0.375,8,P
sample_5.pdf,11,73.2,8.966400146484375,URWPalladioL-Roma,False,420.14898681640625,246.0582275390625,0.0,4,P
sample_5.pdf,11,VOC07++12,8.966400146484375,URWPalladioL-Roma,False,313.2279968261719,257.0172119140625,0.3333333333333333,9,P
sample_5.pdf,11,70.4,8.966400146484375,URWPalladioL-Roma,False,471.50201416015625,257.0172119140625,0.0,4,P
sample_5.pdf,11,COCO (no VOC),8.966400146484375,URWPalladioL-Roma,False,313.2279968261719,268.37420654296875,0.5384615384615384,13,P
sample_5.pdf,11,76.1,8.966400146484375,URWPalladioL-Roma,False,420.14898681640625,268.37420654296875,0.0,4,P
sample_5.pdf,11,73.0,8.966400146484375,URWPalladioL-Roma,False,471.50201416015625,268.37420654296875,0.0,4,P
sample_5.pdf,11,COCO+VOC07+12,8.966400146484375,URWPalladioL-Roma,False,313.22802734375,279.33319091796875,0.5384615384615384,13,P
sample_5.pdf,11,78.8,8.966400146484375,URWPalladioL-Bold,True,420.14898681640625,279.2483215332031,0.0,4,P
sample_5.pdf,11,COCO+VOC07++12,8.966400146484375,URWPalladioL-Roma,False,313.2279968261719,290.29217529296875,0.5,14,P
sample_5.pdf,11,75.9,8.966400146484375,URWPalladioL-Bold,True,471.50201416015625,290.20733642578125,0.0,4,P
sample_5.pdf,11,4.3,9.962599754333496,NimbusSanL-Bold,True,287.05902099609375,327.6297302246094,0.0,3,H3
sample_5.pdf,11,From MS COCO to PASCAL VOC,9.962599754333496,NimbusSanL-Bold,True,310.86962890625,327.6297302246094,0.6153846153846154,26,H3
sample_5.pdf,11,Large-scale data is of crucial importance for improv-,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,343.07647705078125,0.018867924528301886,53,H3
sample_5.pdf,11,"ing deep neural networks. Next, we investigate how",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,355.0314636230469,0.02,50,H3
sample_5.pdf,11,the MS COCO dataset can help with the detection,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,366.9874572753906,0.1276595744680851,47,H3
sample_5.pdf,11,performance on PASCAL VOC.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,378.94244384765625,0.34615384615384615,26,H3
sample_5.pdf,11,"As a simple baseline, we directly evaluate the",9.962599754333496,URWPalladioL-Roma,False,297.0210266113281,390.6064453125,0.021739130434782608,46,H3
sample_5.pdf,11,"COCO detection model on the PASCAL VOC dataset,",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,402.5614318847656,0.2765957446808511,47,H3
sample_5.pdf,11,without ﬁne-tuning on any PASCAL VOC data,9.962599754333496,URWPalladioL-Ital,False,287.05902099609375,414.3465576171875,0.21951219512195122,41,H3
sample_5.pdf,11,. This,9.962599754333496,URWPalladioL-Roma,False,498.95501708984375,414.51641845703125,0.16666666666666666,6,H3
sample_5.pdf,11,evaluation is possible because the categories on,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,426.4714050292969,0.0,48,H3
sample_5.pdf,11,COCO are a superset of those on PASCAL VOC. The,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,438.4263916015625,0.2978723404255319,47,H3
sample_5.pdf,11,categories that are exclusive on COCO are ignored in,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,450.38238525390625,0.07692307692307693,52,H3
sample_5.pdf,11,"this experiment, and the softmax layer is performed",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,462.3373718261719,0.0,51,H3
sample_5.pdf,11,only on the 20 categories plus background. The mAP,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,474.2923583984375,0.06,50,H3
sample_5.pdf,11,under this setting is 76.1% on the PASCAL VOC 2007,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,486.2473449707031,0.18,50,H3
sample_5.pdf,11,test set (Table 12). This result is better than that trained,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,498.20233154296875,0.03333333333333333,60,H3
sample_5.pdf,11,"on VOC07+12 (73.2%) by a good margin, even though",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,510.15728759765625,0.061224489795918366,49,H3
sample_5.pdf,11,the PASCAL VOC data are not exploited.,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,522.1133422851562,0.23684210526315788,38,H3
sample_5.pdf,11,Then we ﬁne-tune the COCO detection model on,9.962599754333496,URWPalladioL-Roma,False,297.0210266113281,533.7772827148438,0.11363636363636363,44,H3
sample_5.pdf,11,"the VOC dataset. In this experiment, the COCO model",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,545.7322998046875,0.1568627450980392,51,H3
sample_5.pdf,11,is in place of the ImageNet-pre-trained model (that,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,557.6873168945312,0.0392156862745098,51,H3
sample_5.pdf,11,"is used to initialize the network weights), and the",9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,569.642333984375,0.0,51,H3
sample_5.pdf,11,Faster R-CNN system is ﬁne-tuned as described in,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,581.5973510742188,0.10416666666666667,48,H3
sample_5.pdf,11,Section 3.2. Doing so leads to 78.8% mAP on the,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,593.5532836914062,0.0851063829787234,47,H3
sample_5.pdf,11,PASCAL VOC 2007 test set. The extra data from,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,605.50830078125,0.2222222222222222,45,H3
sample_5.pdf,11,the COCO set increases the mAP by 5.6%. Table 6,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,617.4633178710938,0.14893617021276595,47,H3
sample_5.pdf,11,shows that the model trained on COCO+VOC has,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,629.4183349609375,0.1590909090909091,44,H3
sample_5.pdf,11,the best AP for every individual category on PASCAL,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,641.3733520507812,0.1568627450980392,51,H3
sample_5.pdf,11,VOC 2007. Similar improvements are observed on the,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,653.3283081054688,0.08,50,H3
sample_5.pdf,11,PASCAL VOC 2012 test set (Table 12 and Table 7). We,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,665.2843017578125,0.23529411764705882,51,H3
sample_5.pdf,11,note that the test-time speed of obtaining these strong,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,677.2393188476562,0.0,55,H3
sample_5.pdf,11,results is still about,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,689.1943359375,0.0,22,H3
sample_5.pdf,11,200ms per image,9.962599754333496,URWPalladioL-Bold,True,375.1283874511719,689.1000366210938,0.0,15,H3
sample_5.pdf,11,ONCLUSION,9.56410026550293,NimbusSanL-Bold,True,315.7870178222656,712.2939453125,1.0,9,H3
sample_5.pdf,11,We have presented RPNs for efﬁcient and accurate,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,727.435302734375,0.08333333333333333,48,H3
sample_5.pdf,11,region proposal generation. By sharing convolutional,9.962599754333496,URWPalladioL-Roma,False,287.05902099609375,739.3903198242188,0.019230769230769232,52,H3
sample_5.pdf,12,bottle : 0.726,3.123745918273926,ArialMT,False,420.4216003417969,108.32221221923828,0.0,14,P
sample_5.pdf,12,person : 0.992,3.123745918273926,ArialMT,False,384.06011962890625,63.73273468017578,0.0,14,P
sample_5.pdf,12,dog : 0.981,3.123745918273926,ArialMT,False,393.1416015625,155.5657958984375,0.0,11,P
sample_5.pdf,12,bicycle : 0.987,3.123745918273926,ArialMT,False,402.6169738769531,280.7543640136719,0.0,15,P
sample_5.pdf,12,bicycle : 0.977,3.123745918273926,ArialMT,False,382.73126220703125,290.154541015625,0.0,15,P
sample_5.pdf,12,bicycle : 0.972,3.123745918273926,ArialMT,False,400.7161865234375,287.20892333984375,0.0,15,P
sample_5.pdf,12,person : 0.995,3.123745918273926,ArialMT,False,410.37432861328125,261.5401916503906,0.0,14,P
sample_5.pdf,12,person : 0.994,3.123745918273926,ArialMT,False,382.3396911621094,281.0908508300781,0.0,14,P
sample_5.pdf,12,e : 0.987,3.123745918273926,ArialMT,False,410.426513671875,280.7543640136719,0.0,9,P
sample_5.pdf,12,e : 0 987,3.123745918273926,ArialMT,False,410.4263916015625,280.7543640136719,0.0,9,P
sample_5.pdf,12,bicyc,3.123745918273926,ArialMT,False,402.6169738769531,280.7543640136719,0.0,5,P
sample_5.pdf,12,bicyc,3.123745918273926,ArialMT,False,402.6169738769531,280.7543640136719,0.0,5,P
sample_5.pdf,12,bicyc,3.123745918273926,ArialMT,False,402.6169738769531,280.7543640136719,0.0,5,P
sample_5.pdf,12,person : 0.981,3.123745918273926,ArialMT,False,402.1732482910156,281.2738037109375,0.0,14,P
sample_5.pdf,12,person : 0.975,3.123745918273926,ArialMT,False,394.911865234375,379.8349304199219,0.0,14,P
sample_5.pdf,12,person : 0.972,3.123745918273926,ArialMT,False,383.8251953125,330.4812927246094,0.0,14,P
sample_5.pdf,12,person : 0.948,3.123745918273926,ArialMT,False,422.78985595703125,324.5155334472656,0.0,14,P
sample_5.pdf,12,person : 0.919,3.123745918273926,ArialMT,False,407.0402526855469,331.2335510253906,0.0,14,P
sample_5.pdf,12,horse : 0.984,3.123745918273926,ArialMT,False,384.81475830078125,437.43475341796875,0.0,13,P
sample_5.pdf,12,person : 0.670,3.123745918273926,ArialMT,False,391.86492919921875,429.3404541015625,0.0,14,P
sample_5.pdf,12,bird : 0.997,3.123745918273926,ArialMT,False,403.1366882324219,523.4109497070312,0.0,12,P
sample_5.pdf,12,bird : 0.727,3.123745918273926,ArialMT,False,419.4344177246094,561.9603271484375,0.0,12,P
sample_5.pdf,12,car : 1.000,2.1943604946136475,ArialMT,False,123.8117446899414,346.76824951171875,0.0,11,P
sample_5.pdf,12,car : 0.982,2.1943604946136475,ArialMT,False,172.89207458496094,349.23614501953125,0.0,11,P
sample_5.pdf,12,car,2.1943604946136475,ArialMT,False,123.8117446899414,346.76824951171875,0.0,3,P
sample_5.pdf,12,car,2.1943604946136475,ArialMT,False,123.8117446899414,346.76824951171875,0.0,3,P
sample_5.pdf,12,car : 0.981,2.1943604946136475,ArialMT,False,116.77247619628906,347.9951171875,0.0,11,P
sample_5.pdf,12,car : 0.880,2.1943604946136475,ArialMT,False,149.3953399658203,346.62347412109375,0.0,11,P
sample_5.pdf,12,bottle : 0.826,2.1943604946136475,ArialMT,False,262.35894775390625,361.41912841796875,0.0,14,P
sample_5.pdf,12,chair : 0.630,2.1943604946136475,ArialMT,False,204.0979766845703,350.00738525390625,0.0,13,P
sample_5.pdf,12,diningtable : 0.862,2.1943604946136475,ArialMT,False,208.2125244140625,360.1756591796875,0.0,19,P
sample_5.pdf,12,pottedplant : 0.728,2.1943604946136475,ArialMT,False,255.44448852539062,344.30035400390625,0.0,19,P
sample_5.pdf,12,boat : 0.995,2.1943604946136475,ArialMT,False,291.11328125,353.3177490234375,0.0,12,P
sample_5.pdf,12,boat : 0.948,2.1943604946136475,ArialMT,False,351.2023620605469,357.1406555175781,0.0,12,P
sample_5.pdf,12,boat : 0.808,2.1943604946136475,ArialMT,False,333.280517578125,375.33203125,0.0,12,P
sample_5.pdf,12,: 0 808,2.1943604946136475,ArialMT,False,338.1607666015625,375.33203125,0.0,7,P
sample_5.pdf,12,boat : 0.692,2.1943604946136475,ArialMT,False,338.3827209472656,373.8892822265625,0.0,12,P
sample_5.pdf,12,boat : 0.992,2.1943604946136475,ArialMT,False,140.20709228515625,293.15032958984375,0.0,12,P
sample_5.pdf,12,boat : 0.846,2.1943604946136475,ArialMT,False,116.76332092285156,323.79998779296875,0.0,12,P
sample_5.pdf,12,boat : 0.693,2.1943604946136475,ArialMT,False,132.06788635253906,319.75872802734375,0.0,12,P
sample_5.pdf,12,bottle : 0.962,2.1943604946136475,ArialMT,False,212.23594665527344,312.4974060058594,0.0,14,P
sample_5.pdf,12,0 962,2.1943604946136475,ArialMT,False,219.43344116210938,312.4974060058594,0.0,5,P
sample_5.pdf,12,bottle : 0.851,2.1943604946136475,ArialMT,False,218.5447998046875,310.3948974609375,0.0,14,P
sample_5.pdf,12,diningtable : 0.791,2.1943604946136475,ArialMT,False,203.05551147460938,320.306884765625,0.0,19,P
sample_5.pdf,12,person : 0.962,2.1943604946136475,ArialMT,False,228.78262329101562,295.4378662109375,0.0,14,P
sample_5.pdf,12,person : 0.930,2.1943604946136475,ArialMT,False,263.6184997558594,286.6802978515625,0.0,14,P
sample_5.pdf,12,pottedplant : 0.951,2.1943604946136475,ArialMT,False,201.48292541503906,301.12359619140625,0.0,19,P
sample_5.pdf,12,dog : 0.987,2.1943604946136475,ArialMT,False,315.0133972167969,298.6177062988281,0.0,11,P
sample_5.pdf,12,person : 0.940,2.1943604946136475,ArialMT,False,292.1543273925781,286.2209167480469,0.0,14,P
sample_5.pdf,12,940,2.1943604946136475,ArialMT,False,302.5228576660156,286.2209167480469,0.0,3,P
sample_5.pdf,12,940,2.1943604946136475,ArialMT,False,302.5226745605469,286.2209167480469,0.0,3,P
sample_5.pdf,12,person : 0.893,2.1943604946136475,ArialMT,False,302.43084716796875,286.2209167480469,0.0,14,P
sample_5.pdf,12,cat : 0.998,2.1943604946136475,ArialMT,False,116.76332092285156,228.12109375,0.0,11,P
sample_5.pdf,12,car : 1.000,2.1943604946136475,ArialMT,False,208.98114013671875,240.84799194335938,0.0,11,P
sample_5.pdf,12,person : 0.917,2.1943604946136475,ArialMT,False,232.71636962890625,235.83926391601562,0.0,14,P
sample_5.pdf,12,boat : 0.895,2.1943604946136475,ArialMT,False,315.75164794921875,241.3970947265625,0.0,12,P
sample_5.pdf,12,boat : 0.877,2.1943604946136475,ArialMT,False,319.2458801269531,245.54937744140625,0.0,12,P
sample_5.pdf,12,boat : 0.749,2.1943604946136475,ArialMT,False,340.09271240234375,240.48345947265625,0.0,12,P
sample_5.pdf,12,boat : 0.671,2.1943604946136475,ArialMT,False,299.14849853515625,238.9661865234375,0.0,12,P
sample_5.pdf,12,person : 0.988,2.1943604946136475,ArialMT,False,337.9890441894531,253.944091796875,0.0,14,P
sample_5.pdf,12,car : 0.955,2.1943604946136475,ArialMT,False,116.81810760498047,67.8151626586914,0.0,11,P
sample_5.pdf,12,car : 0.745,2.1943604946136475,ArialMT,False,124.84449768066406,66.88077545166016,0.0,11,P
sample_5.pdf,12,.745,2.1943604946136475,ArialMT,False,130.94261169433594,66.88077545166016,0.0,4,P
sample_5.pdf,12,horse : 0.991,2.1943604946136475,ArialMT,False,131.3010711669922,68.8917007446289,0.0,13,P
sample_5.pdf,12,person : 0.988,2.1943604946136475,ArialMT,False,145.5643768310547,62.74924087524414,0.0,14,P
sample_5.pdf,12,person : 0.797,2.1943604946136475,ArialMT,False,164.23370361328125,66.84302520751953,0.0,14,P
sample_5.pdf,12,bird : 0.978,2.1943604946136475,ArialMT,False,212.8560028076172,66.57050323486328,0.0,12,P
sample_5.pdf,12,bird : 0.972,2.1943604946136475,ArialMT,False,258.0960693359375,89.39078521728516,0.0,12,P
sample_5.pdf,12,bird : 0.941,2.1943604946136475,ArialMT,False,209.80409240722656,95.6087417602539,0.0,12,P
sample_5.pdf,12,bird : 0.902,2.1943604946136475,ArialMT,False,225.7663116455078,57.700931549072266,0.0,12,P
sample_5.pdf,12,person : 0.918,2.1943604946136475,ArialMT,False,256.2325439453125,53.824405670166016,0.0,14,P
sample_5.pdf,12,cow : 0.998,2.1943604946136475,ArialMT,False,349.5818176269531,90.30484771728516,0.0,11,P
sample_5.pdf,12,cow : 0.995,2.1943604946136475,ArialMT,False,293.06103515625,53.806461334228516,0.0,11,P
sample_5.pdf,12,aeroplane : 0.992,2.1943604946136475,ArialMT,False,116.77247619628906,411.46807861328125,0.0,17,P
sample_5.pdf,12,aeroplane : 0.986,2.1943604946136475,ArialMT,False,154.93557739257812,415.1842041015625,0.0,17,P
sample_5.pdf,12,sheep : 0.970,2.1943604946136475,ArialMT,False,230.53770446777344,416.5723876953125,0.0,13,P
sample_5.pdf,12,bird : 0.998,2.1943604946136475,ArialMT,False,304.6880187988281,412.4196472167969,0.0,12,P
sample_5.pdf,12,bird : 0.980,2.1943604946136475,ArialMT,False,337.16607666015625,422.6971435546875,0.0,12,P
sample_5.pdf,12,bird : 0.806,2.1943604946136475,ArialMT,False,317.1061706542969,430.96466064453125,0.0,12,P
sample_5.pdf,12,pottedplant : 0.993,2.1943604946136475,ArialMT,False,129.7818145751953,481.31732177734375,0.0,19,P
sample_5.pdf,12,pottedplant : 0.940,2.1943604946136475,ArialMT,False,129.2048797607422,500.6643981933594,0.0,19,P
sample_5.pdf,12,pottedplant : 0.869,2.1943604946136475,ArialMT,False,120.3082275390625,507.2328796386719,0.0,19,P
sample_5.pdf,12,pottedplant : 0.820,2.1943604946136475,ArialMT,False,156.1918487548828,471.8253173828125,0.0,19,P
sample_5.pdf,12,pottedplant : 0.715,2.1943604946136475,ArialMT,False,119.7348861694336,488.1325988769531,0.0,19,P
sample_5.pdf,12,aeroplane : 0.998,2.1943604946136475,ArialMT,False,203.19149780273438,463.9161376953125,0.0,17,P
sample_5.pdf,12,car : 0.907,2.1943604946136475,ArialMT,False,203.83242797851562,488.00445556640625,0.0,11,P
sample_5.pdf,12,907,2.1943604946136475,ArialMT,False,210.54043579101562,488.00445556640625,0.0,3,P
sample_5.pdf,12,907,2.1943604946136475,ArialMT,False,210.5405731201172,488.00445556640625,0.0,3,P
sample_5.pdf,12,person : 0.993,2.1943604946136475,ArialMT,False,211.34654235839844,489.0248107910156,0.0,14,P
sample_5.pdf,12,person : 0.987,2.1943604946136475,ArialMT,False,261.9080505371094,488.896728515625,0.0,14,P
sample_5.pdf,12,chair : 0.984,2.1943604946136475,ArialMT,False,292.5937805175781,477.5442810058594,0.0,13,P
sample_5.pdf,12,chair : 0.978,2.1943604946136475,ArialMT,False,335.2724609375,480.89019775390625,0.0,13,P
sample_5.pdf,12,chair : 0.976,2.1943604946136475,ArialMT,False,322.87542724609375,485.13311767578125,0.0,13,P
sample_5.pdf,12,chair : 0.962,2.1943604946136475,ArialMT,False,304.2428283691406,482.75537109375,0.0,13,P
sample_5.pdf,12,984,2.1943604946136475,ArialMT,False,301.0091857910156,477.5442810058594,0.0,3,P
sample_5.pdf,12,984,2.1943604946136475,ArialMT,False,301.0091552734375,477.5442810058594,0.0,3,P
sample_5.pdf,12,diningtable : 0.997,2.1943604946136475,ArialMT,False,302.0091552734375,478.5836181640625,0.0,19,P
sample_5.pdf,12,bottle : 0.789,2.1943604946136475,ArialMT,False,154.75405883789062,537.4150390625,0.0,14,P
sample_5.pdf,12,chair : 0.723,2.1943604946136475,ArialMT,False,172.81851196289062,534.0691528320312,0.0,13,P
sample_5.pdf,12,diningtable : 0.903,2.1943604946136475,ArialMT,False,116.77247619628906,547.179931640625,0.0,19,P
sample_5.pdf,12,e : 0.789,2.1943604946136475,ArialMT,False,158.9013214111328,537.4150390625,0.0,9,P
sample_5.pdf,12,person : 0.968,2.1943604946136475,ArialMT,False,158.849853515625,536.831298828125,0.0,14,P
sample_5.pdf,12,tvmonitor : 0.993,2.1943604946136475,ArialMT,False,139.3179168701172,526.5538330078125,0.0,17,P
sample_5.pdf,12,tvmonitor : 0.945,2.1943604946136475,ArialMT,False,123.70237731933594,518.6161499023438,0.0,17,P
sample_5.pdf,12,aeroplane : 0.978,2.1943604946136475,ArialMT,False,206.13638305664062,524.8547973632812,0.0,17,P
sample_5.pdf,12,person : 0.988,2.1943604946136475,ArialMT,False,234.75570678710938,544.6384887695312,0.0,14,P
sample_5.pdf,12,bottle : 0.903,2.1943604946136475,ArialMT,False,327.1629333496094,548.805419921875,0.0,14,P
sample_5.pdf,12,bottle : 0.884,2.1943604946136475,ArialMT,False,336.30682373046875,558.5917358398438,0.0,14,P
sample_5.pdf,12,bottle : 0.858,2.1943604946136475,ArialMT,False,319.628173828125,546.0836181640625,0.0,14,P
sample_5.pdf,12,bottle : 0,2.1943604946136475,ArialMT,False,319.628173828125,546.0836181640625,0.0,10,P
sample_5.pdf,12,bot,2.1943604946136475,ArialMT,False,319.628173828125,546.0836181640625,0.0,3,P
sample_5.pdf,12,bottle : 0.616,2.1943604946136475,ArialMT,False,314.3430480957031,547.8942260742188,0.0,14,P
sample_5.pdf,12,chair : 0.982,2.1943604946136475,ArialMT,False,307.2677001953125,536.629638671875,0.0,13,P
sample_5.pdf,12,chair : 0.852,2.1943604946136475,ArialMT,False,291.67071533203125,548.1315307617188,0.0,13,P
sample_5.pdf,12,person : 0.983,2.1943604946136475,ArialMT,False,296.38677978515625,520.4291381835938,0.0,14,P
sample_5.pdf,12,person : 0.959,2.1943604946136475,ArialMT,False,347.5529479980469,536.7933349609375,0.0,14,P
sample_5.pdf,12,: 0 903,2.1943604946136475,ArialMT,False,333.14044189453125,548.805419921875,0.0,7,P
sample_5.pdf,12,person : 0.897,2.1943604946136475,ArialMT,False,333.3979797363281,549.3535766601562,0.0,14,P
sample_5.pdf,12,person : 0.870,2.1943604946136475,ArialMT,False,293.8837585449219,551.00048828125,0.0,14,P
sample_5.pdf,12,tvmonitor : 0.993,2.1943604946136475,ArialMT,False,325.2989501953125,536.1170043945312,0.0,17,P
sample_5.pdf,12,dog : 0.697,2.1943604946136475,ArialMT,False,117.10106658935547,207.3079833984375,0.0,11,P
sample_5.pdf,12,person : 0.961,2.1943604946136475,ArialMT,False,139.7754364013672,181.98190307617188,0.0,14,P
sample_5.pdf,12,person : 0.960,2.1943604946136475,ArialMT,False,159.48841857910156,190.15570068359375,0.0,14,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,139.7754364013672,181.98190307617188,0.0,6,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,139.7754364013672,181.98190307617188,0.0,6,P
sample_5.pdf,12,person : 0.958,2.1943604946136475,ArialMT,False,132.0404510498047,183.84707641601562,0.0,14,P
sample_5.pdf,12,person : 0.757,2.1943604946136475,ArialMT,False,151.66253662109375,198.75119018554688,0.0,14,P
sample_5.pdf,12,bus : 0.999,2.1943604946136475,ArialMT,False,219.02011108398438,187.28436279296875,0.0,11,P
sample_5.pdf,12,person : 0.996,2.1943604946136475,ArialMT,False,260.327392578125,197.25143432617188,0.0,14,P
sample_5.pdf,12,per,2.1943604946136475,ArialMT,False,260.327392578125,197.25143432617188,0.0,3,P
sample_5.pdf,12,per,2.1943604946136475,ArialMT,False,260.327392578125,197.25143432617188,0.0,3,P
sample_5.pdf,12,per,2.1943604946136475,ArialMT,False,260.327392578125,197.25143432617188,0.0,3,P
sample_5.pdf,12,person : 0.995,2.1943604946136475,ArialMT,False,248.84469604492188,196.77685546875,0.0,14,P
sample_5.pdf,12,person : 0.994,2.1943604946136475,ArialMT,False,204.1527862548828,198.93154907226562,0.0,14,P
sample_5.pdf,12,person : 0.985,2.1943604946136475,ArialMT,False,214.37425231933594,196.411376953125,0.0,14,P
sample_5.pdf,12,cow : 0.985,2.1943604946136475,ArialMT,False,306.4542541503906,193.11911010742188,0.0,11,P
sample_5.pdf,12,cow : 0.979,2.1943604946136475,ArialMT,False,314.8114929199219,185.05303955078125,0.0,11,P
sample_5.pdf,12,cow : 0.979,2.1943604946136475,ArialMT,False,318.7781677246094,177.66421508789062,0.0,11,P
sample_5.pdf,12,cow : 0.974,2.1943604946136475,ArialMT,False,298.29754638671875,181.58157348632812,0.0,11,P
sample_5.pdf,12,cow : 0.892,2.1943604946136475,ArialMT,False,294.0937805175781,189.16757202148438,0.0,11,P
sample_5.pdf,12,person : 0.998,2.1943604946136475,ArialMT,False,340.4840087890625,178.178466796875,0.0,14,P
sample_5.pdf,12,car : 0.999,2.1943604946136475,ArialMT,False,118.26103973388672,132.18328857421875,0.0,11,P
sample_5.pdf,12,person : 0.929,2.1943604946136475,ArialMT,False,153.06021118164062,134.214599609375,0.0,14,P
sample_5.pdf,12,person : 0.994,2.1943604946136475,ArialMT,False,214.31777954101562,134.74636840820312,0.0,14,P
sample_5.pdf,12,person : 0.991,2.1943604946136475,ArialMT,False,204.1527862548828,137.65213012695312,0.0,14,P
sample_5.pdf,12,person : 0.988,2.1943604946136475,ArialMT,False,243.46676635742188,130.53762817382812,0.0,14,P
sample_5.pdf,12,pers,2.1943604946136475,ArialMT,False,243.46676635742188,130.53762817382812,0.0,4,P
sample_5.pdf,12,person : 0.976,2.1943604946136475,ArialMT,False,233.04359436035156,132.97207641601562,0.0,14,P
sample_5.pdf,12,person : 0.964,2.1943604946136475,ArialMT,False,223.2236328125,129.971923828125,0.0,14,P
sample_5.pdf,12,car : 0.997,2.1943604946136475,ArialMT,False,304.80859375,137.9620361328125,0.0,11,P
sample_5.pdf,12,car : 0.980,2.1943604946136475,ArialMT,False,343.02667236328125,137.2677001953125,0.0,11,P
sample_5.pdf,12,person : 0.993,2.1943604946136475,ArialMT,False,334.9444885253906,131.54403686523438,0.0,14,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,334.9444885253906,131.54403686523438,0.0,6,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,334.9444885253906,131.54403686523438,0.0,6,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,334.9444885253906,131.54403686523438,0.0,6,P
sample_5.pdf,12,person,2.1943604946136475,ArialMT,False,334.9444885253906,131.54403686523438,0.0,6,P
sample_5.pdf,12,person : 0.986,2.1943604946136475,ArialMT,False,328.7440490722656,130.42752075195312,0.0,14,P
sample_5.pdf,12,0 993,2.1943604946136475,ArialMT,False,343.48272705078125,131.54403686523438,0.0,5,P
sample_5.pdf,12,n :,2.1943604946136475,ArialMT,False,340.4326477050781,131.54403686523438,0.0,3,P
sample_5.pdf,12,n :,2.1943604946136475,ArialMT,False,340.4326477050781,131.54403686523438,0.0,3,P
sample_5.pdf,12,person : 0.959,2.1943604946136475,ArialMT,False,341.7656555175781,132.07321166992188,0.0,14,P
sample_5.pdf,12,Figure 5: Selected examples of object detection results on the PASCAL VOC 2007 test set using the Faster,9.962599754333496,URWPalladioL-Roma,False,36.0,582.4944458007812,0.11538461538461539,104,H3
sample_5.pdf,12,R-CNN system. The model is VGG-16 and the training data is 07+12 trainval (73.2% mAP on the 2007 test,9.962599754333496,URWPalladioL-Roma,False,36.0,594.449462890625,0.09900990099009901,101,H3
sample_5.pdf,12,set). Our method detects objects of a wide range of scales and aspect ratios. Each output box is associated,9.962599754333496,URWPalladioL-Roma,False,36.0,606.4054565429688,0.018691588785046728,107,H3
sample_5.pdf,12,with a category label and a softmax score in,9.962599754333496,URWPalladioL-Roma,False,36.0,618.3604736328125,0.0,44,H3
sample_5.pdf,12,. A score threshold of 0.6 is used to display these images.,9.962599754333496,URWPalladioL-Roma,False,262.44097900390625,618.3604736328125,0.01694915254237288,59,H3
sample_5.pdf,12,The running time for obtaining these results is,9.962599754333496,URWPalladioL-Roma,False,35.99998474121094,630.3154907226562,0.02127659574468085,47,H3
sample_5.pdf,12,198ms,9.962599754333496,URWPalladioL-Bold,True,246.3701934814453,630.22119140625,0.0,5,H3
sample_5.pdf,12,"per image,",9.962599754333496,URWPalladioL-Roma,False,278.08001708984375,630.3154907226562,0.0,10,H3
sample_5.pdf,12,including all steps,9.962599754333496,URWPalladioL-Ital,False,329.22808837890625,630.1456298828125,0.0,19,H3
sample_5.pdf,12,"features with the down-stream detection network, the",9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,666.1814575195312,0.0,52,H3
sample_5.pdf,12,region proposal step is nearly cost-free. Our method,9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,678.136474609375,0.019230769230769232,52,H3
sample_5.pdf,12,"enables a uniﬁed, deep-learning-based object detec-",9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,690.0914916992188,0.0,51,H3
sample_5.pdf,12,tion system to run at near real-time frame rates. The,9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,702.0464477539062,0.018867924528301886,53,H3
sample_5.pdf,12,learned RPN also improves region proposal quality,9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,714.00146484375,0.061224489795918366,49,H3
sample_5.pdf,12,and thus the overall object detection accuracy.,9.962599754333496,URWPalladioL-Roma,False,35.999969482421875,725.9564819335938,0.0,47,H3
sample_5.pdf,12,EFERENCES,9.56410026550293,NimbusSanL-Bold,True,296.58697509765625,665.97509765625,1.0,9,H3
sample_5.pdf,12,[1],7.970099925994873,URWPalladioL-Roma,False,287.0589599609375,693.9469604492188,0.0,3,P
sample_5.pdf,12,"K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling",7.970099925994873,URWPalladioL-Roma,False,305.3184814453125,693.9469604492188,0.14754098360655737,61,P
sample_5.pdf,12,"in deep convolutional networks for visual recognition,” in",7.970099925994873,URWPalladioL-Roma,False,305.3179626464844,702.9129638671875,0.0,58,P
sample_5.pdf,12,European Conference on Computer Vision (ECCV),7.970099925994873,URWPalladioL-Ital,False,305.3179626464844,711.7440795898438,0.17777777777777778,45,P
sample_5.pdf,12,", 2014.",7.970099925994873,URWPalladioL-Roma,False,473.0789794921875,711.8800048828125,0.0,7,P
sample_5.pdf,12,[2],7.970099925994873,URWPalladioL-Roma,False,287.0589599609375,721.8670043945312,0.0,3,P
sample_5.pdf,12,"R. Girshick, “Fast R-CNN,” in",7.970099925994873,URWPalladioL-Roma,False,305.3184814453125,721.8670043945312,0.2413793103448276,29,P
sample_5.pdf,12,IEEE International Conference on,7.970099925994873,URWPalladioL-Ital,False,412.8351135253906,721.7310791015625,0.1875,32,P
sample_5.pdf,12,Computer Vision (ICCV),7.970099925994873,URWPalladioL-Ital,False,305.3179626464844,730.6970825195312,0.2727272727272727,22,P
sample_5.pdf,12,", 2015.",7.970099925994873,URWPalladioL-Roma,False,388.23797607421875,730.8330078125,0.0,7,P
sample_5.pdf,12,[3],7.970099925994873,URWPalladioL-Roma,False,287.0589599609375,740.8199462890625,0.0,3,P
sample_5.pdf,12,"K. Simonyan and A. Zisserman, “Very deep convolutional",7.970099925994873,URWPalladioL-Roma,False,305.3184814453125,740.8199462890625,0.09259259259259259,54,P
sample_5.pdf,13,cup : 0.807,2.3071000576019287,Helvetica,False,147.62286376953125,528.6146240234375,0.0,11,P
sample_5.pdf,13,bowl : 0.847,2.3071000576019287,Helvetica,False,114.1861572265625,523.0199584960938,0.0,12,P
sample_5.pdf,13,bowl : 0.816,2.3071000576019287,Helvetica,False,145.77418518066406,517.8889770507812,0.0,12,P
sample_5.pdf,13,bowl : 0.744,2.3071000576019287,Helvetica,False,107.07437896728516,515.3004150390625,0.0,12,P
sample_5.pdf,13,bowl : 0.710,2.3071000576019287,Helvetica,False,132.21353149414062,519.3862915039062,0.0,12,P
sample_5.pdf,13,chair : 0.772,2.3071000576019287,Helvetica,False,148.91925048828125,543.8692016601562,0.0,13,P
sample_5.pdf,13,dining table : 0.618,2.3071000576019287,Helvetica,False,127.9963607788086,549.955322265625,0.0,20,P
sample_5.pdf,13,oven : 0.969,2.3071000576019287,Helvetica,False,105.46646881103516,546.3793334960938,0.0,12,P
sample_5.pdf,13,refrigerator : 0.631,2.3071000576019287,Helvetica,False,124.59696960449219,505.9681701660156,0.0,20,P
sample_5.pdf,13,cup : 0.990,2.3071000576019287,Helvetica,False,200.06396484375,495.2101745605469,0.0,11,P
sample_5.pdf,13,pizza : 0.919,2.3071000576019287,Helvetica,False,181.3404541015625,504.9945983886719,0.0,13,P
sample_5.pdf,13,dining table : 0.888,2.3071000576019287,Helvetica,False,177.33901977539062,496.0753479003906,0.0,20,P
sample_5.pdf,13,person : 0.984,2.3071000576019287,Helvetica,False,255.90338134765625,497.02813720703125,0.0,14,P
sample_5.pdf,13,person,2.3071000576019287,Helvetica,False,255.90338134765625,497.02813720703125,0.0,6,P
sample_5.pdf,13,person,2.3071000576019287,Helvetica,False,255.90338134765625,497.02813720703125,0.0,6,P
sample_5.pdf,13,car : 0.816,2.3071000576019287,Helvetica,False,250.38296508789062,495.6231384277344,0.0,11,P
sample_5.pdf,13,pizza : 0.965,2.3071000576019287,Helvetica,False,269.53375244140625,534.2485961914062,0.0,13,P
sample_5.pdf,13,clock : 0.988,2.3071000576019287,Helvetica,False,324.1741943359375,512.386474609375,0.0,13,P
sample_5.pdf,13,person : 0.998,2.3071000576019287,Helvetica,False,385.4099426269531,519.5408325195312,0.0,14,P
sample_5.pdf,13,kite : 0.934,2.3071000576019287,Helvetica,False,364.3760681152344,507.0617370605469,0.0,12,P
sample_5.pdf,13,toothbrush : 0.668,2.3071000576019287,Helvetica,False,424.66754150390625,496.1629943847656,0.0,18,P
sample_5.pdf,13,teddy bear : 0.999,2.3071000576019287,Helvetica,False,212.21315002441406,246.86907958984375,0.0,18,P
sample_5.pdf,13,teddy bear : 0.890,2.3071000576019287,Helvetica,False,244.51254272460938,265.13299560546875,0.0,18,P
sample_5.pdf,13,teddy bear : 0.802,2.3071000576019287,Helvetica,False,258.7410888671875,261.05242919921875,0.0,18,P
sample_5.pdf,13,teddy bear : 0.738,2.3071000576019287,Helvetica,False,202.81124877929688,260.9220886230469,0.0,18,P
sample_5.pdf,13,bowl : 0.602,2.3071000576019287,Helvetica,False,329.0869140625,278.5243225097656,0.0,12,P
sample_5.pdf,13,potted plant : 0.769,2.3071000576019287,Helvetica,False,326.876708984375,262.66302490234375,0.0,20,P
sample_5.pdf,13,toilet : 0.921,2.3071000576019287,Helvetica,False,335.79803466796875,283.25457763671875,0.0,14,P
sample_5.pdf,13,sink : 0.969,2.3071000576019287,Helvetica,False,310.7832946777344,284.3712463378906,0.0,12,P
sample_5.pdf,13,sink : 0.994,2.3071000576019287,Helvetica,False,404.6026916503906,280.045166015625,0.0,12,P
sample_5.pdf,13,sink : 0.992,2.3071000576019287,Helvetica,False,388.30072021484375,282.830078125,0.0,12,P
sample_5.pdf,13,sink : 0.976,2.3071000576019287,Helvetica,False,417.4093933105469,278.5040283203125,0.0,12,P
sample_5.pdf,13,sink : 0.938,2.3071000576019287,Helvetica,False,428.00128173828125,278.082763671875,0.0,12,P
sample_5.pdf,13,person : 0.970,2.3071000576019287,Helvetica,False,170.50100708007812,273.1222839355469,0.0,14,P
sample_5.pdf,13,: 0.970,2.3071000576019287,Helvetica,False,177.673583984375,273.1222839355469,0.0,7,P
sample_5.pdf,13,erson,2.3071000576019287,Helvetica,False,171.81375122070312,273.1222839355469,0.0,5,P
sample_5.pdf,13,person : 0.869,2.3071000576019287,Helvetica,False,172.73220825195312,272.5851745605469,0.0,14,P
sample_5.pdf,13,bus : 0.999,2.3071000576019287,Helvetica,False,120.2638168334961,253.66650390625,0.0,11,P
sample_5.pdf,13,bottle : 0.768,2.3071000576019287,Helvetica,False,227.5230712890625,324.4339904785156,0.0,14,P
sample_5.pdf,13,cup : 0.720,2.3071000576019287,Helvetica,False,247.74618530273438,356.2927551269531,0.0,11,P
sample_5.pdf,13,chair : 0.644,2.3071000576019287,Helvetica,False,203.71841430664062,350.3542785644531,0.0,13,P
sample_5.pdf,13,tv : 0.964,2.3071000576019287,Helvetica,False,241.51885986328125,318.12872314453125,0.0,10,P
sample_5.pdf,13,tv : 0.959,2.3071000576019287,Helvetica,False,203.81761169433594,335.06976318359375,0.0,10,P
sample_5.pdf,13,laptop : 0.986,2.3071000576019287,Helvetica,False,250.82476806640625,326.55194091796875,0.0,14,P
sample_5.pdf,13,mouse : 0.871,2.3071000576019287,Helvetica,False,241.94241333007812,334.1468811035156,0.0,13,P
sample_5.pdf,13,mouse : 0.677,2.3071000576019287,Helvetica,False,244.24954223632812,341.6219177246094,0.0,13,P
sample_5.pdf,13,keyboard : 0.956,2.3071000576019287,Helvetica,False,225.369140625,336.2232666015625,0.0,16,P
sample_5.pdf,13,book : 0.611,2.3071000576019287,Helvetica,False,264.0619812011719,310.2845458984375,0.0,12,P
sample_5.pdf,13,person : 0.986,2.3071000576019287,Helvetica,False,327.3134460449219,349.7151794433594,0.0,14,P
sample_5.pdf,13,boat : 0.758,2.3071000576019287,Helvetica,False,306.281005859375,334.6267395019531,0.0,12,P
sample_5.pdf,13,boat : 0.746,2.3071000576019287,Helvetica,False,348.4432373046875,333.2978820800781,0.0,12,P
sample_5.pdf,13,boat : 0.613,2.3071000576019287,Helvetica,False,331.1605224609375,333.4294128417969,0.0,12,P
sample_5.pdf,13,bench : 0.971,2.3071000576019287,Helvetica,False,323.3355407714844,343.8736267089844,0.0,13,P
sample_5.pdf,13,train : 0.965,2.3071000576019287,Helvetica,False,395.0235900878906,331.2999572753906,0.0,13,P
sample_5.pdf,13,traffic light : 0.869,2.3071000576019287,Helvetica,False,390.3724670410156,325.6083679199219,0.0,21,P
sample_5.pdf,13,traffic light : 0.713,2.3071000576019287,Helvetica,False,429.9208068847656,323.8202819824219,0.0,21,P
sample_5.pdf,13,chair : 0.631,2.3071000576019287,Helvetica,False,112.80777740478516,343.3753356933594,0.0,13,P
sample_5.pdf,13,couch : 0.991,2.3071000576019287,Helvetica,False,118.49980926513672,333.2217712402344,0.0,13,P
sample_5.pdf,13,couch : 0.719,2.3071000576019287,Helvetica,False,160.91224670410156,335.2035827636719,0.0,13,P
sample_5.pdf,13,couch : 0.627,2.3071000576019287,Helvetica,False,172.157958984375,329.5488586425781,0.0,13,P
sample_5.pdf,13,dining table : 0.637,2.3071000576019287,Helvetica,False,140.26231384277344,337.6998291015625,0.0,20,P
sample_5.pdf,13,dog : 0.966,2.3071000576019287,Helvetica,False,248.70755004882812,386.2873840332031,0.0,11,P
sample_5.pdf,13,frisbee : 0.998,2.3071000576019287,Helvetica,False,239.82684326171875,371.3835144042969,0.0,15,P
sample_5.pdf,13,bird : 0.987,2.3071000576019287,Helvetica,False,293.6318359375,406.6082763671875,0.0,12,P
sample_5.pdf,13,bird : 0.968,2.3071000576019287,Helvetica,False,317.1264343261719,384.2478942871094,0.0,12,P
sample_5.pdf,13,bird : 0.894,2.3071000576019287,Helvetica,False,302.0532531738281,413.7026062011719,0.0,12,P
sample_5.pdf,13,person : 0.723,2.3071000576019287,Helvetica,False,390.36328125,373.0976867675781,0.0,14,P
sample_5.pdf,13,cup : 0.986,2.3071000576019287,Helvetica,False,410.30120849609375,379.9612731933594,0.0,11,P
sample_5.pdf,13,cup : 0.931,2.3071000576019287,Helvetica,False,395.4181213378906,378.3625183105469,0.0,11,P
sample_5.pdf,13,bowl : 0.958,2.3071000576019287,Helvetica,False,435.4255065917969,388.4560241699219,0.0,12,P
sample_5.pdf,13,sandwich : 0.629,2.3071000576019287,Helvetica,False,395.3050537109375,397.05462646484375,0.0,16,P
sample_5.pdf,13,dining table : 0.941,2.3071000576019287,Helvetica,False,375.38323974609375,381.09405517578125,0.0,20,P
sample_5.pdf,13,zebra : 0.996,2.3071000576019287,Helvetica,False,164.70973205566406,391.74365234375,0.0,13,P
sample_5.pdf,13,zebra : 0.993,2.3071000576019287,Helvetica,False,122.39246368408203,397.0500183105469,0.0,13,P
sample_5.pdf,13,zebra : 0.970,2.3071000576019287,Helvetica,False,150.01995849609375,393.8984680175781,0.0,13,P
sample_5.pdf,13,970,2.3071000576019287,Helvetica,False,158.45933532714844,393.8984680175781,0.0,3,P
sample_5.pdf,13,zebra : 0.848,2.3071000576019287,Helvetica,False,159.459228515625,394.5906066894531,0.0,13,P
sample_5.pdf,13,person : 0.917,2.3071000576019287,Helvetica,False,258.37567138671875,433.31298828125,0.0,14,P
sample_5.pdf,13,person : 0.792,2.3071000576019287,Helvetica,False,210.5785675048828,433.5805969238281,0.0,14,P
sample_5.pdf,13,: 0.792,2.3071000576019287,Helvetica,False,217.7513427734375,433.5805969238281,0.0,7,P
sample_5.pdf,13,0 792,2.3071000576019287,Helvetica,False,218.71795654296875,433.5805969238281,0.0,5,P
sample_5.pdf,13,tv : 0.711,2.3071000576019287,Helvetica,False,218.09695434570312,433.3314514160156,0.0,10,P
sample_5.pdf,13,laptop : 0.973,2.3071000576019287,Helvetica,False,217.63507080078125,445.3468017578125,0.0,14,P
sample_5.pdf,13,mouse : 0.981,2.3071000576019287,Helvetica,False,255.60531616210938,468.4570617675781,0.0,13,P
sample_5.pdf,13,keyboard : 0.638,2.3071000576019287,Helvetica,False,220.61630249023438,459.7292785644531,0.0,16,P
sample_5.pdf,13,keyboard : 0.615,2.3071000576019287,Helvetica,False,204.425537109375,463.93743896484375,0.0,16,P
sample_5.pdf,13,person : 0.999,2.3071000576019287,Helvetica,False,319.15716552734375,448.8467102050781,0.0,14,P
sample_5.pdf,13,person : 0.999,2.3071000576019287,Helvetica,False,319.15716552734375,448.8443908691406,0.0,14,P
sample_5.pdf,13,person : 0.999,2.3071000576019287,Helvetica,False,319.15716552734375,448.8467102050781,0.0,14,P
sample_5.pdf,13,perso,2.3071000576019287,Helvetica,False,319.15716552734375,448.8443908691406,0.0,5,P
sample_5.pdf,13,perso,2.3071000576019287,Helvetica,False,319.15716552734375,448.8467102050781,0.0,5,P
sample_5.pdf,13,tennis racket : 0.960,2.3071000576019287,Helvetica,False,319.9447937011719,448.4429626464844,0.0,21,P
sample_5.pdf,13,bird : 0.956,2.3071000576019287,Helvetica,False,406.2222900390625,453.5946960449219,0.0,12,P
sample_5.pdf,13,bird : 0.906,2.3071000576019287,Helvetica,False,380.7934265136719,461.4780578613281,0.0,12,P
sample_5.pdf,13,bird : 0.746,2.3071000576019287,Helvetica,False,418.56756591796875,451.4029235839844,0.0,12,P
sample_5.pdf,13,horse : 0.990,2.3071000576019287,Helvetica,False,394.615234375,448.8097839355469,0.0,13,P
sample_5.pdf,13,person : 0.993,2.3071000576019287,Helvetica,False,128.9051513671875,438.0679016113281,0.0,14,P
sample_5.pdf,13,bottle : 0.982,2.3071000576019287,Helvetica,False,173.7789306640625,442.68212890625,0.0,14,P
sample_5.pdf,13,oven : 0.655,2.3071000576019287,Helvetica,False,153.45730590820312,454.10455322265625,0.0,12,P
sample_5.pdf,13,refrigerator : 0.699,2.3071000576019287,Helvetica,False,144.61463928222656,436.5521545410156,0.0,20,P
sample_5.pdf,13,clock : 0.982,2.3071000576019287,Helvetica,False,236.11398315429688,141.33123779296875,0.0,13,P
sample_5.pdf,13,bed : 0.999,2.3071000576019287,Helvetica,False,302.8981018066406,132.06201171875,0.0,11,P
sample_5.pdf,13,person : 0.808,2.3071000576019287,Helvetica,False,413.6280212402344,119.62349700927734,0.0,14,P
sample_5.pdf,13,bottle : 0.627,2.3071000576019287,Helvetica,False,408.5132141113281,153.6744384765625,0.0,14,P
sample_5.pdf,13,pizza : 0.995,2.3071000576019287,Helvetica,False,379.63525390625,135.3316650390625,0.0,13,P
sample_5.pdf,13,pizza : 0.985,2.3071000576019287,Helvetica,False,384.0002746582031,122.41143035888672,0.0,13,P
sample_5.pdf,13,pizza : 0.982,2.3071000576019287,Helvetica,False,402.7639465332031,139.59747314453125,0.0,13,P
sample_5.pdf,13,pizza : 0.938,2.3071000576019287,Helvetica,False,375.40631103515625,128.75595092773438,0.0,13,P
sample_5.pdf,13,dining table : 0.956,2.3071000576019287,Helvetica,False,375.38323974609375,125.70088958740234,0.0,20,P
sample_5.pdf,13,person : 0.998,2.3071000576019287,Helvetica,False,147.79037475585938,124.3906478881836,0.0,14,P
sample_5.pdf,13,skis : 0.919,2.3071000576019287,Helvetica,False,144.5406036376953,153.09423828125,0.0,12,P
sample_5.pdf,13,bowl : 0.759,2.3071000576019287,Helvetica,False,212.84298706054688,179.17416381835938,0.0,12,P
sample_5.pdf,13,broccoli : 0.953,2.3071000576019287,Helvetica,False,224.18746948242188,206.41775512695312,0.0,16,P
sample_5.pdf,13,person : 0.999,2.3071000576019287,Helvetica,False,314.99884033203125,195.85150146484375,0.0,14,P
sample_5.pdf,13,person : 0.934,2.3071000576019287,Helvetica,False,307.52197265625,211.86968994140625,0.0,14,P
sample_5.pdf,13,surfboard : 0.979,2.3071000576019287,Helvetica,False,327.2855224609375,221.98123168945312,0.0,17,P
sample_5.pdf,13,person : 0.940,2.3071000576019287,Helvetica,False,375.4155578613281,225.97344970703125,0.0,14,P
sample_5.pdf,13,person : 0.927,2.3071000576019287,Helvetica,False,404.425048828125,226.81692504882812,0.0,14,P
sample_5.pdf,13,person : 0.864,2.3071000576019287,Helvetica,False,409.0022888183594,234.66360473632812,0.0,14,P
sample_5.pdf,13,0.940,2.3071000576019287,Helvetica,False,383.5550537109375,225.97344970703125,0.0,5,P
sample_5.pdf,13,person : 0.854,2.3071000576019287,Helvetica,False,384.8746643066406,226.94818115234375,0.0,14,P
sample_5.pdf,13,person : 0.825,2.3071000576019287,Helvetica,False,377.0974426269531,234.3408203125,0.0,14,P
sample_5.pdf,13,person : 0.813,2.3071000576019287,Helvetica,False,390.4001770019531,234.79510498046875,0.0,14,P
sample_5.pdf,13,person : 0.716,2.3071000576019287,Helvetica,False,398.17510986328125,224.18545532226562,0.0,14,P
sample_5.pdf,13,person : 0.692,2.3071000576019287,Helvetica,False,415.7898254394531,231.22161865234375,0.0,14,P
sample_5.pdf,13,person : 0.691,2.3071000576019287,Helvetica,False,384.4132385253906,223.41348266601562,0.0,14,P
sample_5.pdf,13,927,2.3071000576019287,Helvetica,False,414.2255859375,226.81692504882812,0.0,3,P
sample_5.pdf,13,927,2.3071000576019287,Helvetica,False,414.2255859375,226.81692504882812,0.0,3,P
sample_5.pdf,13,person : 0.665,2.3071000576019287,Helvetica,False,415.2499694824219,227.10531616210938,0.0,14,P
sample_5.pdf,13,person : 0.618,2.3071000576019287,Helvetica,False,432.3224792480469,231.08642578125,0.0,14,P
sample_5.pdf,13,boat : 0.992,2.3071000576019287,Helvetica,False,410.90338134765625,210.5537109375,0.0,12,P
sample_5.pdf,13,umbrella : 0.885,2.3071000576019287,Helvetica,False,420.36248779296875,222.0675048828125,0.0,16,P
sample_5.pdf,13,giraffe : 0.993,2.3071000576019287,Helvetica,False,150.83828735351562,191.31619262695312,0.0,15,P
sample_5.pdf,13,giraffe : 0.989,2.3071000576019287,Helvetica,False,134.30352783203125,190.18063354492188,0.0,15,P
sample_5.pdf,13,giraffe : 0.988,2.3071000576019287,Helvetica,False,118.65302276611328,195.52481079101562,0.0,15,P
sample_5.pdf,13,person : 0.867,2.3071000576019287,Helvetica,False,235.57669067382812,70.53902435302734,0.0,14,P
sample_5.pdf,13,airplane : 0.997,2.3071000576019287,Helvetica,False,203.4715576171875,62.52184295654297,0.0,16,P
sample_5.pdf,13,person : 0.970,2.3071000576019287,Helvetica,False,335.0173034667969,76.86507415771484,0.0,14,P
sample_5.pdf,13,person : 0.950,2.3071000576019287,Helvetica,False,298.31341552734375,74.45415496826172,0.0,14,P
sample_5.pdf,13,person : 0.931,2.3071000576019287,Helvetica,False,316.10552978515625,75.57723236083984,0.0,14,P
sample_5.pdf,13,person : 0.916,2.3071000576019287,Helvetica,False,296.295166015625,77.4015121459961,0.0,14,P
sample_5.pdf,13,person : 0.897,2.3071000576019287,Helvetica,False,311.4138488769531,70.61473846435547,0.0,14,P
sample_5.pdf,13,person : 0.842,2.3071000576019287,Helvetica,False,291.9566345214844,68.0782699584961,0.0,14,P
sample_5.pdf,13,person : 0.841,2.3071000576019287,Helvetica,False,335.65728759765625,68.07918548583984,0.0,14,P
sample_5.pdf,13,person : 0.84,2.3071000576019287,Helvetica,False,291.9566345214844,68.0782699584961,0.0,13,P
sample_5.pdf,13,person : 0.772,2.3071000576019287,Helvetica,False,288.1322021484375,66.95446014404297,0.0,14,P
sample_5.pdf,13,bicycle : 0.891,2.3071000576019287,Helvetica,False,308.3292236328125,90.93611907958984,0.0,15,P
sample_5.pdf,13,bicycle : 0.639,2.3071000576019287,Helvetica,False,292.2958068847656,94.26384735107422,0.0,15,P
sample_5.pdf,13,car : 0.957,2.3071000576019287,Helvetica,False,350.57269287109375,70.26482391357422,0.0,11,P
sample_5.pdf,13,motorcycle : 0.827,2.3071000576019287,Helvetica,False,333.0908508300781,102.76045989990234,0.0,18,P
sample_5.pdf,13,motorcycle : 0.713,2.3071000576019287,Helvetica,False,288.13311767578125,83.65306854248047,0.0,18,P
sample_5.pdf,13,traffic light : 0.802,2.3071000576019287,Helvetica,False,335.6595764160156,56.870140075683594,0.0,21,P
sample_5.pdf,13,umbrella : 0.824,2.3071000576019287,Helvetica,False,291.9737548828125,71.34200286865234,0.0,16,P
sample_5.pdf,13,person : 0.800,2.3071000576019287,Helvetica,False,426.630859375,101.43688201904297,0.0,14,P
sample_5.pdf,13,clock : 0.986,2.3071000576019287,Helvetica,False,386.4089050292969,73.25008392333984,0.0,13,P
sample_5.pdf,13,clock : 0.981,2.3071000576019287,Helvetica,False,401.38885498046875,75.7883529663086,0.0,13,P
sample_5.pdf,13,person : 0.996,2.3071000576019287,Helvetica,False,115.13240814208984,97.02129364013672,0.0,14,P
sample_5.pdf,13,person : 0.976,2.3071000576019287,Helvetica,False,137.90953063964844,68.96617889404297,0.0,14,P
sample_5.pdf,13,person : 0.975,2.3071000576019287,Helvetica,False,162.9120330810547,57.22588348388672,0.0,14,P
sample_5.pdf,13,rson : 0.975,2.3071000576019287,Helvetica,False,165.38063049316406,57.22588348388672,0.0,12,P
sample_5.pdf,13,rson,2.3071000576019287,Helvetica,False,165.38047790527344,57.22588348388672,0.0,4,P
sample_5.pdf,13,son : 0,2.3071000576019287,Helvetica,False,166.13504028320312,57.22588348388672,0.0,7,P
sample_5.pdf,13,person : 0.958,2.3071000576019287,Helvetica,False,166.2010498046875,58.283897399902344,0.0,14,P
sample_5.pdf,13,person : 0.950,2.3071000576019287,Helvetica,False,167.3135223388672,71.87642669677734,0.0,14,P
sample_5.pdf,13,person : 0.941,2.3071000576019287,Helvetica,False,119.01768493652344,58.283897399902344,0.0,14,P
sample_5.pdf,13,0.976,2.3071000576019287,Helvetica,False,146.04898071289062,68.96617889404297,0.0,5,P
sample_5.pdf,13,0 976,2.3071000576019287,Helvetica,False,146.04898071289062,68.96617889404297,0.0,5,P
sample_5.pdf,13,person : 0.939,2.3071000576019287,Helvetica,False,146.78033447265625,67.84395599365234,0.0,14,P
sample_5.pdf,13,person : 0.928,2.3071000576019287,Helvetica,False,150.40362548828125,58.415489196777344,0.0,14,P
sample_5.pdf,13,958,2.3071000576019287,Helvetica,False,176.0015869140625,58.283897399902344,0.0,3,P
sample_5.pdf,13,0 975,2.3071000576019287,Helvetica,False,171.05148315429688,57.22588348388672,0.0,5,P
sample_5.pdf,13,n : 0.,2.3071000576019287,Helvetica,False,171.60426330566406,58.283897399902344,0.0,6,P
sample_5.pdf,13,n : 0,2.3071000576019287,Helvetica,False,171.60426330566406,58.283897399902344,0.0,5,P
sample_5.pdf,13,0.975,2.3071000576019287,Helvetica,False,171.05148315429688,57.22588348388672,0.0,5,P
sample_5.pdf,13,0.975,2.3071000576019287,Helvetica,False,171.05148315429688,57.22588348388672,0.0,5,P
sample_5.pdf,13,person : 0.823,2.3071000576019287,Helvetica,False,172.2350311279297,58.544822692871094,0.0,14,P
sample_5.pdf,13,on : 0.950,2.3071000576019287,Helvetica,False,171.4501495361328,71.87642669677734,0.0,10,P
sample_5.pdf,13,0 50,2.3071000576019287,Helvetica,False,175.45245361328125,71.87642669677734,0.0,4,P
sample_5.pdf,13,person : 0.805,2.3071000576019287,Helvetica,False,171.8917236328125,74.04833221435547,0.0,14,P
sample_5.pdf,13,person : 0.766,2.3071000576019287,Helvetica,False,128.80018615722656,66.1086654663086,0.0,14,P
sample_5.pdf,13,person : 0.759,2.3071000576019287,Helvetica,False,171.8917236328125,63.705589294433594,0.0,14,P
sample_5.pdf,13,.941,2.3071000576019287,Helvetica,False,128.34060668945312,58.283897399902344,0.0,4,P
sample_5.pdf,13,person : 0.673,2.3071000576019287,Helvetica,False,129.16885375976562,58.28502655029297,0.0,14,P
sample_5.pdf,13,dog : 0.996,2.3071000576019287,Helvetica,False,142.4761962890625,87.31420135498047,0.0,11,P
sample_5.pdf,13,dog : 0.691,2.3071000576019287,Helvetica,False,131.17141723632812,94.75460052490234,0.0,11,P
sample_5.pdf,13,0 939,2.3071000576019287,Helvetica,False,154.9197998046875,67.84395599365234,0.0,5,P
sample_5.pdf,13,backpack : 0.756,2.3071000576019287,Helvetica,False,154.8180389404297,66.23979949951172,0.0,16,P
sample_5.pdf,13,handbag : 0.848,2.3071000576019287,Helvetica,False,112.98272705078125,74.33672332763672,0.0,15,P
sample_5.pdf,13,Figure 6: Selected examples of object detection results on the MS COCO test-dev set using the Faster R-CNN,9.962599754333496,URWPalladioL-Roma,False,36.0,564.5805053710938,0.12264150943396226,106,H3
sample_5.pdf,13,system. The model is VGG-16 and the training data is COCO trainval (42.7% mAP@0.5 on the test-dev set).,9.962599754333496,URWPalladioL-Roma,False,36.0,576.5354614257812,0.0970873786407767,103,H3
sample_5.pdf,13,Each output box is associated with a category label and a softmax score in,9.962599754333496,URWPalladioL-Roma,False,36.0,588.491455078125,0.013513513513513514,74,H3
sample_5.pdf,13,. A score threshold of 0.6 is,9.962599754333496,URWPalladioL-Roma,False,400.50299072265625,588.491455078125,0.034482758620689655,29,H3
sample_5.pdf,13,"used to display these images. For each image, one color represents one object category in that image.",9.962599754333496,URWPalladioL-Roma,False,36.0,600.4464721679688,0.009900990099009901,101,H3
sample_5.pdf,13,"networks for large-scale image recognition,” in",7.970099925994873,URWPalladioL-Roma,False,54.259002685546875,637.740966796875,0.0,47,P
sample_5.pdf,13,International,7.970099925994873,URWPalladioL-Ital,False,228.7006072998047,637.6050415039062,0.07692307692307693,13,P
sample_5.pdf,13,Conference on Learning Representations (ICLR),7.970099925994873,URWPalladioL-Ital,False,54.259002685546875,646.5720825195312,0.15555555555555556,45,P
sample_5.pdf,13,", 2015.",7.970099925994873,URWPalladioL-Roma,False,212.3050079345703,646.7080078125,0.0,7,P
sample_5.pdf,13,[4],7.970099925994873,URWPalladioL-Roma,False,36.00001525878906,657.156982421875,0.0,3,P
sample_5.pdf,13,"J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeul-",7.970099925994873,URWPalladioL-Roma,False,54.25951385498047,657.156982421875,0.1746031746031746,63,P
sample_5.pdf,13,"ders, “Selective search for object recognition,”",7.970099925994873,URWPalladioL-Roma,False,54.25901794433594,666.1229858398438,0.020833333333333332,48,P
sample_5.pdf,13,International,7.970099925994873,URWPalladioL-Ital,False,228.07098388671875,665.987060546875,0.07692307692307693,13,P
sample_5.pdf,13,Journal of Computer Vision (IJCV),7.970099925994873,URWPalladioL-Ital,False,54.25901794433594,674.9540405273438,0.21212121212121213,33,P
sample_5.pdf,13,", 2013.",7.970099925994873,URWPalladioL-Roma,False,169.76101684570312,675.0899658203125,0.0,7,P
sample_5.pdf,13,[5],7.970099925994873,URWPalladioL-Roma,False,36.00001525878906,685.5390014648438,0.0,3,P
sample_5.pdf,13,"R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature",7.970099925994873,URWPalladioL-Roma,False,54.25951385498047,685.5390014648438,0.140625,64,P
sample_5.pdf,13,hierarchies for accurate object detection and semantic seg-,7.970099925994873,URWPalladioL-Roma,False,54.25901794433594,694.5050048828125,0.0,59,P
sample_5.pdf,13,"mentation,” in",7.970099925994873,URWPalladioL-Roma,False,54.25901794433594,703.4719848632812,0.0,14,P
sample_5.pdf,13,IEEE Conference on Computer Vision and Pattern,7.970099925994873,URWPalladioL-Ital,False,105.92118835449219,703.3360595703125,0.17391304347826086,46,P
sample_5.pdf,13,Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,54.2590217590332,712.3020629882812,0.2777777777777778,18,P
sample_5.pdf,13,", 2014.",7.970099925994873,URWPalladioL-Roma,False,122.28402709960938,712.43798828125,0.0,7,P
sample_5.pdf,13,[6],7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,722.886962890625,0.0,3,P
sample_5.pdf,13,"C. L. Zitnick and P. Doll´ar, “Edge boxes: Locating object",7.970099925994873,URWPalladioL-Roma,False,54.25952911376953,722.8670043945312,0.1206896551724138,58,P
sample_5.pdf,13,"proposals from edges,” in",7.970099925994873,URWPalladioL-Roma,False,54.259033203125,731.85400390625,0.0,25,P
sample_5.pdf,13,European Conference on Computer,7.970099925994873,URWPalladioL-Ital,False,151.59786987304688,731.7180786132812,0.0967741935483871,31,P
sample_5.pdf,13,Vision (ECCV),7.970099925994873,URWPalladioL-Ital,False,54.259033203125,740.68408203125,0.38461538461538464,13,P
sample_5.pdf,13,", 2014.",7.970099925994873,URWPalladioL-Roma,False,104.27903747558594,740.8200073242188,0.0,7,P
sample_5.pdf,13,[7],7.970099925994873,URWPalladioL-Roma,False,287.05804443359375,637.740966796875,0.0,3,P
sample_5.pdf,13,"J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional",7.970099925994873,URWPalladioL-Roma,False,305.31756591796875,637.740966796875,0.11864406779661017,59,P
sample_5.pdf,13,"networks for semantic segmentation,” in",7.970099925994873,URWPalladioL-Roma,False,305.31805419921875,646.7080078125,0.0,39,P
sample_5.pdf,13,IEEE Conference on,7.970099925994873,URWPalladioL-Ital,False,454.7178039550781,646.5720825195312,0.2777777777777778,18,P
sample_5.pdf,13,Computer Vision and Pattern Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,305.31805419921875,655.5380859375,0.17391304347826086,46,P
sample_5.pdf,13,", 2015.",7.970099925994873,URWPalladioL-Roma,False,473.7960510253906,655.6740112304688,0.0,7,P
sample_5.pdf,13,[8],7.970099925994873,URWPalladioL-Roma,False,287.05804443359375,666.1229858398438,0.0,3,P
sample_5.pdf,13,"P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ra-",7.970099925994873,URWPalladioL-Roma,False,305.31756591796875,666.1229858398438,0.18032786885245902,61,P
sample_5.pdf,13,"manan, “Object detection with discriminatively trained part-",7.970099925994873,URWPalladioL-Roma,False,305.31805419921875,675.0899658203125,0.016666666666666666,60,P
sample_5.pdf,13,"based models,”",7.970099925994873,URWPalladioL-Roma,False,305.31805419921875,684.0560302734375,0.0,14,P
sample_5.pdf,13,IEEE Transactions on Pattern Analysis and Ma-,7.970099925994873,URWPalladioL-Ital,False,360.5508728027344,683.9201049804688,0.17777777777777778,45,P
sample_5.pdf,13,chine Intelligence (TPAMI),7.970099925994873,URWPalladioL-Ital,False,305.31805419921875,692.8860473632812,0.23076923076923078,26,P
sample_5.pdf,13,", 2010.",7.970099925994873,URWPalladioL-Roma,False,395.17205810546875,693.02197265625,0.0,7,P
sample_5.pdf,13,[9],7.970099925994873,URWPalladioL-Roma,False,287.05804443359375,703.4719848632812,0.0,3,P
sample_5.pdf,13,"P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,",7.970099925994873,URWPalladioL-Roma,False,305.31756591796875,703.4719848632812,0.18181818181818182,55,P
sample_5.pdf,13,"and Y. LeCun, “Overfeat: Integrated recognition, localization",7.970099925994873,URWPalladioL-Roma,False,305.31805419921875,712.43798828125,0.08196721311475409,61,P
sample_5.pdf,13,"and detection using convolutional networks,” in",7.970099925994873,URWPalladioL-Roma,False,305.31805419921875,721.4039916992188,0.0,47,P
sample_5.pdf,13,International,7.970099925994873,URWPalladioL-Ital,False,480.65252685546875,721.26806640625,0.07692307692307693,13,P
sample_5.pdf,13,Conference on Learning Representations (ICLR),7.970099925994873,URWPalladioL-Ital,False,305.31805419921875,730.2350463867188,0.15555555555555556,45,P
sample_5.pdf,13,", 2014.",7.970099925994873,URWPalladioL-Roma,False,463.363037109375,730.3709716796875,0.0,7,P
sample_5.pdf,13,"[10] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards",7.970099925994873,URWPalladioL-Roma,False,287.05804443359375,740.8200073242188,0.208955223880597,67,P
sample_5.pdf,14,"real-time object detection with region proposal networks,” in",7.970099925994873,URWPalladioL-Roma,False,54.259002685546875,59.37499237060547,0.0,61,P
sample_5.pdf,14,Neural Information Processing Systems (NIPS),7.970099925994873,URWPalladioL-Ital,False,54.259002685546875,68.20606994628906,0.18181818181818182,44,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,211.1009979248047,68.34197235107422,0.0,7,P
sample_5.pdf,14,"[11] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and",7.970099925994873,URWPalladioL-Roma,False,36.0,77.66698455810547,0.171875,64,P
sample_5.pdf,14,"A. Zisserman, “The PASCAL Visual Object Classes Challenge",7.970099925994873,URWPalladioL-Roma,False,54.259002685546875,86.63298797607422,0.22807017543859648,57,P
sample_5.pdf,14,"2007 (VOC2007) Results,” 2007.",7.970099925994873,URWPalladioL-Roma,False,54.259002685546875,95.59996795654297,0.13333333333333333,30,P
sample_5.pdf,14,"[12] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra-",7.970099925994873,URWPalladioL-Roma,False,36.0,104.92498016357422,0.2,65,P
sample_5.pdf,14,"manan, P. Doll´ar, and C. L. Zitnick, “Microsoft COCO: Com-",7.970099925994873,URWPalladioL-Roma,False,54.259002685546875,113.87096405029297,0.1864406779661017,59,P
sample_5.pdf,14,"mon Objects in Context,” in",7.970099925994873,URWPalladioL-Roma,False,54.25899887084961,122.85698699951172,0.07407407407407407,27,P
sample_5.pdf,14,European Conference on Computer,7.970099925994873,URWPalladioL-Ital,False,156.1726531982422,122.72108459472656,0.0967741935483871,31,P
sample_5.pdf,14,Vision (ECCV),7.970099925994873,URWPalladioL-Ital,False,54.259002685546875,131.6880645751953,0.38461538461538464,13,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,104.27900695800781,131.82395935058594,0.0,7,P
sample_5.pdf,14,"[13] S. Song and J. Xiao, “Deep sliding shapes for amodal 3d object",7.970099925994873,URWPalladioL-Roma,False,36.00000762939453,141.1489715576172,0.07462686567164178,67,P
sample_5.pdf,14,"detection in rgb-d images,”",7.970099925994873,URWPalladioL-Roma,False,54.259010314941406,150.11497497558594,0.0,27,P
sample_5.pdf,14,arXiv:1511.02300,7.970099925994873,URWPalladioL-Ital,False,152.45062255859375,149.9790802001953,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,213.68402099609375,150.11497497558594,0.0,7,P
sample_5.pdf,14,"[14] J. Zhu, X. Chen, and A. L. Yuille, “DeePM: A deep part-based",7.970099925994873,URWPalladioL-Roma,False,36.00001525878906,159.4399871826172,0.16923076923076924,65,P
sample_5.pdf,14,"model for object detection and semantic part localization,”",7.970099925994873,URWPalladioL-Roma,False,54.25901794433594,168.40696716308594,0.0,59,P
sample_5.pdf,14,arXiv:1511.07131,7.970099925994873,URWPalladioL-Ital,False,54.25901794433594,177.23707580566406,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,112.70401763916016,177.3729705810547,0.0,7,P
sample_5.pdf,14,"[15] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmenta-",7.970099925994873,URWPalladioL-Roma,False,36.00001525878906,186.69798278808594,0.10606060606060606,66,P
sample_5.pdf,14,"tion via multi-task network cascades,”",7.970099925994873,URWPalladioL-Roma,False,54.25901794433594,195.6639862060547,0.0,38,P
sample_5.pdf,14,arXiv:1512.04412,7.970099925994873,URWPalladioL-Ital,False,191.55990600585938,195.52809143066406,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,252.59002685546875,195.6639862060547,0.0,7,P
sample_5.pdf,14,"[16] J. Johnson, A. Karpathy, and L. Fei-Fei, “Densecap: Fully",7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,204.98899841308594,0.14516129032258066,62,P
sample_5.pdf,14,"convolutional localization networks for dense captioning,”",7.970099925994873,URWPalladioL-Roma,False,54.259033203125,213.9559783935547,0.0,58,P
sample_5.pdf,14,arXiv:1511.07571,7.970099925994873,URWPalladioL-Ital,False,54.259033203125,222.7860870361328,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,112.70403289794922,222.92198181152344,0.0,7,P
sample_5.pdf,14,"[17] D. Kislyuk, Y. Liu, D. Liu, E. Tzeng, and Y. Jing, “Human cu-",7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,232.2469940185547,0.16666666666666666,66,P
sample_5.pdf,14,ration and convnets: Powering item-to-item recommendations,7.970099925994873,URWPalladioL-Roma,False,54.259033203125,241.21299743652344,0.017241379310344827,58,P
sample_5.pdf,14,"on pinterest,”",7.970099925994873,URWPalladioL-Roma,False,54.259033203125,250.1799774169922,0.0,14,P
sample_5.pdf,14,arXiv:1511.04003,7.970099925994873,URWPalladioL-Ital,False,102.98025512695312,250.04408264160156,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,164.2140350341797,250.1799774169922,0.0,7,P
sample_5.pdf,14,"[18] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning",7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,259.5050048828125,0.13846153846153847,65,P
sample_5.pdf,14,"for image recognition,”",7.970099925994873,URWPalladioL-Roma,False,54.259033203125,268.47100830078125,0.0,23,P
sample_5.pdf,14,arXiv:1512.03385,7.970099925994873,URWPalladioL-Ital,False,137.5704803466797,268.3350830078125,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,198.8040313720703,268.47100830078125,0.0,7,P
sample_5.pdf,14,"[19] J. Hosang, R. Benenson, and B. Schiele, “How good are de-",7.970099925994873,URWPalladioL-Roma,False,36.000030517578125,277.7960205078125,0.11290322580645161,62,P
sample_5.pdf,14,"tection proposals, really?” in",7.970099925994873,URWPalladioL-Roma,False,54.259033203125,286.7630310058594,0.0,30,P
sample_5.pdf,14,British Machine Vision Conference,7.970099925994873,URWPalladioL-Ital,False,157.3921661376953,286.6271057128906,0.12121212121212122,33,P
sample_5.pdf,14,(BMVC),7.970099925994873,URWPalladioL-Ital,False,54.259033203125,295.5931091308594,0.6666666666666666,6,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,83.03103637695312,295.7290344238281,0.0,7,P
sample_5.pdf,14,"[20] J. Hosang, R. Benenson, P. Doll´ar, and B. Schiele, “What makes",7.970099925994873,URWPalladioL-Roma,False,36.000038146972656,305.0340576171875,0.1323529411764706,68,P
sample_5.pdf,14,for effective detection proposals?”,7.970099925994873,URWPalladioL-Roma,False,54.25904846191406,314.0200500488281,0.0,35,P
sample_5.pdf,14,IEEE Transactions on Pattern,7.970099925994873,URWPalladioL-Ital,False,175.3726806640625,313.8841247558594,0.21428571428571427,28,P
sample_5.pdf,14,Analysis and Machine Intelligence (TPAMI),7.970099925994873,URWPalladioL-Ital,False,54.25904846191406,322.85113525390625,0.1951219512195122,41,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,201.05105590820312,322.987060546875,0.0,7,P
sample_5.pdf,14,[21] N.,7.970099925994873,URWPalladioL-Roma,False,36.00006103515625,332.31207275390625,0.14285714285714285,7,P
sample_5.pdf,14,"Chavali,",7.970099925994873,URWPalladioL-Roma,False,69.3389892578125,332.31207275390625,0.125,8,P
sample_5.pdf,14,"Agrawal,",7.970099925994873,URWPalladioL-Roma,False,120.28385925292969,332.31207275390625,0.125,8,P
sample_5.pdf,14,"Mahendru,",7.970099925994873,URWPalladioL-Roma,False,174.10594177246094,332.31207275390625,0.1111111111111111,9,P
sample_5.pdf,14,and,7.970099925994873,URWPalladioL-Roma,False,219.9419708251953,332.31207275390625,0.0,3,P
sample_5.pdf,14,"Batra,",7.970099925994873,URWPalladioL-Roma,False,254.5242156982422,332.31207275390625,0.16666666666666666,6,P
sample_5.pdf,14,"“Object-Proposal Evaluation Protocol is ’Gameable’,”",7.970099925994873,URWPalladioL-Roma,False,54.259063720703125,341.278076171875,0.09615384615384616,52,P
sample_5.pdf,14,arXiv:,7.970099925994873,URWPalladioL-Ital,False,250.33944702148438,341.14215087890625,0.16666666666666666,6,P
sample_5.pdf,14,1505.05836,7.970099925994873,URWPalladioL-Ital,False,54.259063720703125,350.1091613769531,0.0,10,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,92.1170654296875,350.2450866699219,0.0,7,P
sample_5.pdf,14,"[22] J. Carreira and C. Sminchisescu, “CPMC: Automatic ob-",7.970099925994873,URWPalladioL-Roma,False,36.000064849853516,359.5700988769531,0.15517241379310345,58,P
sample_5.pdf,14,"ject segmentation using constrained parametric min-cuts,”",7.970099925994873,URWPalladioL-Roma,False,54.259063720703125,368.5361022949219,0.0,57,P
sample_5.pdf,14,IEEE Transactions on Pattern Analysis and Machine Intelligence,7.970099925994873,URWPalladioL-Ital,False,54.259063720703125,377.3661804199219,0.14516129032258066,62,P
sample_5.pdf,14,(TPAMI),7.970099925994873,URWPalladioL-Ital,False,54.259063720703125,386.33319091796875,0.7142857142857143,7,P
sample_5.pdf,14,", 2012.",7.970099925994873,URWPalladioL-Roma,False,84.2110595703125,386.4691162109375,0.0,7,P
sample_5.pdf,14,"[23] P. Arbel´aez, J. Pont-Tuset, J. T. Barron, F. Marques, and J. Malik,",7.970099925994873,URWPalladioL-Roma,False,36.00006103515625,395.7741394042969,0.1643835616438356,73,P
sample_5.pdf,14,"“Multiscale combinatorial grouping,” in",7.970099925994873,URWPalladioL-Roma,False,54.259063720703125,404.7601318359375,0.02564102564102564,39,P
sample_5.pdf,14,IEEE Conference on,7.970099925994873,URWPalladioL-Ital,False,202.0087890625,404.62420654296875,0.2777777777777778,18,P
sample_5.pdf,14,Computer Vision and Pattern Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,54.259063720703125,413.5912170410156,0.17391304347826086,46,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,222.73806762695312,413.7271423339844,0.0,7,P
sample_5.pdf,14,"[24] B. Alexe, T. Deselaers, and V. Ferrari, “Measuring the object-",7.970099925994873,URWPalladioL-Roma,False,36.00006103515625,423.0521545410156,0.1044776119402985,67,P
sample_5.pdf,14,"ness of image windows,”",7.970099925994873,URWPalladioL-Roma,False,54.259063720703125,432.0181579589844,0.0,23,P
sample_5.pdf,14,IEEE Transactions on Pattern Analysis,7.970099925994873,URWPalladioL-Ital,False,144.17771911621094,431.8822326660156,0.1891891891891892,37,P
sample_5.pdf,14,and Machine Intelligence (TPAMI),7.970099925994873,URWPalladioL-Ital,False,54.259063720703125,440.8482360839844,0.21875,32,P
sample_5.pdf,14,", 2012.",7.970099925994873,URWPalladioL-Roma,False,169.92007446289062,440.9841613769531,0.0,7,P
sample_5.pdf,14,"[25] C. Szegedy, A. Toshev, and D. Erhan, “Deep neural networks",7.970099925994873,URWPalladioL-Roma,False,36.00007629394531,450.3091735839844,0.1111111111111111,63,P
sample_5.pdf,14,"for object detection,” in",7.970099925994873,URWPalladioL-Roma,False,54.25907897949219,459.27618408203125,0.0,25,P
sample_5.pdf,14,Neural Information Processing Systems,7.970099925994873,URWPalladioL-Ital,False,140.08111572265625,459.1402587890625,0.10810810810810811,37,P
sample_5.pdf,14,(NIPS),7.970099925994873,URWPalladioL-Ital,False,54.25908660888672,468.10626220703125,0.6666666666666666,6,P
sample_5.pdf,14,", 2013.",7.970099925994873,URWPalladioL-Roma,False,77.72308349609375,468.2421875,0.0,7,P
sample_5.pdf,14,"[26] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov, “Scalable",7.970099925994873,URWPalladioL-Roma,False,36.000083923339844,477.56719970703125,0.140625,64,P
sample_5.pdf,14,"object detection using deep neural networks,” in",7.970099925994873,URWPalladioL-Roma,False,54.25908660888672,486.533203125,0.0,48,P
sample_5.pdf,14,IEEE Confer-,7.970099925994873,URWPalladioL-Ital,False,228.3419952392578,486.39727783203125,0.4166666666666667,12,P
sample_5.pdf,14,ence on Computer Vision and Pattern Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,54.25907897949219,495.3642883300781,0.14814814814814814,54,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,250.1630859375,495.5002136230469,0.0,7,P
sample_5.pdf,14,"[27] C. Szegedy, S. Reed, D. Erhan, and D. Anguelov, “Scalable,",7.970099925994873,URWPalladioL-Roma,False,36.000091552734375,504.8252258300781,0.14285714285714285,63,P
sample_5.pdf,14,"high-quality object detection,”",7.970099925994873,URWPalladioL-Roma,False,54.25909423828125,513.791259765625,0.0,31,P
sample_5.pdf,14,arXiv:1412.1441 (v1),7.970099925994873,URWPalladioL-Ital,False,162.548828125,513.6553344726562,0.05,20,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,235.86509704589844,513.791259765625,0.0,7,P
sample_5.pdf,14,"[28] P. O. Pinheiro, R. Collobert, and P. Dollar, “Learning to",7.970099925994873,URWPalladioL-Roma,False,36.000091552734375,523.1162109375,0.12903225806451613,62,P
sample_5.pdf,14,"segment object candidates,” in",7.970099925994873,URWPalladioL-Roma,False,54.25909423828125,532.083251953125,0.0,30,P
sample_5.pdf,14,Neural Information Processing,7.970099925994873,URWPalladioL-Ital,False,167.474365234375,531.9473266601562,0.10344827586206896,29,P
sample_5.pdf,14,Systems (NIPS),7.970099925994873,URWPalladioL-Ital,False,54.25909423828125,540.9132690429688,0.35714285714285715,14,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,107.08509826660156,541.0491943359375,0.0,7,P
sample_5.pdf,14,"[29] J. Dai, K. He, and J. Sun, “Convolutional feature masking",7.970099925994873,URWPalladioL-Roma,False,36.000099182128906,550.3742065429688,0.11290322580645161,62,P
sample_5.pdf,14,"for joint object and stuff segmentation,” in",7.970099925994873,URWPalladioL-Roma,False,54.25910186767578,559.3402099609375,0.0,44,P
sample_5.pdf,14,IEEE Conference on,7.970099925994873,URWPalladioL-Ital,False,206.5437469482422,559.2042846679688,0.2777777777777778,18,P
sample_5.pdf,14,Computer Vision and Pattern Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,54.25909423828125,568.1713256835938,0.17391304347826086,46,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,222.73809814453125,568.3072509765625,0.0,7,P
sample_5.pdf,14,"[30] S. Ren, K. He, R. Girshick, X. Zhang, and J. Sun, “Ob-",7.970099925994873,URWPalladioL-Roma,False,36.000091552734375,577.6322021484375,0.1864406779661017,59,P
sample_5.pdf,14,"ject detection networks on convolutional feature maps,”",7.970099925994873,URWPalladioL-Roma,False,54.25909423828125,586.5982055664062,0.0,55,P
sample_5.pdf,14,arXiv:1504.06066,7.970099925994873,URWPalladioL-Ital,False,54.25909423828125,595.4292602539062,0.0625,16,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,112.70409393310547,595.565185546875,0.0,7,P
sample_5.pdf,14,"[31] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and",7.970099925994873,URWPalladioL-Roma,False,36.000091552734375,604.8901977539062,0.15517241379310345,58,P
sample_5.pdf,14,"Y. Bengio, “Attention-based models for speech recognition,”",7.970099925994873,URWPalladioL-Roma,False,54.25909423828125,613.856201171875,0.05084745762711865,59,P
sample_5.pdf,14,Neural Information Processing Systems (NIPS),7.970099925994873,URWPalladioL-Ital,False,61.21699142456055,622.686279296875,0.18181818181818182,44,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,220.84909057617188,622.8222045898438,0.0,7,P
sample_5.pdf,14,"[32] M. D. Zeiler and R. Fergus, “Visualizing and understanding",7.970099925994873,URWPalladioL-Roma,False,36.000091552734375,632.147216796875,0.09523809523809523,63,P
sample_5.pdf,14,"convolutional neural networks,” in",7.970099925994873,URWPalladioL-Roma,False,54.25909423828125,641.1141967773438,0.0,34,P
sample_5.pdf,14,European Conference on,7.970099925994873,URWPalladioL-Ital,False,186.24392700195312,640.978271484375,0.09090909090909091,22,P
sample_5.pdf,14,Computer Vision (ECCV),7.970099925994873,URWPalladioL-Ital,False,54.25909423828125,649.9442749023438,0.2727272727272727,22,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,139.3950958251953,650.0802001953125,0.0,7,P
sample_5.pdf,14,"[33] V. Nair and G. E. Hinton, “Rectiﬁed linear units improve",7.970099925994873,URWPalladioL-Roma,False,36.000099182128906,659.4052124023438,0.09836065573770492,61,P
sample_5.pdf,14,"restricted boltzmann machines,” in",7.970099925994873,URWPalladioL-Roma,False,54.25910186767578,668.3721923828125,0.0,34,P
sample_5.pdf,14,International Conference on,7.970099925994873,URWPalladioL-Ital,False,180.40185546875,668.2362670898438,0.07407407407407407,27,P
sample_5.pdf,14,Machine Learning (ICML),7.970099925994873,URWPalladioL-Ital,False,54.25910949707031,677.2022705078125,0.2608695652173913,23,P
sample_5.pdf,14,", 2010.",7.970099925994873,URWPalladioL-Roma,False,142.3441162109375,677.3381958007812,0.0,7,P
sample_5.pdf,14,"[34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,",7.970099925994873,URWPalladioL-Roma,False,36.00011444091797,686.6632080078125,0.1791044776119403,67,P
sample_5.pdf,14,"D. Erhan, and A. Rabinovich, “Going deeper with convo-",7.970099925994873,URWPalladioL-Roma,False,54.259117126464844,695.6292114257812,0.09259259259259259,54,P
sample_5.pdf,14,"lutions,” in",7.970099925994873,URWPalladioL-Roma,False,54.259117126464844,704.59619140625,0.0,12,P
sample_5.pdf,14,IEEE Conference on Computer Vision and Pattern,7.970099925994873,URWPalladioL-Ital,False,95.79927062988281,704.4602661132812,0.17391304347826086,46,P
sample_5.pdf,14,Recognition (CVPR),7.970099925994873,URWPalladioL-Ital,False,54.25911331176758,713.42626953125,0.2777777777777778,18,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,122.28311157226562,713.5621948242188,0.0,7,P
sample_5.pdf,14,"[35] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,",7.970099925994873,URWPalladioL-Roma,False,36.00011444091797,722.88720703125,0.19696969696969696,66,P
sample_5.pdf,14,"W. Hubbard, and L. D. Jackel, “Backpropagation applied to",7.970099925994873,URWPalladioL-Roma,False,54.259117126464844,731.8532104492188,0.10526315789473684,57,P
sample_5.pdf,14,"handwritten zip code recognition,”",7.970099925994873,URWPalladioL-Roma,False,54.259117126464844,740.8201904296875,0.0,34,P
sample_5.pdf,14,Neural computation,7.970099925994873,URWPalladioL-Ital,False,180.18667602539062,740.6842651367188,0.05555555555555555,18,P
sample_5.pdf,14,", 1989.",7.970099925994873,URWPalladioL-Roma,False,248.78411865234375,740.8201904296875,0.0,7,P
sample_5.pdf,14,"[36] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,",7.970099925994873,URWPalladioL-Roma,False,287.05810546875,59.37517547607422,0.1791044776119403,67,P
sample_5.pdf,14,"Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg,",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,68.34215545654297,0.1864406779661017,59,P
sample_5.pdf,14,"and L. Fei-Fei, “ImageNet Large Scale Visual Recognition",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,77.30815887451172,0.16071428571428573,56,P
sample_5.pdf,14,"Challenge,” in",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,86.27416229248047,0.07142857142857142,14,P
sample_5.pdf,14,International Journal of Computer Vision (IJCV),7.970099925994873,URWPalladioL-Ital,False,357.2194519042969,86.13825988769531,0.1702127659574468,47,P
sample_5.pdf,14,2015.,7.970099925994873,URWPalladioL-Roma,False,305.318115234375,95.24114227294922,0.0,5,P
sample_5.pdf,14,"[37] A. Krizhevsky, I. Sutskever, and G. Hinton, “Imagenet classi-",7.970099925994873,URWPalladioL-Roma,False,287.05810546875,104.20714569091797,0.10606060606060606,66,P
sample_5.pdf,14,"ﬁcation with deep convolutional neural networks,” in",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,113.17314910888672,0.0,52,P
sample_5.pdf,14,Neural,7.970099925994873,URWPalladioL-Ital,False,500.5539245605469,113.03724670410156,0.16666666666666666,6,P
sample_5.pdf,14,Information Processing Systems (NIPS),7.970099925994873,URWPalladioL-Ital,False,305.318115234375,122.00422668457031,0.1891891891891892,37,P
sample_5.pdf,14,", 2012.",7.970099925994873,URWPalladioL-Roma,False,436.7831115722656,122.14012908935547,0.0,7,P
sample_5.pdf,14,"[38] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-",7.970099925994873,URWPalladioL-Roma,False,287.05810546875,131.1061248779297,0.1791044776119403,67,P
sample_5.pdf,14,"shick, S. Guadarrama, and T. Darrell, “Caffe: Convolutional",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,140.07310485839844,0.1016949152542373,59,P
sample_5.pdf,14,"architecture for fast feature embedding,”",7.970099925994873,URWPalladioL-Roma,False,305.318115234375,149.0391082763672,0.0,41,P
sample_5.pdf,14,arXiv:1408.5093,7.970099925994873,URWPalladioL-Ital,False,448.062744140625,148.90321350097656,0.06666666666666667,15,P
sample_5.pdf,14,", 2014.",7.970099925994873,URWPalladioL-Roma,False,504.37811279296875,149.0391082763672,0.0,7,P
sample_5.pdf,14,"[39] K. Lenc and A. Vedaldi, “R-CNN minus R,” in",7.970099925994873,URWPalladioL-Roma,False,287.05810546875,158.00511169433594,0.1875,48,P
sample_5.pdf,14,British Machine,7.970099925994873,URWPalladioL-Ital,False,471.1833190917969,157.8692169189453,0.13333333333333333,15,P
sample_5.pdf,14,Vision Conference (BMVC),7.970099925994873,URWPalladioL-Ital,False,305.318115234375,166.83619689941406,0.25,24,P
sample_5.pdf,14,", 2015.",7.970099925994873,URWPalladioL-Roma,False,395.76910400390625,166.9720916748047,0.0,7,P
sample_6.pdf,1,Auto-Encoding Variational Bayes,17.21540069580078,NimbusRomNo9L-Medi,False,183.44400024414062,109.69583892822266,0.12903225806451613,31,TITLE
sample_6.pdf,1,Diederik P. Kingma,9.962599754333496,NimbusRomNo9L-Medi,False,174.18499755859375,171.031494140625,0.16666666666666666,18,H3
sample_6.pdf,1,Machine Learning Group,9.962599754333496,NimbusRomNo9L-Regu,False,164.2429962158203,182.08143615722656,0.13636363636363635,22,H3
sample_6.pdf,1,Universiteit van Amsterdam,9.962599754333496,NimbusRomNo9L-Regu,False,158.7480010986328,193.03944396972656,0.07692307692307693,26,H3
sample_6.pdf,1,dpkingma@gmail.com,9.962599754333496,NimbusMonL-Regu,False,161.07400512695312,203.48837280273438,0.0,18,H3
sample_6.pdf,1,Max Welling,9.962599754333496,NimbusRomNo9L-Medi,False,363.27398681640625,171.031494140625,0.18181818181818182,11,H3
sample_6.pdf,1,Machine Learning Group,9.962599754333496,NimbusRomNo9L-Regu,False,339.85699462890625,182.08143615722656,0.13636363636363635,22,H3
sample_6.pdf,1,Universiteit van Amsterdam,9.962599754333496,NimbusRomNo9L-Regu,False,334.3630065917969,193.03944396972656,0.07692307692307693,26,H3
sample_6.pdf,1,welling.max@gmail.com,9.962599754333496,NimbusMonL-Regu,False,327.7220153808594,203.48837280273438,0.0,21,H3
sample_6.pdf,1,Abstract,11.9552001953125,NimbusRomNo9L-Medi,False,283.7580261230469,243.6251220703125,0.125,8,H3
sample_6.pdf,1,How can we perform efﬁcient inference and learning in directed probabilistic,9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,268.564453125,0.013157894736842105,76,H3
sample_6.pdf,1,"models, in the presence of continuous latent variables with intractable posterior",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,279.5234375,0.0,81,H3
sample_6.pdf,1,"distributions, and large datasets? We introduce a stochastic variational inference",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,290.482421875,0.012195121951219513,82,H3
sample_6.pdf,1,"and learning algorithm that scales to large datasets and, under some mild differ-",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,301.44140625,0.0,81,H3
sample_6.pdf,1,"entiability conditions, even works in the intractable case. Our contributions are",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,312.400390625,0.012345679012345678,81,H3
sample_6.pdf,1,"two-fold. First, we show that a reparameterization of the variational lower bound",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,323.359375,0.012345679012345678,81,H3
sample_6.pdf,1,yields a lower bound estimator that can be straightforwardly optimized using stan-,9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,334.318359375,0.0,82,H3
sample_6.pdf,1,"dard stochastic gradient methods. Second, we show that for i.i.d. datasets with",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,345.27734375,0.012658227848101266,79,H3
sample_6.pdf,1,"continuous latent variables per datapoint, posterior inference can be made espe-",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,356.236328125,0.0,80,H3
sample_6.pdf,1,cially efﬁcient by ﬁtting an approximate inference model (also called a recogni-,9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,367.1953125,0.0,80,H3
sample_6.pdf,1,tion model) to the intractable posterior using the proposed lower bound estimator.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,378.1533203125,0.0,82,H3
sample_6.pdf,1,Theoretical advantages are reﬂected in experimental results.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,389.1123046875,0.016666666666666666,60,H3
sample_6.pdf,1,Introduction,11.9552001953125,NimbusRomNo9L-Medi,False,125.93281555175781,420.2229919433594,0.08333333333333333,12,H3
sample_6.pdf,1,How can we perform efﬁcient approximate inference and learning with directed probabilistic models,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,445.2023010253906,0.010309278350515464,97,H3
sample_6.pdf,1,whose continuous latent variables and/or parameters have intractable posterior distributions? The,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,456.16131591796875,0.010309278350515464,97,H3
sample_6.pdf,1,variational Bayesian (VB) approach involves the optimization of an approximation to the intractable,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,467.12030029296875,0.030303030303030304,99,H3
sample_6.pdf,1,"posterior. Unfortunately, the common mean-ﬁeld approach requires analytical solutions of expecta-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,478.07928466796875,0.010309278350515464,97,H3
sample_6.pdf,1,"tions w.r.t. the approximate posterior, which are also intractable in the general case. We show how a",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,489.03826904296875,0.009900990099009901,101,H3
sample_6.pdf,1,reparameterization of the variational lower bound yields a simple differentiable unbiased estimator,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,499.99627685546875,0.0,99,H3
sample_6.pdf,1,of the lower bound; this SGVB (Stochastic Gradient Variational Bayes) estimator can be used for ef-,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,510.95526123046875,0.08080808080808081,99,H3
sample_6.pdf,1,ﬁcient approximate posterior inference in almost any model with continuous latent variables and/or,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,521.9142456054688,0.0,98,H3
sample_6.pdf,1,"parameters, and is straightforward to optimize using standard stochastic gradient ascent techniques.",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,532.8732299804688,0.0,100,H3
sample_6.pdf,1,"For the case of an i.i.d. dataset and continuous latent variables per datapoint, we propose the Auto-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,549.8102416992188,0.019801980198019802,101,H3
sample_6.pdf,1,Encoding VB (AEVB) algorithm. In the AEVB algorithm we make inference and learning especially,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,560.7692260742188,0.12903225806451613,93,H3
sample_6.pdf,1,efﬁcient by using the SGVB estimator to optimize a recognition model that allows us to perform very,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,571.7272338867188,0.04040404040404041,99,H3
sample_6.pdf,1,"efﬁcient approximate posterior inference using simple ancestral sampling, which in turn allows us",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,582.6862182617188,0.0,97,H3
sample_6.pdf,1,"to efﬁciently learn the model parameters, without the need of expensive iterative inference schemes",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,593.645263671875,0.0,99,H3
sample_6.pdf,1,(such as MCMC) per datapoint. The learned approximate posterior inference model can also be used,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,604.604248046875,0.052083333333333336,96,H3
sample_6.pdf,1,"for a host of tasks such as recognition, denoising, representation and visualization purposes. When",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,615.563232421875,0.010101010101010102,99,H3
sample_6.pdf,1,"a neural network is used for the recognition model, we arrive at the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,626.522216796875,0.0,68,H3
sample_6.pdf,1,variational auto-encoder,9.962599754333496,NimbusRomNo9L-ReguItal,False,375.0474853515625,626.3457641601562,0.0,24,H3
sample_6.pdf,1,Method,11.9552001953125,NimbusRomNo9L-Medi,False,125.93276977539062,653.4909057617188,0.16666666666666666,6,H3
sample_6.pdf,1,The strategy in this section can be used to derive a lower bound estimator (a stochastic objective,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,678.47021484375,0.01020408163265306,98,H3
sample_6.pdf,1,function) for a variety of directed graphical models with continuous latent variables. We will restrict,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,689.4292602539062,0.009708737864077669,103,H3
sample_6.pdf,1,"ourselves here to the common case where we have an i.i.d. dataset with latent variables per datapoint,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,700.3882446289062,0.0,102,H3
sample_6.pdf,1,and where we like to perform maximum likelihood (ML) or maximum a posteriori (MAP) inference,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,711.3472290039062,0.05434782608695652,92,H3
sample_6.pdf,1,"on the (global) parameters, and variational inference on the latent variables. It is, for example,",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,722.3062133789062,0.01020408163265306,98,H3
sample_6.pdf,1,arXiv:1312.6114v11  [stat.ML]  10 Dec 2022,20.0,Times-Roman,False,10.940000534057617,205.5999755859375,0.09523809523809523,42,TITLE
sample_6.pdf,2,Figure 1: The type of directed graphical model under consideration. Solid lines denote the generative,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,184.86048889160156,0.0297029702970297,101,H3
sample_6.pdf,2,model,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,195.81947326660156,0.0,5,H3
sample_6.pdf,2,", dashed lines denote the variational approximation",9.962599754333496,NimbusRomNo9L-Regu,False,190.76296997070312,195.81947326660156,0.0,51,H3
sample_6.pdf,2,to the intractable,9.962599754333496,NimbusRomNo9L-Regu,False,432.79644775390625,195.81947326660156,0.0,18,H3
sample_6.pdf,2,posterior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,206.77845764160156,0.0,9,H3
sample_6.pdf,2,. The variational parameters,9.962599754333496,NimbusRomNo9L-Regu,False,178.27398681640625,206.77845764160156,0.03571428571428571,28,H3
sample_6.pdf,2,are learned jointly with the generative model pa-,9.962599754333496,NimbusRomNo9L-Regu,False,303.4043273925781,206.77845764160156,0.0,49,H3
sample_6.pdf,2,rameters,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,217.73744201660156,0.0,8,H3
sample_6.pdf,2,straightforward to extend this scenario to the case where we also perform variational inference on,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,252.78944396972656,0.0,98,H3
sample_6.pdf,2,"the global parameters; that algorithm is put in the appendix, but experiments with that case are left to",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,263.7484130859375,0.0,104,H3
sample_6.pdf,2,"future work. Note that our method can be applied to online, non-stationary settings, e.g. streaming",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,274.7073974609375,0.010101010101010102,99,H3
sample_6.pdf,2,"data, but here we assume a ﬁxed dataset for simplicity.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,285.6663818359375,0.0,55,H3
sample_6.pdf,2,2.1,9.962599754333496,NimbusRomNo9L-Medi,False,107.99998474121094,312.6934509277344,0.0,3,H3
sample_6.pdf,2,Problem scenario,9.962599754333496,NimbusRomNo9L-Medi,False,130.41583251953125,312.6934509277344,0.0625,16,H3
sample_6.pdf,2,Let us consider some dataset,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,334.1513977050781,0.03571428571428571,28,H3
sample_6.pdf,2,consisting of,9.962599754333496,NimbusRomNo9L-Regu,False,297.03997802734375,334.15142822265625,0.0,13,H3
sample_6.pdf,2,i.i.d. samples of some continuous,9.962599754333496,NimbusRomNo9L-Regu,False,360.51190185546875,334.15142822265625,0.0,33,H3
sample_6.pdf,2,or discrete variable,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,345.11041259765625,0.0,20,H3
sample_6.pdf,2,". We assume that the data are generated by some random process, involving",9.962599754333496,NimbusRomNo9L-Regu,False,194.38397216796875,345.11041259765625,0.0136986301369863,73,H3
sample_6.pdf,2,an unobserved continuous random variable,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,357.1094055175781,0.0,40,H3
sample_6.pdf,2,. The process consists of two steps: (1) a value,9.962599754333496,NimbusRomNo9L-Regu,False,290.5950012207031,357.1094055175781,0.020833333333333332,48,H3
sample_6.pdf,2,is generated from some prior distribution,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,369.1084289550781,0.0,41,H3
sample_6.pdf,2,; (2) a value,9.962599754333496,NimbusRomNo9L-Regu,False,306.26202392578125,369.1083984375,0.0,13,H3
sample_6.pdf,2,is generated from some condi-,9.962599754333496,NimbusRomNo9L-Regu,False,379.2910461425781,369.1083984375,0.0,29,H3
sample_6.pdf,2,tional distribution,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,380.0673828125,0.0,19,H3
sample_6.pdf,2,. We assume that the prior,9.962599754333496,NimbusRomNo9L-Regu,False,218.5240478515625,380.0673522949219,0.038461538461538464,26,H3
sample_6.pdf,2,and likelihood,9.962599754333496,NimbusRomNo9L-Regu,False,357.10150146484375,380.06732177734375,0.0,14,H3
sample_6.pdf,2,come from,9.962599754333496,NimbusRomNo9L-Regu,False,456.93646240234375,380.0672912597656,0.0,9,H3
sample_6.pdf,2,parametric families of distributions,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,391.02630615234375,0.0,36,H3
sample_6.pdf,2,and,9.962599754333496,NimbusRomNo9L-Regu,False,272.7034606933594,391.02630615234375,0.0,3,H3
sample_6.pdf,2,", and that their PDFs are differentiable almost",9.962599754333496,NimbusRomNo9L-Regu,False,323.4840087890625,391.02630615234375,0.06382978723404255,47,H3
sample_6.pdf,2,everywhere w.r.t. both,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,401.98529052734375,0.0,22,H3
sample_6.pdf,2,and,9.962599754333496,NimbusRomNo9L-Regu,False,204.5590057373047,401.98529052734375,0.0,3,H3
sample_6.pdf,2,". Unfortunately, a lot of this process is hidden from our view: the true",9.962599754333496,NimbusRomNo9L-Regu,False,228.95101928710938,401.98529052734375,0.013888888888888888,72,H3
sample_6.pdf,2,parameters,9.962599754333496,NimbusRomNo9L-Regu,False,108.0000228881836,413.9842834472656,0.0,10,H3
sample_6.pdf,2,as well as the values of the latent variables,9.962599754333496,NimbusRomNo9L-Regu,False,167.1820068359375,413.9842834472656,0.0,45,H3
sample_6.pdf,2,are unknown to us.,9.962599754333496,NimbusRomNo9L-Regu,False,356.1809997558594,413.9842834472656,0.0,18,H3
sample_6.pdf,2,"Very importantly, we",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,430.9202880859375,0.05,20,H3
sample_6.pdf,2,do not,9.962599754333496,NimbusRomNo9L-ReguItal,False,191.86517333984375,430.74383544921875,0.0,6,H3
sample_6.pdf,2,make the common simplifying assumptions about the marginal or pos-,9.962599754333496,NimbusRomNo9L-Regu,False,219.6432342529297,430.9202880859375,0.0,66,H3
sample_6.pdf,2,"terior probabilities. Conversely, we are here interested in a general algorithm that even works efﬁ-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,441.8792724609375,0.01,100,H3
sample_6.pdf,2,ciently in the case of:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,452.8382568359375,0.0,23,H3
sample_6.pdf,2,Intractability,9.962599754333496,NimbusRomNo9L-ReguItal,False,138.88392639160156,474.52178955078125,0.07142857142857142,14,H3
sample_6.pdf,2,the case where the integral of the marginal likelihood,9.962599754333496,NimbusRomNo9L-Regu,False,210.37515258789062,474.6982421875,0.0,54,H3
sample_6.pdf,2,is intractable (so we cannot evaluate or differentiate the marginal like-,9.962599754333496,NimbusRomNo9L-Regu,False,218.88482666015625,485.6572570800781,0.0,73,H3
sample_6.pdf,2,"lihood), where the true posterior density",9.962599754333496,NimbusRomNo9L-Regu,False,143.8649444580078,496.61627197265625,0.0,41,H3
sample_6.pdf,2,) =,9.962599754333496,CMR10,False,342.1849670410156,496.3857421875,0.0,3,H3
sample_6.pdf,2,is intractable,9.962599754333496,NimbusRomNo9L-Regu,False,447.7704162597656,496.61627197265625,0.0,14,H3
sample_6.pdf,2,"(so the EM algorithm cannot be used), and where the required integrals for any reason-",9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,507.57525634765625,0.023255813953488372,86,H3
sample_6.pdf,2,able mean-ﬁeld VB algorithm are also intractable. These intractabilities are quite common,9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,518.5342407226562,0.033707865168539325,89,H3
sample_6.pdf,2,and appear in cases of moderately complicated likelihood functions,9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,529.4932250976562,0.0,66,H3
sample_6.pdf,2,", e.g. a neural",9.962599754333496,NimbusRomNo9L-Regu,False,448.7239685058594,529.4932250976562,0.0,15,H3
sample_6.pdf,2,network with a nonlinear hidden layer.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,540.4512329101562,0.0,38,H3
sample_6.pdf,2,A large dataset,9.962599754333496,NimbusRomNo9L-ReguItal,False,138.88389587402344,557.0957641601562,0.06666666666666667,15,H3
sample_6.pdf,2,: we have so much data that batch optimization is too costly; we would like,9.962599754333496,NimbusRomNo9L-Regu,False,204.39495849609375,557.272216796875,0.0,75,H3
sample_6.pdf,2,to make parameter updates using small minibatches or even single datapoints. Sampling-,9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,568.231201171875,0.011627906976744186,86,H3
sample_6.pdf,2,"based solutions, e.g. Monte Carlo EM, would in general be too slow, since it involves a",9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,579.1902465820312,0.04597701149425287,87,H3
sample_6.pdf,2,typically expensive sampling loop per datapoint.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,590.1492309570312,0.0,48,H3
sample_6.pdf,2,"We are interested in, and propose a solution to, three related problems in the above scenario:",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,612.0092163085938,0.010638297872340425,94,H3
sample_6.pdf,2,1. Efﬁcient approximate ML or MAP estimation for the parameters,9.962599754333496,NimbusRomNo9L-Regu,False,131.41195678710938,633.8692626953125,0.09523809523809523,63,H3
sample_6.pdf,2,. The parameters can be,9.962599754333496,NimbusRomNo9L-Regu,False,408.8929443359375,633.8692626953125,0.043478260869565216,23,H3
sample_6.pdf,2,"of interest themselves, e.g. if we are analyzing some natural process. They also allow us to",9.962599754333496,NimbusRomNo9L-Regu,False,143.86492919921875,644.8282470703125,0.010869565217391304,92,H3
sample_6.pdf,2,mimic the hidden random process and generate artiﬁcial data that resembles the real data.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86492919921875,655.7872314453125,0.0,89,H3
sample_6.pdf,2,2. Efﬁcient approximate posterior inference of the latent variable,9.962599754333496,NimbusRomNo9L-Regu,False,131.41192626953125,672.6082153320312,0.015151515151515152,66,H3
sample_6.pdf,2,given an observed value,9.962599754333496,NimbusRomNo9L-Regu,False,398.1578063964844,672.6082153320312,0.0,23,H3
sample_6.pdf,2,for a choice of parameters,9.962599754333496,NimbusRomNo9L-Regu,False,143.86492919921875,683.5672607421875,0.0,26,H3
sample_6.pdf,2,. This is useful for coding or data representation tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,256.2799377441406,683.5672607421875,0.017543859649122806,57,H3
sample_6.pdf,2,3. Efﬁcient approximate marginal inference of the variable,9.962599754333496,NimbusRomNo9L-Regu,False,131.4119415283203,700.3882446289062,0.017241379310344827,58,H3
sample_6.pdf,2,. This allows us to perform all,9.962599754333496,NimbusRomNo9L-Regu,False,379.5599365234375,700.3882446289062,0.03225806451612903,31,H3
sample_6.pdf,2,kinds of inference tasks where a prior over,9.962599754333496,NimbusRomNo9L-Regu,False,143.86492919921875,711.3472290039062,0.0,43,H3
sample_6.pdf,2,is required. Common applications in computer,9.962599754333496,NimbusRomNo9L-Regu,False,318.2032470703125,711.3472290039062,0.022727272727272728,44,H3
sample_6.pdf,2,"vision include image denoising, inpainting and super-resolution.",9.962599754333496,NimbusRomNo9L-Regu,False,143.86495971679688,722.3062133789062,0.0,64,H3
sample_6.pdf,3,"For the purpose of solving the above problems, let us introduce a recognition model",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.012048192771084338,83,H3
sample_6.pdf,3,: an,9.962599754333496,NimbusRomNo9L-Regu,False,487.22900390625,84.26844787597656,0.0,4,H3
sample_6.pdf,3,approximation to the intractable true posterior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,95.22743225097656,0.0,47,H3
sample_6.pdf,3,. Note that in contrast with the approximate,9.962599754333496,NimbusRomNo9L-Regu,False,327.5159912109375,95.22743225097656,0.022727272727272728,44,H3
sample_6.pdf,3,"posterior in mean-ﬁeld variational inference, it is not necessarily factorial and its parameters",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,106.18641662597656,0.0,96,H3
sample_6.pdf,3,are,9.962599754333496,NimbusRomNo9L-Regu,False,489.04132080078125,106.18641662597656,0.0,3,H3
sample_6.pdf,3,"not computed from some closed-form expectation. Instead, we’ll introduce a method for learning",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,117.14540100097656,0.010638297872340425,94,H3
sample_6.pdf,3,the recognition model parameters,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,128.10438537597656,0.0,32,H3
sample_6.pdf,3,jointly with the generative model parameters,9.962599754333496,NimbusRomNo9L-Regu,False,251.23133850097656,128.10438537597656,0.0,44,H3
sample_6.pdf,3,"From a coding theory perspective, the unobserved variables",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,145.0403594970703,0.017241379310344827,58,H3
sample_6.pdf,3,have an interpretation as a latent,9.962599754333496,NimbusRomNo9L-Regu,False,364.264892578125,145.0403594970703,0.0,34,H3
sample_6.pdf,3,representation or,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,155.9993438720703,0.0,17,H3
sample_6.pdf,3,code,9.962599754333496,NimbusRomNo9L-ReguItal,False,175.63612365722656,155.8228759765625,0.0,4,H3
sample_6.pdf,3,. In this paper we will therefore also refer to the recognition model,9.962599754333496,NimbusRomNo9L-Regu,False,197.33604431152344,155.9993438720703,0.014492753623188406,69,H3
sample_6.pdf,3,as a probabilistic,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,166.9583282470703,0.0,18,H3
sample_6.pdf,3,encoder,9.962599754333496,NimbusRomNo9L-ReguItal,False,177.54896545410156,166.7818603515625,0.0,7,H3
sample_6.pdf,3,", since given a datapoint",9.962599754333496,NimbusRomNo9L-Regu,False,213.14303588867188,166.9583282470703,0.0,25,H3
sample_6.pdf,3,it produces a distribution (e.g. a Gaussian),9.962599754333496,NimbusRomNo9L-Regu,False,323.183349609375,166.9583282470703,0.022727272727272728,44,H3
sample_6.pdf,3,over the possible values of the code,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,177.9173126220703,0.0,36,H3
sample_6.pdf,3,from which the datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,259.4869384765625,177.9173126220703,0.0,24,H3
sample_6.pdf,3,could have been generated. In a,9.962599754333496,NimbusRomNo9L-Regu,False,372.557373046875,177.9173126220703,0.03225806451612903,31,H3
sample_6.pdf,3,similar vein we will refer to,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,188.8762969970703,0.0,29,H3
sample_6.pdf,3,as a probabilistic,9.962599754333496,NimbusRomNo9L-Regu,False,255.53952026367188,188.8762969970703,0.0,18,H3
sample_6.pdf,3,decoder,9.962599754333496,NimbusRomNo9L-ReguItal,False,326.7704772949219,188.6998291015625,0.0,7,H3
sample_6.pdf,3,", since given a code",9.962599754333496,NimbusRomNo9L-Regu,False,361.7560729980469,188.8762969970703,0.0,20,H3
sample_6.pdf,3,it produces a,9.962599754333496,NimbusRomNo9L-Regu,False,449.3759460449219,188.8762969970703,0.0,13,H3
sample_6.pdf,3,distribution over the possible corresponding values of,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,199.8352813720703,0.0,54,H3
sample_6.pdf,3,2.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.00006103515625,224.1103515625,0.0,3,H3
sample_6.pdf,3,The variational bound,9.962599754333496,NimbusRomNo9L-Medi,False,130.41590881347656,224.1103515625,0.047619047619047616,21,H3
sample_6.pdf,3,The marginal likelihood is composed of a sum over the marginal likelihoods of individual datapoints,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,244.7243194580078,0.010101010101010102,99,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,108.00006103515625,257.4217529296875,0.0,3,H3
sample_6.pdf,3,(1),6.973800182342529,CMR7,False,142.59207153320312,256.142578125,0.0,3,P
sample_6.pdf,3,) =,9.962599754333496,CMR10,False,196.91806030273438,257.4217529296875,0.0,3,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,239.65606689453125,257.4217529296875,0.0,3,H3
sample_6.pdf,3,", which can each be rewritten as:",9.962599754333496,NimbusRomNo9L-Regu,False,287.6670837402344,257.65228271484375,0.0,33,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,184.10809326171875,274.1707458496094,0.0,3,H3
sample_6.pdf,3,) =,9.962599754333496,CMR10,False,228.24407958984375,274.1707763671875,0.0,3,H3
sample_6.pdf,3,)) +,9.962599754333496,CMR10,False,355.38909912109375,274.1707763671875,0.0,4,H3
sample_6.pdf,3,(1),9.962599754333496,NimbusRomNo9L-Regu,False,492.38409423828125,274.40130615234375,0.0,3,H3
sample_6.pdf,3,The ﬁrst RHS term is the KL divergence of the approximate from the true posterior. Since this,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,288.779296875,0.07526881720430108,93,H3
sample_6.pdf,3,"KL-divergence is non-negative, the second RHS term",9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,300.7782897949219,0.1,50,H3
sample_6.pdf,3,is called the (variational),9.962599754333496,NimbusRomNo9L-Regu,False,376.64556884765625,300.7782897949219,0.0,27,H3
sample_6.pdf,3,lower,9.962599754333496,NimbusRomNo9L-ReguItal,False,478.69171142578125,300.6018371582031,0.0,5,H3
sample_6.pdf,3,bound,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0001220703125,311.56085205078125,0.0,5,H3
sample_6.pdf,3,on the marginal likelihood of datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,132.9066162109375,311.7373046875,0.0,39,H3
sample_6.pdf,3,", and can be written as:",9.962599754333496,NimbusRomNo9L-Regu,False,297.1041259765625,311.7373046875,0.0,24,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,164.01512145996094,327.42376708984375,0.0,3,H3
sample_6.pdf,3,) =,9.962599754333496,CMR10,False,274.0121154785156,327.42376708984375,0.0,3,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,338.3531188964844,327.42376708984375,0.0,3,H3
sample_6.pdf,3,) + log,9.962599754333496,CMR10,False,381.18011474609375,327.42376708984375,0.0,7,H3
sample_6.pdf,3,(2),9.962599754333496,NimbusRomNo9L-Regu,False,492.38409423828125,327.654296875,0.0,3,H3
sample_6.pdf,3,which can also be written as:,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,342.03228759765625,0.0,29,H3
sample_6.pdf,3,) =,9.962599754333496,CMR10,False,207.70306396484375,357.81475830078125,0.0,3,H3
sample_6.pdf,3,)) +,9.962599754333496,CMR10,False,324.2380676269531,357.81475830078125,0.0,4,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,392.42706298828125,357.8147277832031,0.0,3,H3
sample_6.pdf,3,(3),9.962599754333496,NimbusRomNo9L-Regu,False,492.38409423828125,358.0452575683594,0.0,3,H3
sample_6.pdf,3,We want to differentiate and optimize the lower bound,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,377.7822570800781,0.018867924528301886,53,H3
sample_6.pdf,3,w.r.t. both the variational,9.962599754333496,NimbusRomNo9L-Regu,False,393.0825500488281,377.7822570800781,0.0,27,H3
sample_6.pdf,3,parameters,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,388.74127197265625,0.0,10,H3
sample_6.pdf,3,and generative parameters,9.962599754333496,NimbusRomNo9L-Regu,False,162.63043212890625,388.74127197265625,0.0,25,H3
sample_6.pdf,3,". However, the gradient of the lower bound w.r.t.",9.962599754333496,NimbusRomNo9L-Regu,False,283.01409912109375,388.74127197265625,0.02040816326530612,49,H3
sample_6.pdf,3,is a bit problematic. The usual (na¨ıve) Monte Carlo gradient estimator for this type of problem,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,399.6502685546875,0.03125,96,H3
sample_6.pdf,3,is:,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,412.6282653808594,0.0,3,H3
sample_6.pdf,3,)] =,9.962599754333496,CMR10,False,180.91812133789062,412.3977355957031,0.0,4,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,279.9304504394531,412.39776611328125,0.0,3,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,429.7590026855469,412.39788818359375,0.0,3,H3
sample_6.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,476.93145751953125,412.62841796875,0.0,5,H3
sample_6.pdf,3,. This gradient estimator exhibits exhibits very high variance (see e.g. [BJP12]),9.962599754333496,NimbusRomNo9L-Regu,False,178.81300354003906,426.7964172363281,0.04938271604938271,81,H3
sample_6.pdf,3,and is impractical for our purposes.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,437.75543212890625,0.0,36,H3
sample_6.pdf,3,2.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,462.031494140625,0.0,3,H3
sample_6.pdf,3,The SGVB estimator and AEVB algorithm,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,462.031494140625,0.24324324324324326,37,H3
sample_6.pdf,3,In this section we introduce a practical estimator of the lower bound and its derivatives w.r.t. the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,482.64544677734375,0.01,100,H3
sample_6.pdf,3,parameters. We assume an approximate posterior in the form,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,493.60345458984375,0.017241379310344827,58,H3
sample_6.pdf,3,", but please note that the",9.962599754333496,NimbusRomNo9L-Regu,False,400.3450012207031,493.60345458984375,0.0,26,H3
sample_6.pdf,3,technique can be applied to the case,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,504.56243896484375,0.0,36,H3
sample_6.pdf,3,", i.e. where we do not condition on",9.962599754333496,NimbusRomNo9L-Regu,False,278.36602783203125,504.56243896484375,0.0,35,H3
sample_6.pdf,3,", as well. The fully",9.962599754333496,NimbusRomNo9L-Regu,False,427.61700439453125,504.56243896484375,0.05,20,H3
sample_6.pdf,3,variational Bayesian method for inferring a posterior over the parameters is given in the appendix.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,515.5214233398438,0.010101010101010102,99,H3
sample_6.pdf,3,Under certain mild conditions outlined in section 2.4 for a chosen approximate posterior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,532.4584350585938,0.011363636363636364,88,H3
sample_6.pdf,3,can reparameterize the random variable,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,543.4174194335938,0.0,38,H3
sample_6.pdf,3,using a differentiable transformation,9.962599754333496,NimbusRomNo9L-Regu,False,319.1844787597656,543.4174194335938,0.0,37,H3
sample_6.pdf,3,of an (auxiliary) noise variable,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,554.3764038085938,0.0,32,H3
sample_6.pdf,3,with,9.962599754333496,NimbusRomNo9L-Regu,False,304.1781005859375,568.75439453125,0.0,4,H3
sample_6.pdf,3,(4),9.962599754333496,NimbusRomNo9L-Regu,False,492.38409423828125,568.75439453125,0.0,3,H3
sample_6.pdf,3,See section 2.4 for general strategies for chosing such an approriate distribution,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,583.1334228515625,0.012195121951219513,82,H3
sample_6.pdf,3,and function,9.962599754333496,NimbusRomNo9L-Regu,False,450.560546875,583.1334228515625,0.0,12,H3
sample_6.pdf,3,. We can now form Monte Carlo estimates of expectations of some function,9.962599754333496,NimbusRomNo9L-Regu,False,141.86109924316406,594.0924072265625,0.041666666666666664,72,H3
sample_6.pdf,3,w.r.t.,9.962599754333496,NimbusRomNo9L-Regu,False,480.892578125,594.0924072265625,0.0,6,H3
sample_6.pdf,3,as follows:,9.962599754333496,NimbusRomNo9L-Regu,False,140.173583984375,605.0513916015625,0.0,11,H3
sample_6.pdf,3,)] =,9.962599754333496,CMR10,False,176.98414611816406,630.3018798828125,0.0,4,H3
sample_6.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,402.8900146484375,630.532470703125,0.0,5,H3
sample_6.pdf,3,(5),9.962599754333496,NimbusRomNo9L-Regu,False,484.6434631347656,630.532470703125,0.0,3,H3
sample_6.pdf,3,"We apply this technique to the variational lower bound (eq. (2)), yielding our generic Stochastic",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,654.7224731445312,0.020618556701030927,97,H3
sample_6.pdf,3,Gradient Variational Bayes (SGVB) estimator,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,667.5884399414062,0.16279069767441862,43,H3
sample_6.pdf,3,) =,9.962599754333496,CMR10,False,233.88201904296875,692.4799194335938,0.0,3,H3
sample_6.pdf,3,log,9.962599754333496,CMR10,False,277.9219970703125,692.4799194335938,0.0,3,H3
sample_6.pdf,3,"i,l",6.973800182342529,CMMI7,False,334.6910095214844,690.7017211914062,0.0,3,P
sample_6.pdf,3,log,9.962599754333496,CMR10,False,362.0980224609375,692.4799194335938,0.0,3,H3
sample_6.pdf,3,"i,l",6.973800182342529,CMMI7,False,399.22503662109375,690.7017211914062,0.0,3,P
sample_6.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,181.40301513671875,719.0184326171875,0.0,5,H3
sample_6.pdf,3,"i,l",6.973800182342529,CMMI7,False,226.40000915527344,717.0107421875,0.0,3,P
sample_6.pdf,3,"i,l",6.973800182342529,CMMI7,False,273.6650085449219,717.0107421875,0.0,3,P
sample_6.pdf,3,and,9.962599754333496,NimbusRomNo9L-Regu,False,318.8760070800781,719.0184326171875,0.0,3,H3
sample_6.pdf,3,(6),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,719.0184326171875,0.0,3,H3
sample_6.pdf,4,Algorithm 1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,83.86949920654297,0.09090909090909091,11,H3
sample_6.pdf,4,Minibatch version of the Auto-Encoding VB (AEVB) algorithm. Either of the two,9.962599754333496,NimbusRomNo9L-Regu,False,160.63241577148438,83.96046447753906,0.12987012987012986,77,H3
sample_6.pdf,4,SGVB estimators in section 2.3 can be used. We use settings,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,94.91847229003906,0.0847457627118644,59,H3
sample_6.pdf,4,= 100,9.962599754333496,CMR10,False,362.3537292480469,94.68791198730469,0.0,5,H3
sample_6.pdf,4,and,9.962599754333496,NimbusRomNo9L-Regu,False,391.6723937988281,94.91847229003906,0.0,3,H3
sample_6.pdf,4,= 1,9.962599754333496,CMR10,False,417.820556640625,94.68791198730469,0.0,3,H3
sample_6.pdf,4,in experiments.,9.962599754333496,NimbusRomNo9L-Regu,False,436.0848083496094,94.91847229003906,0.0,15,H3
sample_6.pdf,4,Initialize parameters,9.962599754333496,NimbusRomNo9L-Regu,False,150.625,110.37049865722656,0.047619047619047616,21,H3
sample_6.pdf,4,repeat,9.962599754333496,NimbusRomNo9L-Medi,False,117.96299743652344,121.23851776123047,0.0,6,H3
sample_6.pdf,4,Random minibatch of,9.962599754333496,NimbusRomNo9L-Regu,False,165.6320037841797,132.28846740722656,0.05263157894736842,19,H3
sample_6.pdf,4,datapoints (drawn from full dataset),9.962599754333496,NimbusRomNo9L-Regu,False,264.6797180175781,132.28846740722656,0.0,36,H3
sample_6.pdf,4,Random samples from noise distribution,9.962599754333496,NimbusRomNo9L-Regu,False,152.94200134277344,143.24745178222656,0.02631578947368421,38,H3
sample_6.pdf,4,(Gradients of minibatch estimator (8)),9.962599754333496,NimbusRomNo9L-Regu,False,247.74440002441406,156.4474639892578,0.02631578947368421,38,H3
sample_6.pdf,4,Update parameters using gradients,9.962599754333496,NimbusRomNo9L-Regu,False,165.56893920898438,167.4064483642578,0.030303030303030304,33,H3
sample_6.pdf,4,(e.g. SGD or Adagrad [DHS10]),9.962599754333496,NimbusRomNo9L-Regu,False,311.8484191894531,167.4064483642578,0.2413793103448276,29,H3
sample_6.pdf,4,until,9.962599754333496,NimbusRomNo9L-Medi,False,117.96292114257812,178.27447509765625,0.0,5,H3
sample_6.pdf,4,convergence of parameters,9.962599754333496,NimbusRomNo9L-Regu,False,137.89810180664062,178.3654327392578,0.0,25,H3
sample_6.pdf,4,return,9.962599754333496,NimbusRomNo9L-Medi,False,117.96292114257812,189.23345947265625,0.0,6,H3
sample_6.pdf,4,"Often, the KL-divergence",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,222.34547424316406,0.125,24,H3
sample_6.pdf,4,of eq. (3) can be integrated analytically (see,9.962599754333496,NimbusRomNo9L-Regu,False,316.22894287109375,222.34547424316406,0.0,46,H3
sample_6.pdf,4,"appendix B), such that only the expected reconstruction error",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,235.03846740722656,0.01639344262295082,61,H3
sample_6.pdf,4,log,9.962599754333496,CMR10,False,408.6399841308594,234.8079071044922,0.0,3,H3
sample_6.pdf,4,requires,9.962599754333496,NimbusRomNo9L-Regu,False,471.9109802246094,235.03846740722656,0.0,8,H3
sample_6.pdf,4,estimation by sampling. The KL-divergence term can then be interpreted as regularizing,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,247.2794952392578,0.03488372093023256,86,H3
sample_6.pdf,4,", encour-",9.962599754333496,NimbusRomNo9L-Regu,False,468.83197021484375,247.2794952392578,0.0,9,H3
sample_6.pdf,4,aging the approximate posterior to be close to the prior,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,258.23846435546875,0.0,56,H3
sample_6.pdf,4,. This yields a second version of the,9.962599754333496,NimbusRomNo9L-Regu,False,356.48797607421875,258.23846435546875,0.02702702702702703,37,H3
sample_6.pdf,4,SGVB estimator,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,271.4384765625,0.2857142857142857,14,H3
sample_6.pdf,4,", corresponding to eq. (3), which typically has less",9.962599754333496,NimbusRomNo9L-Regu,False,302.21893310546875,271.4384765625,0.0,52,H3
sample_6.pdf,4,variance than the generic estimator:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,282.3974609375,0.0,36,H3
sample_6.pdf,4,) =,9.962599754333496,CMR10,False,213.64590454101562,306.5249328613281,0.0,3,H3
sample_6.pdf,4,)) +,9.962599754333496,CMR10,False,330.180908203125,306.5249328613281,0.0,4,H3
sample_6.pdf,4,(log,9.962599754333496,CMR10,False,375.3289794921875,306.5249328613281,0.0,4,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,434.31201171875,304.74774169921875,0.0,3,P
sample_6.pdf,4,where,9.962599754333496,NimbusRomNo9L-Regu,False,161.1669921875,333.0634765625,0.0,5,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,206.1639862060547,331.0557556152344,0.0,3,P
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,253.42898559570312,331.0557556152344,0.0,3,P
sample_6.pdf,4,and,9.962599754333496,NimbusRomNo9L-Regu,False,298.6399841308594,333.0634765625,0.0,3,H3
sample_6.pdf,4,(7),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,333.0634765625,0.0,3,H3
sample_6.pdf,4,Given multiple datapoints from a dataset,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,347.0124816894531,0.025,40,H3
sample_6.pdf,4,with,9.962599754333496,NimbusRomNo9L-Regu,False,280.6984558105469,347.0124816894531,0.0,4,H3
sample_6.pdf,4,"datapoints, we can construct an estimator of the",9.962599754333496,NimbusRomNo9L-Regu,False,311.2468566894531,347.0124816894531,0.0,48,H3
sample_6.pdf,4,"marginal likelihood lower bound of the full dataset, based on minibatches:",9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,357.97149658203125,0.0,74,H3
sample_6.pdf,4,) =,9.962599754333496,CMR10,False,314.6539001464844,382.0999755859375,0.0,3,H3
sample_6.pdf,4,(8),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,382.3304748535156,0.0,3,H3
sample_6.pdf,4,where the minibatch,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,407.9134826660156,0.0,19,H3
sample_6.pdf,4,is a randomly drawn sample of,9.962599754333496,NimbusRomNo9L-Regu,False,275.01995849609375,407.91351318359375,0.0,29,H3
sample_6.pdf,4,datapoints from the,9.962599754333496,NimbusRomNo9L-Regu,False,418.6796875,407.91351318359375,0.0,19,H3
sample_6.pdf,4,full dataset,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,418.87152099609375,0.0,12,H3
sample_6.pdf,4,with,9.962599754333496,NimbusRomNo9L-Regu,False,165.96646118164062,418.87152099609375,0.0,4,H3
sample_6.pdf,4,datapoints. In our experiments we found that the number of samples,9.962599754333496,NimbusRomNo9L-Regu,False,199.49989318847656,418.87152099609375,0.015151515151515152,66,H3
sample_6.pdf,4,per datapoint can be set to,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,429.83050537109375,0.0,27,H3
sample_6.pdf,4,as long as the minibatch size,9.962599754333496,NimbusRomNo9L-Regu,False,224.37725830078125,429.83050537109375,0.0,29,H3
sample_6.pdf,4,"was large enough, e.g.",9.962599754333496,NimbusRomNo9L-Regu,False,358.6647033691406,429.83050537109375,0.0,22,H3
sample_6.pdf,4,= 100,9.962599754333496,CMR10,False,469.3567199707031,429.5999755859375,0.0,5,H3
sample_6.pdf,4,Derivatives,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,442.697509765625,0.09090909090909091,11,H3
sample_6.pdf,4,"can be taken, and the resulting gradients can be used in conjunction",9.962599754333496,NimbusRomNo9L-Regu,False,220.3654327392578,442.697509765625,0.0,68,H3
sample_6.pdf,4,with stochastic optimization methods such as SGD or Adagrad [DHS10]. See algorithm 1 for a,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,453.656494140625,0.08888888888888889,90,H3
sample_6.pdf,4,basic approach to compute the stochastic gradients.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,464.615478515625,0.0,51,H3
sample_6.pdf,4,A connection with auto-encoders becomes clear when looking at the objective function given at,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,481.5514831542969,0.010752688172043012,93,H3
sample_6.pdf,4,eq. (7). The ﬁrst term is (the KL divergence of the approximate posterior from the prior) acts as a,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,492.510498046875,0.030303030303030304,99,H3
sample_6.pdf,4,"regularizer, while the second term is a an expected negative reconstruction error. The function",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,503.469482421875,0.010526315789473684,95,H3
sample_6.pdf,4,is chosen such that it maps a datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,516.1624755859375,0.0,39,H3
sample_6.pdf,4,and a random noise vector,9.962599754333496,NimbusRomNo9L-Regu,False,289.3809814453125,516.1624755859375,0.0,25,H3
sample_6.pdf,4,to a sample from the,9.962599754333496,NimbusRomNo9L-Regu,False,418.63800048828125,516.1624755859375,0.0,20,H3
sample_6.pdf,4,approximate posterior for that datapoint:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,528.1604614257812,0.0,41,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,283.88702392578125,526.6507568359375,0.0,3,P
sample_6.pdf,4,where,9.962599754333496,NimbusRomNo9L-Regu,False,363.0694885253906,528.1604614257812,0.0,5,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,401.5940246582031,526.6507568359375,0.0,3,P
sample_6.pdf,4,. Subse-,9.962599754333496,NimbusRomNo9L-Regu,False,469.802001953125,528.1604614257812,0.125,8,H3
sample_6.pdf,4,"quently, the sample",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,540.8534545898438,0.0,19,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,197.77000427246094,539.3427124023438,0.0,3,P
sample_6.pdf,4,is then input to function,9.962599754333496,NimbusRomNo9L-Regu,False,212.2220001220703,540.8534545898438,0.0,25,H3
sample_6.pdf,4,log,9.962599754333496,CMR10,False,309.8454284667969,540.6229248046875,0.0,3,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,368.0450134277344,539.3427124023438,0.0,3,P
sample_6.pdf,4,", which equals the probability",9.962599754333496,NimbusRomNo9L-Regu,False,383.2760009765625,540.8534545898438,0.0,30,H3
sample_6.pdf,4,density (or mass) of datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,553.1854248046875,0.0,30,H3
sample_6.pdf,4,"under the generative model, given",9.962599754333496,NimbusRomNo9L-Regu,False,248.7379913330078,553.1854248046875,0.0,33,H3
sample_6.pdf,4,"i,l",6.973800182342529,CMMI7,False,395.52301025390625,551.6757202148438,0.0,3,P
sample_6.pdf,4,. This term is a negative,9.962599754333496,NimbusRomNo9L-Regu,False,406.8789978027344,553.1854248046875,0.04,25,H3
sample_6.pdf,4,reconstruction error,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0,563.968017578125,0.0,20,H3
sample_6.pdf,4,in auto-encoder parlance.,9.962599754333496,NimbusRomNo9L-Regu,False,188.81663513183594,564.1444702148438,0.0,25,H3
sample_6.pdf,4,2.4,9.962599754333496,NimbusRomNo9L-Medi,False,108.00000762939453,588.342529296875,0.0,3,H3
sample_6.pdf,4,The reparameterization trick,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,588.342529296875,0.03571428571428571,28,H3
sample_6.pdf,4,In order to solve our problem we invoked an alternative method for generating samples from,9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,608.9564208984375,0.011111111111111112,90,H3
sample_6.pdf,4,. The essential parameterization trick is quite simple. Let,9.962599754333496,NimbusRomNo9L-Regu,False,140.1730194091797,619.9154663085938,0.03389830508474576,59,H3
sample_6.pdf,4,be a continuous random vari-,9.962599754333496,NimbusRomNo9L-Regu,False,382.2998962402344,619.9154663085938,0.0,28,H3
sample_6.pdf,4,"able, and",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,630.8744506835938,0.0,9,H3
sample_6.pdf,4,be some conditional distribution. It is then often possible to express the,9.962599754333496,NimbusRomNo9L-Regu,False,203.07247924804688,630.8744506835938,0.013513513513513514,74,H3
sample_6.pdf,4,random variable,9.962599754333496,NimbusRomNo9L-Regu,False,108.0000228881836,641.8334350585938,0.0,15,H3
sample_6.pdf,4,as a deterministic variable,9.962599754333496,NimbusRomNo9L-Regu,False,181.71591186523438,641.8334350585938,0.0,27,H3
sample_6.pdf,4,", where",9.962599754333496,NimbusRomNo9L-Regu,False,348.944091796875,641.8334350585938,0.0,7,H3
sample_6.pdf,4,is an auxiliary variable with,9.962599754333496,NimbusRomNo9L-Regu,False,387.10504150390625,641.8334350585938,0.0,29,H3
sample_6.pdf,4,independent marginal,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,652.79248046875,0.0,20,H3
sample_6.pdf,4,", and",9.962599754333496,NimbusRomNo9L-Regu,False,214.49208068847656,652.79248046875,0.0,5,H3
sample_6.pdf,4,is some vector-valued function parameterized by,9.962599754333496,NimbusRomNo9L-Regu,False,257.68951416015625,652.79248046875,0.0,47,H3
sample_6.pdf,4,This reparameterization is useful for our case since it can be used to rewrite an expectation w.r.t,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,669.7294311523438,0.010101010101010102,99,H3
sample_6.pdf,4,such that the Monte Carlo estimate of the expectation is differentiable w.r.t.,9.962599754333496,NimbusRomNo9L-Regu,False,140.17352294921875,680.6874389648438,0.02564102564102564,78,H3
sample_6.pdf,4,. A proof,9.962599754333496,NimbusRomNo9L-Regu,False,464.1470642089844,680.6874389648438,0.1111111111111111,9,H3
sample_6.pdf,4,is as follows. Given the deterministic mapping,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,691.6464233398438,0.021739130434782608,46,H3
sample_6.pdf,4,we know that,9.962599754333496,NimbusRomNo9L-Regu,False,365.7215576171875,691.6464233398438,0.0,12,H3
sample_6.pdf,4,. Therefore,9.962599754333496,NimbusRomNo9L-Regu,False,154.17005920410156,704.00341796875,0.09090909090909091,11,H3
sample_6.pdf,4,. It follows,9.962599754333496,NimbusRomNo9L-Regu,False,456.8791198730469,704.00341796875,0.08333333333333333,12,H3
sample_6.pdf,4,Note that for inﬁnitesimals we use the notational convention,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.016666666666666666,60,P
sample_6.pdf,5,that a differentiable estimator can be constructed:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.0,51,H3
sample_6.pdf,5,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,97.54646301269531,0.0,5,H3
sample_6.pdf,5,. In section 2.3 we applied this trick to obtain a differentiable estimator of the,9.962599754333496,NimbusRomNo9L-Regu,False,183.3380126953125,97.54646301269531,0.012195121951219513,82,H3
sample_6.pdf,5,variational lower bound.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,108.50544738769531,0.0,24,H3
sample_6.pdf,5,"Take, for example, the univariate Gaussian case: let",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,125.44142150878906,0.038461538461538464,52,H3
sample_6.pdf,5,) =,9.962599754333496,CMR10,False,361.9510498046875,125.21086120605469,0.0,3,H3
sample_6.pdf,5,". In this case, a valid",9.962599754333496,NimbusRomNo9L-Regu,False,418.9980163574219,125.44142150878906,0.043478260869565216,23,H3
sample_6.pdf,5,reparameterization is,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,136.40040588378906,0.0,21,H3
sample_6.pdf,5,", where",9.962599754333496,NimbusRomNo9L-Regu,False,244.66603088378906,136.40040588378906,0.0,7,H3
sample_6.pdf,5,is an auxiliary noise variable,9.962599754333496,NimbusRomNo9L-Regu,False,281.6868591308594,136.40040588378906,0.0,30,H3
sample_6.pdf,5,". Therefore,",9.962599754333496,NimbusRomNo9L-Regu,False,455.1040344238281,136.40040588378906,0.08333333333333333,12,H3
sample_6.pdf,5,)] =,9.962599754333496,CMR10,False,170.57601928710938,149.43186950683594,0.0,4,H3
sample_6.pdf,5,where,9.962599754333496,NimbusRomNo9L-Regu,False,375.87347412109375,149.66249084472656,0.0,5,H3
sample_6.pdf,5,For which,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,167.6504669189453,0.1111111111111111,9,H3
sample_6.pdf,5,can we choose such a differentiable transformation,9.962599754333496,NimbusRomNo9L-Regu,False,183.58547973632812,167.6504669189453,0.0,50,H3
sample_6.pdf,5,and auxiliary variable,9.962599754333496,NimbusRomNo9L-Regu,False,414.2965087890625,167.6504669189453,0.0,22,H3
sample_6.pdf,5,? Three basic approaches are:,9.962599754333496,NimbusRomNo9L-Regu,False,143.67503356933594,178.6094512939453,0.034482758620689655,29,H3
sample_6.pdf,5,"1. Tractable inverse CDF. In this case, let",9.962599754333496,NimbusRomNo9L-Regu,False,131.4120330810547,198.40345764160156,0.11627906976744186,43,H3
sample_6.pdf,5,", and let",9.962599754333496,NimbusRomNo9L-Regu,False,346.87603759765625,198.40345764160156,0.0,9,H3
sample_6.pdf,5,be the inverse CDF of,9.962599754333496,NimbusRomNo9L-Regu,False,414.697509765625,198.40345764160156,0.14285714285714285,21,H3
sample_6.pdf,5,". Examples: Exponential, Cauchy, Logistic, Rayleigh, Pareto, Weibull, Reciprocal,",9.962599754333496,NimbusRomNo9L-Regu,False,176.0380401611328,209.36244201660156,0.09876543209876543,81,H3
sample_6.pdf,5,"Gompertz, Gumbel and Erlang distributions.",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,220.32142639160156,0.07142857142857142,42,H3
sample_6.pdf,5,"2. Analogous to the Gaussian example, for any ”location-scale” family of distributions we can",9.962599754333496,NimbusRomNo9L-Regu,False,131.4120330810547,234.70240783691406,0.021505376344086023,93,H3
sample_6.pdf,5,choose the standard distribution (with location,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,245.66139221191406,0.0,47,H3
sample_6.pdf,5,= 0,9.962599754333496,CMR10,False,332.40716552734375,245.4308319091797,0.0,3,H3
sample_6.pdf,5,", scale",9.962599754333496,NimbusRomNo9L-Regu,False,353.3510437011719,245.66139221191406,0.0,7,H3
sample_6.pdf,5,= 1,9.962599754333496,CMR10,False,379.1542053222656,245.4308319091797,0.0,3,H3
sample_6.pdf,5,) as the auxiliary variable,9.962599754333496,NimbusRomNo9L-Regu,False,400.0960388183594,245.66139221191406,0.0,27,H3
sample_6.pdf,5,", and let",9.962599754333496,NimbusRomNo9L-Regu,False,148.68104553222656,256.619384765625,0.0,9,H3
sample_6.pdf,5,) =,9.962599754333496,CMR10,False,195.51304626464844,256.38885498046875,0.0,3,H3
sample_6.pdf,5,location,9.962599754333496,NimbusRomNo9L-Regu,False,210.3473663330078,256.619384765625,0.0,8,H3
sample_6.pdf,5,scale,9.962599754333496,NimbusRomNo9L-Regu,False,255.7889404296875,256.619384765625,0.0,5,H3
sample_6.pdf,5,". Examples: Laplace, Elliptical, Student’s t, Logistic,",9.962599754333496,NimbusRomNo9L-Regu,False,290.4530334472656,256.619384765625,0.09090909090909091,55,H3
sample_6.pdf,5,"Uniform, Triangular and Gaussian distributions.",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,267.578369140625,0.06382978723404255,47,H3
sample_6.pdf,5,3. Composition: It is often possible to express random variables as different transformations,9.962599754333496,NimbusRomNo9L-Regu,False,131.4120330810547,281.9593811035156,0.021505376344086023,93,H3
sample_6.pdf,5,of auxiliary variables. Examples: Log-Normal (exponentiation of normally distributed,9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,292.91839599609375,0.03571428571428571,84,H3
sample_6.pdf,5,"variable), Gamma (a sum over exponentially distributed variables), Dirichlet (weighted",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,303.87738037109375,0.023255813953488372,86,H3
sample_6.pdf,5,"sum of Gamma variates), Beta, Chi-Squared, and F distributions.",9.962599754333496,NimbusRomNo9L-Regu,False,143.8650360107422,314.83636474609375,0.07936507936507936,63,H3
sample_6.pdf,5,"When all three approaches fail, good approximations to the inverse CDF exist requiring computa-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,334.63037109375,0.042105263157894736,95,H3
sample_6.pdf,5,tions with time complexity comparable to the PDF (see e.g. [Dev86] for some methods).,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,345.58935546875,0.047058823529411764,85,H3
sample_6.pdf,5,Example: Variational Auto-Encoder,11.9552001953125,NimbusRomNo9L-Medi,False,125.93283081054688,372.35406494140625,0.12121212121212122,33,H3
sample_6.pdf,5,In this section we’ll give an example where we use a neural network for the probabilistic encoder,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,397.12835693359375,0.010309278350515464,97,H3
sample_6.pdf,5,(the approximation to the posterior of the generative model,9.962599754333496,NimbusRomNo9L-Regu,False,140.17349243164062,408.08734130859375,0.0,59,H3
sample_6.pdf,5,) and where the param-,9.962599754333496,NimbusRomNo9L-Regu,False,412.2780456542969,408.08734130859375,0.0,22,H3
sample_6.pdf,5,eters,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,419.04632568359375,0.0,5,H3
sample_6.pdf,5,and,9.962599754333496,NimbusRomNo9L-Regu,False,136.4033660888672,419.04632568359375,0.0,3,H3
sample_6.pdf,5,are optimized jointly with the AEVB algorithm.,9.962599754333496,NimbusRomNo9L-Regu,False,161.36402893066406,419.04632568359375,0.08695652173913043,46,H3
sample_6.pdf,5,Let the prior over the latent variables be the centered isotropic multivariate Gaussian,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,435.9823303222656,0.022988505747126436,87,H3
sample_6.pdf,5,) =,9.962599754333496,CMR10,False,486.6780700683594,435.7518005371094,0.0,3,H3
sample_6.pdf,5,". Note that in this case, the prior lacks parameters. We let",9.962599754333496,NimbusRomNo9L-Regu,False,149.41204833984375,446.94134521484375,0.03333333333333333,60,H3
sample_6.pdf,5,be a multivariate,9.962599754333496,NimbusRomNo9L-Regu,False,431.47052001953125,446.94134521484375,0.0,17,H3
sample_6.pdf,5,Gaussian (in case of real-valued data) or Bernoulli (in case of binary data) whose distribution pa-,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,457.90032958984375,0.020202020202020204,99,H3
sample_6.pdf,5,rameters are computed from,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,468.85931396484375,0.0,26,H3
sample_6.pdf,5,with a MLP (a fully-connected neural network with a single hidden,9.962599754333496,NimbusRomNo9L-Regu,False,229.52194213867188,468.85931396484375,0.046153846153846156,65,H3
sample_6.pdf,5,"layer, see appendix C). Note the true posterior",9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,479.81829833984375,0.0425531914893617,47,H3
sample_6.pdf,5,is in this case intractable. While there is,9.962599754333496,NimbusRomNo9L-Regu,False,333.20751953125,479.81829833984375,0.023255813953488372,43,H3
sample_6.pdf,5,much freedom in the form,9.962599754333496,NimbusRomNo9L-Regu,False,108.00004577636719,490.77728271484375,0.0,24,H3
sample_6.pdf,5,", we’ll assume the true (but intractable) posterior takes on a ap-",9.962599754333496,NimbusRomNo9L-Regu,False,248.90403747558594,490.77728271484375,0.0,66,H3
sample_6.pdf,5,"proximate Gaussian form with an approximately diagonal covariance. In this case, we can let the",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,501.73529052734375,0.021052631578947368,95,H3
sample_6.pdf,5,variational approximate posterior be a multivariate Gaussian with a diagonal covariance structure,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,512.6942749023438,0.010309278350515464,97,H3
sample_6.pdf,5,log,9.962599754333496,CMR10,False,227.4730224609375,529.1177368164062,0.0,3,H3
sample_6.pdf,5,) = log,9.962599754333496,CMR10,False,279.84405517578125,529.1177368164062,0.0,7,H3
sample_6.pdf,5,(9),9.962599754333496,NimbusRomNo9L-Regu,False,492.38409423828125,529.3482666015625,0.0,3,H3
sample_6.pdf,5,"where the mean and s.d. of the approximate posterior,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,546.63427734375,0.0,53,H3
sample_6.pdf,5,and,9.962599754333496,NimbusRomNo9L-Regu,False,352.6321105957031,546.63427734375,0.0,3,H3
sample_6.pdf,5,", are outputs of the encoding",9.962599754333496,NimbusRomNo9L-Regu,False,386.943115234375,546.63427734375,0.0,29,H3
sample_6.pdf,5,"MLP, i.e. nonlinear functions of datapoint",9.962599754333496,NimbusRomNo9L-Regu,False,108.0001220703125,558.6332397460938,0.07142857142857142,42,H3
sample_6.pdf,5,and the variational parameters,9.962599754333496,NimbusRomNo9L-Regu,False,295.75311279296875,558.6332397460938,0.0,30,H3
sample_6.pdf,5,(see appendix C).,9.962599754333496,NimbusRomNo9L-Regu,False,425.4454345703125,558.6332397460938,0.058823529411764705,17,H3
sample_6.pdf,5,"As explained in section 2.4, we sample from the posterior",9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,576.6092529296875,0.017543859649122806,57,H3
sample_6.pdf,5,"i,l",6.973800182342529,CMMI7,False,367.1990966796875,575.0995483398438,0.0,3,P
sample_6.pdf,5,using,9.962599754333496,NimbusRomNo9L-Regu,False,440.3195495605469,576.6092529296875,0.0,5,H3
sample_6.pdf,5,"i,l",6.973800182342529,CMMI7,False,478.7461242675781,575.0995483398438,0.0,3,P
sample_6.pdf,5,) =,9.962599754333496,CMR10,False,156.8151092529297,589.0717163085938,0.0,3,H3
sample_6.pdf,5,where,9.962599754333496,NimbusRomNo9L-Regu,False,256.7301025390625,589.30224609375,0.0,5,H3
sample_6.pdf,5,. With,9.962599754333496,NimbusRomNo9L-Regu,False,348.0340881347656,589.30224609375,0.16666666666666666,6,H3
sample_6.pdf,5,we signify an element-wise,9.962599754333496,NimbusRomNo9L-Regu,False,391.3960876464844,589.30224609375,0.0,26,H3
sample_6.pdf,5,product. In this model both,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,600.26123046875,0.037037037037037035,27,H3
sample_6.pdf,5,(the prior) and,9.962599754333496,NimbusRomNo9L-Regu,False,242.43553161621094,600.26123046875,0.0,15,H3
sample_6.pdf,5,"are Gaussian; in this case, we can use the",9.962599754333496,NimbusRomNo9L-Regu,False,337.22454833984375,600.26123046875,0.023809523809523808,42,H3
sample_6.pdf,5,estimator of eq. (7) where the KL divergence can be computed and differentiated without estimation,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,611.22021484375,0.02040816326530612,98,H3
sample_6.pdf,5,(see appendix B). The resulting estimator for this model and datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,108.00009155273438,623.21826171875,0.02857142857142857,70,H3
sample_6.pdf,5,is:,9.962599754333496,NimbusRomNo9L-Regu,False,408.319091796875,623.21826171875,0.0,3,H3
sample_6.pdf,5,1 + log((,9.962599754333496,CMR10,False,224.6580047607422,648.512939453125,0.0,9,H3
sample_6.pdf,5,log,9.962599754333496,CMR10,False,415.1829833984375,648.512939453125,0.0,3,H3
sample_6.pdf,5,"i,l",6.973800182342529,CMMI7,False,470.2909851074219,646.7347412109375,0.0,3,P
sample_6.pdf,5,where,9.962599754333496,NimbusRomNo9L-Regu,False,126.47796630859375,676.179443359375,0.0,5,H3
sample_6.pdf,5,"i,l",6.973800182342529,CMMI7,False,168.9839630126953,674.1707153320312,0.0,3,P
sample_6.pdf,5,and,9.962599754333496,NimbusRomNo9L-Regu,False,275.3809814453125,676.179443359375,0.0,3,H3
sample_6.pdf,5,(10),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019775390625,676.179443359375,0.0,4,H3
sample_6.pdf,5,"As explained above and in appendix C, the decoding term",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,693.4654541015625,0.03636363636363636,55,H3
sample_6.pdf,5,log,9.962599754333496,CMR10,False,338.076171875,693.2349243164062,0.0,3,H3
sample_6.pdf,5,"i,l",6.973800182342529,CMMI7,False,395.6519775390625,691.9557495117188,0.0,3,P
sample_6.pdf,5,is a Bernoulli or Gaus-,9.962599754333496,NimbusRomNo9L-Regu,False,410.8834228515625,693.4654541015625,0.08695652173913043,23,H3
sample_6.pdf,5,"sian MLP, depending on the type of data we are modelling.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,704.4244384765625,0.05263157894736842,57,H3
sample_6.pdf,5,"Note that this is just a (simplifying) choice, and not a limitation of our method.",8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.012195121951219513,82,P
sample_6.pdf,6,Related work,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,82.64812469482422,0.08333333333333333,12,H3
sample_6.pdf,6,"The wake-sleep algorithm [HDFN95] is, to the best of our knowledge, the only other on-line learn-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,107.45643615722656,0.05154639175257732,97,H3
sample_6.pdf,6,ing method in the literature that is applicable to the same general class of continuous latent variable,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,118.41444396972656,0.0,103,H3
sample_6.pdf,6,"models. Like our method, the wake-sleep algorithm employs a recognition model that approximates",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,129.37342834472656,0.010526315789473684,95,H3
sample_6.pdf,6,the true posterior. A drawback of the wake-sleep algorithm is that it requires a concurrent optimiza-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,140.33241271972656,0.009900990099009901,101,H3
sample_6.pdf,6,"tion of two objective functions, which together do not correspond to optimization of (a bound of)",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,151.29139709472656,0.0,97,H3
sample_6.pdf,6,the marginal likelihood. An advantage of wake-sleep is that it also applies to models with discrete,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,162.25038146972656,0.010101010101010102,99,H3
sample_6.pdf,6,latent variables. Wake-Sleep has the same computational complexity as AEVB per datapoint.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,173.20936584472656,0.06741573033707865,89,H3
sample_6.pdf,6,Stochastic variational inference [HBWP13] has recently received increasing interest.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,190.1453399658203,0.05952380952380952,84,H3
sample_6.pdf,6,"Recently,",9.962599754333496,NimbusRomNo9L-Regu,False,466.7431945800781,190.1453399658203,0.1111111111111111,9,H3
sample_6.pdf,6,[BJP12] introduced a control variate schemes to reduce the high variance of the na¨ıve gradient,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,201.05433654785156,0.031578947368421054,95,H3
sample_6.pdf,6,"estimator discussed in section 2.1, and applied to exponential family approximations of the poste-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,212.0633087158203,0.0,98,H3
sample_6.pdf,6,"rior. In [RGB13] some general methods, i.e. a control variate scheme, were introduced for reducing",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,223.0222930908203,0.04081632653061224,98,H3
sample_6.pdf,6,"the variance of the original gradient estimator. In [SK13], a similar reparameterization as in this",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,233.9812774658203,0.030303030303030304,99,H3
sample_6.pdf,6,paper was used in an efﬁcient version of a stochastic variational inference algorithm for learning the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,244.9402618408203,0.0,102,H3
sample_6.pdf,6,natural parameters of exponential-family approximating distributions.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,255.8992462158203,0.0,69,H3
sample_6.pdf,6,The AEVB algorithm exposes a connection between directed probabilistic models (trained with a,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,272.8352355957031,0.053763440860215055,93,H3
sample_6.pdf,6,variational objective) and auto-encoders. A connection between,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,283.79425048828125,0.016129032258064516,62,H3
sample_6.pdf,6,linear,9.962599754333496,NimbusRomNo9L-ReguItal,False,364.3675537109375,283.6177978515625,0.0,6,H3
sample_6.pdf,6,auto-encoders and a certain,9.962599754333496,NimbusRomNo9L-Regu,False,390.92962646484375,283.79425048828125,0.0,27,H3
sample_6.pdf,6,class of generative linear-Gaussian models has long been known. In [Row98] it was shown that PCA,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,294.75323486328125,0.0625,96,H3
sample_6.pdf,6,corresponds to the maximum-likelihood (ML) solution of a special case of the linear-Gaussian model,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,305.71221923828125,0.030612244897959183,98,H3
sample_6.pdf,6,with a prior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,316.67120361328125,0.0,12,H3
sample_6.pdf,6,) =,9.962599754333496,CMR10,False,171.00698852539062,316.440673828125,0.0,3,H3
sample_6.pdf,6,and a conditional distribution,9.962599754333496,NimbusRomNo9L-Regu,False,219.3744354248047,316.67120361328125,0.0,30,H3
sample_6.pdf,6,) =,9.962599754333496,CMR10,False,364.094970703125,316.440673828125,0.0,3,H3
sample_6.pdf,6,", speciﬁcally the",9.962599754333496,NimbusRomNo9L-Regu,False,438.93597412109375,316.67120361328125,0.0,17,H3
sample_6.pdf,6,case with inﬁnitesimally small,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,327.63018798828125,0.0,30,H3
sample_6.pdf,6,In relevant recent work on autoencoders [VLL,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,344.5661926269531,0.09090909090909091,44,H3
sample_6.pdf,6,10] it was shown that the training criterion of un-,9.962599754333496,NimbusRomNo9L-Regu,False,302.88800048828125,344.5661926269531,0.0,51,H3
sample_6.pdf,6,regularized autoencoders corresponds to maximization of a lower bound (see the infomax princi-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,355.52520751953125,0.0,94,H3
sample_6.pdf,6,ple [Lin89]) of the mutual information between input,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,366.48419189453125,0.019230769230769232,52,H3
sample_6.pdf,6,and latent representation,9.962599754333496,NimbusRomNo9L-Regu,False,340.01300048828125,366.48419189453125,0.0,25,H3
sample_6.pdf,6,. Maximiz-,9.962599754333496,NimbusRomNo9L-Regu,False,455.74200439453125,366.48419189453125,0.1,10,H3
sample_6.pdf,6,ing (w.r.t. parameters) of the mutual information is equivalent to maximizing the conditional en-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,377.44317626953125,0.0,97,H3
sample_6.pdf,6,"tropy, which is lower bounded by the expected loglikelihood of the data under the autoencoding",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,388.40216064453125,0.0,94,H3
sample_6.pdf,6,model [VLL,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,399.36114501953125,0.3,10,H3
sample_6.pdf,6,"10], i.e. the negative reconstrution error. However, it is well known that this recon-",9.962599754333496,NimbusRomNo9L-Regu,False,165.2169952392578,399.36114501953125,0.011627906976744186,86,H3
sample_6.pdf,6,struction criterion is in itself not sufﬁcient for learning useful representations [BCV13]. Regular-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,410.32012939453125,0.04,100,H3
sample_6.pdf,6,"ization techniques have been proposed to make autoencoders learn useful representations, such as",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,421.27911376953125,0.0,96,H3
sample_6.pdf,6,"denoising, contractive and sparse autoencoder variants [BCV13]. The SGVB objective contains a",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,432.23809814453125,0.08602150537634409,93,H3
sample_6.pdf,6,"regularization term dictated by the variational bound (e.g. eq. (10)), lacking the usual nuisance regu-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,443.19610595703125,0.0,103,H3
sample_6.pdf,6,larization hyperparameter required to learn useful representations. Related are also encoder-decoder,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,454.15509033203125,0.01,100,H3
sample_6.pdf,6,"architectures such as the predictive sparse decomposition (PSD) [KRL08], from which we drew",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,465.11407470703125,0.06593406593406594,91,H3
sample_6.pdf,6,some inspiration. Also relevant are the recently introduced Generative Stochastic Networks [BTL13],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,476.07305908203125,0.07142857142857142,98,H3
sample_6.pdf,6,where noisy auto-encoders learn the transition operator of a Markov chain that samples from the data,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,487.03204345703125,0.01,100,H3
sample_6.pdf,6,distribution. In [SL10] a recognition model was employed for efﬁcient learning with Deep Boltz-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,497.99102783203125,0.05263157894736842,95,H3
sample_6.pdf,6,mann Machines. These methods are targeted at either unnormalized models (i.e. undirected models,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,508.95001220703125,0.021052631578947368,95,H3
sample_6.pdf,6,"like Boltzmann machines) or limited to sparse coding models, in contrast to our proposed algorithm",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,519.9089965820312,0.01020408163265306,98,H3
sample_6.pdf,6,for learning a general class of directed probabilistic models.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,530.8679809570312,0.0,62,H3
sample_6.pdf,6,"The recently proposed DARN method [GMW13], also learns a directed probabilistic model using",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,547.8040161132812,0.08791208791208792,91,H3
sample_6.pdf,6,"an auto-encoding structure, however their method applies to binary latent variables. Even more",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,558.7630004882812,0.010638297872340425,94,H3
sample_6.pdf,6,"recently, [RMW14] also make the connection between auto-encoders, directed proabilistic models",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,569.7219848632812,0.031914893617021274,94,H3
sample_6.pdf,6,and stochastic variational inference using the reparameterization trick we describe in this paper.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,580.6810302734375,0.0,98,H3
sample_6.pdf,6,Their work was developed independently of ours and provides an additional perspective on AEVB.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,591.6400146484375,0.05319148936170213,94,H3
sample_6.pdf,6,Experiments,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,618.4367065429688,0.09090909090909091,11,H3
sample_6.pdf,6,We trained generative models of images from the MNIST and Frey Face datasets,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,643.2440185546875,0.10526315789473684,76,H3
sample_6.pdf,6,and compared,9.962599754333496,NimbusRomNo9L-Regu,False,447.0450134277344,643.2440185546875,0.0,12,H3
sample_6.pdf,6,"learning algorithms in terms of the variational lower bound, and the estimated marginal likelihood.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,654.2030029296875,0.0,99,H3
sample_6.pdf,6,"The generative model (encoder) and variational approximation (decoder) from section 3 were used,",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,671.1400146484375,0.010416666666666666,96,H3
sample_6.pdf,6,where the described encoder and decoder have an equal number of hidden units. Since the Frey,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,682.0989990234375,0.021739130434782608,92,H3
sample_6.pdf,6,"Face data are continuous, we used a decoder with Gaussian outputs, identical to the encoder, except",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,693.0579833984375,0.020202020202020204,99,H3
sample_6.pdf,6,that the means were constrained to the interval,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,704.0169677734375,0.0,47,H3
sample_6.pdf,6,using a sigmoidal activation function at the,9.962599754333496,NimbusRomNo9L-Regu,False,324.3547668457031,704.0169677734375,0.0,44,H3
sample_6.pdf,6,Available at,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.08333333333333333,12,P
sample_6.pdf,6,http://www.cs.nyu.edu/˜roweis/data.html,8.966400146484375,NimbusMonL-Regu,False,166.82803344726562,722.6029052734375,0.0,39,P
sample_6.pdf,7,Training,5.298840045928955,BitstreamVeraSans-Roman,False,127.32218933105469,152.3940887451172,0.125,8,P
sample_6.pdf,7,samples,5.298840045928955,BitstreamVeraSans-Roman,False,150.70068359375,152.3940887451172,0.0,7,P
sample_6.pdf,7,evaluated,5.298840045928955,BitstreamVeraSans-Roman,False,174.41299438476562,152.3940887451172,0.0,9,P
sample_6.pdf,7,150,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,141.12998962402344,0.0,3,P
sample_6.pdf,7,140,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,131.6923370361328,0.0,3,P
sample_6.pdf,7,130,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,122.25470733642578,0.0,3,P
sample_6.pdf,7,120,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,112.81707000732422,0.0,3,P
sample_6.pdf,7,110,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,103.37943267822266,0.0,3,P
sample_6.pdf,7,100,4.4156999588012695,BitstreamVeraSans-Roman,False,122.22028350830078,93.94178771972656,0.0,3,P
sample_6.pdf,7,"MNIST,",6.358608245849609,BitstreamVeraSans-Roman,False,139.86341857910156,83.72330474853516,0.8333333333333334,6,P
sample_6.pdf,7,150,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,141.12998962402344,0.0,3,P
sample_6.pdf,7,140,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,131.6923370361328,0.0,3,P
sample_6.pdf,7,130,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,122.25470733642578,0.0,3,P
sample_6.pdf,7,120,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,112.81707000732422,0.0,3,P
sample_6.pdf,7,110,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,103.37943267822266,0.0,3,P
sample_6.pdf,7,100,4.4156999588012695,BitstreamVeraSans-Roman,False,194.08580017089844,93.94178771972656,0.0,3,P
sample_6.pdf,7,"MNIST,",6.358608245849609,BitstreamVeraSans-Roman,False,211.72894287109375,83.72330474853516,0.8333333333333334,6,P
sample_6.pdf,7,150,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,141.12998962402344,0.0,3,P
sample_6.pdf,7,140,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,131.6923370361328,0.0,3,P
sample_6.pdf,7,130,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,122.25470733642578,0.0,3,P
sample_6.pdf,7,120,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,112.81707000732422,0.0,3,P
sample_6.pdf,7,110,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,103.37943267822266,0.0,3,P
sample_6.pdf,7,100,4.4156999588012695,BitstreamVeraSans-Roman,False,265.9513244628906,93.94178771972656,0.0,3,P
sample_6.pdf,7,"MNIST,",6.358608245849609,BitstreamVeraSans-Roman,False,282.0489501953125,83.72330474853516,0.8333333333333334,6,P
sample_6.pdf,7,=10,6.358608245849609,Cmr10,False,313.1943054199219,84.86149597167969,0.0,3,P
sample_6.pdf,7,150,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,141.12998962402344,0.0,3,P
sample_6.pdf,7,140,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,131.6923370361328,0.0,3,P
sample_6.pdf,7,130,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,122.25470733642578,0.0,3,P
sample_6.pdf,7,120,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,112.81707000732422,0.0,3,P
sample_6.pdf,7,110,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,103.37943267822266,0.0,3,P
sample_6.pdf,7,100,4.4156999588012695,BitstreamVeraSans-Roman,False,337.81683349609375,93.94178771972656,0.0,3,P
sample_6.pdf,7,"MNIST,",6.358608245849609,BitstreamVeraSans-Roman,False,353.91448974609375,83.72330474853516,0.8333333333333334,6,P
sample_6.pdf,7,=20,6.358608245849609,Cmr10,False,385.0598449707031,84.86149597167969,0.0,3,P
sample_6.pdf,7,150,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,141.12998962402344,0.0,3,P
sample_6.pdf,7,140,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,131.6923370361328,0.0,3,P
sample_6.pdf,7,130,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,122.25470733642578,0.0,3,P
sample_6.pdf,7,120,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,112.81707000732422,0.0,3,P
sample_6.pdf,7,110,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,103.37943267822266,0.0,3,P
sample_6.pdf,7,100,4.4156999588012695,BitstreamVeraSans-Roman,False,409.6823425292969,93.94178771972656,0.0,3,P
sample_6.pdf,7,"MNIST,",6.358608245849609,BitstreamVeraSans-Roman,False,424.2344970703125,83.72330474853516,0.8333333333333334,6,P
sample_6.pdf,7,=200,6.358608245849609,Cmr10,False,455.3798522949219,84.86149597167969,0.0,4,P
sample_6.pdf,7,200,4.4156999588012695,BitstreamVeraSans-Roman,False,193.93917846679688,209.90676879882812,0.0,3,P
sample_6.pdf,7,400,4.4156999588012695,BitstreamVeraSans-Roman,False,193.82879638671875,203.41839599609375,0.0,3,P
sample_6.pdf,7,600,4.4156999588012695,BitstreamVeraSans-Roman,False,193.92538452148438,196.9300079345703,0.0,3,P
sample_6.pdf,7,800,4.4156999588012695,BitstreamVeraSans-Roman,False,193.91848754882812,190.44163513183594,0.0,3,P
sample_6.pdf,7,1000,4.4156999588012695,BitstreamVeraSans-Roman,False,191.28976440429688,183.95326232910156,0.0,4,P
sample_6.pdf,7,1200,4.4156999588012695,BitstreamVeraSans-Roman,False,191.28976440429688,177.4648895263672,0.0,4,P
sample_6.pdf,7,1400,4.4156999588012695,BitstreamVeraSans-Roman,False,191.28976440429688,170.9765167236328,0.0,4,P
sample_6.pdf,7,1600,4.4156999588012695,BitstreamVeraSans-Roman,False,191.28976440429688,164.48814392089844,0.0,4,P
sample_6.pdf,7,Frey,6.358608245849609,BitstreamVeraSans-Roman,False,206.4300994873047,158.90567016601562,0.25,4,P
sample_6.pdf,7,"Face,",6.358608245849609,BitstreamVeraSans-Roman,False,222.38763427734375,158.90567016601562,0.2,5,P
sample_6.pdf,7,Wake-Sleep,4.4156999588012695,BitstreamVeraSans-Roman,False,131.4073486328125,180.0807342529297,0.2,10,P
sample_6.pdf,7,(test),4.4156999588012695,BitstreamVeraSans-Roman,False,159.0187225341797,180.0807342529297,0.0,6,P
sample_6.pdf,7,Wake-Sleep,4.4156999588012695,BitstreamVeraSans-Roman,False,131.4073486328125,186.55938720703125,0.2,10,P
sample_6.pdf,7,(train),4.4156999588012695,BitstreamVeraSans-Roman,False,159.0187225341797,186.55938720703125,0.0,7,P
sample_6.pdf,7,AEVB,4.4156999588012695,BitstreamVeraSans-Roman,False,131.4073486328125,193.0380401611328,1.0,4,P
sample_6.pdf,7,(test),4.4156999588012695,BitstreamVeraSans-Roman,False,144.672119140625,193.0380401611328,0.0,6,P
sample_6.pdf,7,AEVB,4.4156999588012695,BitstreamVeraSans-Roman,False,131.4073486328125,199.51670837402344,1.0,4,P
sample_6.pdf,7,(train),4.4156999588012695,BitstreamVeraSans-Roman,False,144.672119140625,199.51670837402344,0.0,7,P
sample_6.pdf,7,200,4.4156999588012695,BitstreamVeraSans-Roman,False,265.8046875,209.90676879882812,0.0,3,P
sample_6.pdf,7,400,4.4156999588012695,BitstreamVeraSans-Roman,False,265.6943359375,203.41839599609375,0.0,3,P
sample_6.pdf,7,600,4.4156999588012695,BitstreamVeraSans-Roman,False,265.7908935546875,196.9300079345703,0.0,3,P
sample_6.pdf,7,800,4.4156999588012695,BitstreamVeraSans-Roman,False,265.78399658203125,190.44163513183594,0.0,3,P
sample_6.pdf,7,1000,4.4156999588012695,BitstreamVeraSans-Roman,False,263.1552734375,183.95326232910156,0.0,4,P
sample_6.pdf,7,1200,4.4156999588012695,BitstreamVeraSans-Roman,False,263.1552734375,177.4648895263672,0.0,4,P
sample_6.pdf,7,1400,4.4156999588012695,BitstreamVeraSans-Roman,False,263.1552734375,170.9765167236328,0.0,4,P
sample_6.pdf,7,1600,4.4156999588012695,BitstreamVeraSans-Roman,False,263.1552734375,164.48814392089844,0.0,4,P
sample_6.pdf,7,Frey,6.358608245849609,BitstreamVeraSans-Roman,False,278.29559326171875,158.90567016601562,0.25,4,P
sample_6.pdf,7,"Face,",6.358608245849609,BitstreamVeraSans-Roman,False,294.25311279296875,158.90567016601562,0.2,5,P
sample_6.pdf,7,200,4.4156999588012695,BitstreamVeraSans-Roman,False,337.67022705078125,209.90676879882812,0.0,3,P
sample_6.pdf,7,400,4.4156999588012695,BitstreamVeraSans-Roman,False,337.559814453125,203.41839599609375,0.0,3,P
sample_6.pdf,7,600,4.4156999588012695,BitstreamVeraSans-Roman,False,337.65643310546875,196.9300079345703,0.0,3,P
sample_6.pdf,7,800,4.4156999588012695,BitstreamVeraSans-Roman,False,337.6495361328125,190.44163513183594,0.0,3,P
sample_6.pdf,7,1000,4.4156999588012695,BitstreamVeraSans-Roman,False,335.02081298828125,183.95326232910156,0.0,4,P
sample_6.pdf,7,1200,4.4156999588012695,BitstreamVeraSans-Roman,False,335.02081298828125,177.4648895263672,0.0,4,P
sample_6.pdf,7,1400,4.4156999588012695,BitstreamVeraSans-Roman,False,335.02081298828125,170.9765167236328,0.0,4,P
sample_6.pdf,7,1600,4.4156999588012695,BitstreamVeraSans-Roman,False,335.02081298828125,164.48814392089844,0.0,4,P
sample_6.pdf,7,Frey,6.358608245849609,BitstreamVeraSans-Roman,False,348.39483642578125,158.90567016601562,0.25,4,P
sample_6.pdf,7,"Face,",6.358608245849609,BitstreamVeraSans-Roman,False,364.35235595703125,158.90567016601562,0.2,5,P
sample_6.pdf,7,=10,6.358608245849609,Cmr10,False,390.4247131347656,160.0438690185547,0.0,3,P
sample_6.pdf,7,200,4.4156999588012695,BitstreamVeraSans-Roman,False,409.5357360839844,209.90676879882812,0.0,3,P
sample_6.pdf,7,400,4.4156999588012695,BitstreamVeraSans-Roman,False,409.42535400390625,203.41839599609375,0.0,3,P
sample_6.pdf,7,600,4.4156999588012695,BitstreamVeraSans-Roman,False,409.5219421386719,196.9300079345703,0.0,3,P
sample_6.pdf,7,800,4.4156999588012695,BitstreamVeraSans-Roman,False,409.5150451660156,190.44163513183594,0.0,3,P
sample_6.pdf,7,1000,4.4156999588012695,BitstreamVeraSans-Roman,False,406.8863220214844,183.95326232910156,0.0,4,P
sample_6.pdf,7,1200,4.4156999588012695,BitstreamVeraSans-Roman,False,406.8863220214844,177.4648895263672,0.0,4,P
sample_6.pdf,7,1400,4.4156999588012695,BitstreamVeraSans-Roman,False,406.8863220214844,170.9765167236328,0.0,4,P
sample_6.pdf,7,1600,4.4156999588012695,BitstreamVeraSans-Roman,False,406.8863220214844,164.48814392089844,0.0,4,P
sample_6.pdf,7,Frey,6.358608245849609,BitstreamVeraSans-Roman,False,420.2603759765625,158.90567016601562,0.25,4,P
sample_6.pdf,7,"Face,",6.358608245849609,BitstreamVeraSans-Roman,False,436.2178955078125,158.90567016601562,0.2,5,P
sample_6.pdf,7,=20,6.358608245849609,Cmr10,False,462.2902526855469,160.0438690185547,0.0,3,P
sample_6.pdf,7,"Figure 2: Comparison of our AEVB method to the wake-sleep algorithm, in terms of optimizing the",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,239.6024932861328,0.06315789473684211,95,H3
sample_6.pdf,7,"lower bound, for different dimensionality of latent space (",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,250.5614776611328,0.0,59,H3
sample_6.pdf,7,). Our method converged considerably,9.962599754333496,NimbusRomNo9L-Regu,False,350.718994140625,250.5614776611328,0.027777777777777776,36,H3
sample_6.pdf,7,"faster and reached a better solution in all experiments. Interestingly enough, more latent variables",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,261.51947021484375,0.01,100,H3
sample_6.pdf,7,"does not result in more overﬁtting, which is explained by the regularizing effect of the lower bound.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,272.47845458984375,0.0,101,H3
sample_6.pdf,7,Vertical axis: the estimated average variational lower bound per datapoint. The estimator variance,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,283.43743896484375,0.02040816326530612,98,H3
sample_6.pdf,7,was small (,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,294.39642333984375,0.0,11,H3
sample_6.pdf,7,) and omitted. Horizontal axis: amount of training points evaluated. Computa-,9.962599754333496,NimbusRomNo9L-Regu,False,173.4550018310547,294.39642333984375,0.025974025974025976,77,H3
sample_6.pdf,7,tion took around 20-40 minutes per million training samples with a Intel Xeon CPU running at an,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,305.35540771484375,0.05263157894736842,95,H3
sample_6.pdf,7,effective 40 GFLOPS.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,316.31439208984375,0.3,20,H3
sample_6.pdf,7,decoder output. Note that with,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,358.2923889160156,0.03333333333333333,30,H3
sample_6.pdf,7,hidden units,9.962599754333496,NimbusRomNo9L-ReguItal,False,232.47271728515625,358.1159362792969,0.0,12,H3
sample_6.pdf,7,we refer to the hidden layer of the neural networks of,9.962599754333496,NimbusRomNo9L-Regu,False,284.7425537109375,358.2923889160156,0.0,54,H3
sample_6.pdf,7,the encoder and decoder.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,369.25140380859375,0.0,24,H3
sample_6.pdf,7,Parameters are updated using stochastic gradient ascent where gradients are computed by differenti-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,386.1874084472656,0.010101010101010102,99,H3
sample_6.pdf,7,ating the lower bound estimator,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,397.14642333984375,0.0,31,H3
sample_6.pdf,7,"(see algorithm 1), plus a small weight decay term",9.962599754333496,NimbusRomNo9L-Regu,False,303.4194641113281,397.14642333984375,0.0,49,H3
sample_6.pdf,7,corresponding to a prior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,408.10540771484375,0.0,24,H3
sample_6.pdf,7,) =,9.962599754333496,CMR10,False,223.74798583984375,407.8748779296875,0.0,3,H3
sample_6.pdf,7,. Optimization of this objective is equivalent to approxi-,9.962599754333496,NimbusRomNo9L-Regu,False,274.31597900390625,408.10540771484375,0.017241379310344827,58,H3
sample_6.pdf,7,"mate MAP estimation, where the likelihood gradient is approximated by the gradient of the lower",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,419.06439208984375,0.031578947368421054,95,H3
sample_6.pdf,7,bound.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,430.02337646484375,0.0,6,H3
sample_6.pdf,7,We compared performance of AEVB to the wake-sleep algorithm [HDFN95]. We employed the,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,446.9593811035156,0.11764705882352941,85,H3
sample_6.pdf,7,same encoder (also called recognition model) for the wake-sleep algorithm and the variational auto-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,457.91839599609375,0.0,99,H3
sample_6.pdf,7,"encoder. All parameters, both variational and generative, were initialized by random sampling from",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,468.87738037109375,0.01020408163265306,98,H3
sample_6.pdf,7,01),9.962599754333496,CMR10,False,138.67498779296875,479.6058349609375,0.0,3,H3
sample_6.pdf,7,", and were jointly stochastically optimized using the MAP criterion. Stepsizes were",9.962599754333496,NimbusRomNo9L-Regu,False,152.51199340820312,479.83636474609375,0.04819277108433735,83,H3
sample_6.pdf,7,adapted with Adagrad [DHS10]; the Adagrad global stepsize parameters were chosen from,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,490.79534912109375,0.058823529411764705,85,H3
sample_6.pdf,7,"0.01,",9.962599754333496,NimbusRomNo9L-Regu,False,484.0749816894531,490.79534912109375,0.0,5,H3
sample_6.pdf,7,"0.02, 0.1",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,501.75433349609375,0.0,9,H3
sample_6.pdf,7,based on performance on the training set in the ﬁrst few iterations. Minibatches of size,9.962599754333496,NimbusRomNo9L-Regu,False,148.41726684570312,501.75433349609375,0.011363636363636364,88,H3
sample_6.pdf,7,= 100,9.962599754333496,CMR10,False,117.66368865966797,512.4827880859375,0.0,5,H3
sample_6.pdf,7,"were used, with",9.962599754333496,NimbusRomNo9L-Regu,False,146.9833526611328,512.7133178710938,0.0,15,H3
sample_6.pdf,7,= 1,9.962599754333496,CMR10,False,221.54849243164062,512.4827880859375,0.0,3,H3
sample_6.pdf,7,samples per datapoint.,9.962599754333496,NimbusRomNo9L-Regu,False,239.81275939941406,512.7133178710938,0.0,22,H3
sample_6.pdf,7,Likelihood lower bound,9.962599754333496,NimbusRomNo9L-Medi,False,107.99996948242188,546.1853637695312,0.045454545454545456,22,H3
sample_6.pdf,7,We trained generative models (decoders) and corresponding encoders,9.962599754333496,NimbusRomNo9L-Regu,False,221.30397033691406,546.2763061523438,0.015151515151515152,66,H3
sample_6.pdf,7,(a.k.a. recognition models) having,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,557.2353515625,0.0,34,H3
sample_6.pdf,7,500,9.962599754333496,CMR10,False,244.84620666503906,557.0048217773438,0.0,3,H3
sample_6.pdf,7,"hidden units in case of MNIST, and",9.962599754333496,NimbusRomNo9L-Regu,False,262.1788635253906,557.2353515625,0.14705882352941177,34,H3
sample_6.pdf,7,200,9.962599754333496,CMR10,False,405.718017578125,557.0048217773438,0.0,3,H3
sample_6.pdf,7,hidden units in case,9.962599754333496,NimbusRomNo9L-Regu,False,423.0538635253906,557.2353515625,0.0,20,H3
sample_6.pdf,7,"of the Frey Face dataset (to prevent overﬁtting, since it is a considerably smaller dataset). The chosen",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,568.1943359375,0.028846153846153848,104,H3
sample_6.pdf,7,"number of hidden units is based on prior literature on auto-encoders, and the relative performance",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,579.1533203125,0.0,98,H3
sample_6.pdf,7,of different algorithms was not very sensitive to these choices. Figure 2 shows the results when,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,590.1123046875,0.010416666666666666,96,H3
sample_6.pdf,7,"comparing the lower bounds. Interestingly, superﬂuous latent variables did not result in overﬁtting,",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,601.0712890625,0.01,100,H3
sample_6.pdf,7,which is explained by the regularizing nature of the variational bound.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,612.0303344726562,0.0,71,H3
sample_6.pdf,7,Marginal likelihood,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,645.5023803710938,0.05263157894736842,19,H3
sample_6.pdf,7,For very low-dimensional latent space it is possible to estimate the marginal,9.962599754333496,NimbusRomNo9L-Regu,False,202.1009979248047,645.5933227539062,0.012987012987012988,77,H3
sample_6.pdf,7,likelihood of the learned generative models using an MCMC estimator. More information about the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,656.5523071289062,0.05263157894736842,95,H3
sample_6.pdf,7,marginal likelihood estimator is available in the appendix. For the encoder and decoder we again,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,667.5113525390625,0.010416666666666666,96,H3
sample_6.pdf,7,"used neural networks, this time with 100 hidden units, and 3 latent variables; for higher dimensional",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,678.4703369140625,0.0,101,H3
sample_6.pdf,7,"latent space the estimates became unreliable. Again, the MNIST dataset was used. The AEVB",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,689.4293212890625,0.12359550561797752,89,H3
sample_6.pdf,7,and Wake-Sleep methods were compared to Monte Carlo EM (MCEM) with a Hybrid Monte Carlo,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,700.3883056640625,0.14942528735632185,87,H3
sample_6.pdf,7,(HMC) [DKPR87] sampler; details are in the appendix. We compared the convergence speed for,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,711.3472900390625,0.08888888888888889,90,H3
sample_6.pdf,7,"the three algorithms, for a small and large training set size. Results are in ﬁgure 3.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,722.3063354492188,0.011627906976744186,86,H3
sample_6.pdf,8,Training,6.918600082397461,BitstreamVeraSans-Roman,False,135.32960510253906,221.0701141357422,0.125,8,P
sample_6.pdf,8,samples,6.918600082397461,BitstreamVeraSans-Roman,False,165.85446166992188,221.0701141357422,0.0,7,P
sample_6.pdf,8,evaluated,6.918600082397461,BitstreamVeraSans-Roman,False,196.81521606445312,221.0701141357422,0.0,9,P
sample_6.pdf,8,(millions),6.918600082397461,BitstreamVeraSans-Roman,False,233.5183868408203,221.0701141357422,0.0,10,P
sample_6.pdf,8,160,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,207.70506286621094,0.0,3,P
sample_6.pdf,8,150,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,188.33297729492188,0.0,3,P
sample_6.pdf,8,140,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,168.96090698242188,0.0,3,P
sample_6.pdf,8,130,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,149.5888214111328,0.0,3,P
sample_6.pdf,8,120,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,130.2167510986328,0.0,3,P
sample_6.pdf,8,110,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,110.84467315673828,0.0,3,P
sample_6.pdf,8,100,5.765500068664551,BitstreamVeraSans-Roman,False,126.5671615600586,91.47258758544922,0.0,3,P
sample_6.pdf,8,Marginal,6.918600082397461,BitstreamVeraSans-Roman,False,110.98480224609375,162.11941528320312,0.125,8,P
sample_6.pdf,8,log-likelihood,6.918600082397461,BitstreamVeraSans-Roman,False,110.98480224609375,113.66847229003906,0.0,14,P
sample_6.pdf,8,train,5.811624050140381,Cmmi10,False,175.50755310058594,89.76378631591797,0.0,5,P
sample_6.pdf,8,1000,8.302319526672363,BitstreamVeraSans-Roman,False,201.0002899169922,84.29178619384766,0.0,4,P
sample_6.pdf,8,160,5.765500068664551,BitstreamVeraSans-Roman,False,262.8229064941406,207.70506286621094,0.0,3,P
sample_6.pdf,8,155,5.765500068664551,BitstreamVeraSans-Roman,False,262.94903564453125,191.1004180908203,0.0,3,P
sample_6.pdf,8,150,5.765500068664551,BitstreamVeraSans-Roman,False,262.8229064941406,174.4957733154297,0.0,3,P
sample_6.pdf,8,145,5.765500068664551,BitstreamVeraSans-Roman,False,262.94903564453125,157.89114379882812,0.0,3,P
sample_6.pdf,8,140,5.765500068664551,BitstreamVeraSans-Roman,False,262.8229064941406,141.28651428222656,0.0,3,P
sample_6.pdf,8,135,5.765500068664551,BitstreamVeraSans-Roman,False,262.94903564453125,124.68187713623047,0.0,3,P
sample_6.pdf,8,130,5.765500068664551,BitstreamVeraSans-Roman,False,262.8229064941406,108.07723236083984,0.0,3,P
sample_6.pdf,8,125,5.765500068664551,BitstreamVeraSans-Roman,False,262.94903564453125,91.47258758544922,0.0,3,P
sample_6.pdf,8,train,5.811624050140381,Cmmi10,False,309.1688232421875,89.76378631591797,0.0,5,P
sample_6.pdf,8,50000,8.302319526672363,BitstreamVeraSans-Roman,False,334.66156005859375,84.29178619384766,0.0,5,P
sample_6.pdf,8,Wake-Sleep,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,120.96842956542969,0.2,10,P
sample_6.pdf,8,(train),6.918600082397461,BitstreamVeraSans-Roman,False,476.7926330566406,120.96842956542969,0.0,7,P
sample_6.pdf,8,Wake-Sleep,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,131.13011169433594,0.2,10,P
sample_6.pdf,8,(test),6.918600082397461,BitstreamVeraSans-Roman,False,476.7926330566406,131.13011169433594,0.0,6,P
sample_6.pdf,8,MCEM,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,141.29180908203125,1.0,4,P
sample_6.pdf,8,(train),6.918600082397461,BitstreamVeraSans-Roman,False,456.8739929199219,141.29180908203125,0.0,7,P
sample_6.pdf,8,MCEM,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,151.45350646972656,1.0,4,P
sample_6.pdf,8,(test),6.918600082397461,BitstreamVeraSans-Roman,False,456.8739929199219,151.45350646972656,0.0,6,P
sample_6.pdf,8,AEVB,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,161.6151885986328,1.0,4,P
sample_6.pdf,8,(train),6.918600082397461,BitstreamVeraSans-Roman,False,454.3140869140625,161.6151885986328,0.0,7,P
sample_6.pdf,8,AEVB,6.918600082397461,BitstreamVeraSans-Roman,False,433.5306396484375,171.77688598632812,1.0,4,P
sample_6.pdf,8,(test),6.918600082397461,BitstreamVeraSans-Roman,False,454.3140869140625,171.77688598632812,0.0,6,P
sample_6.pdf,8,"Figure 3: Comparison of AEVB to the wake-sleep algorithm and Monte Carlo EM, in terms of the",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,243.16749572753906,0.10869565217391304,92,H3
sample_6.pdf,8,"estimated marginal likelihood, for a different number of training points. Monte Carlo EM is not an",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,254.12648010253906,0.04081632653061224,98,H3
sample_6.pdf,8,"on-line algorithm, and (unlike AEVB and the wake-sleep method) can’t be applied efﬁciently for",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,265.08544921875,0.0425531914893617,94,H3
sample_6.pdf,8,the full MNIST dataset.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,276.04443359375,0.21739130434782608,23,H3
sample_6.pdf,8,Visualisation of high-dimensional data,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,309.1294860839844,0.02631578947368421,38,H3
sample_6.pdf,8,"If we choose a low-dimensional latent space (e.g. 2D),",9.962599754333496,NimbusRomNo9L-Regu,False,282.39898681640625,309.2204284667969,0.037037037037037035,54,H3
sample_6.pdf,8,we can use the learned encoders (recognition model) to project high-dimensional data to a low-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,320.179443359375,0.0,94,H3
sample_6.pdf,8,dimensional manifold. See appendix A for visualisations of the 2D latent manifolds for the MNIST,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,331.137451171875,0.08333333333333333,96,H3
sample_6.pdf,8,and Frey Face datasets.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,342.096435546875,0.08695652173913043,23,H3
sample_6.pdf,8,Conclusion,11.9552001953125,NimbusRomNo9L-Medi,False,125.93278503417969,369.3681335449219,0.1,10,H3
sample_6.pdf,8,"We have introduced a novel estimator of the variational lower bound, Stochastic Gradient VB",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,394.6494445800781,0.054945054945054944,91,H3
sample_6.pdf,8,"(SGVB), for efﬁcient approximate inference with continuous latent variables. The proposed estima-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,405.60845947265625,0.05154639175257732,97,H3
sample_6.pdf,8,tor can be straightforwardly differentiated and optimized using standard stochastic gradient meth-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,416.56744384765625,0.0,98,H3
sample_6.pdf,8,ods. For the case of i.i.d. datasets and continuous latent variables per datapoint we introduce an,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,427.52642822265625,0.01020408163265306,98,H3
sample_6.pdf,8,"efﬁcient algorithm for efﬁcient inference and learning, Auto-Encoding VB (AEVB), that learns an",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,438.48541259765625,0.08421052631578947,95,H3
sample_6.pdf,8,approximate inference model using the SGVB estimator. The theoretical advantages are reﬂected in,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,449.44439697265625,0.052083333333333336,96,H3
sample_6.pdf,8,experimental results.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,460.40338134765625,0.0,21,H3
sample_6.pdf,8,Future work,11.9552001953125,NimbusRomNo9L-Medi,False,125.93278503417969,487.674072265625,0.09090909090909091,11,H3
sample_6.pdf,8,Since the SGVB estimator and the AEVB algorithm can be applied to almost any inference and,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,512.9563598632812,0.1,90,H3
sample_6.pdf,8,"learning problem with continuous latent variables, there are plenty of future directions: (i) learning",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,523.9143676757812,0.0,102,H3
sample_6.pdf,8,hierarchical generative architectures with deep neural networks (e.g. convolutional networks) used,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,534.8733520507812,0.0,98,H3
sample_6.pdf,8,"for the encoders and decoders, trained jointly with AEVB; (ii) time-series models (i.e. dynamic",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,545.8323974609375,0.042105263157894736,95,H3
sample_6.pdf,8,Bayesian networks); (iii) application of SGVB to the global parameters; (iv) supervised models,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,556.7913818359375,0.05319148936170213,94,H3
sample_6.pdf,8,"with latent variables, useful for learning complicated noise distributions.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,567.7503662109375,0.0,75,H3
sample_6.pdf,9,References,11.9552001953125,NimbusRomNo9L-Medi,False,108.0,82.64812469482422,0.1,10,H3
sample_6.pdf,9,[BCV13],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,106.06745910644531,0.42857142857142855,7,H3
sample_6.pdf,9,"Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A re-",9.962599754333496,NimbusRomNo9L-Regu,False,158.36094665527344,106.06745910644531,0.0975609756097561,82,H3
sample_6.pdf,9,view and new perspectives. 2013.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,117.02644348144531,0.0,32,H3
sample_6.pdf,9,[BJP12],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,133.7764434814453,0.42857142857142855,7,H3
sample_6.pdf,9,"David M Blei, Michael I Jordan, and John W Paisley. Variational Bayesian inference",9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,133.7764434814453,0.13414634146341464,82,H3
sample_6.pdf,9,with Stochastic Search. In,9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,144.7354278564453,0.11538461538461539,26,H3
sample_6.pdf,9,Proceedings of the 29th International Conference on Ma-,9.962599754333496,NimbusRomNo9L-ReguItal,False,266.9931945800781,144.5589599609375,0.07272727272727272,55,H3
sample_6.pdf,9,chine Learning (ICML-12),9.962599754333496,NimbusRomNo9L-ReguItal,False,158.36099243164062,155.5179443359375,0.20833333333333334,24,H3
sample_6.pdf,9,", pages 1367–1374, 2012.",9.962599754333496,NimbusRomNo9L-Regu,False,265.0199890136719,155.6944122314453,0.0,24,H3
sample_6.pdf,9,[BTL13],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,173.6054229736328,0.42857142857142855,7,H3
sample_6.pdf,9,Yoshua Bengio and,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609161376953,173.6054229736328,0.11764705882352941,17,H3
sample_6.pdf,9,Eric Thibodeau-Laufer. Deep generative stochastic networks train-,9.962599754333496,NimbusRomNo9L-Regu,False,238.10198974609375,173.6054229736328,0.06153846153846154,65,H3
sample_6.pdf,9,able by backprop.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,184.5644073486328,0.0,17,H3
sample_6.pdf,9,arXiv preprint arXiv:1306.1091,9.962599754333496,NimbusRomNo9L-ReguItal,False,229.4640350341797,184.387939453125,0.06666666666666667,30,H3
sample_6.pdf,9,", 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,360.2519836425781,184.5644073486328,0.0,7,H3
sample_6.pdf,9,[Dev86],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,201.3144073486328,0.14285714285714285,7,H3
sample_6.pdf,9,Luc Devroye. Sample-based non-uniform random variate generation. In,9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,201.3144073486328,0.05970149253731343,67,H3
sample_6.pdf,9,Proceedings,9.962599754333496,NimbusRomNo9L-ReguItal,False,451.67962646484375,201.137939453125,0.09090909090909091,11,H3
sample_6.pdf,9,of the 18th conference on Winter simulation,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.36099243164062,212.096923828125,0.023255813953488372,43,H3
sample_6.pdf,9,", pages 260–265. ACM, 1986.",9.962599754333496,NimbusRomNo9L-Regu,False,332.885009765625,212.2733917236328,0.1111111111111111,27,H3
sample_6.pdf,9,[DHS10],9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,229.0243682861328,0.42857142857142855,7,H3
sample_6.pdf,9,"John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online",9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,229.0243682861328,0.08641975308641975,81,H3
sample_6.pdf,9,learning and stochastic optimization.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36102294921875,239.9823760986328,0.0,37,H3
sample_6.pdf,9,Journal of Machine Learning Research,9.962599754333496,NimbusRomNo9L-ReguItal,False,303.974365234375,239.805908203125,0.1111111111111111,36,H3
sample_6.pdf,9,", 12:2121–",9.962599754333496,NimbusRomNo9L-Regu,False,461.65899658203125,239.9823760986328,0.0,10,H3
sample_6.pdf,9,"2159, 2010.",9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,250.9413604736328,0.0,11,H3
sample_6.pdf,9,"[DKPR87] Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,267.69232177734375,0.17647058823529413,85,H3
sample_6.pdf,9,monte carlo.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,278.65130615234375,0.0,12,H3
sample_6.pdf,9,Physics letters B,9.962599754333496,NimbusRomNo9L-ReguItal,False,208.16403198242188,278.474853515625,0.11764705882352941,17,H3
sample_6.pdf,9,", 195(2):216–222, 1987.",9.962599754333496,NimbusRomNo9L-Regu,False,278.05999755859375,278.65130615234375,0.0,23,H3
sample_6.pdf,9,[GMW13],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,295.40130615234375,0.42857142857142855,7,H3
sample_6.pdf,9,"Karol Gregor, Andriy Mnih, and Daan Wierstra. Deep autoregressive networks.",9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,295.40130615234375,0.09333333333333334,75,H3
sample_6.pdf,9,arXiv,9.962599754333496,NimbusRomNo9L-ReguItal,False,477.73187255859375,295.224853515625,0.2,5,H3
sample_6.pdf,9,preprint arXiv:1310.8499,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.36099243164062,306.183837890625,0.041666666666666664,24,H3
sample_6.pdf,9,", 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,260.93499755859375,306.36029052734375,0.0,7,H3
sample_6.pdf,9,"[HBWP13] Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic varia-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,323.11029052734375,0.16853932584269662,89,H3
sample_6.pdf,9,tional inference.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36099243164062,334.06927490234375,0.0,17,H3
sample_6.pdf,9,The Journal of Machine Learning Research,9.962599754333496,NimbusRomNo9L-ReguItal,False,223.09799194335938,333.892822265625,0.125,40,H3
sample_6.pdf,9,", 14(1):1303–1347, 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,400.3709716796875,334.06927490234375,0.0,24,H3
sample_6.pdf,9,"[HDFN95] Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The” wake-",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,350.8202819824219,0.1839080459770115,87,H3
sample_6.pdf,9,sleep” algorithm for unsupervised neural networks.,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,361.7782897949219,0.0,50,H3
sample_6.pdf,9,SCIENCE,9.962599754333496,NimbusRomNo9L-ReguItal,False,360.0238342285156,361.6018371582031,1.0,7,H3
sample_6.pdf,9,", pages 1158–1158, 1995.",9.962599754333496,NimbusRomNo9L-Regu,False,402.9719543457031,361.7782897949219,0.0,24,H3
sample_6.pdf,9,[KRL08],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,378.529296875,0.42857142857142855,7,H3
sample_6.pdf,9,"Koray Kavukcuoglu, Marc’Aurelio Ranzato, and Yann LeCun. Fast inference in sparse",9.962599754333496,NimbusRomNo9L-Regu,False,158.3609161376953,378.529296875,0.1111111111111111,81,H3
sample_6.pdf,9,coding algorithms with applications to object recognition. Technical Report CBLL-,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,389.48828125,0.07407407407407407,81,H3
sample_6.pdf,9,"TR-2008-12-01, Computational and Biological Learning Lab, Courant Institute, NYU,",9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,400.447265625,0.13580246913580246,81,H3
sample_6.pdf,9,2008.,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,411.40625,0.0,5,H3
sample_6.pdf,9,[Lin89],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,428.15625,0.14285714285714285,7,H3
sample_6.pdf,9,Ralph Linsker.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36090087890625,428.15625,0.14285714285714285,14,H3
sample_6.pdf,9,An application of the principle of maximum information preservation to,9.962599754333496,NimbusRomNo9L-ReguItal,False,216.7218017578125,427.97979736328125,0.014285714285714285,70,H3
sample_6.pdf,9,linear systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.3609619140625,438.93878173828125,0.0,14,H3
sample_6.pdf,9,". Morgan Kaufmann Publishers Inc., 1989.",9.962599754333496,NimbusRomNo9L-Regu,False,215.0869598388672,439.115234375,0.1,40,H3
sample_6.pdf,9,[RGB13],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,455.865234375,0.42857142857142855,7,H3
sample_6.pdf,9,"Rajesh Ranganath, Sean Gerrish, and David M Blei. Black Box Variational Inference.",9.962599754333496,NimbusRomNo9L-Regu,False,158.36090087890625,455.865234375,0.13414634146341464,82,H3
sample_6.pdf,9,arXiv preprint arXiv:1401.0118,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.3609619140625,466.64776611328125,0.06666666666666667,30,H3
sample_6.pdf,9,", 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,285.5629577636719,466.82421875,0.0,7,H3
sample_6.pdf,9,[RMW14],9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,483.5752258300781,0.42857142857142855,7,H3
sample_6.pdf,9,"Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.",9.962599754333496,NimbusRomNo9L-Regu,False,158.3608856201172,483.5752258300781,0.1206896551724138,58,H3
sample_6.pdf,9,Stochastic back-,9.962599754333496,NimbusRomNo9L-Regu,False,436.5665588378906,483.5752258300781,0.0625,16,H3
sample_6.pdf,9,propagation and variational inference in deep latent gaussian models.,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,494.5332336425781,0.0,69,H3
sample_6.pdf,9,arXiv preprint,9.962599754333496,NimbusRomNo9L-ReguItal,False,440.1829833984375,494.3567810058594,0.07142857142857142,14,H3
sample_6.pdf,9,arXiv:1401.4082,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.3609619140625,505.3157958984375,0.06666666666666667,15,H3
sample_6.pdf,9,", 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,226.1559600830078,505.49224853515625,0.0,7,H3
sample_6.pdf,9,[Row98],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996185302734,522.2432861328125,0.14285714285714285,7,H3
sample_6.pdf,9,Sam Roweis. EM algorithms for PCA and SPCA.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36090087890625,522.2432861328125,0.2558139534883721,43,H3
sample_6.pdf,9,Advances in neural information,9.962599754333496,NimbusRomNo9L-ReguItal,False,367.2467041015625,522.0668334960938,0.03333333333333333,30,H3
sample_6.pdf,9,processing systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,158.3609619140625,533.0258178710938,0.0,18,H3
sample_6.pdf,9,", pages 626–632, 1998.",9.962599754333496,NimbusRomNo9L-Regu,False,234.00595092773438,533.2022705078125,0.0,22,H3
sample_6.pdf,9,[SK13],9.962599754333496,NimbusRomNo9L-Regu,False,107.99995422363281,549.9522705078125,0.3333333333333333,6,H3
sample_6.pdf,9,Tim Salimans and David A Knowles. Fixed-form variational posterior approximation,9.962599754333496,NimbusRomNo9L-Regu,False,158.36090087890625,549.9522705078125,0.075,80,H3
sample_6.pdf,9,through stochastic linear regression.,9.962599754333496,NimbusRomNo9L-Regu,False,158.3609619140625,560.9112548828125,0.0,37,H3
sample_6.pdf,9,Bayesian Analysis,9.962599754333496,NimbusRomNo9L-ReguItal,False,302.0914001464844,560.7348022460938,0.11764705882352941,17,H3
sample_6.pdf,9,", 8(4), 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,378.45294189453125,560.9112548828125,0.0,13,H3
sample_6.pdf,9,[SL10],9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,577.6612548828125,0.3333333333333333,6,H3
sample_6.pdf,9,Ruslan Salakhutdinov and Hugo Larochelle. Efﬁcient learning of deep boltzmann ma-,9.962599754333496,NimbusRomNo9L-Regu,False,158.3608856201172,577.6612548828125,0.06172839506172839,81,H3
sample_6.pdf,9,chines. In,9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,588.6202392578125,0.1,10,H3
sample_6.pdf,9,International Conference on Artiﬁcial Intelligence and Statistics,9.962599754333496,NimbusRomNo9L-ReguItal,False,197.57373046875,588.4437866210938,0.07692307692307693,65,H3
sample_6.pdf,9,", pages 693–",9.962599754333496,NimbusRomNo9L-Regu,False,454.42694091796875,588.6202392578125,0.0,12,H3
sample_6.pdf,9,"700, 2010.",9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,599.5792236328125,0.0,10,H3
sample_6.pdf,9,[VLL,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993133544922,616.3292236328125,0.75,4,H3
sample_6.pdf,9,"10] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine",9.962599754333496,NimbusRomNo9L-Regu,False,137.29893493652344,616.3292236328125,0.11494252873563218,87,H3
sample_6.pdf,9,Manzagol. Stacked denoising autoencoders: Learning useful representations in a deep,9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,627.2882690429688,0.03614457831325301,83,H3
sample_6.pdf,9,network with a local denoising criterion.,9.962599754333496,NimbusRomNo9L-Regu,False,158.36093139648438,638.2472534179688,0.0,41,H3
sample_6.pdf,9,The Journal of Machine Learning Research,9.962599754333496,NimbusRomNo9L-ReguItal,False,321.5083923339844,638.07080078125,0.125,40,H3
sample_6.pdf,9,"9999:3371–3408, 2010.",9.962599754333496,NimbusRomNo9L-Regu,False,158.36090087890625,649.2062377929688,0.0,21,H3
sample_6.pdf,9,Visualisations,11.9552001953125,NimbusRomNo9L-Medi,False,128.58676147460938,684.845947265625,0.07142857142857142,14,H3
sample_6.pdf,9,See ﬁgures 4 and 5 for visualisations of latent space and corresponding observed space of models,9.962599754333496,NimbusRomNo9L-Regu,False,107.9999008178711,711.3472290039062,0.010416666666666666,96,H3
sample_6.pdf,9,learned with SGVB.,9.962599754333496,NimbusRomNo9L-Regu,False,107.9999008178711,722.3062744140625,0.2222222222222222,18,H3
sample_6.pdf,10,(a) Learned Frey Face manifold,8.966400146484375,NimbusRomNo9L-Regu,False,133.76600646972656,312.6559753417969,0.1,30,P
sample_6.pdf,10,(b) Learned MNIST manifold,8.966400146484375,NimbusRomNo9L-Regu,False,320.41900634765625,312.6559753417969,0.23076923076923078,26,P
sample_6.pdf,10,Figure 4: Visualisations of learned data manifold for generative models with two-dimensional latent,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,332.5234375,0.020202020202020204,99,H3
sample_6.pdf,10,"space, learned with AEVB. Since the prior of the latent space is Gaussian, linearly spaced coor-",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,343.482421875,0.0625,96,H3
sample_6.pdf,10,dinates on the unit square were transformed through the inverse CDF of the Gaussian to produce,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,354.44140625,0.0425531914893617,94,H3
sample_6.pdf,10,values of the latent variables,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,365.400390625,0.0,30,H3
sample_6.pdf,10,. For each of these values,9.962599754333496,NimbusRomNo9L-Regu,False,229.45399475097656,365.400390625,0.038461538461538464,26,H3
sample_6.pdf,10,", we plotted the corresponding generative",9.962599754333496,NimbusRomNo9L-Regu,False,339.10101318359375,365.400390625,0.0,41,H3
sample_6.pdf,10,with the learned parameters,9.962599754333496,NimbusRomNo9L-Regu,False,139.7984619140625,376.359375,0.0,27,H3
sample_6.pdf,10,(a) 2-D latent space,8.966400146484375,NimbusRomNo9L-Regu,False,130.41799926757812,502.6979675292969,0.05,20,P
sample_6.pdf,10,(b) 5-D latent space,8.966400146484375,NimbusRomNo9L-Regu,False,223.73599243164062,502.6979675292969,0.05,20,P
sample_6.pdf,10,(c) 10-D latent space,8.966400146484375,NimbusRomNo9L-Regu,False,315.3139953613281,502.6979675292969,0.047619047619047616,21,P
sample_6.pdf,10,(d) 20-D latent space,8.966400146484375,NimbusRomNo9L-Regu,False,408.6319885253906,502.6979675292969,0.047619047619047616,21,P
sample_6.pdf,10,Figure 5: Random samples from learned generative models of MNIST for different dimensionalities,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,522.564453125,0.07368421052631578,95,H3
sample_6.pdf,10,of latent space.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,533.5234375,0.0,16,H3
sample_6.pdf,10,Solution of,11.9552001953125,NimbusRomNo9L-Medi,False,127.9293212890625,571.951171875,0.09090909090909091,11,H3
sample_6.pdf,10,", Gaussian case",11.9552001953125,NimbusRomNo9L-Medi,False,288.35302734375,571.951171875,0.06666666666666667,15,H3
sample_6.pdf,10,The variational lower bound (the objective to be maximized) contains a KL term that can often be,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,601.8714599609375,0.03125,96,H3
sample_6.pdf,10,integrated analytically. Here we give the solution when both the prior,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,612.8304443359375,0.014285714285714285,70,H3
sample_6.pdf,10,) =,9.962599754333496,CMR10,False,418.61004638671875,612.5999145507812,0.0,3,H3
sample_6.pdf,10,and the,9.962599754333496,NimbusRomNo9L-Regu,False,470.5155029296875,612.8304443359375,0.0,7,H3
sample_6.pdf,10,posterior approximation,9.962599754333496,NimbusRomNo9L-Regu,False,108.00006103515625,625.1624755859375,0.0,23,H3
sample_6.pdf,10,are Gaussian. Let,9.962599754333496,NimbusRomNo9L-Regu,False,249.55853271484375,625.1624755859375,0.11764705882352941,17,H3
sample_6.pdf,10,be the dimensionality of,9.962599754333496,NimbusRomNo9L-Regu,False,334.1003112792969,625.1624755859375,0.0,24,H3
sample_6.pdf,10,. Let,9.962599754333496,NimbusRomNo9L-Regu,False,445.0331115722656,625.1624755859375,0.2,5,H3
sample_6.pdf,10,and,9.962599754333496,NimbusRomNo9L-Regu,False,476.10064697265625,625.1624755859375,0.0,3,H3
sample_6.pdf,10,denote the variational mean and s.d. evaluated at datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,108.0001220703125,636.1214599609375,0.0,59,H3
sample_6.pdf,10,", and let",9.962599754333496,NimbusRomNo9L-Regu,False,352.7811279296875,636.1214599609375,0.0,9,H3
sample_6.pdf,10,and,9.962599754333496,NimbusRomNo9L-Regu,False,398.0147399902344,636.1214599609375,0.0,3,H3
sample_6.pdf,10,simply denote the,9.962599754333496,NimbusRomNo9L-Regu,False,428.2707214355469,636.1214599609375,0.0,17,H3
sample_6.pdf,10,-th element of these vectors. Then:,9.962599754333496,NimbusRomNo9L-Regu,False,112.6731185913086,647.0804443359375,0.02857142857142857,35,H3
sample_6.pdf,10,) log,9.962599754333496,CMR10,False,223.902099609375,677.18994140625,0.0,5,H3
sample_6.pdf,10,) log,9.962599754333496,CMR10,False,344.8511047363281,677.18994140625,0.0,5,H3
sample_6.pdf,10,log(2,9.962599754333496,CMR10,False,305.322998046875,707.9689331054688,0.0,5,H3
sample_6.pdf,11,And:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.25,4,H3
sample_6.pdf,11,) log,9.962599754333496,CMR10,False,217.2939910888672,103.31187438964844,0.0,5,H3
sample_6.pdf,11,) log,9.962599754333496,CMR10,False,342.8089904785156,103.31187438964844,0.0,5,H3
sample_6.pdf,11,log(2,9.962599754333496,CMR10,False,303.2799987792969,134.09092712402344,0.0,5,H3
sample_6.pdf,11,(1 + log,9.962599754333496,CMR10,False,370.5150146484375,134.0908660888672,0.0,8,H3
sample_6.pdf,11,Therefore:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,160.82044982910156,0.1,10,H3
sample_6.pdf,11,)) =,9.962599754333496,CMR10,False,256.44097900390625,179.86387634277344,0.0,4,H3
sample_6.pdf,11,) (log,9.962599754333496,CMR10,False,307.6399841308594,179.86387634277344,0.0,6,H3
sample_6.pdf,11,log,9.962599754333496,CMR10,False,366.7380065917969,179.86387634277344,0.0,3,H3
sample_6.pdf,11,1 + log((,9.962599754333496,CMR10,False,307.1230163574219,210.64292907714844,0.0,9,H3
sample_6.pdf,11,When using a recognition model,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,238.0504913330078,0.03333333333333333,30,H3
sample_6.pdf,11,then,9.962599754333496,NimbusRomNo9L-Regu,False,279.0014343261719,238.0504913330078,0.0,4,H3
sample_6.pdf,11,and s.d.,9.962599754333496,NimbusRomNo9L-Regu,False,310.70550537109375,238.0504913330078,0.0,8,H3
sample_6.pdf,11,are simply functions of,9.962599754333496,NimbusRomNo9L-Regu,False,360.1183166503906,238.0504913330078,0.0,23,H3
sample_6.pdf,11,and the,9.962599754333496,NimbusRomNo9L-Regu,False,469.94427490234375,238.0504913330078,0.0,7,H3
sample_6.pdf,11,variational parameters,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,249.0094757080078,0.0,22,H3
sample_6.pdf,11,", as exempliﬁed in the text.",9.962599754333496,NimbusRomNo9L-Regu,False,206.14599609375,249.0094757080078,0.0,28,H3
sample_6.pdf,11,MLP’s as probabilistic encoders and decoders,11.9552001953125,NimbusRomNo9L-Medi,False,128.58685302734375,275.8531494140625,0.06818181818181818,44,H3
sample_6.pdf,11,"In variational auto-encoders, neural networks are used as probabilistic encoders and decoders. There",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,300.70843505859375,0.02,100,H3
sample_6.pdf,11,"are many possible choices of encoders and decoders, depending on the type of data and model. In",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,311.66741943359375,0.010526315789473684,95,H3
sample_6.pdf,11,"our example we used relatively simple neural networks, namely multi-layered perceptrons (MLPs).",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,322.62640380859375,0.031578947368421054,95,H3
sample_6.pdf,11,"For the encoder we used a MLP with Gaussian output, while for the decoder we used MLPs with",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,333.58538818359375,0.08791208791208792,91,H3
sample_6.pdf,11,"either Gaussian or Bernoulli outputs, depending on the type of data.",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,344.54339599609375,0.029411764705882353,68,H3
sample_6.pdf,11,C.1,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,369.0324401855469,0.3333333333333333,3,H3
sample_6.pdf,11,Bernoulli MLP as decoder,9.962599754333496,NimbusRomNo9L-Medi,False,132.62753295898438,369.0324401855469,0.16666666666666666,24,H3
sample_6.pdf,11,In this case let,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,389.6463928222656,0.0625,16,H3
sample_6.pdf,11,be a multivariate Bernoulli whose probabilities are computed from,9.962599754333496,NimbusRomNo9L-Regu,False,200.09144592285156,389.6463928222656,0.015384615384615385,65,H3
sample_6.pdf,11,with a,9.962599754333496,NimbusRomNo9L-Regu,False,476.61688232421875,389.6463928222656,0.0,6,H3
sample_6.pdf,11,fully-connected neural network with a single hidden layer:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,400.60540771484375,0.0,58,H3
sample_6.pdf,11,log,9.962599754333496,CMR10,False,204.4010009765625,426.3448791503906,0.0,3,H3
sample_6.pdf,11,) =,9.962599754333496,CMR10,False,241.72299194335938,426.3448791503906,0.0,3,H3
sample_6.pdf,11,log,9.962599754333496,CMR10,False,283.44342041015625,426.3448791503906,0.0,3,H3
sample_6.pdf,11,+ (1,9.962599754333496,CMR10,False,307.8334045410156,426.3448791503906,0.0,4,H3
sample_6.pdf,11,log(1,9.962599754333496,CMR10,False,359.4106140136719,426.3448791503906,0.0,5,H3
sample_6.pdf,11,where,9.962599754333496,NimbusRomNo9L-Regu,False,210.0709991455078,450.982421875,0.0,5,H3
sample_6.pdf,11,tanh(,9.962599754333496,CMR10,False,288.8170166015625,450.75189208984375,0.0,5,H3
sample_6.pdf,11,) +,9.962599754333496,CMR10,False,359.18792724609375,450.75189208984375,0.0,3,H3
sample_6.pdf,11,(11),9.962599754333496,NimbusRomNo9L-Regu,False,487.40191650390625,450.982421875,0.0,4,H3
sample_6.pdf,11,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,466.5434265136719,0.0,5,H3
sample_6.pdf,11,"is the elementwise sigmoid activation function, and where",9.962599754333496,NimbusRomNo9L-Regu,False,155.6323699951172,466.5434265136719,0.0,57,H3
sample_6.pdf,11,are,9.962599754333496,NimbusRomNo9L-Regu,False,489.3011779785156,466.5434265136719,0.0,3,H3
sample_6.pdf,11,the weights and biases of the MLP.,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,477.50244140625,0.08823529411764706,34,H3
sample_6.pdf,11,C.2,9.962599754333496,NimbusRomNo9L-Medi,False,107.9998779296875,501.9905090332031,0.3333333333333333,3,H3
sample_6.pdf,11,Gaussian MLP as encoder or decoder,9.962599754333496,NimbusRomNo9L-Medi,False,132.62742614746094,501.9905090332031,0.11764705882352941,34,H3
sample_6.pdf,11,In this case let encoder or decoder be a multivariate Gaussian with a diagonal covariance structure:,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,522.6044921875,0.02,100,H3
sample_6.pdf,11,log,9.962599754333496,CMR10,False,242.71487426757812,537.9349365234375,0.0,3,H3
sample_6.pdf,11,) = log,9.962599754333496,CMR10,False,280.036865234375,537.9349365234375,0.0,7,H3
sample_6.pdf,11,where,9.962599754333496,NimbusRomNo9L-Regu,False,247.53787231445312,552.1134643554688,0.0,5,H3
sample_6.pdf,11,log,9.962599754333496,CMR10,False,257.71087646484375,567.762939453125,0.0,3,H3
sample_6.pdf,11,= tanh(,9.962599754333496,CMR10,False,283.9119567871094,581.7109375,0.0,7,H3
sample_6.pdf,11,(12),9.962599754333496,NimbusRomNo9L-Regu,False,487.4028625488281,581.9414672851562,0.0,4,H3
sample_6.pdf,11,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,597.50244140625,0.0,5,H3
sample_6.pdf,11,are the weights and biases of the MLP and part of,9.962599754333496,NimbusRomNo9L-Regu,False,248.49510192871094,597.50244140625,0.061224489795918366,49,H3
sample_6.pdf,11,when used,9.962599754333496,NimbusRomNo9L-Regu,False,458.6217956542969,597.50244140625,0.0,9,H3
sample_6.pdf,11,as decoder. Note that when this network is used as an encoder,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,608.4614868164062,0.01639344262295082,61,H3
sample_6.pdf,11,", then",9.962599754333496,NimbusRomNo9L-Regu,False,392.9078063964844,608.4614868164062,0.0,6,H3
sample_6.pdf,11,and,9.962599754333496,NimbusRomNo9L-Regu,False,423.1886901855469,608.4614868164062,0.0,3,H3
sample_6.pdf,11,"are swapped,",9.962599754333496,NimbusRomNo9L-Regu,False,449.1051330566406,608.4614868164062,0.0,12,H3
sample_6.pdf,11,and the weights and biases are variational parameters,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,619.4204711914062,0.0,53,H3
sample_6.pdf,11,Marginal likelihood estimator,11.9552001953125,NimbusRomNo9L-Medi,False,128.58665466308594,646.2651977539062,0.034482758620689655,29,H3
sample_6.pdf,11,We derived the following marginal likelihood estimator that produces good estimates of the marginal,9.962599754333496,NimbusRomNo9L-Regu,False,107.99980163574219,671.1194458007812,0.010101010101010102,99,H3
sample_6.pdf,11,"likelihood as long as the dimensionality of the sampled space is low (less then 5 dimensions), and",9.962599754333496,NimbusRomNo9L-Regu,False,107.99980163574219,682.0784912109375,0.0,98,H3
sample_6.pdf,11,sufﬁcient samples are taken. Let,9.962599754333496,NimbusRomNo9L-Regu,False,107.99980163574219,693.0374755859375,0.03125,32,H3
sample_6.pdf,11,) =,9.962599754333496,CMR10,False,268.1208190917969,692.8069458007812,0.0,3,H3
sample_6.pdf,11,be the generative model we are sampling,9.962599754333496,NimbusRomNo9L-Regu,False,340.060302734375,693.0374755859375,0.0,39,H3
sample_6.pdf,11,"from, and for a given datapoint",9.962599754333496,NimbusRomNo9L-Regu,False,107.99983215332031,705.3694458007812,0.0,31,H3
sample_6.pdf,11,we would like to estimate the marginal likelihood,9.962599754333496,NimbusRomNo9L-Regu,False,252.12782287597656,705.3694458007812,0.0,49,H3
sample_6.pdf,11,The estimation process consists of three stages:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,722.3064575195312,0.020833333333333332,48,H3
sample_6.pdf,12,1. Sample,9.962599754333496,NimbusRomNo9L-Regu,False,131.41200256347656,84.26844787597656,0.1111111111111111,9,H3
sample_6.pdf,12,values,9.962599754333496,NimbusRomNo9L-Regu,False,182.50953674316406,84.26844787597656,0.0,6,H3
sample_6.pdf,12,"from the posterior using gradient-based MCMC, e.g. Hybrid Monte",9.962599754333496,NimbusRomNo9L-Regu,False,235.9943084716797,84.26844787597656,0.09523809523809523,63,H3
sample_6.pdf,12,"Carlo, using",9.962599754333496,NimbusRomNo9L-Regu,False,143.86502075195312,95.22743225097656,0.08333333333333333,12,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,207.38192749023438,94.99687194824219,0.0,3,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,251.9940185546875,94.99687194824219,0.0,3,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,281.4709167480469,94.99687194824219,0.0,3,H3
sample_6.pdf,12,) +,9.962599754333496,CMR10,False,317.26800537109375,94.99687194824219,0.0,3,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,345.6379089355469,94.99687194824219,0.0,3,H3
sample_6.pdf,12,2. Fit a density estimator,9.962599754333496,NimbusRomNo9L-Regu,False,131.4119873046875,111.50746154785156,0.038461538461538464,26,H3
sample_6.pdf,12,to these samples,9.962599754333496,NimbusRomNo9L-Regu,False,252.83843994140625,111.50746154785156,0.0,16,H3
sample_6.pdf,12,"3. Again, sample",9.962599754333496,NimbusRomNo9L-Regu,False,131.41197204589844,126.41249084472656,0.0625,16,H3
sample_6.pdf,12,"new values from the posterior. Plug these samples, as well as the ﬁtted",9.962599754333496,NimbusRomNo9L-Regu,False,211.95350646972656,126.41249084472656,0.014084507042253521,71,H3
sample_6.pdf,12,", into the following estimator:",9.962599754333496,NimbusRomNo9L-Regu,False,161.51095581054688,137.37147521972656,0.0,31,H3
sample_6.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,364.9070129394531,167.8875274658203,0.0,5,H3
sample_6.pdf,12,Derivation of the estimator:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,198.5435333251953,0.03571428571428571,28,H3
sample_6.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,334.1040344238281,315.98046875,0.0,5,H3
sample_6.pdf,12,Monte Carlo EM,11.9552001953125,NimbusRomNo9L-Medi,False,127.92935180664062,351.482177734375,0.2857142857142857,14,H3
sample_6.pdf,12,"The Monte Carlo EM algorithm does not employ an encoder, instead it samples from the pos-",9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,376.7294921875,0.056179775280898875,89,H3
sample_6.pdf,12,terior of the latent variables using gradients of the posterior computed with,9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,387.6884765625,0.0,77,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,441.804931640625,387.45794677734375,0.0,3,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,486.4170227050781,387.45794677734375,0.0,3,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,120.31893920898438,398.41693115234375,0.0,3,H3
sample_6.pdf,12,) +,9.962599754333496,CMR10,False,156.11703491210938,398.41693115234375,0.0,3,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,186.56593322753906,398.41693115234375,0.0,3,H3
sample_6.pdf,12,. The Monte Carlo EM procedure consists of 10 HMC leapfrog,9.962599754333496,NimbusRomNo9L-Regu,False,235.05201721191406,398.6474609375,0.13793103448275862,58,H3
sample_6.pdf,12,"steps with an automatically tuned stepsize such that the acceptance rate was 90%, followed by 5",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,409.60546875,0.0,95,H3
sample_6.pdf,12,weight updates steps using the acquired sample. For all algorithms the parameters were updated,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,420.564453125,0.010638297872340425,94,H3
sample_6.pdf,12,using the Adagrad stepsizes (with accompanying annealing schedule).,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,431.5234375,0.014925373134328358,67,H3
sample_6.pdf,12,"The marginal likelihood was estimated with the ﬁrst 1000 datapoints from the train and test sets,",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,448.46044921875,0.010309278350515464,97,H3
sample_6.pdf,12,for each datapoint sampling 50 values from the posterior of the latent variables using Hybrid Monte,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,459.41943359375,0.020202020202020204,99,H3
sample_6.pdf,12,Carlo with 4 leapfrog steps.,9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,470.37841796875,0.03571428571428571,28,H3
sample_6.pdf,12,Full VB,11.9552001953125,NimbusRomNo9L-Medi,False,127.25984191894531,497.6151123046875,0.42857142857142855,7,H3
sample_6.pdf,12,"As written in the paper, it is possible to perform variational inference on both the parameters",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,522.8624267578125,0.010526315789473684,95,H3
sample_6.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,486.6759948730469,522.8624267578125,0.0,3,H3
sample_6.pdf,12,the latent variables,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,533.8204345703125,0.0,20,H3
sample_6.pdf,12,", as opposed to just the latent variables as we did in the paper. Here, we’ll derive",9.962599754333496,NimbusRomNo9L-Regu,False,189.4919891357422,533.8204345703125,0.011904761904761904,84,H3
sample_6.pdf,12,our estimator for that case.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,544.7794189453125,0.0,28,H3
sample_6.pdf,12,Let,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,561.7164306640625,0.3333333333333333,3,H3
sample_6.pdf,12,"be some hyperprior for the parameters introduced above, parameterized by",9.962599754333496,NimbusRomNo9L-Regu,False,150.5514373779297,561.7164306640625,0.0,72,H3
sample_6.pdf,12,. The,9.962599754333496,NimbusRomNo9L-Regu,False,478.1949462890625,561.7164306640625,0.2,5,H3
sample_6.pdf,12,marginal likelihood can be written as:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,572.6754150390625,0.0,38,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,206.88194274902344,590.1859130859375,0.0,3,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,245.4849395751953,590.1859130859375,0.0,3,H3
sample_6.pdf,12,)) +,9.962599754333496,CMR10,False,350.3849182128906,590.1859130859375,0.0,4,H3
sample_6.pdf,12,(13),9.962599754333496,NimbusRomNo9L-Regu,False,487.4018859863281,590.4164428710938,0.0,4,H3
sample_6.pdf,12,"where the ﬁrst RHS term denotes a KL divergence of the approximate from the true posterior, and",9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,608.1574096679688,0.05263157894736842,95,H3
sample_6.pdf,12,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,619.116455078125,0.0,5,H3
sample_6.pdf,12,denotes the variational lower bound to the marginal likelihood:,9.962599754333496,NimbusRomNo9L-Regu,False,169.63832092285156,619.116455078125,0.0,63,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,211.13186645507812,642.7158813476562,0.0,3,H3
sample_6.pdf,12,) (log,9.962599754333496,CMR10,False,260.2208557128906,642.7158813476562,0.0,6,H3
sample_6.pdf,12,) + log,9.962599754333496,CMR10,False,306.8368225097656,642.7158813476562,0.0,7,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,374.7948303222656,642.7158813476562,0.0,3,H3
sample_6.pdf,12,(14),9.962599754333496,NimbusRomNo9L-Regu,False,487.4018249511719,642.9464111328125,0.0,4,H3
sample_6.pdf,12,Note that this is a lower bound since the KL divergence is non-negative; the bound equals the true,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,666.0984497070312,0.030612244897959183,98,H3
sample_6.pdf,12,marginal when the approximate and true posteriors match exactly. The term,9.962599754333496,NimbusRomNo9L-Regu,False,107.99981689453125,677.0574340820312,0.0136986301369863,73,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,408.800537109375,676.826904296875,0.0,3,H3
sample_6.pdf,12,is composed,9.962599754333496,NimbusRomNo9L-Regu,False,452.2412414550781,677.0574340820312,0.0,11,H3
sample_6.pdf,12,of a sum over the marginal likelihoods of individual datapoints,9.962599754333496,NimbusRomNo9L-Regu,False,107.99978637695312,690.3184204101562,0.0,63,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,366.6287536621094,690.087890625,0.0,3,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,407.27276611328125,690.087890625,0.0,3,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,453.4987487792969,690.087890625,0.0,3,H3
sample_6.pdf,12,which can each be rewritten as:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99972534179688,701.2774047851562,0.0,31,H3
sample_6.pdf,12,log,9.962599754333496,CMR10,False,184.35671997070312,718.7879028320312,0.0,3,H3
sample_6.pdf,12,) =,9.962599754333496,CMR10,False,228.49270629882812,718.7879028320312,0.0,3,H3
sample_6.pdf,12,)) +,9.962599754333496,CMR10,False,355.6377258300781,718.7879028320312,0.0,4,H3
sample_6.pdf,12,(15),9.962599754333496,NimbusRomNo9L-Regu,False,487.4017333984375,719.0184326171875,0.0,4,H3
sample_6.pdf,13,"where again the ﬁrst RHS term is the KL divergence of the approximate from the true posterior, and",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,84.26844787597656,0.05102040816326531,98,H3
sample_6.pdf,13,is the variational lower bound of the marginal likelihood of datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,150.53746032714844,95.22743225097656,0.0,70,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,203.82896423339844,118.38389587402344,0.0,3,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,272.3919677734375,118.38389587402344,0.0,3,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,324.3879699707031,118.38389587402344,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,390.12701416015625,118.38389587402344,0.0,3,H3
sample_6.pdf,13,(16),9.962599754333496,NimbusRomNo9L-Regu,False,487.4020080566406,118.61445617675781,0.0,4,H3
sample_6.pdf,13,The expectations on the RHS of eqs (14) and (16) can obviously be written as a sum of three separate,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,147.3014678955078,0.04,100,H3
sample_6.pdf,13,"expectations, of which the second and third component can sometimes be analytically solved, e.g.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,158.2604522705078,0.0,96,H3
sample_6.pdf,13,when both,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,169.2194366455078,0.0,9,H3
sample_6.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,176.82345581054688,169.2194366455078,0.0,3,H3
sample_6.pdf,13,are Gaussian. For generality we will here assume that each of these,9.962599754333496,NimbusRomNo9L-Regu,False,228.9744415283203,169.2194366455078,0.029850746268656716,67,H3
sample_6.pdf,13,expectations is intractable.,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,180.1784210205078,0.0,28,H3
sample_6.pdf,13,Under certain mild conditions outlined in section (see paper) for chosen approximate posteriors,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,197.1154327392578,0.010526315789473684,95,H3
sample_6.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,132.18243408203125,208.0734405517578,0.0,3,H3
sample_6.pdf,13,we can reparameterize conditional samples,9.962599754333496,NimbusRomNo9L-Regu,False,183.72242736816406,208.0734405517578,0.0,41,H3
sample_6.pdf,13,with,9.962599754333496,NimbusRomNo9L-Regu,False,304.177978515625,225.37245178222656,0.0,4,H3
sample_6.pdf,13,(17),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019775390625,225.37245178222656,0.0,4,H3
sample_6.pdf,13,where we choose a prior,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,242.6714630126953,0.0,23,H3
sample_6.pdf,13,and a function,9.962599754333496,NimbusRomNo9L-Regu,False,225.44239807128906,242.6714630126953,0.0,14,H3
sample_6.pdf,13,such that the following holds:,9.962599754333496,NimbusRomNo9L-Regu,False,321.2804260253906,242.6714630126953,0.0,30,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,178.59194946289062,266.18792724609375,0.0,3,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,247.1559600830078,266.18792724609375,0.0,3,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,299.1509704589844,266.18792724609375,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,364.8909912109375,266.18792724609375,0.0,3,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,232.5599822998047,293.19793701171875,0.0,3,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,284.55499267578125,293.19793701171875,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,350.2950134277344,293.19793701171875,0.0,3,H3
sample_6.pdf,13,(18),9.962599754333496,NimbusRomNo9L-Regu,False,487.4020080566406,293.428466796875,0.0,4,H3
sample_6.pdf,13,The same can be done for the approximate posterior,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,320.2244567871094,0.02,50,H3
sample_6.pdf,13,with,9.962599754333496,NimbusRomNo9L-Regu,False,299.4129943847656,340.2354431152344,0.0,4,H3
sample_6.pdf,13,(19),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019470214844,340.2354431152344,0.0,4,H3
sample_6.pdf,13,"where we, similarly as above, choose a prior",9.962599754333496,NimbusRomNo9L-Regu,False,107.99993896484375,357.5344543457031,0.0,44,H3
sample_6.pdf,13,and a function,9.962599754333496,NimbusRomNo9L-Regu,False,314.7193603515625,357.5344543457031,0.0,14,H3
sample_6.pdf,13,such that the following,9.962599754333496,NimbusRomNo9L-Regu,False,406.0513610839844,357.5344543457031,0.0,23,H3
sample_6.pdf,13,holds:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,368.4924621582031,0.0,6,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,196.57791137695312,389.2729187011719,0.0,3,H3
sample_6.pdf,13,) (log,9.962599754333496,CMR10,False,245.66592407226562,389.2729187011719,0.0,6,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,292.28289794921875,389.2729187011719,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,360.24090576171875,389.2729187011719,0.0,3,H3
sample_6.pdf,13,) (log,9.962599754333496,CMR10,False,239.92889404296875,416.2829284667969,0.0,6,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,286.5458679199219,416.2829284667969,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,354.50286865234375,416.2829284667969,0.0,3,H3
sample_6.pdf,13,(20),9.962599754333496,NimbusRomNo9L-Regu,False,487.40185546875,416.513427734375,0.0,4,H3
sample_6.pdf,13,For notational conciseness we introduce a shorthand notation,9.962599754333496,NimbusRomNo9L-Regu,False,107.99984741210938,449.28741455078125,0.016666666666666666,60,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,168.62692260742188,466.35589599609375,0.0,3,H3
sample_6.pdf,13,(log,9.962599754333496,CMR10,False,199.8595428466797,466.35589599609375,0.0,4,H3
sample_6.pdf,13,) + log,9.962599754333496,CMR10,False,248.3969268798828,466.35589599609375,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,314.136962890625,466.35589599609375,0.0,3,H3
sample_6.pdf,13,)) + log,9.962599754333496,CMR10,False,356.9639587402344,466.35589599609375,0.0,8,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,428.7959899902344,466.35589599609375,0.0,3,H3
sample_6.pdf,13,(21),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019775390625,466.58642578125,0.0,4,H3
sample_6.pdf,13,"Using equations (20) and (18), the Monte Carlo estimate of the variational lower bound, given",9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,483.88543701171875,0.03225806451612903,93,H3
sample_6.pdf,13,datapoint,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,495.8844299316406,0.0,9,H3
sample_6.pdf,13,", is:",9.962599754333496,NimbusRomNo9L-Regu,False,163.16098022460938,495.8844299316406,0.0,5,H3
sample_6.pdf,13,", g",9.962599754333496,CMMI10,False,309.0149841308594,523.3619384765625,0.0,3,H3
sample_6.pdf,13,", h",9.962599754333496,CMMI10,False,365.87298583984375,523.3619384765625,0.0,3,H3
sample_6.pdf,13,(22),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019775390625,523.5924682617188,0.0,4,H3
sample_6.pdf,13,where,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,552.7534790039062,0.0,5,H3
sample_6.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,183.14341735839844,552.7534790039062,0.0,3,H3
sample_6.pdf,13,. The estimator only depends on samples from,9.962599754333496,NimbusRomNo9L-Regu,False,252.68194580078125,552.7534790039062,0.022727272727272728,44,H3
sample_6.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,464.7633972167969,552.7534790039062,0.0,3,H3
sample_6.pdf,13,which are obviously not inﬂuenced by,9.962599754333496,NimbusRomNo9L-Regu,False,107.99990844726562,563.71142578125,0.0,36,H3
sample_6.pdf,13,", therefore the estimator can be differentiated w.r.t.",9.962599754333496,NimbusRomNo9L-Regu,False,277.3179016113281,563.71142578125,0.0,54,H3
sample_6.pdf,13,The resulting stochastic gradients can be used in conjunction with stochastic optimization methods,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,574.6704711914062,0.01020408163265306,98,H3
sample_6.pdf,13,such as SGD or Adagrad [DHS10]. See algorithm 1 for a basic approach to computing stochastic,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,585.6294555664062,0.08695652173913043,92,H3
sample_6.pdf,13,gradients.,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,596.5884399414062,0.0,10,H3
sample_6.pdf,13,F.1,9.962599754333496,NimbusRomNo9L-Medi,False,107.9998779296875,621.3895263671875,0.3333333333333333,3,H3
sample_6.pdf,13,Example,9.962599754333496,NimbusRomNo9L-Medi,False,130.42568969726562,621.3895263671875,0.14285714285714285,7,H3
sample_6.pdf,13,Let the prior over the parameters and latent variables be the centered isotropic Gaussian,9.962599754333496,NimbusRomNo9L-Regu,False,107.9998779296875,642.00341796875,0.02247191011235955,89,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,488.63287353515625,641.7728881835938,0.0,3,H3
sample_6.pdf,13,and,9.962599754333496,NimbusRomNo9L-Regu,False,149.413330078125,652.9624633789062,0.0,3,H3
sample_6.pdf,13,) =,9.962599754333496,CMR10,False,189.432861328125,652.73193359375,0.0,3,H3
sample_6.pdf,13,". Note that in this case, the prior lacks parameters. Let’s also",9.962599754333496,NimbusRomNo9L-Regu,False,250.86183166503906,652.9624633789062,0.03125,64,H3
sample_6.pdf,13,assume that the true posteriors are approximatily Gaussian with an approximately diagonal covari-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99983215332031,663.9214477539062,0.010309278350515464,97,H3
sample_6.pdf,13,"ance. In this case, we can let the variational approximate posteriors be multivariate Gaussians with",9.962599754333496,NimbusRomNo9L-Regu,False,107.99983215332031,674.8804321289062,0.02,100,H3
sample_6.pdf,13,a diagonal covariance structure:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99983215332031,685.8394775390625,0.0,32,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,246.22283935546875,702.9069213867188,0.0,3,H3
sample_6.pdf,13,) = log,9.962599754333496,CMR10,False,281.059814453125,702.9069213867188,0.0,7,H3
sample_6.pdf,13,log,9.962599754333496,CMR10,False,238.23284912109375,718.7879028320312,0.0,3,H3
sample_6.pdf,13,) = log,9.962599754333496,CMR10,False,281.05987548828125,718.7879028320312,0.0,7,H3
sample_6.pdf,13,(23),9.962599754333496,NimbusRomNo9L-Regu,False,487.4018859863281,719.0184326171875,0.0,4,H3
sample_6.pdf,14,Algorithm 2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,83.86949920654297,0.09090909090909091,11,H3
sample_6.pdf,14,Pseudocode for computing a stochastic gradient using our estimator. See text for,9.962599754333496,NimbusRomNo9L-Regu,False,161.1405029296875,83.96046447753906,0.025,80,H3
sample_6.pdf,14,meaning of the functions,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,94.91847229003906,0.0,24,H3
sample_6.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,236.080078125,94.91847229003906,0.0,3,H3
sample_6.pdf,14,Require:,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,110.97252655029297,0.125,8,H3
sample_6.pdf,14,(Current value of variational parameters),9.962599754333496,NimbusRomNo9L-Regu,False,157.5333251953125,111.06349182128906,0.024390243902439025,41,H3
sample_6.pdf,14,for,9.962599754333496,NimbusRomNo9L-Medi,False,117.9629898071289,132.8905029296875,0.0,3,H3
sample_6.pdf,14,Random draw from dataset,9.962599754333496,NimbusRomNo9L-Regu,False,154.1739959716797,143.94044494628906,0.041666666666666664,24,H3
sample_6.pdf,14,Random draw from prior,9.962599754333496,NimbusRomNo9L-Regu,False,152.94200134277344,154.89942932128906,0.045454545454545456,22,H3
sample_6.pdf,14,Random draw from prior,9.962599754333496,NimbusRomNo9L-Regu,False,153.8109893798828,165.85841369628906,0.045454545454545456,22,H3
sample_6.pdf,14,", g",9.962599754333496,CMMI10,False,215.4539794921875,176.58689880371094,0.0,3,H3
sample_6.pdf,14,", h",9.962599754333496,CMMI10,False,253.74195861816406,176.58689880371094,0.0,3,H3
sample_6.pdf,14,end for,9.962599754333496,NimbusRomNo9L-Medi,False,117.96299743652344,187.68548583984375,0.0,7,H3
sample_6.pdf,14,return,9.962599754333496,NimbusRomNo9L-Medi,False,117.96299743652344,198.64447021484375,0.0,6,H3
sample_6.pdf,14,where,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,234.94349670410156,0.0,5,H3
sample_6.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,146.04591369628906,234.94349670410156,0.0,3,H3
sample_6.pdf,14,are yet unspeciﬁed functions of,9.962599754333496,NimbusRomNo9L-Regu,False,177.42691040039062,234.94349670410156,0.0,31,H3
sample_6.pdf,14,". Since they are Gaussian, we can parameterize",9.962599754333496,NimbusRomNo9L-Regu,False,314.8999938964844,234.94349670410156,0.043478260869565216,46,H3
sample_6.pdf,14,the variational approximate posteriors:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,245.90248107910156,0.0,39,H3
sample_6.pdf,14,where,9.962599754333496,NimbusRomNo9L-Regu,False,362.43304443359375,265.85345458984375,0.0,5,H3
sample_6.pdf,14,where,9.962599754333496,NimbusRomNo9L-Regu,False,363.301025390625,279.80145263671875,0.0,5,H3
sample_6.pdf,14,With,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,297.7344665527344,0.25,4,H3
sample_6.pdf,14,we signify an element-wise product. These can be plugged into the lower bound deﬁned,9.962599754333496,NimbusRomNo9L-Regu,False,141.73399353027344,297.7344665527344,0.011904761904761904,84,H3
sample_6.pdf,14,above (eqs (21) and (22)).,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,308.6934814453125,0.0,26,H3
sample_6.pdf,14,"In this case it is possible to construct an alternative estimator with a lower variance, since in this",9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,325.6294860839844,0.00980392156862745,102,H3
sample_6.pdf,14,model,9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,336.5885009765625,0.0,5,H3
sample_6.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,217.514404296875,336.5885009765625,0.0,3,H3
sample_6.pdf,14,"are Gaussian, and therefore four terms of",9.962599754333496,NimbusRomNo9L-Regu,False,268.89141845703125,336.5885009765625,0.024390243902439025,41,H3
sample_6.pdf,14,can be solved,9.962599754333496,NimbusRomNo9L-Regu,False,447.17901611328125,336.5885009765625,0.0,13,H3
sample_6.pdf,14,analytically. The resulting estimator is:,9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,347.5474853515625,0.024390243902439025,41,H3
sample_6.pdf,14,1 + log((,9.962599754333496,CMR10,False,252.802001953125,377.8679504394531,0.0,9,H3
sample_6.pdf,14,+ log,9.962599754333496,CMR10,False,408.8829650878906,377.867919921875,0.0,5,H3
sample_6.pdf,14,1 + log((,9.962599754333496,CMR10,False,199.80899047851562,415.50994873046875,0.0,9,H3
sample_6.pdf,14,(24),9.962599754333496,NimbusRomNo9L-Regu,False,487.4019775390625,415.7404479980469,0.0,4,H3
sample_6.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,126.03697204589844,448.2224426269531,0.0,3,H3
sample_6.pdf,14,simply denote the,9.962599754333496,NimbusRomNo9L-Regu,False,160.99798583984375,448.2224426269531,0.0,17,H3
sample_6.pdf,14,-th element of vectors,9.962599754333496,NimbusRomNo9L-Regu,False,239.00498962402344,448.2224426269531,0.0,22,H3
sample_6.pdf,14,and,9.962599754333496,NimbusRomNo9L-Regu,False,347.5849914550781,448.2224426269531,0.0,3,H3
sample_7.pdf,1,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,1,NIVERSAL,13.772299766540527,NimbusRomNo9L-Regu,False,121.72100067138672,83.00323486328125,1.0,8,TITLE
sample_7.pdf,1,RANSFORMERS,13.772299766540527,NimbusRomNo9L-Regu,False,211.4290008544922,83.00323486328125,1.0,11,TITLE
sample_7.pdf,1,Mostafa Dehghani,9.962599754333496,NimbusRomNo9L-Medi,False,117.96299743652344,113.92552947998047,0.125,16,H3
sample_7.pdf,1,Stephan Gouws,9.962599754333496,NimbusRomNo9L-Medi,False,230.35000610351562,113.92552947998047,0.15384615384615385,13,H3
sample_7.pdf,1,Oriol Vinyals,9.962599754333496,NimbusRomNo9L-Medi,False,344.9200134277344,113.92552947998047,0.15384615384615385,13,H3
sample_7.pdf,1,University of Amsterdam,9.962599754333496,NimbusRomNo9L-Regu,False,117.9630126953125,126.36750793457031,0.08695652173913043,23,H3
sample_7.pdf,1,DeepMind,9.962599754333496,NimbusRomNo9L-Regu,False,230.35113525390625,126.36750793457031,0.25,8,H3
sample_7.pdf,1,DeepMind,9.962599754333496,NimbusRomNo9L-Regu,False,346.91351318359375,126.36750793457031,0.25,8,H3
sample_7.pdf,1,dehghani@uva.nl,9.962599754333496,NimbusMonL-Regu,False,117.9630126953125,138.20742797851562,0.0,15,H3
sample_7.pdf,1,sgouws@google.com,9.962599754333496,NimbusMonL-Regu,False,230.3510284423828,138.20742797851562,0.0,17,H3
sample_7.pdf,1,vinyals@google.com,9.962599754333496,NimbusMonL-Regu,False,346.9135437011719,138.20742797851562,0.0,18,H3
sample_7.pdf,1,Jakob Uszkoreit,9.962599754333496,NimbusRomNo9L-Medi,False,117.9630126953125,163.3275146484375,0.13333333333333333,15,H3
sample_7.pdf,1,Łukasz Kaiser,9.962599754333496,NimbusRomNo9L-Medi,False,230.35110473632812,163.3275146484375,0.15384615384615385,13,H3
sample_7.pdf,1,Google Brain,9.962599754333496,NimbusRomNo9L-Regu,False,117.9630126953125,175.7694854736328,0.16666666666666666,12,H3
sample_7.pdf,1,Google Brain,9.962599754333496,NimbusRomNo9L-Regu,False,230.35110473632812,175.7694854736328,0.16666666666666666,12,H3
sample_7.pdf,1,usz@google.com,9.962599754333496,NimbusMonL-Regu,False,117.9630126953125,187.60940551757812,0.0,14,H3
sample_7.pdf,1,lukaszkaiser@google.com,9.962599754333496,NimbusMonL-Regu,False,230.35104370117188,187.60940551757812,0.0,23,H3
sample_7.pdf,1,BSTRACT,9.56410026550293,NimbusRomNo9L-Regu,False,287.5180358886719,229.86668395996094,1.0,7,H3
sample_7.pdf,1,Recurrent neural networks (RNNs) sequentially process data by updating their,10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,255.03530883789062,0.05263157894736842,76,H3
sample_7.pdf,1,"state with each new data point, and have long been the de facto choice for sequence",9.952631950378418,NimbusRomNo9L-Regu,False,143.86500549316406,265.8580322265625,0.0,83,H3
sample_7.pdf,1,"modeling tasks. However, their inherently sequential computation makes them",10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,276.5142822265625,0.013333333333333334,75,H3
sample_7.pdf,1,slow to train. Feed-forward and convolutional architectures have recently been,10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,287.2543029785156,0.01282051282051282,78,H3
sample_7.pdf,1,shown to achieve superior results on some sequence modeling tasks such as machine,9.862470626831055,NimbusRomNo9L-Regu,False,143.86500549316406,298.1454162597656,0.0,81,H3
sample_7.pdf,1,"translation, with the added advantage that they concurrently process all inputs in",10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,308.7333068847656,0.0,82,H3
sample_7.pdf,1,"the sequence, leading to easy parallelization and faster training times. Despite these",9.902643203735352,NimbusRomNo9L-Regu,False,143.86500549316406,319.59393310546875,0.011627906976744186,86,H3
sample_7.pdf,1,"successes, however, popular feed-forward sequence models like the Transformer",10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,330.2132873535156,0.012987012987012988,77,H3
sample_7.pdf,1,"fail to generalize in many simple tasks that recurrent models handle with ease, e.g.",10.032095909118652,NimbusRomNo9L-Regu,False,143.86500549316406,340.9747619628906,0.0,84,H3
sample_7.pdf,1,copying strings or even simple logical inference when the string or formula lengths,9.952631950378418,NimbusRomNo9L-Regu,False,143.86500549316406,351.7750244140625,0.0,83,H3
sample_7.pdf,1,exceed those observed at training time. We propose the Universal Transformer,10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,362.4322814941406,0.039473684210526314,76,H3
sample_7.pdf,1,"(UT), a parallel-in-time self-attentive recurrent sequence model which can be",10.061732292175293,NimbusRomNo9L-Regu,False,143.53700256347656,373.1712951660156,0.025974025974025976,77,H3
sample_7.pdf,1,cast as a generalization of the Transformer model and which addresses these,10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,383.9112854003906,0.013333333333333334,75,H3
sample_7.pdf,1,issues. UTs combine the parallelizability and global receptive ﬁeld of feed-forward,9.927669525146484,NimbusRomNo9L-Regu,False,143.86500549316406,394.7529602050781,0.024096385542168676,83,H3
sample_7.pdf,1,sequence models like the Transformer with the recurrent inductive bias of RNNs.,10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,405.3902893066406,0.05063291139240506,79,H3
sample_7.pdf,1,We also add a dynamic per-position halting mechanism and ﬁnd that it improves,10.061732292175293,NimbusRomNo9L-Regu,False,143.39700317382812,416.1302795410156,0.012987012987012988,77,H3
sample_7.pdf,1,"accuracy on several tasks. In contrast to the standard Transformer, under certain",10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,426.87030029296875,0.024691358024691357,81,H3
sample_7.pdf,1,assumptions UTs can be shown to be Turing-complete. Our experiments show that,9.96757984161377,NimbusRomNo9L-Regu,False,143.86500549316406,437.6806945800781,0.05194805194805195,77,H3
sample_7.pdf,1,UTs outperform standard Transformers on a wide range of algorithmic and language,9.862470626831055,NimbusRomNo9L-Regu,False,143.86500549316406,448.50042724609375,0.0375,80,H3
sample_7.pdf,1,"understanding tasks, including the challenging LAMBADA language modeling",10.061732292175293,NimbusRomNo9L-Regu,False,143.86500549316406,459.08929443359375,0.09722222222222222,72,H3
sample_7.pdf,1,"task where UTs achieve a new state of the art, and machine translation where UTs",10.041984558105469,NimbusRomNo9L-Regu,False,143.86500549316406,469.8442687988281,0.05,80,H3
sample_7.pdf,1,achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset.,9.882577896118164,NimbusRomNo9L-Regu,False,143.86500549316406,480.70416259765625,0.13157894736842105,76,H3
sample_7.pdf,1,NTRODUCTION,9.56410026550293,NimbusRomNo9L-Regu,False,131.4080047607422,515.669677734375,1.0,11,H3
sample_7.pdf,1,Convolutional and fully-attentional feed-forward architectures like the Transformer have recently,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,538.25830078125,0.020618556701030927,97,H3
sample_7.pdf,1,emerged as viable alternatives to recurrent neural networks (RNNs) for a range of sequence,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,548.998291015625,0.03333333333333333,90,H3
sample_7.pdf,1,"modeling tasks, notably machine translation (Gehring et al., 2017; Vaswani et al., 2017). These",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,559.7372436523438,0.031578947368421054,95,H3
sample_7.pdf,1,"parallel-in-time architectures address a signiﬁcant shortcoming of RNNs, namely their inherently",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,570.477294921875,0.03125,96,H3
sample_7.pdf,1,"sequential computation which prevents parallelization across elements of the input sequence, whilst",10.022196769714355,NimbusRomNo9L-Regu,False,108.0,581.247314453125,0.0,99,H3
sample_7.pdf,1,"still addressing the vanishing gradients problem as the sequence length gets longer (Hochreiter et al.,",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,592.005126953125,0.009708737864077669,103,H3
sample_7.pdf,1,"2003). The Transformer model in particular relies entirely on a self-attention mechanism (Parikh et al.,",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,602.828369140625,0.028846153846153848,104,H3
sample_7.pdf,1,"2016; Lin et al., 2017) to compute a series of context-informed vector-space representations of the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,613.436279296875,0.010101010101010102,99,H3
sample_7.pdf,1,"symbols in its input and output, which are then used to predict distributions over subsequent symbols as",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,624.326416015625,0.0,104,H3
sample_7.pdf,1,the model predicts the output sequence symbol-by-symbol. Not only is this mechanism straightforward,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,635.06640625,0.010101010101010102,99,H3
sample_7.pdf,1,"to parallelize, but as each symbol’s representation is also directly informed by all other symbols’",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,645.6552734375,0.0,99,H3
sample_7.pdf,1,"representations, this results in an effectively global receptive ﬁeld across the whole sequence. This",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,656.394287109375,0.009900990099009901,101,H3
sample_7.pdf,1,stands in contrast to e.g. convolutional architectures which typically only have a limited receptive ﬁeld.,9.882577896118164,NimbusRomNo9L-Regu,False,108.0,667.2702026367188,0.0,106,H3
sample_7.pdf,1,"Notably, however, the Transformer with its ﬁxed stack of distinct layers foregoes RNNs’ inductive bias",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,683.9985961914062,0.049019607843137254,102,H3
sample_7.pdf,1,towards learning iterative or recursive transformations. Our experiments indicate that this inductive,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,694.6024780273438,0.009900990099009901,101,H3
sample_7.pdf,1,"Equal contribution, alphabetically by last name.",8.966400146484375,NimbusRomNo9L-Regu,False,130.25,712.1129150390625,0.020833333333333332,48,P
sample_7.pdf,1,Work performed while at Google Brain.,8.966400146484375,NimbusRomNo9L-Regu,False,127.57014465332031,719.2529296875,0.08108108108108109,37,P
sample_7.pdf,1,arXiv:1807.03819v3  [cs.CL]  5 Mar 2019,20.0,Times-Roman,False,10.940000534057617,215.03997802734375,0.10256410256410256,39,TITLE
sample_7.pdf,2,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,2,Per Position States,6.155400276184082,HelveticaNeue,False,110.56442260742188,109.68714904785156,0.15789473684210525,19,P
sample_7.pdf,2,Time,6.155400276184082,HelveticaNeue,False,323.75921630859375,177.9933624267578,0.25,4,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,175.18106079101562,105.79308319091797,0.14285714285714285,14,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,175.18106079101562,123.2041015625,0.14285714285714285,14,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,175.18106079101562,156.60955810546875,0.14285714285714285,14,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,231.44012451171875,105.79308319091797,0.10526315789473684,19,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,231.5633544921875,123.2041015625,0.10526315789473684,19,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,231.44012451171875,156.60955810546875,0.10526315789473684,19,P
sample_7.pdf,2,Parameters are tied across positions and time steps,6.155400276184082,HelveticaNeue,False,259.0567321777344,84.89139556884766,0.0196078431372549,51,P
sample_7.pdf,2,t+1,6.155400276184082,HelveticaNeue,False,308.4236755371094,103.46988677978516,0.0,3,P
sample_7.pdf,2,t+1,6.155400276184082,HelveticaNeue,False,308.4236755371094,120.88085174560547,0.0,3,P
sample_7.pdf,2,t+1,6.155400276184082,HelveticaNeue,False,309.3086242675781,154.5109405517578,0.0,3,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,355.0932312011719,105.7637939453125,0.14285714285714285,14,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,355.0932312011719,123.17475891113281,0.14285714285714285,14,P
sample_7.pdf,2,Self-Attention,6.155400276184082,HelveticaNeue,False,355.0932312011719,156.5802459716797,0.14285714285714285,14,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,411.352294921875,105.7637939453125,0.10526315789473684,19,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,411.4755859375,123.17475891113281,0.10526315789473684,19,P
sample_7.pdf,2,Transition Function,6.155400276184082,HelveticaNeue,False,411.352294921875,156.5802459716797,0.10526315789473684,19,P
sample_7.pdf,2,t+2,6.155400276184082,HelveticaNeue,False,488.3358459472656,103.46988677978516,0.0,3,P
sample_7.pdf,2,t+2,6.155400276184082,HelveticaNeue,False,488.3358459472656,120.88085174560547,0.0,3,P
sample_7.pdf,2,t+2,6.155400276184082,HelveticaNeue,False,490.6364440917969,154.5109405517578,0.0,3,P
sample_7.pdf,2,Figure 1: The Universal Transformer repeatedly reﬁnes a series of vector representations for each,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,199.55526733398438,0.041237113402061855,97,H3
sample_7.pdf,2,"position of the sequence in parallel, by combining information from different positions using",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,210.51431274414062,0.0,93,H3
sample_7.pdf,2,self-attention (see Eqn 2) and applying a recurrent transition function (see Eqn 4) across all time,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,221.47329711914062,0.020202020202020204,99,H3
sample_7.pdf,2,steps,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,232.43228149414062,0.0,5,H3
sample_7.pdf,2,. We show this process over two recurrent time-steps. Arrows denote dependencies,10.061732292175293,NimbusRomNo9L-Regu,False,168.43299865722656,232.43228149414062,0.025,80,H3
sample_7.pdf,2,"between operations. Initially,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,243.39126586914062,0.03333333333333333,30,H3
sample_7.pdf,2,is initialized with the embedding for each symbol in the sequence.,10.061732292175293,NimbusRomNo9L-Regu,False,240.61099243164062,243.39126586914062,0.0,66,H3
sample_7.pdf,2,represents the representation for input symbol,10.061732292175293,NimbusRomNo9L-Regu,False,119.5270004272461,254.35031127929688,0.0,46,H3
sample_7.pdf,2,at recurrent time-step,10.061732292175293,NimbusRomNo9L-Regu,False,346.2601318359375,254.35031127929688,0.0,22,H3
sample_7.pdf,2,. With dynamic,10.061732292175293,NimbusRomNo9L-Regu,False,440.8070068359375,254.35031127929688,0.07142857142857142,14,H3
sample_7.pdf,2,"halting,",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,265.38446044921875,0.0,8,H3
sample_7.pdf,2,is dynamically determined for each position (Section 2.2).,9.962599754333496,NimbusRomNo9L-Regu,False,145.97715759277344,265.38446044921875,0.017241379310344827,58,H3
sample_7.pdf,2,bias may be crucial for several algorithmic and language understanding tasks of varying complexity:,10.012289047241211,NimbusRomNo9L-Regu,False,108.0,288.38580322265625,0.0,99,H3
sample_7.pdf,2,"in contrast to models such as the Neural Turing Machine (Graves et al., 2014), the Neural GPU (Kaiser",9.882577896118164,NimbusRomNo9L-Regu,False,108.0,299.2241516113281,0.0891089108910891,101,H3
sample_7.pdf,2,"& Sutskever, 2016) or Stack RNNs (Joulin & Mikolov, 2015), the Transformer does not generalize",10.061732292175293,NimbusRomNo9L-Regu,False,107.61100006103516,309.8273010253906,0.0851063829787234,94,H3
sample_7.pdf,2,well to input lengths not encountered during training.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,320.6424560546875,0.0,54,H3
sample_7.pdf,2,"In this paper, we introduce the",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,337.3708190917969,0.03225806451612903,31,H3
sample_7.pdf,2,Universal Transformer (UT),9.947644233703613,NimbusRomNo9L-ReguItal,False,226.05027770996094,337.1946105957031,0.15384615384615385,26,H3
sample_7.pdf,2,", a parallel-in-time recurrent self-attentive",9.947644233703613,NimbusRomNo9L-Regu,False,339.97900390625,337.3708190917969,0.0,45,H3
sample_7.pdf,2,"sequence model which can be cast as a generalization of the Transformer model, yielding increased",10.056798934936523,NimbusRomNo9L-Regu,False,108.0,348.02801513671875,0.010309278350515464,97,H3
sample_7.pdf,2,theoretical capabilities and improved results on a wide range of challenging sequence-to-sequence,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,358.7642822265625,0.0,97,H3
sample_7.pdf,2,tasks. UTs combine the parallelizability and global receptive ﬁeld of feed-forward sequence models,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,369.53326416015625,0.02040816326530612,98,H3
sample_7.pdf,2,"like the Transformer with the recurrent inductive bias of RNNs, which seems to be better suited to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,380.2432861328125,0.04081632653061224,98,H3
sample_7.pdf,2,a range of algorithmic and natural language understanding sequence-to-sequence problems. As the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,390.9833068847656,0.010526315789473684,95,H3
sample_7.pdf,2,"name implies, and in contrast to the standard Transformer, under certain assumptions UTs can be",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,401.7222900390625,0.031578947368421054,95,H3
sample_7.pdf,2,"shown to be Turing-complete (or “computationally universal”, as shown in Section 4).",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,412.5374450683594,0.023809523809523808,84,H3
sample_7.pdf,2,"In each recurrent step, the Universal Transformer iteratively reﬁnes its representations for all symbols",9.937662124633789,NimbusRomNo9L-Regu,False,108.0,429.27337646484375,0.028846153846153848,104,H3
sample_7.pdf,2,"in the sequence in parallel using a self-attention mechanism (Parikh et al., 2016; Lin et al., 2017),",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,439.9192810058594,0.019801980198019802,101,H3
sample_7.pdf,2,followed by a transformation (shared across all positions and time-steps) consisting of a depth-wise,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,450.6705322265625,0.0,100,H3
sample_7.pdf,2,"separable convolution (Chollet, 2016; Kaiser et al., 2017) or a position-wise fully-connected layer",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,461.3982849121094,0.020202020202020204,99,H3
sample_7.pdf,2,"(see Fig 1). We also add a dynamic per-position halting mechanism (Graves, 2016), allowing the model",9.862470626831055,NimbusRomNo9L-Regu,False,107.6709976196289,472.2894287109375,0.03,100,H3
sample_7.pdf,2,to choose the required number of reﬁnement steps,9.932666778564453,NimbusRomNo9L-Regu,False,108.0,482.9761657714844,0.0,48,H3
sample_7.pdf,2,for each symbol,9.932666778564453,NimbusRomNo9L-ReguItal,False,302.9965515136719,482.80023193359375,0.0,15,H3
sample_7.pdf,2,"dynamically, and show for the ﬁrst",9.932666778564453,NimbusRomNo9L-Regu,False,367.1659851074219,482.9761657714844,0.0,34,H3
sample_7.pdf,2,"time that such a conditional computation mechanism can in fact improve accuracy on several smaller,",9.96757984161377,NimbusRomNo9L-Regu,False,108.0,493.6886901855469,0.0,99,H3
sample_7.pdf,2,structured algorithmic and linguistic inference tasks (although it marginally degraded results on MT).,9.95761775970459,NimbusRomNo9L-Regu,False,108.0,504.4362487792969,0.0196078431372549,102,H3
sample_7.pdf,2,Our strong experimental results show that UTs outperform Transformers and LSTMs across a wide,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,521.07421875,0.08602150537634409,93,H3
sample_7.pdf,2,range of tasks. The added recurrence yields improved results in machine translation where UTs,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,531.8142700195312,0.03225806451612903,93,H3
sample_7.pdf,2,outperform the standard Transformer. In experiments on several algorithmic tasks and the bAbI,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,542.5542602539062,0.043010752688172046,93,H3
sample_7.pdf,2,"language understanding task, UTs also consistently and signiﬁcantly improve over LSTMs and the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,553.2932739257812,0.06382978723404255,94,H3
sample_7.pdf,2,"standard Transformer. Furthermore, on the challenging LAMBADA text understanding data set UTs",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,564.089599609375,0.11827956989247312,93,H3
sample_7.pdf,2,with dynamic halting achieve a new state of the art.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,574.8484497070312,0.0,52,H3
sample_7.pdf,2,ODEL,9.56410026550293,NimbusRomNo9L-Regu,False,138.05499267578125,603.7236938476562,1.0,4,H3
sample_7.pdf,2,ESCRIPTION,9.56410026550293,NimbusRomNo9L-Regu,False,177.52999877929688,603.7236938476562,1.0,10,H3
sample_7.pdf,2,2.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,626.824462890625,0.0,3,H3
sample_7.pdf,2,NIVERSAL,7.970099925994873,NimbusRomNo9L-Regu,False,160.0349884033203,628.3355712890625,1.0,8,P
sample_7.pdf,2,RANSFORMER,7.970099925994873,NimbusRomNo9L-Regu,False,211.94898986816406,628.3355712890625,1.0,10,P
sample_7.pdf,2,The Universal Transformer (UT; see Fig. 2) is based on the popular encoder-decoder architecture,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,647.0532836914062,0.06315789473684211,95,H3
sample_7.pdf,2,"commonly used in most neural sequence-to-sequence models (Sutskever et al., 2014; Cho et al., 2014;",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,657.8987426757812,0.020202020202020204,99,H3
sample_7.pdf,2,"Vaswani et al., 2017). Both the encoder and decoder of the UT operate by applying a recurrent neural",9.977532386779785,NimbusRomNo9L-Regu,False,107.64099884033203,668.59619140625,0.04,100,H3
sample_7.pdf,2,"network to the representations of each of the positions of the input and output sequence, respectively.",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,679.3211059570312,0.0,103,H3
sample_7.pdf,2,"However, in contrast to most applications of recurrent neural networks to sequential data, the UT does",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,690.1177368164062,0.029411764705882353,102,H3
sample_7.pdf,2,"not recur over positions in the sequence, but over consecutive revisions of the vector representations of",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,700.8833618164062,0.0,105,H3
sample_7.pdf,2,"each position (i.e., over “depth”). In other words, the UT is not computationally bound by the number",9.942654609680176,NimbusRomNo9L-Regu,False,108.0,711.5816040039062,0.0297029702970297,101,H3
sample_7.pdf,2,"of symbols in the sequence, but only by the number of revisions made to each symbol’s representation.",9.90765380859375,NimbusRomNo9L-Regu,False,108.0,722.34814453125,0.0,101,H3
sample_7.pdf,3,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,3,"In each recurrent time-step, the representation of every position is concurrently (in parallel) revised",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,84.19326782226562,0.009708737864077669,103,H3
sample_7.pdf,3,"in two sub-steps: ﬁrst, using a self-attention mechanism to exchange information across all positions",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,94.98963165283203,0.0,101,H3
sample_7.pdf,3,"in the sequence, thereby generating a vector representation for each position that is informed by the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,105.67330932617188,0.0,101,H3
sample_7.pdf,3,"representations of all other positions at the previous time-step. Then, by applying a transition function",9.9126615524292,NimbusRomNo9L-Regu,False,108.0,116.52537536621094,0.009523809523809525,105,H3
sample_7.pdf,3,"(shared across position and time) to the outputs of the self-attention mechanism, independently at",10.061732292175293,NimbusRomNo9L-Regu,False,107.6709976196289,127.15231323242188,0.0,98,H3
sample_7.pdf,3,"each position. As the recurrent transition function can be applied any number of times, this implies",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,137.89230346679688,0.01,100,H3
sample_7.pdf,3,"that UTs can have variable depth (number of per-symbol processing steps). Crucially, this is in contrast",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,148.7824249267578,0.028846153846153848,104,H3
sample_7.pdf,3,"to most popular neural sequence models, including the Transformer (Vaswani et al., 2017) or deep",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,159.37130737304688,0.020833333333333332,96,H3
sample_7.pdf,3,"RNNs, which have constant depth as a result of applying a",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,170.11129760742188,0.05263157894736842,57,H3
sample_7.pdf,3,ﬁxed stack,10.061732292175293,NimbusRomNo9L-ReguItal,False,345.2183837890625,169.93307495117188,0.0,10,H3
sample_7.pdf,3,of layers. We now describe,10.061732292175293,NimbusRomNo9L-Regu,False,390.080810546875,170.11129760742188,0.038461538461538464,26,H3
sample_7.pdf,3,the encoder and decoder in more detail.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,180.9264678955078,0.0,39,H3
sample_7.pdf,3,NCODER,7.970099925994873,NimbusRomNo9L-Medi,False,115.39199829101562,199.08177185058594,1.0,6,P
sample_7.pdf,3,Given an input sequence of length,10.061732292175293,NimbusRomNo9L-Regu,False,156.19854736328125,197.56826782226562,0.030303030303030304,33,H3
sample_7.pdf,3,", we start with a matrix whose rows are initialized",10.061732292175293,NimbusRomNo9L-Regu,False,306.1319885253906,197.56826782226562,0.0,51,H3
sample_7.pdf,3,as the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,208.30728149414062,0.0,6,H3
sample_7.pdf,3,-dimensional embeddings of the symbols at each position of the sequence,10.061732292175293,NimbusRomNo9L-Regu,False,138.23300170898438,208.30728149414062,0.0,71,H3
sample_7.pdf,3,. The,10.061732292175293,NimbusRomNo9L-Regu,False,482.7969970703125,208.30728149414062,0.2,5,H3
sample_7.pdf,3,UT then iteratively computes representations,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,219.04727172851562,0.045454545454545456,44,H3
sample_7.pdf,3,at step,10.061732292175293,NimbusRomNo9L-Regu,False,304.9960021972656,219.04727172851562,0.0,7,H3
sample_7.pdf,3,for all,10.061732292175293,NimbusRomNo9L-Regu,False,336.32550048828125,219.04727172851562,0.0,7,H3
sample_7.pdf,3,positions in parallel by applying,10.061732292175293,NimbusRomNo9L-Regu,False,373.1221618652344,219.04727172851562,0.0,33,H3
sample_7.pdf,3,"the multi-headed dot-product self-attention mechanism from Vaswani et al. (2017), followed by a",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,229.78732299804688,0.010526315789473684,95,H3
sample_7.pdf,3,recurrent transition function. We also add residual connections around each of these function blocks,10.012289047241211,NimbusRomNo9L-Regu,False,108.0,240.5637664794922,0.01,100,H3
sample_7.pdf,3,"and apply dropout and layer normalization (Srivastava et al., 2014; Ba et al., 2016) (see Fig. 2 for a",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,251.26626586914062,0.029411764705882353,102,H3
sample_7.pdf,3,"simpliﬁed diagram, and Fig. 4 in the Appendix A for the complete model.).",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,262.08148193359375,0.0410958904109589,73,H3
sample_7.pdf,3,"More speciﬁcally, we use the scaled dot-product attention which combines queries",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,278.7232971191406,0.0125,80,H3
sample_7.pdf,3,", keys",10.061732292175293,NimbusRomNo9L-Regu,False,451.9219970703125,278.7232971191406,0.0,6,H3
sample_7.pdf,3,and,10.061732292175293,NimbusRomNo9L-Regu,False,486.2072448730469,278.7232971191406,0.0,3,H3
sample_7.pdf,3,values,9.962599754333496,NimbusRomNo9L-Regu,False,107.7509994506836,289.5384521484375,0.0,6,H3
sample_7.pdf,3,as follows,9.962599754333496,NimbusRomNo9L-Regu,False,140.7572021484375,289.5384521484375,0.0,10,H3
sample_7.pdf,3,TTENTION,7.970099925994873,NimbusRomNo9L-Regu,False,218.5340118408203,323.883544921875,1.0,8,P
sample_7.pdf,3,"Q,K,V",9.962599754333496,CMMI10,False,265.48602294921875,322.14190673828125,0.6,5,H3
sample_7.pdf,3,SOFTMAX,7.970099925994873,NimbusRomNo9L-Regu,False,308.2752380371094,323.883544921875,1.0,7,P
sample_7.pdf,3,(1),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,322.3724365234375,0.0,3,H3
sample_7.pdf,3,where,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,351.5122985839844,0.0,5,H3
sample_7.pdf,3,is the number of columns of,10.061732292175293,NimbusRomNo9L-Regu,False,140.0355224609375,351.5122985839844,0.0,27,H3
sample_7.pdf,3,and,10.061732292175293,NimbusRomNo9L-Regu,False,279.6362609863281,351.5122985839844,0.0,3,H3
sample_7.pdf,3,. We use the multi-head version with,10.061732292175293,NimbusRomNo9L-Regu,False,305.5911865234375,351.5122985839844,0.027777777777777776,36,H3
sample_7.pdf,3,"heads, as",10.061732292175293,NimbusRomNo9L-Regu,False,464.6935119628906,351.5122985839844,0.0,9,H3
sample_7.pdf,3,"introduced in (Vaswani et al., 2017),",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,362.32745361328125,0.02702702702702703,37,H3
sample_7.pdf,3,ULTI,7.970099925994873,NimbusRomNo9L-Regu,False,160.3489990234375,401.0585632324219,1.0,4,P
sample_7.pdf,3,EAD,7.970099925994873,NimbusRomNo9L-Regu,False,187.42698669433594,401.0585632324219,1.0,3,P
sample_7.pdf,3,ELF,7.970099925994873,NimbusRomNo9L-Regu,False,211.31698608398438,401.0585632324219,1.0,3,P
sample_7.pdf,3,TTENTION,7.970099925994873,NimbusRomNo9L-Regu,False,233.0059814453125,401.0585632324219,1.0,8,P
sample_7.pdf,3,ONCAT,7.970099925994873,NimbusRomNo9L-Regu,False,313.78497314453125,401.0585632324219,1.0,5,P
sample_7.pdf,3,(head,9.962599754333496,CMR10,False,342.5569763183594,399.3169250488281,0.0,5,H3
sample_7.pdf,3,",...,",9.962599754333496,CMMI10,False,371.3799743652344,399.3169250488281,0.0,5,H3
sample_7.pdf,3,head,9.962599754333496,CMR10,False,385.21697998046875,399.3169250488281,0.0,4,H3
sample_7.pdf,3,(2),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,399.5474548339844,0.0,3,H3
sample_7.pdf,3,where,9.962599754333496,NimbusRomNo9L-Regu,False,246.86700439453125,416.3074645996094,0.0,5,H3
sample_7.pdf,3,head,9.962599754333496,CMR10,False,271.20562744140625,416.0769348144531,0.0,4,H3
sample_7.pdf,3,TTENTION,7.970099925994873,NimbusRomNo9L-Regu,False,313.34698486328125,417.8185729980469,1.0,8,P
sample_7.pdf,3,(3),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,416.3074035644531,0.0,3,H3
sample_7.pdf,3,and we map the state,10.051863670349121,NimbusRomNo9L-Regu,False,108.0,444.103759765625,0.0,20,H3
sample_7.pdf,3,"to queries, keys and values with afﬁne projections using learned parameter",10.051863670349121,NimbusRomNo9L-Regu,False,207.50599670410156,444.103759765625,0.0,74,H3
sample_7.pdf,3,matrices,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,456.17047119140625,0.0,8,H3
sample_7.pdf,3,d/k,6.973800182342529,CMMI7,False,187.7349853515625,454.6597595214844,0.0,3,P
sample_7.pdf,3,d/k,6.973800182342529,CMMI7,False,250.24795532226562,454.6597595214844,0.0,3,P
sample_7.pdf,3,d/k,6.973800182342529,CMMI7,False,311.99896240234375,454.6597595214844,0.0,3,P
sample_7.pdf,3,and,9.962599754333496,NimbusRomNo9L-Regu,False,327.1219482421875,456.17047119140625,0.0,3,H3
sample_7.pdf,3,At step,9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,472.9634094238281,0.14285714285714285,7,H3
sample_7.pdf,3,", the UT then computes revised representations",9.862470626831055,NimbusRomNo9L-Regu,False,140.427001953125,472.9634094238281,0.043478260869565216,46,H3
sample_7.pdf,3,for all,9.862470626831055,NimbusRomNo9L-Regu,False,370.5060119628906,472.9634094238281,0.0,7,H3
sample_7.pdf,3,input positions as follows,9.862470626831055,NimbusRomNo9L-Regu,False,404.0961608886719,472.9634094238281,0.0,26,H3
sample_7.pdf,3,AYER,7.970099925994873,NimbusRomNo9L-Regu,False,179.8260040283203,511.6185302734375,1.0,4,P
sample_7.pdf,3,ORM,7.970099925994873,NimbusRomNo9L-Regu,False,210.34100341796875,511.6185302734375,1.0,3,P
sample_7.pdf,3,RANSITION,7.970099925994873,NimbusRomNo9L-Regu,False,260.2720031738281,511.6185302734375,1.0,9,P
sample_7.pdf,3,(4),9.962599754333496,NimbusRomNo9L-Regu,False,492.384033203125,510.107421875,0.0,3,H3
sample_7.pdf,3,where,9.962599754333496,CMR10,False,124.56903076171875,525.6919555664062,0.0,5,H3
sample_7.pdf,3,AYER,7.970099925994873,NimbusRomNo9L-Regu,False,179.82603454589844,527.43359375,1.0,4,P
sample_7.pdf,3,ORM,7.970099925994873,NimbusRomNo9L-Regu,False,210.34103393554688,527.43359375,1.0,3,P
sample_7.pdf,3,ULTI,7.970099925994873,NimbusRomNo9L-Regu,False,302.75103759765625,527.43359375,1.0,4,P
sample_7.pdf,3,EAD,7.970099925994873,NimbusRomNo9L-Regu,False,329.8290100097656,527.43359375,1.0,3,P
sample_7.pdf,3,ELF,7.970099925994873,NimbusRomNo9L-Regu,False,353.718994140625,527.43359375,1.0,3,P
sample_7.pdf,3,TTENTION,7.970099925994873,NimbusRomNo9L-Regu,False,375.406982421875,527.43359375,1.0,8,P
sample_7.pdf,3,(5),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,525.9224853515625,0.0,3,H3
sample_7.pdf,3,where L,9.962599754333496,NimbusRomNo9L-Regu,False,107.64096069335938,547.8084716796875,0.14285714285714285,7,H3
sample_7.pdf,3,AYER,7.970099925994873,NimbusRomNo9L-Regu,False,140.8069610595703,549.319580078125,1.0,4,P
sample_7.pdf,3,ORM,7.970099925994873,NimbusRomNo9L-Regu,False,171.32196044921875,549.319580078125,1.0,3,P
sample_7.pdf,3,"() is deﬁned in Ba et al. (2016), and T",9.962599754333496,NimbusRomNo9L-Regu,False,190.9579620361328,547.8084716796875,0.05128205128205128,39,H3
sample_7.pdf,3,RANSITION,7.970099925994873,NimbusRomNo9L-Regu,False,338.2149658203125,549.319580078125,1.0,9,P
sample_7.pdf,3,() and,9.962599754333496,NimbusRomNo9L-Regu,False,385.5859680175781,547.8084716796875,0.0,6,H3
sample_7.pdf,3,are discussed below.,9.962599754333496,NimbusRomNo9L-Regu,False,424.6199645996094,547.8084716796875,0.0,20,H3
sample_7.pdf,3,"Depending on the task, we use one of two different transition functions: either a separable",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,564.4512939453125,0.01098901098901099,91,H3
sample_7.pdf,3,"convolution (Chollet, 2016) or a fully-connected neural network that consists of a single rectiﬁed-linear",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,575.3413696289062,0.009523809523809525,105,H3
sample_7.pdf,3,"activation function between two afﬁne transformations, applied position-wise, i.e. individually to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,585.9302978515625,0.0,98,H3
sample_7.pdf,3,each row of,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,596.7454833984375,0.0,11,H3
sample_7.pdf,3,"above are ﬁxed, constant, two-dimensional (position, time)",10.061732292175293,NimbusRomNo9L-Regu,False,160.6750030517578,613.3872680664062,0.0,58,H3
sample_7.pdf,3,coordinate embeddings,10.061732292175293,NimbusRomNo9L-ReguItal,False,404.21392822265625,613.2090454101562,0.0,21,H3
sample_7.pdf,3,"obtained by computing the sinusoidal position embedding vectors as deﬁned in (Vaswani et al., 2017)",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,624.2100219726562,0.010101010101010102,99,H3
sample_7.pdf,3,for the positions,9.96757984161377,NimbusRomNo9L-Regu,False,108.0,634.9376831054688,0.0,17,H3
sample_7.pdf,3,and the time-step,9.96757984161377,NimbusRomNo9L-Regu,False,210.89016723632812,634.9376831054688,0.0,17,H3
sample_7.pdf,3,separately for each vector-dimension,9.96757984161377,NimbusRomNo9L-Regu,False,316.8761291503906,634.9376831054688,0.0,36,H3
sample_7.pdf,3,and summing:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,645.6814575195312,0.0,12,H3
sample_7.pdf,3,=sin(,9.962599754333496,CMR10,False,240.34397888183594,667.7109375,0.0,5,H3
sample_7.pdf,3,10000,9.962599754333496,CMR10,False,273.7189636230469,667.7109375,0.0,5,H3
sample_7.pdf,3,j/d,6.973800182342529,CMMI7,False,302.59698486328125,665.9337768554688,0.0,3,P
sample_7.pdf,3,)+sin(,9.962599754333496,CMR10,False,315.02398681640625,667.7109375,0.0,6,H3
sample_7.pdf,3,10000,9.962599754333496,CMR10,False,352.44000244140625,667.7109375,0.0,5,H3
sample_7.pdf,3,j/d,6.973800182342529,CMMI7,False,381.3179931640625,665.9337768554688,0.0,3,P
sample_7.pdf,3,(6),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,667.9414672851562,0.0,3,H3
sample_7.pdf,3,=cos(,9.962599754333496,CMR10,False,240.343994140625,684.8589477539062,0.0,5,H3
sample_7.pdf,3,10000,9.962599754333496,CMR10,False,274.82598876953125,684.8589477539062,0.0,5,H3
sample_7.pdf,3,j/d,6.973800182342529,CMMI7,False,303.7040100097656,683.081787109375,0.0,3,P
sample_7.pdf,3,)+cos(,9.962599754333496,CMR10,False,316.1310119628906,684.8589477539062,0.0,6,H3
sample_7.pdf,3,10000,9.962599754333496,CMR10,False,354.6540222167969,684.8589477539062,0.0,5,H3
sample_7.pdf,3,j/d,6.973800182342529,CMMI7,False,383.5320129394531,683.081787109375,0.0,3,P
sample_7.pdf,3,(7),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,685.0894775390625,0.0,3,H3
sample_7.pdf,4,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,4,Input Sequence,6.73091983795166,HelveticaNeue,False,181.87913513183594,271.9591979980469,0.14285714285714285,14,P
sample_7.pdf,4,Embed Input Symbols,6.73091983795166,HelveticaNeue,False,172.27410888671875,250.78485107421875,0.15789473684210525,19,P
sample_7.pdf,4,Multihead Self-Attention,6.73091983795166,HelveticaNeue,False,169.22837829589844,205.95977783203125,0.125,24,P
sample_7.pdf,4,Transition Function,6.73091983795166,HelveticaNeue,False,177.14393615722656,181.65269470214844,0.10526315789473684,19,P
sample_7.pdf,4,Multihead Attention,6.73091983795166,HelveticaNeue,False,395.2700500488281,181.65269470214844,0.10526315789473684,19,P
sample_7.pdf,4,Target Sequence (right-shifted by one),6.73091983795166,HelveticaNeue,False,367.3199157714844,271.9591979980469,0.05263157894736842,38,P
sample_7.pdf,4,Embed Target Symbols,6.73091983795166,HelveticaNeue,False,389.7540588378906,250.78485107421875,0.15,20,P
sample_7.pdf,4,Multihead Self-Attention,6.73091983795166,HelveticaNeue,False,388.2295227050781,205.95977783203125,0.125,24,P
sample_7.pdf,4,Transition Function,6.73091983795166,HelveticaNeue,False,396.14508056640625,158.54937744140625,0.10526315789473684,19,P
sample_7.pdf,4,Softmax,6.73091983795166,HelveticaNeue,False,443.58404541015625,105.50916290283203,0.14285714285714285,7,P
sample_7.pdf,4,Output Probabilities,6.73091983795166,HelveticaNeue,False,426.14892578125,84.6152572631836,0.1,20,P
sample_7.pdf,4,After T steps,6.73091983795166,HelveticaNeue,False,277.54962158203125,176.02627563476562,0.15384615384615385,13,P
sample_7.pdf,4,After T steps,6.73091983795166,HelveticaNeue,False,462.3609313964844,121.50366973876953,0.15384615384615385,13,P
sample_7.pdf,4,For T steps,6.73091983795166,HelveticaNeue,False,271.9065856933594,194.13064575195312,0.18181818181818182,11,P
sample_7.pdf,4,For T steps,6.73091983795166,HelveticaNeue,False,492.5318298339844,173.7211456298828,0.18181818181818182,11,P
sample_7.pdf,4,Recurrent,6.73091983795166,HelveticaNeue-Bold,True,112.20263671875,174.0654754638672,0.1111111111111111,9,P
sample_7.pdf,4,Encoder,6.73091983795166,HelveticaNeue-Bold,True,112.20263671875,182.6743621826172,0.14285714285714285,7,P
sample_7.pdf,4,Block,6.73091983795166,HelveticaNeue-Bold,True,112.20263671875,191.28326416015625,0.2,5,P
sample_7.pdf,4,Recurrent,6.73091983795166,HelveticaNeue-Bold,True,332.0435485839844,148.4860076904297,0.1111111111111111,9,P
sample_7.pdf,4,Decoder,6.73091983795166,HelveticaNeue-Bold,True,332.0435485839844,157.0948944091797,0.14285714285714285,7,P
sample_7.pdf,4,Block,6.73091983795166,HelveticaNeue-Bold,True,332.0435485839844,165.70379638671875,0.2,5,P
sample_7.pdf,4,Figure 2: The recurrent blocks of the Universal Transformer encoder and decoder. This diagram omits,9.902643203735352,NimbusRomNo9L-Regu,False,108.0,294.34893798828125,0.050505050505050504,99,H3
sample_7.pdf,4,"position and time-step encodings as well as dropout, residual connections and layer normalization.",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,305.1872863769531,0.0,98,H3
sample_7.pdf,4,A complete version can be found in Appendix A. The Universal Transformer with dynamic halting,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,316.14630126953125,0.06451612903225806,93,H3
sample_7.pdf,4,determines the number of steps,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,327.1804504394531,0.0,30,H3
sample_7.pdf,4,"for each position individually using ACT (Graves, 2016).",9.962599754333496,NimbusRomNo9L-Regu,False,238.3301544189453,327.1804504394531,0.07142857142857142,56,H3
sample_7.pdf,4,After,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,352.4112854003906,0.2,5,H3
sample_7.pdf,4,"steps (each updating all positions of the input sequence in parallel), the ﬁnal output of the",10.061732292175293,NimbusRomNo9L-Regu,False,137.38116455078125,352.4112854003906,0.0,93,H3
sample_7.pdf,4,Universal Transformer encoder is a matrix of,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,363.15130615234375,0.045454545454545456,44,H3
sample_7.pdf,4,-dimensional vector representations,10.061732292175293,NimbusRomNo9L-Regu,False,295.14599609375,363.15130615234375,0.0,35,H3
sample_7.pdf,4,for,10.061732292175293,NimbusRomNo9L-Regu,False,492.3210144042969,363.15130615234375,0.0,3,H3
sample_7.pdf,4,the,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,373.9664611816406,0.0,3,H3
sample_7.pdf,4,symbols of the input sequence.,9.962599754333496,NimbusRomNo9L-Regu,False,130.91416931152344,373.9664611816406,0.0,30,H3
sample_7.pdf,4,ECODER,7.970099925994873,NimbusRomNo9L-Medi,False,115.93999481201172,392.1217956542969,1.0,6,P
sample_7.pdf,4,"The decoder shares the same basic recurrent structure of the encoder. However, after",10.061732292175293,NimbusRomNo9L-Regu,False,156.3085479736328,390.6083068847656,0.023809523809523808,84,H3
sample_7.pdf,4,"the self-attention function, the decoder additionally also attends to the ﬁnal encoder representation",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,401.3472900390625,0.0,101,H3
sample_7.pdf,4,of each position in the input sequence using the same multihead dot-product attention function,10.061732292175293,NimbusRomNo9L-Regu,False,125.47599792480469,412.0872802734375,0.0,94,H3
sample_7.pdf,4,"from Equation 2, but with queries",10.037040710449219,NimbusRomNo9L-Regu,False,108.0,422.8460388183594,0.030303030303030304,33,H3
sample_7.pdf,4,"obtained from projecting the decoder representations, and keys",10.037040710449219,NimbusRomNo9L-Regu,False,251.534423828125,422.8460388183594,0.0,62,H3
sample_7.pdf,4,and values (,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,433.5672912597656,0.0,12,H3
sample_7.pdf,4,and,10.061732292175293,NimbusRomNo9L-Regu,False,164.7882537841797,433.5672912597656,0.0,3,H3
sample_7.pdf,4,) obtained from projecting the encoder representations (this process is akin to,10.061732292175293,NimbusRomNo9L-Regu,False,190.54519653320312,433.5672912597656,0.0,79,H3
sample_7.pdf,4,"standard attention (Bahdanau et al., 2014)).",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,444.3814697265625,0.022727272727272728,44,H3
sample_7.pdf,4,"Like the Transformer model, the UT is autoregressive (Graves, 2013). Trained using teacher-forcing, at",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,461.1744079589844,0.058823529411764705,102,H3
sample_7.pdf,4,"generation time it produces its output one symbol at a time, with the decoder consuming the previously",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,471.9029846191406,0.0,102,H3
sample_7.pdf,4,"produced output positions. During training, the decoder input is the target output, shifted to the right",10.012289047241211,NimbusRomNo9L-Regu,False,108.0,482.5408020019531,0.009615384615384616,104,H3
sample_7.pdf,4,by one position. The decoder self-attention distributions are further masked so that the model can,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,493.2422790527344,0.01020408163265306,98,H3
sample_7.pdf,4,"only attend to positions to the left of any predicted symbol. Finally, the per-symbol target distributions",9.902643203735352,NimbusRomNo9L-Regu,False,108.0,504.1029357910156,0.009433962264150943,106,H3
sample_7.pdf,4,are obtained by applying an afﬁne transformation,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,514.7222900390625,0.0,48,H3
sample_7.pdf,4,from the ﬁnal decoder state to the,10.061732292175293,NimbusRomNo9L-Regu,False,363.8840026855469,514.7222900390625,0.0,34,H3
sample_7.pdf,4,output vocabulary size,9.947644233703613,NimbusRomNo9L-Regu,False,108.0,525.548828125,0.0,22,H3
sample_7.pdf,4,", followed by a softmax which yields an",9.947644233703613,NimbusRomNo9L-Regu,False,204.3321990966797,525.548828125,0.0,39,H3
sample_7.pdf,4,-dimensional output matrix,9.947644233703613,NimbusRomNo9L-Regu,False,397.0870056152344,525.548828125,0.0,26,H3
sample_7.pdf,4,normalized over its rows:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,536.2764892578125,0.0,25,H3
sample_7.pdf,4,pos,6.973800182342529,CMMI7,False,232.05799865722656,567.333740234375,0.0,3,P
sample_7.pdf,4,[1:,6.973800182342529,CMR7,False,252.00799560546875,567.6377563476562,0.0,3,P
sample_7.pdf,4,pos,6.973800182342529,CMMI7,False,260.489990234375,567.6377563476562,0.0,3,P
sample_7.pdf,4,SOFTMAX,7.970099925994873,NimbusRomNo9L-Regu,False,316.7999267578125,565.2445678710938,1.0,7,P
sample_7.pdf,4,(8),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,563.7334594726562,0.0,3,H3
sample_7.pdf,4,"To generate from the model, the encoder is run once for the conditioning input sequence. Then the",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,586.2332763671875,0.020618556701030927,97,H3
sample_7.pdf,4,"decoder is run repeatedly, consuming all already-generated symbols, while generating one additional",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,597.0484619140625,0.0,99,H3
sample_7.pdf,4,distribution over the vocabulary for the symbol at the next output position per iteration. We then,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,607.7132568359375,0.01020408163265306,98,H3
sample_7.pdf,4,typically sample or select the highest probability symbol as the next symbol.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,618.5274658203125,0.0,77,H3
sample_7.pdf,4,2.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,645.66943359375,0.0,3,H3
sample_7.pdf,4,YNAMIC,7.970099925994873,NimbusRomNo9L-Regu,False,139.36199951171875,647.1805419921875,1.0,6,P
sample_7.pdf,4,ALTING,7.970099925994873,NimbusRomNo9L-Regu,False,184.0540008544922,647.1805419921875,1.0,6,P
sample_7.pdf,4,"In sequence processing systems, certain symbols (e.g. some words or phonemes) are usually more",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,666.8402709960938,0.010638297872340425,94,H3
sample_7.pdf,4,ambiguous than others. It is therefore reasonable to allocate more processing resources to these,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,677.5802612304688,0.010416666666666666,96,H3
sample_7.pdf,4,"more ambiguous symbols. Adaptive Computation Time (ACT) (Graves, 2016) is a mechanism for",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,688.3202514648438,0.07865168539325842,89,H3
sample_7.pdf,4,dynamically modulating the number of computational steps needed to process each input symbol,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,699.0592651367188,0.0,92,H3
sample_7.pdf,4,Note that,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.1111111111111111,9,P
sample_7.pdf,4,here denotes time-step,8.966400146484375,NimbusRomNo9L-Regu,False,163.98583984375,723.0619506835938,0.0,22,P
sample_7.pdf,4,and not the transpose operation.,8.966400146484375,NimbusRomNo9L-Regu,False,254.0098419189453,723.0619506835938,0.0,32,P
sample_7.pdf,5,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,5,Model,8.966400146484375,NimbusRomNo9L-Medi,False,135.69200134277344,100.48212432861328,0.2,5,P
sample_7.pdf,5,10K examples,8.966400146484375,NimbusRomNo9L-Medi,False,292.458984375,95.50110626220703,0.08333333333333333,12,P
sample_7.pdf,5,1K examples,8.966400146484375,NimbusRomNo9L-Medi,False,404.26104736328125,95.50110626220703,0.09090909090909091,11,P
sample_7.pdf,5,train single,8.966400146484375,NimbusRomNo9L-Regu,False,269.1499938964844,110.34695434570312,0.0,12,P
sample_7.pdf,5,train joint,8.966400146484375,NimbusRomNo9L-Regu,False,324.98370361328125,110.34695434570312,0.0,11,P
sample_7.pdf,5,train single,8.966400146484375,NimbusRomNo9L-Regu,False,380.8263244628906,110.34695434570312,0.0,12,P
sample_7.pdf,5,train joint,8.966400146484375,NimbusRomNo9L-Regu,False,432.4278869628906,110.34695434570312,0.0,11,P
sample_7.pdf,5,Previous best results:,8.966400146484375,NimbusRomNo9L-Medi,False,264.9389953613281,125.22809600830078,0.045454545454545456,22,P
sample_7.pdf,5,"QRNet (Seo et al., 2016)",8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,140.27395629882812,0.16666666666666666,24,P
sample_7.pdf,5,0.3 (0/20),8.966400146484375,NimbusRomNo9L-Regu,False,269.1481628417969,140.27395629882812,0.0,10,P
sample_7.pdf,5,"Sparse DNC (Rae et al., 2016)",8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,150.23593139648438,0.1724137931034483,29,P
sample_7.pdf,5,2.9 (1/20),8.966400146484375,NimbusRomNo9L-Regu,False,324.9908752441406,150.23593139648438,0.0,10,P
sample_7.pdf,5,GA+MAGE Dhingra et al. (2017),8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,160.19894409179688,0.2413793103448276,29,P
sample_7.pdf,5,8.7 (5/20),8.966400146484375,NimbusRomNo9L-Regu,False,380.82464599609375,160.19894409179688,0.0,10,P
sample_7.pdf,5,MemN2N Sukhbaatar et al. (2015),8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,170.16195678710938,0.12903225806451613,31,P
sample_7.pdf,5,12.4 (11/20),8.966400146484375,NimbusRomNo9L-Regu,False,432.42626953125,170.16195678710938,0.0,12,P
sample_7.pdf,5,Our Results:,8.966400146484375,NimbusRomNo9L-Medi,False,280.7959899902344,185.04310607910156,0.16666666666666666,12,P
sample_7.pdf,5,"Transformer (Vaswani et al., 2017)",8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,200.08798217773438,0.058823529411764705,34,P
sample_7.pdf,5,15.2 (10/20),8.966400146484375,NimbusRomNo9L-Regu,False,269.14813232421875,200.08798217773438,0.0,12,P
sample_7.pdf,5,22.1 (12/20),8.966400146484375,NimbusRomNo9L-Regu,False,324.9908752441406,200.08798217773438,0.0,12,P
sample_7.pdf,5,21.8 (5/20),8.966400146484375,NimbusRomNo9L-Regu,False,380.8246154785156,200.08798217773438,0.0,11,P
sample_7.pdf,5,26.8 (14/20),8.966400146484375,NimbusRomNo9L-Regu,False,432.42620849609375,200.08798217773438,0.0,12,P
sample_7.pdf,5,Universal Transformer (this work),8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,210.05099487304688,0.06060606060606061,33,P
sample_7.pdf,5,0.23 (0/20),8.966400146484375,NimbusRomNo9L-Regu,False,269.14813232421875,210.05099487304688,0.0,11,P
sample_7.pdf,5,0.47 (0/20),8.966400146484375,NimbusRomNo9L-Regu,False,324.9908447265625,210.05099487304688,0.0,11,P
sample_7.pdf,5,5.31 (5/20),8.966400146484375,NimbusRomNo9L-Regu,False,380.8246154785156,210.05099487304688,0.0,11,P
sample_7.pdf,5,8.50 (8/20),8.966400146484375,NimbusRomNo9L-Regu,False,432.42620849609375,210.05099487304688,0.0,11,P
sample_7.pdf,5,UT w/ dynamic halting (this work),8.966400146484375,NimbusRomNo9L-Regu,False,133.8990020751953,220.01400756835938,0.06060606060606061,33,P
sample_7.pdf,5,0.21 (0/20),8.966400146484375,NimbusRomNo9L-Medi,False,269.1500244140625,219.93214416503906,0.0,11,P
sample_7.pdf,5,0.29 (0/20),8.966400146484375,NimbusRomNo9L-Medi,False,324.9837951660156,219.93214416503906,0.0,11,P
sample_7.pdf,5,4.55 (3/20),8.966400146484375,NimbusRomNo9L-Medi,False,380.82647705078125,219.93214416503906,0.0,11,P
sample_7.pdf,5,7.78 (5/20),8.966400146484375,NimbusRomNo9L-Medi,False,432.4281005859375,219.93214416503906,0.0,11,P
sample_7.pdf,5,Table 1: Average error and number of failed tasks (,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,237.33627319335938,0.0392156862745098,51,H3
sample_7.pdf,5,error) out of 20 (in parentheses; lower is,10.061732292175293,NimbusRomNo9L-Regu,False,338.2361755371094,237.33627319335938,0.0,42,H3
sample_7.pdf,5,better in both cases) on the bAbI dataset under the different training/evaluation setups. We indicate,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,248.29531860351562,0.0297029702970297,101,H3
sample_7.pdf,5,"state-of-the-art where available for each, or ‘-’ otherwise.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,259.3294677734375,0.0,60,H3
sample_7.pdf,5,(called the “ponder time”) in standard recurrent neural networks based on a scalar,9.96757984161377,NimbusRomNo9L-Regu,False,107.6709976196289,282.03369140625,0.0,82,H3
sample_7.pdf,5,halting probability,9.96757984161377,NimbusRomNo9L-ReguItal,False,427.8599548339844,281.85711669921875,0.0,19,H3
sample_7.pdf,5,predicted by the model at each step.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,292.7764587402344,0.0,36,H3
sample_7.pdf,5,Inspired by the interpretation of Universal Transformers as applying self-attentive RNNs in parallel,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,309.4305114746094,0.06,100,H3
sample_7.pdf,5,"to all positions in the sequence, we also add a dynamic ACT halting mechanism to each position (i.e. to",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,320.3094177246094,0.02912621359223301,103,H3
sample_7.pdf,5,each per-symbol self-attentive RNN; see Appendix C for more details). Once the per-symbol recurrent,9.877554893493652,NimbusRomNo9L-Regu,False,108.0,331.0379638671875,0.06060606060606061,99,H3
sample_7.pdf,5,"block halts, its state is simply copied to the next step until all blocks halt, or we reach a maximum number",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,341.7894287109375,0.0,108,H3
sample_7.pdf,5,of steps. The ﬁnal output of the encoder is then the ﬁnal layer of representations produced in this way.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,352.45245361328125,0.009615384615384616,104,H3
sample_7.pdf,5,XPERIMENTS AND,9.56410026550293,NimbusRomNo9L-Regu,False,134.7320098876953,381.253662109375,0.9285714285714286,14,H3
sample_7.pdf,5,NALYSIS,9.56410026550293,NimbusRomNo9L-Regu,False,237.17401123046875,381.253662109375,1.0,7,H3
sample_7.pdf,5,"We evaluated the Universal Transformer on a range of algorithmic and language understanding tasks,",9.977532386779785,NimbusRomNo9L-Regu,False,107.53199768066406,404.2691345214844,0.030612244897959183,98,H3
sample_7.pdf,5,as well as on machine translation. We describe these tasks and datasets in more detail in Appendix D.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,415.01947021484375,0.0297029702970297,101,H3
sample_7.pdf,5,3.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,439.6934814453125,0.0,3,H3
sample_7.pdf,5,I Q,9.962599754333496,NimbusRomNo9L-Regu,False,151.15798950195312,439.6934814453125,0.6666666666666666,3,H3
sample_7.pdf,5,UESTION,7.970099925994873,NimbusRomNo9L-Regu,False,164.5679931640625,441.20458984375,1.0,7,P
sample_7.pdf,5,NSWERING,7.970099925994873,NimbusRomNo9L-Regu,False,213.60299682617188,441.20458984375,1.0,8,P
sample_7.pdf,5,"The bAbi question answering dataset (Weston et al., 2015) consists of 20 different tasks, where the",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,459.92230224609375,0.030303030303030304,99,H3
sample_7.pdf,5,goal is to answer a question given a number of English sentences that encode potentially multiple,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,470.6612854003906,0.010309278350515464,97,H3
sample_7.pdf,5,supporting facts. The goal is to measure various forms of language understanding by requiring a,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,481.40130615234375,0.010526315789473684,95,H3
sample_7.pdf,5,certain type of reasoning over the linguistic facts presented in each story. A standard Transformer,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,492.14129638671875,0.020202020202020204,99,H3
sample_7.pdf,5,does not achieve good results on this task,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,503.0314025878906,0.0,42,H3
sample_7.pdf,5,". However, we have designed a model based on the Universal",9.862470626831055,NimbusRomNo9L-Regu,False,269.9570007324219,503.0314025878906,0.034482758620689655,58,H3
sample_7.pdf,5,Transformer which achieves state-of-the-art results on this task.,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,513.6954345703125,0.015384615384615385,65,H3
sample_7.pdf,5,"To encode the input, similar to Henaff et al. (2016), we ﬁrst encode each fact in the story by applying a",9.9126615524292,NimbusRomNo9L-Regu,False,107.69100189208984,530.4503784179688,0.01904761904761905,105,H3
sample_7.pdf,5,"learned multiplicative positional mask to each word’s embedding, and summing up all embeddings. We",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,541.2283935546875,0.01020408163265306,98,H3
sample_7.pdf,5,"embed the question in the same way, and then feed the (Universal) Transformer with these embeddings",9.872529029846191,NimbusRomNo9L-Regu,False,108.0,551.9607543945312,0.020202020202020204,99,H3
sample_7.pdf,5,of the facts and questions.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,562.6314697265625,0.0,27,H3
sample_7.pdf,5,"As originally proposed, models can either be trained on each task separately (“train single”) or jointly",9.952631950378418,NimbusRomNo9L-Regu,False,107.64099884033203,579.3560180664062,0.009615384615384616,104,H3
sample_7.pdf,5,on all tasks (“train joint”). Table 1 summarizes our results. We conducted 10 runs with different,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,590.0132446289062,0.020618556701030927,97,H3
sample_7.pdf,5,"initializations and picked the best model based on performance on the validation set, similar to previous",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,600.9044189453125,0.0,105,H3
sample_7.pdf,5,work. Both the UT and UT with dynamic halting achieve state-of-the-art results on all tasks in terms,10.017244338989258,NimbusRomNo9L-Regu,False,107.64099884033203,611.5270385742188,0.05,100,H3
sample_7.pdf,5,of average error and number of failed tasks,9.942654609680176,NimbusRomNo9L-Regu,False,108.0,622.3226318359375,0.0,43,H3
sample_7.pdf,5,", in both the 10K and 1K training regime (see Appendix E",9.942654609680176,NimbusRomNo9L-Regu,False,279.1860046386719,622.3226318359375,0.07142857142857142,56,H3
sample_7.pdf,5,for breakdown by task).,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,633.0474853515625,0.0,23,H3
sample_7.pdf,5,"To understand the working of the model better, we analyzed both the attention distributions and the",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,649.6892700195312,0.010101010101010102,99,H3
sample_7.pdf,5,"average ACT ponder times for this task (see Appendix F for details). First, we observe that the attention",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,660.5803833007812,0.05714285714285714,105,H3
sample_7.pdf,5,"distributions start out very uniform, but get progressively sharper in later steps around the correct",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,671.1692504882812,0.0,101,H3
sample_7.pdf,5,"supporting facts that are required to answer each question, which is indeed very similar to how humans",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,682.0479736328125,0.0,102,H3
sample_7.pdf,5,"would solve the task. Second, with dynamic halting we observe that the average ponder time (i.e. depth",9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,692.7993774414062,0.00980392156862745,102,H3
sample_7.pdf,5,"We experimented with different hyper-parameters and different network sizes, but it always overﬁts.",8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,712.2109375,0.010101010101010102,99,P
sample_7.pdf,5,Deﬁned as,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.1111111111111111,9,P
sample_7.pdf,5,error.,8.966400146484375,NimbusRomNo9L-Regu,False,184.0669403076172,723.0619506835938,0.0,6,P
sample_7.pdf,6,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,6,Figure 3: Ponder time of UT with dynamic halting for encoding facts in a story and question in a bAbI,9.9176664352417,NimbusRomNo9L-Regu,False,108.0,216.74856567382812,0.0594059405940594,101,H3
sample_7.pdf,6,task requiring three supporting facts.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,227.67347717285156,0.0,38,H3
sample_7.pdf,6,of the per-symbol recurrent processing chain) over all positions in all samples in the test data for tasks,9.932666778564453,NimbusRomNo9L-Regu,False,108.0,253.73316955566406,0.0,106,H3
sample_7.pdf,6,requiring three supporting facts is higher (,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,264.4883117675781,0.0,44,H3
sample_7.pdf,6,) than for tasks requiring only two (,9.9126615524292,NimbusRomNo9L-Regu,False,303.3169860839844,264.4883117675781,0.0,37,H3
sample_7.pdf,6,"), which",9.9126615524292,NimbusRomNo9L-Regu,False,472.1470031738281,264.4883117675781,0.0,8,H3
sample_7.pdf,6,is in turn higher than for tasks requiring only one supporting fact (,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,275.11529541015625,0.0,69,H3
sample_7.pdf,6,). This indicates that the,10.061732292175293,NimbusRomNo9L-Regu,False,405.8599853515625,275.11529541015625,0.038461538461538464,26,H3
sample_7.pdf,6,model adjusts the number of processing steps with the number of supporting facts required to answer,9.977532386779785,NimbusRomNo9L-Regu,False,108.0,285.9181213378906,0.0,99,H3
sample_7.pdf,6,"the questions. Finally, we observe that the histogram of ponder times at different positions is more",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,296.59429931640625,0.01,100,H3
sample_7.pdf,6,"uniform in tasks requiring only one supporting fact compared to two and three, and likewise for tasks",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,307.40191650390625,0.0,101,H3
sample_7.pdf,6,"requiring two compared to three. Especially for tasks requiring three supporting facts, many positions",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,318.1749572753906,0.00980392156862745,102,H3
sample_7.pdf,6,halt at step 1 or 2 already and only a few get transformed for more steps (see for example Fig 3). This,9.977532386779785,NimbusRomNo9L-Regu,False,108.0,328.87713623046875,0.019417475728155338,103,H3
sample_7.pdf,6,"is particularly interesting as the length of stories is indeed much higher in this setting, with more",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,339.55328369140625,0.0,101,H3
sample_7.pdf,6,irrelevant facts which the model seems to successfully learn to ignore in this way.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,350.3674621582031,0.0,83,H3
sample_7.pdf,6,"Similar to dynamic memory networks (Kumar et al., 2016), there is an iterative attention process in",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,367.0102844238281,0.020202020202020204,99,H3
sample_7.pdf,6,UTs that allows the model to condition its attention over memory on the result of previous iterations.,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,377.7792663574219,0.0196078431372549,102,H3
sample_7.pdf,6,"Appendix F presents some examples illustrating that there is a notion of temporal states in UT, where",9.977532386779785,NimbusRomNo9L-Regu,False,107.64099884033203,388.5531311035156,0.039603960396039604,101,H3
sample_7.pdf,6,"the model updates its states (memory) in each step based on the output of previous steps, and this chain",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,399.36895751953125,0.0,104,H3
sample_7.pdf,6,of updates can also be viewed as steps in a multi-hop reasoning process.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,410.04345703125,0.0,72,H3
sample_7.pdf,6,3.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,438.0074462890625,0.0,3,H3
sample_7.pdf,6,UBJECT,7.970099925994873,NimbusRomNo9L-Regu,False,138.19700622558594,439.5185546875,1.0,6,P
sample_7.pdf,6,ERB,7.970099925994873,NimbusRomNo9L-Regu,False,181.06500244140625,439.5185546875,1.0,3,P
sample_7.pdf,6,GREEMENT,7.970099925994873,NimbusRomNo9L-Regu,False,207.36700439453125,439.5185546875,1.0,8,P
sample_7.pdf,6,"Next, we consider the task of predicting number-agreement between subjects and verbs in English",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,459.5072937011719,0.021052631578947368,95,H3
sample_7.pdf,6,"sentences (Linzen et al., 2016). This task acts as a proxy for measuring the ability of a model to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,470.2472839355469,0.02040816326530612,98,H3
sample_7.pdf,6,capture hierarchical (dependency) structure in natural language sentences. We use the dataset provided,9.867501258850098,NimbusRomNo9L-Regu,False,108.0,481.13360595703125,0.00980392156862745,102,H3
sample_7.pdf,6,"by (Linzen et al., 2016) and follow their experimental protocol of solving the task using a language mod-",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,491.8774108886719,0.009523809523809525,105,H3
sample_7.pdf,6,"eling training setup, i.e. a next word prediction objective, followed by calculating the ranking accuracy",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,502.59832763671875,0.0,105,H3
sample_7.pdf,6,of the target verb at test time. We evaluated our model on subsets of the test data with different task dif-,9.887598037719727,NimbusRomNo9L-Regu,False,108.0,513.3373413085938,0.009259259259259259,108,H3
sample_7.pdf,6,"ﬁculty, measured in terms of",9.872529029846191,NimbusRomNo9L-Regu,False,108.0,524.0887451171875,0.0,28,H3
sample_7.pdf,6,agreement attractors,9.872529029846191,NimbusRomNo9L-ReguItal,False,217.75857543945312,523.9138793945312,0.0,20,H3
sample_7.pdf,6,– the number of intervening nouns with the opposite,9.872529029846191,NimbusRomNo9L-Regu,False,300.9080810546875,524.0887451171875,0.0,51,H3
sample_7.pdf,6,"number from the subject (meant to confuse the model). For example, given the sentence",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,534.8363647460938,0.011764705882352941,85,H3
sample_7.pdf,6,The keys to the,9.862470626831055,NimbusRomNo9L-ReguItal,False,445.49957275390625,534.6616821289062,0.06666666666666667,15,H3
sample_7.pdf,6,cabinet,9.932666778564453,NimbusRomNo9L-ReguItal,False,108.0,545.3462524414062,0.0,7,H3
sample_7.pdf,6,", the objective during training is to predict the verb",9.932666778564453,NimbusRomNo9L-Regu,False,141.3179931640625,545.5221557617188,0.0,54,H3
sample_7.pdf,6,are,9.932666778564453,NimbusRomNo9L-ReguItal,False,337.6811828613281,545.3462524414062,0.0,3,H3
sample_7.pdf,6,"(plural). At test time, we then evaluate",9.932666778564453,NimbusRomNo9L-Regu,False,352.4980773925781,545.5221557617188,0.025,40,H3
sample_7.pdf,6,the ranking accuracy of the agreement attractors: i.e. the goal is to rank,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,556.2394409179688,0.0,74,H3
sample_7.pdf,6,are,9.962599754333496,NimbusRomNo9L-ReguItal,False,385.77716064453125,556.06298828125,0.0,3,H3
sample_7.pdf,6,higher than,9.962599754333496,NimbusRomNo9L-Regu,False,400.6795349121094,556.2394409179688,0.0,11,H3
sample_7.pdf,6,in this case.,9.962599754333496,NimbusRomNo9L-Regu,False,455.91204833984375,556.2394409179688,0.0,13,H3
sample_7.pdf,6,Our results are summarized in Table 2. The best LSTM with attention from the literature achieves,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,572.8812255859375,0.07291666666666667,96,H3
sample_7.pdf,6,"99.18% on this task (Yogatama et al., 2018), outperforming a vanilla Transformer (Tran et al., 2018).",10.007330894470215,NimbusRomNo9L-Regu,False,108.0,583.6625366210938,0.0297029702970297,101,H3
sample_7.pdf,6,"UTs signiﬁcantly outperform standard Transformers, and achieve an",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,594.4667358398438,0.046153846153846156,65,H3
sample_7.pdf,6,average,9.92266845703125,NimbusRomNo9L-ReguItal,False,374.6405029296875,594.291015625,0.0,7,H3
sample_7.pdf,6,result comparable to the,9.92266845703125,NimbusRomNo9L-Regu,False,408.139892578125,594.4667358398438,0.0,24,H3
sample_7.pdf,6,"current state of the art (99.2%). However, we see that UTs (and particularly with dynamic halting) per-",9.90765380859375,NimbusRomNo9L-Regu,False,108.0,605.2171630859375,0.02912621359223301,103,H3
sample_7.pdf,6,"form progressively better than all other models as the number of attractors increases (see the last row,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,615.9913940429688,0.0,104,H3
sample_7.pdf,6,3.3,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,643.8794555664062,0.0,3,H3
sample_7.pdf,6,LAMBADA L,9.962599754333496,NimbusRomNo9L-Regu,False,132.15924072265625,643.8794555664062,0.8888888888888888,9,H3
sample_7.pdf,6,ANGUAGE,7.970099925994873,NimbusRomNo9L-Regu,False,193.83799743652344,645.3905639648438,1.0,7,P
sample_7.pdf,6,ODELING,7.970099925994873,NimbusRomNo9L-Regu,False,247.38600158691406,645.3905639648438,1.0,7,P
sample_7.pdf,6,"The LAMBADA task (Paperno et al., 2016) is a language modeling task consisting of predicting a",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,665.3792724609375,0.09574468085106383,94,H3
sample_7.pdf,6,missing target word given a broader context of 4-5 preceding sentences. The dataset was speciﬁcally,10.002370834350586,NimbusRomNo9L-Regu,False,108.0,676.163330078125,0.010101010101010102,99,H3
sample_7.pdf,6,"designed so that humans are able to accurately predict the target word when shown the full context,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,686.8582763671875,0.0,99,H3
sample_7.pdf,6,but not when only shown the target sentence in which it appears. It therefore goes beyond language,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,697.5982666015625,0.01020408163265306,98,H3
sample_7.pdf,6,Cabinet,8.966400146484375,NimbusRomNo9L-ReguItal,False,124.13899993896484,722.9031372070312,0.14285714285714285,7,P
sample_7.pdf,6,(singular) is an agreement attractor in this case.,8.966400146484375,NimbusRomNo9L-Regu,False,152.53558349609375,723.0619506835938,0.0,50,P
sample_7.pdf,7,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,7,Model,8.966400146484375,NimbusRomNo9L-Medi,False,152.55299377441406,90.51911163330078,0.2,5,P
sample_7.pdf,7,Number of attractors,8.966400146484375,NimbusRomNo9L-Medi,False,295.0299987792969,85.53809356689453,0.05,20,P
sample_7.pdf,7,Total,8.966400146484375,NimbusRomNo9L-Regu,False,439.2733459472656,100.38400268554688,0.2,5,P
sample_7.pdf,7,"Previous best results (Yogatama et al., 2018):",8.966400146484375,NimbusRomNo9L-Medi,False,221.01300048828125,115.26612091064453,0.043478260869565216,46,P
sample_7.pdf,7,Best Stack-RNN,8.966400146484375,NimbusRomNo9L-Regu,False,150.75999450683594,130.31100463867188,0.35714285714285715,14,P
sample_7.pdf,7,0.994,8.966400146484375,NimbusRomNo9L-ReguItal,False,243.50999450683594,130.1521759033203,0.0,5,P
sample_7.pdf,7,0.979,8.966400146484375,NimbusRomNo9L-Regu,False,275.6390075683594,130.31100463867188,0.0,5,P
sample_7.pdf,7,0.965,8.966400146484375,NimbusRomNo9L-Regu,False,310.7514343261719,130.31100463867188,0.0,5,P
sample_7.pdf,7,0.935,8.966400146484375,NimbusRomNo9L-Regu,False,342.88702392578125,130.31100463867188,0.0,5,P
sample_7.pdf,7,0.916,8.966400146484375,NimbusRomNo9L-Regu,False,375.013671875,130.31100463867188,0.0,5,P
sample_7.pdf,7,0.880,8.966400146484375,NimbusRomNo9L-Regu,False,407.14031982421875,130.31100463867188,0.0,5,P
sample_7.pdf,7,0.992,8.966400146484375,NimbusRomNo9L-Regu,False,439.27593994140625,130.31100463867188,0.0,5,P
sample_7.pdf,7,Best LSTM,8.966400146484375,NimbusRomNo9L-Regu,False,150.760009765625,140.27401733398438,0.5555555555555556,9,P
sample_7.pdf,7,0.993,8.966400146484375,NimbusRomNo9L-Regu,False,243.50845336914062,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.972,8.966400146484375,NimbusRomNo9L-Regu,False,275.64404296875,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.950,8.966400146484375,NimbusRomNo9L-Regu,False,310.7565002441406,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.922,8.966400146484375,NimbusRomNo9L-Regu,False,342.88311767578125,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.900,8.966400146484375,NimbusRomNo9L-Regu,False,375.01873779296875,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.842,8.966400146484375,NimbusRomNo9L-Regu,False,407.1453857421875,140.27401733398438,0.0,5,P
sample_7.pdf,7,0.991,8.966400146484375,NimbusRomNo9L-Regu,False,439.27203369140625,140.27401733398438,0.0,5,P
sample_7.pdf,7,Best Attention,8.966400146484375,NimbusRomNo9L-Regu,False,150.760009765625,150.23599243164062,0.14285714285714285,14,P
sample_7.pdf,7,0.994,8.966400146484375,NimbusRomNo9L-Medi,False,243.510009765625,150.1541290283203,0.0,5,P
sample_7.pdf,7,0.977,8.966400146484375,NimbusRomNo9L-Medi,False,275.6365966796875,150.1541290283203,0.0,5,P
sample_7.pdf,7,0.959,8.966400146484375,NimbusRomNo9L-Regu,False,310.7550048828125,150.23599243164062,0.0,5,P
sample_7.pdf,7,0.929,8.966400146484375,NimbusRomNo9L-Regu,False,342.88165283203125,150.23599243164062,0.0,5,P
sample_7.pdf,7,0.907,8.966400146484375,NimbusRomNo9L-Regu,False,375.01727294921875,150.23599243164062,0.0,5,P
sample_7.pdf,7,0.842,8.966400146484375,NimbusRomNo9L-Regu,False,407.1439208984375,150.23599243164062,0.0,5,P
sample_7.pdf,7,0.992,8.966400146484375,NimbusRomNo9L-Medi,False,439.27301025390625,150.1541290283203,0.0,5,P
sample_7.pdf,7,Our results:,8.966400146484375,NimbusRomNo9L-Medi,False,282.12298583984375,165.1181182861328,0.08333333333333333,12,P
sample_7.pdf,7,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,150.75999450683594,180.16299438476562,0.09090909090909091,11,P
sample_7.pdf,7,0.973,8.966400146484375,NimbusRomNo9L-Regu,False,243.5084228515625,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.941,8.966400146484375,NimbusRomNo9L-Regu,False,275.64398193359375,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.932,8.966400146484375,NimbusRomNo9L-Regu,False,310.7564392089844,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.917,8.966400146484375,NimbusRomNo9L-Regu,False,342.883056640625,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.901,8.966400146484375,NimbusRomNo9L-Regu,False,375.0186767578125,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.883,8.966400146484375,NimbusRomNo9L-Regu,False,407.14532470703125,180.16299438476562,0.0,5,P
sample_7.pdf,7,0.962,8.966400146484375,NimbusRomNo9L-Regu,False,439.27197265625,180.16299438476562,0.0,5,P
sample_7.pdf,7,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,150.75999450683594,190.12600708007812,0.09523809523809523,21,P
sample_7.pdf,7,0.993,8.966400146484375,NimbusRomNo9L-Regu,False,243.50840759277344,190.12600708007812,0.0,5,P
sample_7.pdf,7,0.971,8.966400146484375,NimbusRomNo9L-Regu,False,275.64398193359375,190.12600708007812,0.0,5,P
sample_7.pdf,7,0.969,8.966400146484375,NimbusRomNo9L-Medi,False,310.7550048828125,190.0441436767578,0.0,5,P
sample_7.pdf,7,0.940,8.966400146484375,NimbusRomNo9L-Regu,False,342.8840026855469,190.12600708007812,0.0,5,P
sample_7.pdf,7,0.921,8.966400146484375,NimbusRomNo9L-Regu,False,375.0106201171875,190.12600708007812,0.0,5,P
sample_7.pdf,7,0.892,8.966400146484375,NimbusRomNo9L-Regu,False,407.146240234375,190.12600708007812,0.0,5,P
sample_7.pdf,7,0.992,8.966400146484375,NimbusRomNo9L-Medi,False,439.27301025390625,190.0441436767578,0.0,5,P
sample_7.pdf,7,UT w/ ACT,8.966400146484375,NimbusRomNo9L-Regu,False,150.760009765625,200.08798217773438,0.5555555555555556,9,P
sample_7.pdf,7,0.994,8.966400146484375,NimbusRomNo9L-Medi,False,243.510009765625,200.00611877441406,0.0,5,P
sample_7.pdf,7,0.969,8.966400146484375,NimbusRomNo9L-Regu,False,275.6390075683594,200.08798217773438,0.0,5,P
sample_7.pdf,7,0.967,8.966400146484375,NimbusRomNo9L-Regu,False,310.7514343261719,200.08798217773438,0.0,5,P
sample_7.pdf,7,0.944,8.966400146484375,NimbusRomNo9L-Medi,False,342.8840026855469,200.00611877441406,0.0,5,P
sample_7.pdf,7,0.932,8.966400146484375,NimbusRomNo9L-Medi,False,375.0106201171875,200.00611877441406,0.0,5,P
sample_7.pdf,7,0.907,8.966400146484375,NimbusRomNo9L-Medi,False,407.146240234375,200.00611877441406,0.0,5,P
sample_7.pdf,7,0.992,8.966400146484375,NimbusRomNo9L-Medi,False,439.27288818359375,200.00611877441406,0.0,5,P
sample_7.pdf,7,(UT w/ ACT - Best),8.966400146484375,NimbusRomNo9L-Regu,False,160.23199462890625,215.05197143554688,0.3333333333333333,18,P
sample_7.pdf,7,-0.008,8.966400146484375,NimbusRomNo9L-Regu,False,275.63848876953125,215.05197143554688,0.0,6,P
sample_7.pdf,7,0.002,8.966400146484375,NimbusRomNo9L-Regu,False,310.75091552734375,215.05197143554688,0.0,5,P
sample_7.pdf,7,0.009,8.966400146484375,NimbusRomNo9L-Regu,False,342.88653564453125,215.05197143554688,0.0,5,P
sample_7.pdf,7,0.016,8.966400146484375,NimbusRomNo9L-Regu,False,375.01318359375,215.05197143554688,0.0,5,P
sample_7.pdf,7,0.027,8.966400146484375,NimbusRomNo9L-Regu,False,407.13983154296875,215.05197143554688,0.0,5,P
sample_7.pdf,7,Table 2: Accuracy on the subject-verb agreement number prediction task (higher is better).,9.962599754333496,NimbusRomNo9L-Regu,False,128.00399780273438,232.44947814941406,0.022222222222222223,90,H3
sample_7.pdf,7,Model,8.966400146484375,NimbusRomNo9L-Medi,False,117.30799865722656,254.21510314941406,0.2,5,P
sample_7.pdf,7,LM Perplexity & (Accuracy),8.966400146484375,NimbusRomNo9L-Medi,False,264.2449951171875,249.2340850830078,0.15384615384615385,26,P
sample_7.pdf,7,RC Accuracy,8.966400146484375,NimbusRomNo9L-Medi,False,421.6232604980469,249.2340850830078,0.2727272727272727,11,P
sample_7.pdf,7,control,8.966400146484375,NimbusRomNo9L-Regu,False,251.2760009765625,264.0799865722656,0.0,7,P
sample_7.pdf,7,dev,8.966400146484375,NimbusRomNo9L-Regu,False,300.1339416503906,264.0799865722656,0.0,3,P
sample_7.pdf,7,test,8.966400146484375,NimbusRomNo9L-Regu,False,349.00079345703125,264.0799865722656,0.0,4,P
sample_7.pdf,7,control,8.966400146484375,NimbusRomNo9L-Regu,False,397.8586730957031,264.0799865722656,0.0,7,P
sample_7.pdf,7,dev,8.966400146484375,NimbusRomNo9L-Regu,False,435.2126770019531,264.0799865722656,0.0,3,P
sample_7.pdf,7,test,8.966400146484375,NimbusRomNo9L-Regu,False,471.8314208984375,264.0799865722656,0.0,4,P
sample_7.pdf,7,"Neural Cache (Grave et al., 2016)",8.966400146484375,NimbusRomNo9L-Regu,False,115.51499938964844,279.0439758300781,0.09090909090909091,33,P
sample_7.pdf,7,129,8.966400146484375,NimbusRomNo9L-Medi,False,251.2760009765625,278.96209716796875,0.0,3,P
sample_7.pdf,7,139,8.966400146484375,NimbusRomNo9L-Regu,False,300.1369934082031,279.0439758300781,0.0,3,P
sample_7.pdf,7,Dhingra et al. Dhingra et al. (2018),8.966400146484375,NimbusRomNo9L-Regu,False,115.51499938964844,289.0059814453125,0.05555555555555555,36,P
sample_7.pdf,7,0.5569,8.966400146484375,NimbusRomNo9L-Regu,False,471.8307189941406,289.0059814453125,0.0,6,P
sample_7.pdf,7,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,115.51499938964844,303.969970703125,0.09090909090909091,11,P
sample_7.pdf,7,142 (0.19),8.966400146484375,NimbusRomNo9L-Regu,False,251.27525329589844,303.969970703125,0.0,10,P
sample_7.pdf,7,5122 (0.0),8.966400146484375,NimbusRomNo9L-Regu,False,300.1331481933594,303.969970703125,0.0,10,P
sample_7.pdf,7,7321 (0.0),8.966400146484375,NimbusRomNo9L-Regu,False,349.0000305175781,303.969970703125,0.0,10,P
sample_7.pdf,7,0.4102,8.966400146484375,NimbusRomNo9L-Regu,False,397.8579406738281,303.969970703125,0.0,6,P
sample_7.pdf,7,0.4401,8.966400146484375,NimbusRomNo9L-Regu,False,435.21197509765625,303.969970703125,0.0,6,P
sample_7.pdf,7,0.3988,8.966400146484375,NimbusRomNo9L-Regu,False,471.830810546875,303.969970703125,0.0,6,P
sample_7.pdf,7,LSTM,8.966400146484375,NimbusRomNo9L-Regu,False,115.51499938964844,313.9319763183594,1.0,4,P
sample_7.pdf,7,138 (0.23),8.966400146484375,NimbusRomNo9L-Regu,False,251.2752685546875,313.9319763183594,0.0,10,P
sample_7.pdf,7,4966 (0.0),8.966400146484375,NimbusRomNo9L-Regu,False,300.1331481933594,313.9319763183594,0.0,10,P
sample_7.pdf,7,5174 (0.0),8.966400146484375,NimbusRomNo9L-Regu,False,349.0000305175781,313.9319763183594,0.0,10,P
sample_7.pdf,7,0.1103,8.966400146484375,NimbusRomNo9L-Regu,False,397.8579406738281,313.9319763183594,0.0,6,P
sample_7.pdf,7,0.2316,8.966400146484375,NimbusRomNo9L-Regu,False,435.21197509765625,313.9319763183594,0.0,6,P
sample_7.pdf,7,0.2007,8.966400146484375,NimbusRomNo9L-Regu,False,471.830810546875,313.9319763183594,0.0,6,P
sample_7.pdf,7,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,127.46720886230469,323.7361755371094,0.0,4,P
sample_7.pdf,7,", 6 steps (ﬁxed)",8.966400146484375,NimbusRomNo9L-Regu,False,145.6949920654297,323.8949890136719,0.0,16,P
sample_7.pdf,7,131 (0.32),8.966400146484375,NimbusRomNo9L-Regu,False,251.2743377685547,323.8949890136719,0.0,10,P
sample_7.pdf,7,279 (0.18),8.966400146484375,NimbusRomNo9L-Regu,False,300.1412048339844,323.8949890136719,0.0,10,P
sample_7.pdf,7,319 (0.17),8.966400146484375,NimbusRomNo9L-Regu,False,348.9991149902344,323.8949890136719,0.0,10,P
sample_7.pdf,7,0.4801,8.966400146484375,NimbusRomNo9L-Medi,False,397.8590087890625,323.8131103515625,0.0,6,P
sample_7.pdf,7,0.5422,8.966400146484375,NimbusRomNo9L-Regu,False,435.2149963378906,323.8949890136719,0.0,6,P
sample_7.pdf,7,0.5216,8.966400146484375,NimbusRomNo9L-Regu,False,471.8248291015625,323.8949890136719,0.0,6,P
sample_7.pdf,7,UT w/ dynamic halting,8.966400146484375,NimbusRomNo9L-Regu,False,115.51498413085938,333.8580017089844,0.09523809523809523,21,P
sample_7.pdf,7,130 (0.32),8.966400146484375,NimbusRomNo9L-Regu,False,251.27523803710938,333.8580017089844,0.0,10,P
sample_7.pdf,7,134,8.966400146484375,NimbusRomNo9L-Medi,False,300.136962890625,333.776123046875,0.0,3,P
sample_7.pdf,7,(0.22),8.966400146484375,NimbusRomNo9L-Regu,False,313.58660888671875,333.8580017089844,0.0,6,P
sample_7.pdf,7,142,8.966400146484375,NimbusRomNo9L-Medi,False,348.99798583984375,333.776123046875,0.0,3,P
sample_7.pdf,7,(0.19),8.966400146484375,NimbusRomNo9L-Regu,False,362.4476318359375,333.8580017089844,0.0,6,P
sample_7.pdf,7,0.4603,8.966400146484375,NimbusRomNo9L-Regu,False,397.8560485839844,333.8580017089844,0.0,6,P
sample_7.pdf,7,0.5831,8.966400146484375,NimbusRomNo9L-Medi,False,435.2149963378906,333.776123046875,0.0,6,P
sample_7.pdf,7,0.5625,8.966400146484375,NimbusRomNo9L-Medi,False,471.8248291015625,333.776123046875,0.0,6,P
sample_7.pdf,7,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,127.46720886230469,348.66217041015625,0.0,4,P
sample_7.pdf,7,", 8 steps (ﬁxed)",8.966400146484375,NimbusRomNo9L-Regu,False,145.6949920654297,348.82098388671875,0.0,16,P
sample_7.pdf,7,129(0.32),8.966400146484375,NimbusRomNo9L-Regu,False,251.2743377685547,348.82098388671875,0.0,9,P
sample_7.pdf,7,192 (0.21),8.966400146484375,NimbusRomNo9L-Regu,False,300.1412048339844,348.82098388671875,0.0,10,P
sample_7.pdf,7,202 (0.18),8.966400146484375,NimbusRomNo9L-Regu,False,348.9991149902344,348.82098388671875,0.0,10,P
sample_7.pdf,7,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,127.46720123291016,358.62518310546875,0.0,4,P
sample_7.pdf,7,", 9 steps (ﬁxed)",8.966400146484375,NimbusRomNo9L-Regu,False,145.6949920654297,358.78399658203125,0.0,16,P
sample_7.pdf,7,129(0.33),8.966400146484375,NimbusRomNo9L-Medi,False,251.2760009765625,358.7021179199219,0.0,9,P
sample_7.pdf,7,214 (0.21),8.966400146484375,NimbusRomNo9L-Regu,False,300.1369934082031,358.78399658203125,0.0,10,P
sample_7.pdf,7,239 (0.17),8.966400146484375,NimbusRomNo9L-Regu,False,348.9949035644531,358.78399658203125,0.0,10,P
sample_7.pdf,7,Table 3: LAMBADA language modeling (LM) perplexity (lower better) with accuracy in parentheses,9.937662124633789,NimbusRomNo9L-Regu,False,107.69100189208984,377.1963806152344,0.10638297872340426,94,H3
sample_7.pdf,7,"(higher better), and Reading Comprehension (RC) accuracy results (higher better). ‘-’ indicates no",10.061732292175293,NimbusRomNo9L-Regu,False,107.6709976196289,388.061279296875,0.04081632653061224,98,H3
sample_7.pdf,7,reported results in that setting.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,399.095458984375,0.0,33,H3
sample_7.pdf,7,"modeling, and tests the ability of a model to incorporate broader discourse and longer term context",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,422.50628662109375,0.0,99,H3
sample_7.pdf,7,when predicting the target word.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,433.3204650878906,0.0,32,H3
sample_7.pdf,7,The task is evaluated in two settings: as,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,449.9622802734375,0.024390243902439025,41,H3
sample_7.pdf,7,language modeling,10.061732292175293,NimbusRomNo9L-ReguItal,False,274.09136962890625,449.7840576171875,0.0,17,H3
sample_7.pdf,7,(the standard setup) and as,10.061732292175293,NimbusRomNo9L-Regu,False,355.7914733886719,449.9622802734375,0.0,27,H3
sample_7.pdf,7,reading,10.061732292175293,NimbusRomNo9L-ReguItal,False,469.6325378417969,449.7840576171875,0.0,7,H3
sample_7.pdf,7,comprehension,10.061732292175293,NimbusRomNo9L-ReguItal,False,108.0,460.5240783691406,0.0,13,H3
sample_7.pdf,7,". In the former (more challenging) case, a model is simply trained for next-word",10.061732292175293,NimbusRomNo9L-Regu,False,169.72000122070312,460.7023010253906,0.0125,80,H3
sample_7.pdf,7,"prediction on the training data, and evaluated on the target words at test time (i.e. the model is trained",9.977532386779785,NimbusRomNo9L-Regu,False,108.0,471.5061340332031,0.0,106,H3
sample_7.pdf,7,"to predict all words, not speciﬁcally challenging target words). In the latter setting, introduced by Chu",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,482.2867736816406,0.01904761904761905,105,H3
sample_7.pdf,7,"et al. Chu et al. (2017), the target sentence (minus the last word) is used as query for selecting the target",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,493.0724182128906,0.009174311926605505,109,H3
sample_7.pdf,7,"word from the context sentences. Note that the target word appears in the context 81% of the time,",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,503.6612854003906,0.01020408163265306,98,H3
sample_7.pdf,7,making this setup much simpler. However the task is impossible in the remaining 19% of the cases.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,514.4764404296875,0.010309278350515464,97,H3
sample_7.pdf,7,The results are shown in Table 3. Universal Transformer achieves state-of-the-art results in both,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,531.1182861328125,0.041237113402061855,97,H3
sample_7.pdf,7,"the language modeling and reading comprehension setup, outperforming both LSTMs and vanilla",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,541.8572998046875,0.04395604395604396,91,H3
sample_7.pdf,7,Transformers. Note that the control set was constructed similar to the LAMBADA development and,10.022196769714355,NimbusRomNo9L-Regu,False,107.69100189208984,552.6273193359375,0.09574468085106383,94,H3
sample_7.pdf,7,"test sets, but without ﬁltering them in any way, so achieving good results on this set shows a model’s",10.02714729309082,NimbusRomNo9L-Regu,False,108.0,563.363525390625,0.0,102,H3
sample_7.pdf,7,strength in standard language modeling.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,574.1524658203125,0.0,39,H3
sample_7.pdf,7,"Our best ﬁxed UT results used 6 steps. However, the average number of steps that the best UT with",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,590.7942504882812,0.061855670103092786,97,H3
sample_7.pdf,7,dynamic halting took on the test data over all positions and examples was,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,601.5332641601562,0.0,73,H3
sample_7.pdf,7,. In order to see if,10.061732292175293,NimbusRomNo9L-Regu,False,433.8450012207031,601.5332641601562,0.05,20,H3
sample_7.pdf,7,"the dynamic model did better simply because it took more steps, we trained two ﬁxed UT models with",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,612.382568359375,0.02040816326530612,98,H3
sample_7.pdf,7,"8 and 9 steps respectively (see last two rows). Interestingly, these two models achieve better results",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,623.0132446289062,0.00980392156862745,102,H3
sample_7.pdf,7,"compared to the model with 6 steps, but",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,633.7522583007812,0.0,39,H3
sample_7.pdf,7,do not outperform the UT with dynamic halting,10.061732292175293,NimbusRomNo9L-ReguItal,False,266.7077941894531,633.5740356445312,0.044444444444444446,45,H3
sample_7.pdf,7,. This leads,10.061732292175293,NimbusRomNo9L-Regu,False,457.8380126953125,633.7522583007812,0.08333333333333333,12,H3
sample_7.pdf,7,us to believe that dynamic halting may act as a useful regularizer for the model via incentivizing a,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,644.4922485351562,0.0,100,H3
sample_7.pdf,7,"smaller numbers of steps for some of the input symbols, while allowing more computation for others.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,655.3074951171875,0.0,99,H3
sample_7.pdf,7,3.4,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,680.4004516601562,0.0,3,H3
sample_7.pdf,7,LGORITHMIC,7.970099925994873,NimbusRomNo9L-Regu,False,139.85000610351562,681.9115600585938,1.0,10,P
sample_7.pdf,7,ASKS,7.970099925994873,NimbusRomNo9L-Regu,False,202.5540008544922,681.9115600585938,1.0,4,P
sample_7.pdf,7,"We trained UTs on three algorithmic tasks, namely Copy, Reverse, and (integer) Addition, all on",10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,700.7512817382812,0.06315789473684211,95,H3
sample_7.pdf,7,"strings composed of decimal symbols (‘0’-‘9’). In all the experiments, we train the models on",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,711.4912719726562,0.010752688172043012,93,H3
sample_7.pdf,7,"sequences of length 40 and evaluated on sequences of length 400 (Kaiser & Sutskever, 2016). We",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,722.2312622070312,0.031914893617021274,94,H3
sample_7.pdf,8,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,8,Model,8.966400146484375,NimbusRomNo9L-Medi,False,145.04200744628906,100.48212432861328,0.2,5,P
sample_7.pdf,8,Copy,8.966400146484375,NimbusRomNo9L-Medi,False,260.29400634765625,95.50110626220703,0.25,4,P
sample_7.pdf,8,Reverse,8.966400146484375,NimbusRomNo9L-Medi,False,336.4097900390625,95.50110626220703,0.14285714285714285,7,P
sample_7.pdf,8,Addition,8.966400146484375,NimbusRomNo9L-Medi,False,415.5113525390625,95.50110626220703,0.125,8,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,235.99899291992188,110.34695434570312,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,278.1321105957031,110.34695434570312,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,316.9745178222656,110.34695434570312,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,359.10760498046875,110.34695434570312,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,397.9410705566406,110.34695434570312,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,440.07415771484375,110.34695434570312,0.0,7,P
sample_7.pdf,8,LSTM,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,125.30996704101562,1.0,4,P
sample_7.pdf,8,0.45,8.966400146484375,NimbusRomNo9L-Regu,False,235.9964599609375,125.30996704101562,0.0,4,P
sample_7.pdf,8,0.09,8.966400146484375,NimbusRomNo9L-Regu,False,278.1385498046875,125.30996704101562,0.0,4,P
sample_7.pdf,8,0.66,8.966400146484375,NimbusRomNo9L-Regu,False,316.9720458984375,125.30996704101562,0.0,4,P
sample_7.pdf,8,0.11,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051940917969,125.30996704101562,0.0,4,P
sample_7.pdf,8,0.08,8.966400146484375,NimbusRomNo9L-Regu,False,397.93865966796875,125.30996704101562,0.0,4,P
sample_7.pdf,8,0.0,8.966400146484375,NimbusRomNo9L-Regu,False,440.08074951171875,125.30996704101562,0.0,3,P
sample_7.pdf,8,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,135.27297973632812,0.09090909090909091,11,P
sample_7.pdf,8,0.53,8.966400146484375,NimbusRomNo9L-Regu,False,235.99642944335938,135.27297973632812,0.0,4,P
sample_7.pdf,8,0.03,8.966400146484375,NimbusRomNo9L-Regu,False,278.13848876953125,135.27297973632812,0.0,4,P
sample_7.pdf,8,0.13,8.966400146484375,NimbusRomNo9L-Regu,False,316.97198486328125,135.27297973632812,0.0,4,P
sample_7.pdf,8,0.06,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051330566406,135.27297973632812,0.0,4,P
sample_7.pdf,8,0.07,8.966400146484375,NimbusRomNo9L-Regu,False,397.9385986328125,135.27297973632812,0.0,4,P
sample_7.pdf,8,0.0,8.966400146484375,NimbusRomNo9L-Regu,False,440.0806884765625,135.27297973632812,0.0,3,P
sample_7.pdf,8,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,145.23495483398438,0.09523809523809523,21,P
sample_7.pdf,8,0.91,8.966400146484375,NimbusRomNo9L-Regu,False,235.9964141845703,145.23495483398438,0.0,4,P
sample_7.pdf,8,0.35,8.966400146484375,NimbusRomNo9L-Regu,False,278.13848876953125,145.23495483398438,0.0,4,P
sample_7.pdf,8,0.96,8.966400146484375,NimbusRomNo9L-Regu,False,316.97198486328125,145.23495483398438,0.0,4,P
sample_7.pdf,8,0.46,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051330566406,145.23495483398438,0.0,4,P
sample_7.pdf,8,0.34,8.966400146484375,NimbusRomNo9L-Regu,False,397.9385986328125,145.23495483398438,0.0,4,P
sample_7.pdf,8,0.02,8.966400146484375,NimbusRomNo9L-Regu,False,440.0806884765625,145.23495483398438,0.0,4,P
sample_7.pdf,8,Neural GPU,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,155.19796752929688,0.4,10,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,235.99899291992188,155.11610412597656,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,278.1321105957031,155.11610412597656,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,316.97454833984375,155.11610412597656,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,359.107666015625,155.11610412597656,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,397.941162109375,155.11610412597656,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,440.07427978515625,155.11610412597656,0.0,3,P
sample_7.pdf,8,Table 4: Accuracy (higher better) on the algorithmic tasks.,9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,172.67237854003906,0.03389830508474576,59,H3
sample_7.pdf,8,Note that the Neural GPU was trained with,9.862470626831055,NimbusRomNo9L-Regu,False,339.4119873046875,172.67237854003906,0.12195121951219512,41,H3
sample_7.pdf,8,"a special curriculum to obtain the perfect result, while other models are trained without any curriculum.",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,183.63038635253906,0.0,105,H3
sample_7.pdf,8,Copy,8.966400146484375,NimbusRomNo9L-Medi,False,260.29400634765625,207.8061065673828,0.25,4,P
sample_7.pdf,8,Double,8.966400146484375,NimbusRomNo9L-Medi,False,337.7816467285156,207.8061065673828,0.16666666666666666,6,P
sample_7.pdf,8,Reverse,8.966400146484375,NimbusRomNo9L-Medi,False,417.3763732910156,207.8061065673828,0.14285714285714285,7,P
sample_7.pdf,8,Model,8.966400146484375,NimbusRomNo9L-Medi,False,143.2480010986328,222.5701446533203,0.2,5,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,235.99899291992188,222.65200805664062,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,278.1321105957031,222.65200805664062,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,316.9745178222656,222.65200805664062,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,359.10760498046875,222.65200805664062,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,397.9410705566406,222.65200805664062,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,440.07415771484375,222.65200805664062,0.0,7,P
sample_7.pdf,8,LSTM,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,237.61599731445312,1.0,4,P
sample_7.pdf,8,0.78,8.966400146484375,NimbusRomNo9L-Regu,False,235.9964599609375,237.61599731445312,0.0,4,P
sample_7.pdf,8,0.11,8.966400146484375,NimbusRomNo9L-Regu,False,278.1385498046875,237.61599731445312,0.0,4,P
sample_7.pdf,8,0.51,8.966400146484375,NimbusRomNo9L-Regu,False,316.9720458984375,237.61599731445312,0.0,4,P
sample_7.pdf,8,0.047,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051940917969,237.61599731445312,0.0,5,P
sample_7.pdf,8,0.91,8.966400146484375,NimbusRomNo9L-Regu,False,397.9386901855469,237.61599731445312,0.0,4,P
sample_7.pdf,8,0.32,8.966400146484375,NimbusRomNo9L-Regu,False,440.08074951171875,237.61599731445312,0.0,4,P
sample_7.pdf,8,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,247.57901000976562,0.09090909090909091,11,P
sample_7.pdf,8,0.98,8.966400146484375,NimbusRomNo9L-Regu,False,235.99642944335938,247.57901000976562,0.0,4,P
sample_7.pdf,8,0.63,8.966400146484375,NimbusRomNo9L-Regu,False,278.13848876953125,247.57901000976562,0.0,4,P
sample_7.pdf,8,0.94,8.966400146484375,NimbusRomNo9L-Regu,False,316.97198486328125,247.57901000976562,0.0,4,P
sample_7.pdf,8,0.55,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051330566406,247.57901000976562,0.0,4,P
sample_7.pdf,8,0.81,8.966400146484375,NimbusRomNo9L-Regu,False,397.9385986328125,247.57901000976562,0.0,4,P
sample_7.pdf,8,0.26,8.966400146484375,NimbusRomNo9L-Regu,False,440.0806884765625,247.57901000976562,0.0,4,P
sample_7.pdf,8,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,257.5409851074219,0.09523809523809523,21,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,235.99899291992188,257.4591064453125,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,278.1321105957031,257.4591064453125,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,316.97454833984375,257.4591064453125,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,359.107666015625,257.4591064453125,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,397.941162109375,257.4591064453125,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,440.07427978515625,257.4591064453125,0.0,3,P
sample_7.pdf,8,Table 5: Character-level (,9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,275.0154113769531,0.07692307692307693,26,H3
sample_7.pdf,8,char-acc,9.862470626831055,NimbusRomNo9L-ReguItal,False,205.95199584960938,274.8406982421875,0.0,8,H3
sample_7.pdf,8,) and sequence-level accuracy (,9.862470626831055,NimbusRomNo9L-Regu,False,240.302001953125,275.0154113769531,0.0,31,H3
sample_7.pdf,8,seq-acc,9.862470626831055,NimbusRomNo9L-ReguItal,False,360.74200439453125,274.8406982421875,0.0,7,H3
sample_7.pdf,8,) results on the Memorization,9.862470626831055,NimbusRomNo9L-Regu,False,390.5589904785156,275.0154113769531,0.034482758620689655,29,H3
sample_7.pdf,8,"LTE tasks, with maximum length of 55.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,285.8984680175781,0.08108108108108109,37,H3
sample_7.pdf,8,Program,8.966400146484375,NimbusRomNo9L-Medi,False,253.4080047607422,310.14910888671875,0.14285714285714285,7,P
sample_7.pdf,8,Control,8.966400146484375,NimbusRomNo9L-Medi,False,336.6162109375,310.14910888671875,0.14285714285714285,7,P
sample_7.pdf,8,Addition,8.966400146484375,NimbusRomNo9L-Medi,False,415.5115661621094,310.14910888671875,0.125,8,P
sample_7.pdf,8,Model,8.966400146484375,NimbusRomNo9L-Medi,False,143.2480010986328,324.9140930175781,0.2,5,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,235.99899291992188,324.9959716796875,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,278.1321105957031,324.9959716796875,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,316.9745178222656,324.9959716796875,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,359.10760498046875,324.9959716796875,0.0,7,P
sample_7.pdf,8,char-acc,8.966400146484375,NimbusRomNo9L-Regu,False,397.9410705566406,324.9959716796875,0.0,8,P
sample_7.pdf,8,seq-acc,8.966400146484375,NimbusRomNo9L-Regu,False,440.07415771484375,324.9959716796875,0.0,7,P
sample_7.pdf,8,LSTM,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,339.958984375,1.0,4,P
sample_7.pdf,8,0.53,8.966400146484375,NimbusRomNo9L-Regu,False,235.9964599609375,339.958984375,0.0,4,P
sample_7.pdf,8,0.12,8.966400146484375,NimbusRomNo9L-Regu,False,278.1385498046875,339.958984375,0.0,4,P
sample_7.pdf,8,0.68,8.966400146484375,NimbusRomNo9L-Regu,False,316.9720458984375,339.958984375,0.0,4,P
sample_7.pdf,8,0.21,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051940917969,339.958984375,0.0,4,P
sample_7.pdf,8,0.83,8.966400146484375,NimbusRomNo9L-Regu,False,397.93865966796875,339.958984375,0.0,4,P
sample_7.pdf,8,0.11,8.966400146484375,NimbusRomNo9L-Regu,False,440.08074951171875,339.958984375,0.0,4,P
sample_7.pdf,8,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.2480010986328,349.9219970703125,0.09090909090909091,11,P
sample_7.pdf,8,0.71,8.966400146484375,NimbusRomNo9L-Regu,False,235.99642944335938,349.9219970703125,0.0,4,P
sample_7.pdf,8,0.29,8.966400146484375,NimbusRomNo9L-Regu,False,278.13848876953125,349.9219970703125,0.0,4,P
sample_7.pdf,8,0.93,8.966400146484375,NimbusRomNo9L-Regu,False,316.97198486328125,349.9219970703125,0.0,4,P
sample_7.pdf,8,0.66,8.966400146484375,NimbusRomNo9L-Regu,False,359.1051330566406,349.9219970703125,0.0,4,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,397.9420166015625,349.8401184082031,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,440.07513427734375,349.8401184082031,0.0,3,P
sample_7.pdf,8,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,143.24801635742188,359.8840026855469,0.09523809523809523,21,P
sample_7.pdf,8,0.89,8.966400146484375,NimbusRomNo9L-Medi,False,235.9990234375,359.8021240234375,0.0,4,P
sample_7.pdf,8,0.63,8.966400146484375,NimbusRomNo9L-Medi,False,278.13214111328125,359.8021240234375,0.0,4,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,316.974609375,359.8021240234375,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,359.10772705078125,359.8021240234375,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,397.94122314453125,359.8021240234375,0.0,3,P
sample_7.pdf,8,1.0,8.966400146484375,NimbusRomNo9L-Medi,False,440.0743408203125,359.8021240234375,0.0,3,P
sample_7.pdf,8,Table 6: Character-level (,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,377.2073059082031,0.07692307692307693,26,H3
sample_7.pdf,8,char-acc,10.061732292175293,NimbusRomNo9L-ReguItal,False,212.08700561523438,377.0290832519531,0.0,8,H3
sample_7.pdf,8,) and sequence-level accuracy (,10.061732292175293,NimbusRomNo9L-Regu,False,247.85299682617188,377.2073059082031,0.0,31,H3
sample_7.pdf,8,seq-acc,10.061732292175293,NimbusRomNo9L-ReguItal,False,375.3529968261719,377.0290832519531,0.0,7,H3
sample_7.pdf,8,) results on the Program,10.061732292175293,NimbusRomNo9L-Regu,False,406.3869934082031,377.2073059082031,0.041666666666666664,24,H3
sample_7.pdf,8,Evaluation LTE tasks with maximum nesting of 2 and length of 5.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,388.241455078125,0.06349206349206349,63,H3
sample_7.pdf,8,train UTs using positions starting with randomized offsets to further encourage the model to learn,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,419.1182861328125,0.02040816326530612,98,H3
sample_7.pdf,8,position-relative transformations. Results are shown in Table 4. The UT outperforms both LSTM and,9.942654609680176,NimbusRomNo9L-Regu,False,108.0,429.9486083984375,0.09278350515463918,97,H3
sample_7.pdf,8,vanilla Transformer by a wide margin on all three tasks. The Neural GPU reports perfect results on this,9.872529029846191,NimbusRomNo9L-Regu,False,107.7509994506836,440.7417907714844,0.05825242718446602,103,H3
sample_7.pdf,8,"task (Kaiser & Sutskever, 2016), however we note that this result required a special curriculum-based",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,451.4237976074219,0.019801980198019802,101,H3
sample_7.pdf,8,training protocol which was not used for other models.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,462.1524658203125,0.0,54,H3
sample_7.pdf,8,3.5,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,495.6464538574219,0.0,3,H3
sample_7.pdf,8,EARNING TO,7.970099925994873,NimbusRomNo9L-Regu,False,138.7449951171875,497.1575622558594,0.9,10,P
sample_7.pdf,8,XECUTE,7.970099925994873,NimbusRomNo9L-Regu,False,200.08399963378906,497.1575622558594,1.0,6,P
sample_7.pdf,8,(LTE),9.962599754333496,NimbusRomNo9L-Regu,False,233.9728546142578,495.6464538574219,0.6,5,H3
sample_7.pdf,8,"As another class of sequence-to-sequence learning problems, we also evaluate UTs on tasks",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,519.3572998046875,0.033707865168539325,89,H3
sample_7.pdf,8,"indicating the ability of a model to learn to execute computer programs, as proposed in (Zaremba &",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,530.0972900390625,0.01020408163265306,98,H3
sample_7.pdf,8,"Sutskever, 2015). These tasks include program evaluation tasks (program, control, and addition), and",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,540.9190063476562,0.02,100,H3
sample_7.pdf,8,"memorization tasks (copy, double, and reverse).",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,551.6514892578125,0.0,47,H3
sample_7.pdf,8,"We use the mix-strategy discussed in (Zaremba & Sutskever, 2015) to generate the datasets.",10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,568.2932739257812,0.03333333333333333,90,H3
sample_7.pdf,8,"Unlike (Zaremba & Sutskever, 2015), we do not use any curriculum learning strategy during training",9.977532386779785,NimbusRomNo9L-Regu,False,108.0,579.09716796875,0.030612244897959183,98,H3
sample_7.pdf,8,and we make no use of target sequences at test time. Tables 5 and 6 present the performance of an,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,589.7732543945312,0.010309278350515464,97,H3
sample_7.pdf,8,"LSTM model, Transformer, and Universal Transformer on the program evaluation and memorization",9.95761775970459,NimbusRomNo9L-Regu,False,108.0,600.5912475585938,0.07526881720430108,93,H3
sample_7.pdf,8,"tasks, respectively. UT achieves perfect scores in all the memorization tasks and also outperforms",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,611.2522583007812,0.02040816326530612,98,H3
sample_7.pdf,8,both LSTMs and Transformers in all program evaluation tasks by a wide margin.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,622.0674438476562,0.06493506493506493,77,H3
sample_7.pdf,8,3.6,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,655.5614624023438,0.0,3,H3
sample_7.pdf,8,ACHINE,7.970099925994873,NimbusRomNo9L-Regu,False,141.51400756835938,657.0725708007812,1.0,6,P
sample_7.pdf,8,RANSLATION,7.970099925994873,NimbusRomNo9L-Regu,False,182.82901000976562,657.0725708007812,1.0,10,P
sample_7.pdf,8,We trained a UT on the WMT 2014 English-German translation task using the same setup as reported in,9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,679.4234008789062,0.08080808080808081,99,H3
sample_7.pdf,8,"(Vaswani et al., 2017) in order to evaluate its performance on a large-scale sequence-to-sequence task.",9.937662124633789,NimbusRomNo9L-Regu,False,107.6709976196289,690.1063842773438,0.009708737864077669,103,H3
sample_7.pdf,8,Results are summarized in Table 7. The UT with a fully-connected recurrent transition function (instead,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,700.9024047851562,0.04854368932038835,103,H3
sample_7.pdf,8,of separable convolution) and without ACT improves by 0.9 BLEU over a Transformer and 0.5 BLEU,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,711.6043701171875,0.1276595744680851,94,H3
sample_7.pdf,8,"over a Weighted Transformer with approximately the same number of parameters (Ahmed et al., 2017).",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,722.3823852539062,0.030612244897959183,98,H3
sample_7.pdf,9,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,9,Model,8.966400146484375,NimbusRomNo9L-Medi,False,200.13299560546875,85.53809356689453,0.2,5,P
sample_7.pdf,9,BLEU,8.966400146484375,NimbusRomNo9L-Medi,False,385.65679931640625,85.53809356689453,1.0,4,P
sample_7.pdf,9,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,200.13299560546875,100.58297729492188,0.09523809523809523,21,P
sample_7.pdf,9,small,8.966400146484375,NimbusRomNo9L-ReguItal,False,280.9291687011719,100.42415618896484,0.0,5,P
sample_7.pdf,9,26.8,8.966400146484375,NimbusRomNo9L-Regu,False,390.0199890136719,100.58297729492188,0.0,4,P
sample_7.pdf,9,Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,200.13299560546875,110.54598999023438,0.09090909090909091,11,P
sample_7.pdf,9,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,244.6332244873047,110.38716888427734,0.0,4,P
sample_7.pdf,9,"(Vaswani et al., 2017)",8.966400146484375,NimbusRomNo9L-Regu,False,262.86138916015625,110.54598999023438,0.045454545454545456,22,P
sample_7.pdf,9,28.0,8.966400146484375,NimbusRomNo9L-Regu,False,390.023193359375,110.54598999023438,0.0,4,P
sample_7.pdf,9,Weighted Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,200.13299560546875,120.50900268554688,0.1,20,P
sample_7.pdf,9,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,280.5705261230469,120.35018157958984,0.0,4,P
sample_7.pdf,9,"(Ahmed et al., 2017)",8.966400146484375,NimbusRomNo9L-Regu,False,298.79840087890625,120.50900268554688,0.05,20,P
sample_7.pdf,9,28.4,8.966400146484375,NimbusRomNo9L-Regu,False,390.0229187011719,120.50900268554688,0.0,4,P
sample_7.pdf,9,Universal Transformer,8.966400146484375,NimbusRomNo9L-Regu,False,200.1330108642578,130.47097778320312,0.09523809523809523,21,P
sample_7.pdf,9,base,8.966400146484375,NimbusRomNo9L-ReguItal,False,280.9292297363281,130.31214904785156,0.0,4,P
sample_7.pdf,9,28.9,8.966400146484375,NimbusRomNo9L-Medi,False,390.02001953125,130.3891143798828,0.0,4,P
sample_7.pdf,9,Table 7: Machine translation results on the WMT14 En-De translation task trained on 8xP100 GPUs,10.002370834350586,NimbusRomNo9L-Regu,False,107.69100189208984,147.83929443359375,0.11578947368421053,95,H3
sample_7.pdf,9,in comparable training setups. All,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,158.8284454345703,0.029411764705882353,34,H3
sample_7.pdf,9,base,9.962599754333496,NimbusRomNo9L-ReguItal,False,241.91729736328125,158.6519775390625,0.0,4,H3
sample_7.pdf,9,results have the same number of parameters.,9.962599754333496,NimbusRomNo9L-Regu,False,262.1704406738281,158.8284454345703,0.0,43,H3
sample_7.pdf,9,ISCUSSION,9.56410026550293,NimbusRomNo9L-Regu,False,136.05899047851562,188.53367614746094,1.0,9,H3
sample_7.pdf,9,"When running for a ﬁxed number of steps, the Universal Transformer is equivalent to a multi-layer",10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,215.77731323242188,0.030927835051546393,97,H3
sample_7.pdf,9,Transformer with tied parameters across all its layers.,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,226.51730346679688,0.01818181818181818,55,H3
sample_7.pdf,9,This is partly similar to the Recursive,10.061732292175293,NimbusRomNo9L-Regu,False,343.3850402832031,226.51730346679688,0.05128205128205128,39,H3
sample_7.pdf,9,"Transformer, which ties the weights of its self-attention layers across depth (Gulcehre et al., 2018)",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,237.25631713867188,0.019801980198019802,101,H3
sample_7.pdf,9,"However, as the per-symbol recurrent transition functions can be applied any number of times, another",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,248.1283721923828,0.009900990099009901,101,H3
sample_7.pdf,9,and possibly more informative way of characterizing the UT is as a block of parallel RNNs (one for,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,258.7362976074219,0.05102040816326531,98,H3
sample_7.pdf,9,"each symbol, with shared parameters) evolving per-symbol hidden states concurrently, generated at",10.046924591064453,NimbusRomNo9L-Regu,False,108.0,269.4865417480469,0.0,97,H3
sample_7.pdf,9,"each step by attending to the sequence of hidden states at the previous step. In this way, it is related",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,280.2153015136719,0.009615384615384616,104,H3
sample_7.pdf,9,"to architectures such as the Neural GPU (Kaiser & Sutskever, 2016) and the Neural Turing Machine",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,290.9777526855469,0.09375,96,H3
sample_7.pdf,9,"(Graves et al., 2014). UTs thereby retain the attractive computational efﬁciency of the original feed-",10.056798934936523,NimbusRomNo9L-Regu,False,107.6709976196289,301.69805908203125,0.029411764705882353,102,H3
sample_7.pdf,9,"forward Transformer model, but with the added recurrent inductive bias of RNNs. Furthermore, using",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,312.5435485839844,0.05102040816326531,98,H3
sample_7.pdf,9,"a dynamic halting mechanism, UTs can choose the number of processing steps based on the input data.",9.89763069152832,NimbusRomNo9L-Regu,False,108.0,323.2987365722656,0.020202020202020204,99,H3
sample_7.pdf,9,The connection between the Universal Transformer and other sequence models is apparent from,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,339.89129638671875,0.03296703296703297,91,H3
sample_7.pdf,9,"the architecture: if we limited the recurrent steps to one, it would be a Transformer. But it is more",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,350.63128662109375,0.019801980198019802,101,H3
sample_7.pdf,9,interesting to consider the relationship between the Universal Transformer and RNNs and other,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,361.37030029296875,0.053763440860215055,93,H3
sample_7.pdf,9,networks where recurrence happens over the time dimension. Superﬁcially these models may seem,10.056798934936523,NimbusRomNo9L-Regu,False,108.0,372.114013671875,0.010752688172043012,93,H3
sample_7.pdf,9,closely related since they are recurrent as well. But there is a crucial difference: time-recurrent models,9.89261531829834,NimbusRomNo9L-Regu,False,108.0,382.9785461425781,0.009433962264150943,106,H3
sample_7.pdf,9,like RNNs cannot access memory in the recurrent steps. This makes them computationally more similar,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,393.74041748046875,0.04040404040404041,99,H3
sample_7.pdf,9,"to automata, since the only memory available in the recurrent part is a ﬁxed-size state vector. UTs on",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,404.3780517578125,0.0196078431372549,102,H3
sample_7.pdf,9,"the other hand can attend to the whole previous layer, allowing it to access memory in the recurrent step.",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,415.2204284667969,0.0,106,H3
sample_7.pdf,9,Given sufﬁcient memory the Universal Transformer is computationally universal – i.e. it belongs to,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,431.7862854003906,0.030612244897959183,98,H3
sample_7.pdf,9,"the class of models that can be used to simulate any Turing machine, thereby addressing a shortcoming",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,442.6659851074219,0.009900990099009901,101,H3
sample_7.pdf,9,of the standard Transformer model,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,453.2652893066406,0.030303030303030304,33,H3
sample_7.pdf,9,". In addition to being theoretically appealing, our results show",10.061732292175293,NimbusRomNo9L-Regu,False,254.27099609375,453.2652893066406,0.015625,64,H3
sample_7.pdf,9,that this added expressivity also leads to improved accuracy on several challenging sequence modeling,9.872529029846191,NimbusRomNo9L-Regu,False,108.0,464.1487731933594,0.0,101,H3
sample_7.pdf,9,tasks. This closes the gap between practical sequence models competitive on large-scale tasks such,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,474.74530029296875,0.01020408163265306,98,H3
sample_7.pdf,9,"as machine translation, and computationally universal models such as the Neural Turing Machine",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,485.4842834472656,0.031914893617021274,94,H3
sample_7.pdf,9,"or the Neural GPU (Graves et al., 2014; Kaiser & Sutskever, 2016), which can be trained using gradient",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,496.37542724609375,0.06862745098039216,102,H3
sample_7.pdf,9,descent to perform algorithmic tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,507.0394287109375,0.0,37,H3
sample_7.pdf,9,"To show this, we can reduce a Neural GPU to a Universal Transformer. Ignoring the decoder and pa-",10.032095909118652,NimbusRomNo9L-Regu,False,107.69100189208984,523.7037963867188,0.08247422680412371,97,H3
sample_7.pdf,9,"rameterizing the self-attention module, i.e. self-attention with the residual connection, to be the identity",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,534.5723876953125,0.0,108,H3
sample_7.pdf,9,"function, we assume the transition function to be a convolution. If we now set the total number of",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,545.1602783203125,0.01020408163265306,98,H3
sample_7.pdf,9,recurrent steps,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,556.0513916015625,0.0,15,H3
sample_7.pdf,9,"to be equal to the input length, we obtain exactly a Neural GPU. Note that the last step",9.862470626831055,NimbusRomNo9L-Regu,False,172.38516235351562,556.0513916015625,0.056818181818181816,88,H3
sample_7.pdf,9,is where the Universal Transformer crucially differs from the vanilla Transformer whose depth cannot,9.9176664352417,NimbusRomNo9L-Regu,False,108.0,566.7495727539062,0.03,100,H3
sample_7.pdf,9,scale dynamically with the size of the input. A similar relationship exists between the Universal Trans-,9.902643203735352,NimbusRomNo9L-Regu,False,108.0,577.4999389648438,0.028846153846153848,104,H3
sample_7.pdf,9,"former and the Neural Turing Machine, whose single read/write operations per step can be expressed by",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,588.2703857421875,0.0297029702970297,101,H3
sample_7.pdf,9,"the global, parallel representation revisions of the Universal Transformer. In contrast to these models,",9.95761775970459,NimbusRomNo9L-Regu,False,108.0,598.938232421875,0.028846153846153848,104,H3
sample_7.pdf,9,"however, which only perform well on algorithmic tasks, the Universal Transformer also achieves",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,609.5982666015625,0.02127659574468085,94,H3
sample_7.pdf,9,competitive results on realistic natural language tasks such as LAMBADA and machine translation.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,620.4134521484375,0.07291666666666667,96,H3
sample_7.pdf,9,"Another related model architecture is that of end-to-end Memory Networks (Sukhbaatar et al.,",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,637.0552978515625,0.043478260869565216,92,H3
sample_7.pdf,9,2015).,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,647.7952880859375,0.0,6,H3
sample_7.pdf,9,"In contrast to end-to-end memory networks, however, the Universal Transformer uses",10.061732292175293,NimbusRomNo9L-Regu,False,142.4283447265625,647.7952880859375,0.036585365853658534,82,H3
sample_7.pdf,9,"memory corresponding to states aligned to individual positions of its inputs or outputs. Furthermore,",10.002370834350586,NimbusRomNo9L-Regu,False,108.0,658.580322265625,0.009900990099009901,101,H3
sample_7.pdf,9,the Universal Transformer follows the encoder-decoder conﬁguration and achieves competitive,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,669.2742919921875,0.02197802197802198,91,H3
sample_7.pdf,9,performance in large-scale sequence-to-sequence tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,680.0894775390625,0.0,54,H3
sample_7.pdf,9,Note that in UT both the self-attention and transition weights are tied across layers.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,712.2109375,0.03488372093023256,86,P
sample_7.pdf,9,Appendix B illustrates how UT is computationally more powerful than the standard Transformer.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,723.0619506835938,0.053763440860215055,93,P
sample_7.pdf,10,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,10,ONCLUSION,9.56410026550293,NimbusRomNo9L-Regu,False,135.4010009765625,84.57066345214844,1.0,9,H3
sample_7.pdf,10,"This paper introduces the Universal Transformer, a generalization of the Transformer model that",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,107.81228637695312,0.042105263157894736,95,H3
sample_7.pdf,10,extends its theoretical capabilities and produces state-of-the-art results on a wide range of challenging,9.9176664352417,NimbusRomNo9L-Regu,False,108.0,118.66152954101562,0.0,105,H3
sample_7.pdf,10,"sequence modeling tasks, such as language understanding but also a variety of algorithmic tasks,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,129.29226684570312,0.0,96,H3
sample_7.pdf,10,thereby addressing a key shortcoming of the standard Transformer. The Universal Transformer,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,140.03128051757812,0.04395604395604396,91,H3
sample_7.pdf,10,combines the following key properties into one model:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,150.84645080566406,0.0,53,H3
sample_7.pdf,10,Weight sharing,9.962599754333496,NimbusRomNo9L-Medi,False,107.50199890136719,167.47247314453125,0.07142857142857142,14,H3
sample_7.pdf,10,": Following intuitions behind weight sharing found in CNNs and RNNs, we extend the",9.862470626831055,NimbusRomNo9L-Regu,False,171.9029998779297,167.63941955566406,0.08536585365853659,82,H3
sample_7.pdf,10,Transformer with a simple form of weight sharing that strikes an effective balance between inductive,9.982504844665527,NimbusRomNo9L-Regu,False,107.69100189208984,178.28839111328125,0.01,100,H3
sample_7.pdf,10,"bias and model expressivity, which we show extensively on both small and large-scale experiments.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,189.04347229003906,0.0,97,H3
sample_7.pdf,10,Conditional computation,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,205.66949462890625,0.043478260869565216,23,H3
sample_7.pdf,10,": In our goal to build a computationally universal machine, we equipped the",9.862470626831055,NimbusRomNo9L-Regu,False,214.01800537109375,205.8363800048828,0.013333333333333334,75,H3
sample_7.pdf,10,Universal Transformer with the ability to halt or continue computation through a recently introduced,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,216.48162841796875,0.02,100,H3
sample_7.pdf,10,"mechanism, which shows stronger results compared to the ﬁxed-depth Universal Transformer.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,227.2394561767578,0.02247191011235955,89,H3
sample_7.pdf,10,We are enthusiastic about the recent developments on parallel-in-time sequence models. By adding,10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,243.88229370117188,0.020833333333333332,96,H3
sample_7.pdf,10,"computational capacity and recurrence in processing depth, we hope that further improvements beyond",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,254.7724151611328,0.0,99,H3
sample_7.pdf,10,the basic Universal Transformer presented here will help us build learning algorithms that are both,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,265.3612976074219,0.020202020202020204,99,H3
sample_7.pdf,10,"more powerful, data efﬁcient, and generalize beyond the current state-of-the-art.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,276.17645263671875,0.0,81,H3
sample_7.pdf,10,The code used to train and evaluate Universal Transformers is available at,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,299.05828857421875,0.04054054054054054,74,H3
sample_7.pdf,10,https:,9.962599754333496,NimbusMonL-Regu,False,463.5083923339844,298.6234130859375,0.0,6,H3
sample_7.pdf,10,//github.com/tensorflow/tensor2tensor,9.962599754333496,NimbusMonL-Regu,False,107.4019775390625,309.3624267578125,0.0,37,H3
sample_7.pdf,10,"(Vaswani et al., 2018).",9.962599754333496,NimbusRomNo9L-Regu,False,328.57171630859375,309.8724670410156,0.043478260869565216,23,H3
sample_7.pdf,10,Acknowledgements,9.962599754333496,NimbusRomNo9L-Medi,False,107.99996948242188,339.7585144042969,0.0625,16,H3
sample_7.pdf,10,"We are grateful to Ashish Vaswani, Douglas Eck, and David Dohan for their",10.061732292175293,NimbusRomNo9L-Regu,False,200.322998046875,339.7742919921875,0.0958904109589041,73,H3
sample_7.pdf,10,fruitful comments and inspiration.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,350.5894470214844,0.0,34,H3
sample_7.pdf,10,EFERENCES,9.56410026550293,NimbusRomNo9L-Regu,False,116.87100219726562,378.8726806640625,1.0,9,H3
sample_7.pdf,10,"Karim Ahmed, Nitish Shirish Keskar, and Richard Socher. Weighted transformer network for machine translation.",8.885335922241211,NimbusRomNo9L-Regu,False,108.0,395.3624572753906,0.07339449541284404,109,P
sample_7.pdf,10,arXiv preprint arXiv:1711.02132,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,404.9061584472656,0.06451612903225806,31,P
sample_7.pdf,10,", 2017.",8.966400146484375,NimbusRomNo9L-Regu,False,236.031005859375,405.0649719238281,0.0,7,P
sample_7.pdf,10,"Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization.",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,423.39129638671875,0.13333333333333333,75,P
sample_7.pdf,10,arXiv preprint arXiv:1607.06450,8.876283645629883,NimbusRomNo9L-ReguItal,False,384.4324645996094,423.23406982421875,0.06451612903225806,31,P
sample_7.pdf,10,2016. URL,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,433.0859680175781,0.3333333333333333,9,P
sample_7.pdf,10,http://arxiv.org/abs/1607.06450,8.966400146484375,NimbusMonL-Regu,False,158.8497772216797,432.6269226074219,0.0,31,P
sample_7.pdf,10,"Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align",8.916949272155762,NimbusRomNo9L-Regu,False,108.0,451.3815002441406,0.06542056074766354,107,P
sample_7.pdf,10,and translate.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,461.10699462890625,0.0,14,P
sample_7.pdf,10,CoRR,8.966400146484375,NimbusRomNo9L-ReguItal,False,165.32351684570312,460.94818115234375,0.75,4,P
sample_7.pdf,10,", abs/1409.0473, 2014. URL",8.966400146484375,NimbusRomNo9L-Regu,False,189.5229949951172,461.10699462890625,0.11538461538461539,26,P
sample_7.pdf,10,http://arxiv.org/abs/1409.0473,8.966400146484375,NimbusMonL-Regu,False,291.0316467285156,460.64794921875,0.0,30,P
sample_7.pdf,10,"Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio.",8.957428932189941,NimbusRomNo9L-Regu,False,108.0,479.3717956542969,0.11538461538461539,104,P
sample_7.pdf,10,Learning phrase representations using RNN encoder-decoder for statistical machine translation.,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,489.0603332519531,0.0425531914893617,94,P
sample_7.pdf,10,CoRR,9.055620193481445,NimbusRomNo9L-ReguItal,False,474.3080749511719,488.8999328613281,0.75,4,P
sample_7.pdf,10,"abs/1406.1078, 2014. URL",8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,498.8919677734375,0.125,24,P
sample_7.pdf,10,http://arxiv.org/abs/1406.1078,8.966400146484375,NimbusMonL-Regu,False,215.43675231933594,498.43292236328125,0.0,30,P
sample_7.pdf,10,Francois Chollet.,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,517.0823364257812,0.11764705882352941,17,P
sample_7.pdf,10,Xception:,9.055620193481445,NimbusRomNo9L-Regu,False,184.92471313476562,517.0823364257812,0.1111111111111111,9,P
sample_7.pdf,10,Deep learning with depthwise separable convolutions.,9.055620193481445,NimbusRomNo9L-Regu,False,228.8607635498047,517.0823364257812,0.019230769230769232,52,P
sample_7.pdf,10,arXiv preprint,9.055620193481445,NimbusRomNo9L-ReguItal,False,449.4679870605469,516.9219360351562,0.07142857142857142,14,P
sample_7.pdf,10,arXiv:1610.02357,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,526.754150390625,0.0625,16,P
sample_7.pdf,10,", 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,183.46200561523438,526.9129638671875,0.0,7,P
sample_7.pdf,10,"Zewei Chu, Hai Wang, Kevin Gimpel, and David McAllester. Broad context language modeling as reading",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,545.1033325195312,0.10101010101010101,99,P
sample_7.pdf,10,comprehension. In,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,554.8663330078125,0.058823529411764705,17,P
sample_7.pdf,10,Proceedings of the 15th Conference of the European Chapter of the Association for,9.055620193481445,NimbusRomNo9L-ReguItal,False,189.85755920410156,554.7059326171875,0.06172839506172839,81,P
sample_7.pdf,10,"Computational Linguistics: Volume 2, Short Papers",8.966400146484375,NimbusRomNo9L-ReguItal,False,117.66699981689453,564.5391235351562,0.10204081632653061,49,P
sample_7.pdf,10,", volume 2, pp. 52–57, 2017.",8.966400146484375,NimbusRomNo9L-Regu,False,300.47100830078125,564.6979370117188,0.0,28,P
sample_7.pdf,10,"Bhuwan Dhingra, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. Linguistic knowledge as memory",8.975361824035645,NimbusRomNo9L-Regu,False,108.0,582.9491577148438,0.09803921568627451,102,P
sample_7.pdf,10,for recurrent neural networks.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,592.7189331054688,0.0,30,P
sample_7.pdf,10,arXiv preprint arXiv:1703.02620,8.966400146484375,NimbusRomNo9L-ReguItal,False,223.587158203125,592.5601196289062,0.06451612903225806,31,P
sample_7.pdf,10,", 2017.",8.966400146484375,NimbusRomNo9L-Regu,False,344.4329833984375,592.7189331054688,0.0,7,P
sample_7.pdf,10,"Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. Neural models for",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,610.9093017578125,0.12121212121212122,99,P
sample_7.pdf,10,reasoning over multiple mentions using coreference.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,620.7399291992188,0.0,51,P
sample_7.pdf,10,arXiv preprint arXiv:1804.05922,8.966400146484375,NimbusRomNo9L-ReguItal,False,303.7109069824219,620.5811157226562,0.06451612903225806,31,P
sample_7.pdf,10,", 2018.",8.966400146484375,NimbusRomNo9L-Regu,False,424.55596923828125,620.7399291992188,0.0,7,P
sample_7.pdf,10,"Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,638.9302978515625,0.11764705882352941,102,P
sample_7.pdf,10,to sequence learning.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,648.760986328125,0.0,21,P
sample_7.pdf,10,CoRR,8.966400146484375,NimbusRomNo9L-ReguItal,False,193.01174926757812,648.6021728515625,0.75,4,P
sample_7.pdf,10,", abs/1705.03122, 2017. URL",8.966400146484375,NimbusRomNo9L-Regu,False,217.2110137939453,648.760986328125,0.1111111111111111,27,P
sample_7.pdf,10,http://arxiv.org/abs/1705.03122,8.966400146484375,NimbusMonL-Regu,False,323.2029113769531,648.3019409179688,0.0,31,P
sample_7.pdf,10,"Edouard Grave, Armand Joulin, and Nicolas Usunier. Improving neural language models with a continuous cache.",8.880810737609863,NimbusRomNo9L-Regu,False,108.0,667.0838623046875,0.06481481481481481,108,P
sample_7.pdf,10,arXiv preprint arXiv:1612.04426,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,676.6241455078125,0.06451612903225806,31,P
sample_7.pdf,10,", 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,236.031005859375,676.782958984375,0.0,7,P
sample_7.pdf,10,Alex Graves. Generating sequences with recurrent neural networks.,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,694.9733276367188,0.046153846153846156,65,P
sample_7.pdf,10,CoRR,9.055620193481445,NimbusRomNo9L-ReguItal,False,364.8761291503906,694.8129272460938,0.75,4,P
sample_7.pdf,10,", abs/1308.0850, 2013. URL",9.055620193481445,NimbusRomNo9L-Regu,False,393.7659912109375,694.9733276367188,0.11538461538461539,26,P
sample_7.pdf,10,http://arxiv.org/abs/1308.0850,8.966400146484375,NimbusMonL-Regu,False,117.96299743652344,704.3449096679688,0.0,30,P
sample_7.pdf,10,Alex Graves. Adaptive computation time for recurrent neural networks.,8.952940940856934,NimbusRomNo9L-Regu,False,108.0,723.0722045898438,0.043478260869565216,69,P
sample_7.pdf,10,arXiv preprint arXiv:1603.08983,8.952940940856934,NimbusRomNo9L-ReguItal,False,360.76458740234375,722.91357421875,0.06451612903225806,31,P
sample_7.pdf,10,", 2016.",8.952940940856934,NimbusRomNo9L-Regu,False,481.26300048828125,723.0722045898438,0.0,7,P
sample_7.pdf,11,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,11,"Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines.",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,84.95629119873047,0.1044776119402985,67,P
sample_7.pdf,11,CoRR,9.055620193481445,NimbusRomNo9L-ReguItal,False,371.51593017578125,84.79589080810547,0.75,4,P
sample_7.pdf,11,", abs/1410.5401, 2014. URL",9.055620193481445,NimbusRomNo9L-Regu,False,397.9530029296875,84.95629119873047,0.11538461538461539,26,P
sample_7.pdf,11,http://arxiv.org/abs/1410.5401,8.966400146484375,NimbusMonL-Regu,False,117.96299743652344,94.32894897460938,0.0,30,P
sample_7.pdf,11,"Caglar Gulcehre, Misha Denil, Mateusz Malinowski, Ali Razavi, Razvan Pascanu, Karl Moritz Hermann, Peter",9.00219440460205,NimbusRomNo9L-Regu,False,108.0,112.41184997558594,0.1346153846153846,104,P
sample_7.pdf,11,"Battaglia, Victor Bapst, David Raposo, Adam Santoro, et al. Hyperbolic attention networks.",9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,122.13433074951172,0.08888888888888889,90,P
sample_7.pdf,11,arXiv preprint,9.055620193481445,NimbusRomNo9L-ReguItal,False,449.42254638671875,121.97393035888672,0.07142857142857142,14,P
sample_7.pdf,11,arXiv:1805.09786,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,131.80714416503906,0.0625,16,P
sample_7.pdf,11,", 2018.",8.966400146484375,NimbusRomNo9L-Regu,False,183.46200561523438,131.96597290039062,0.0,7,P
sample_7.pdf,11,"Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. Tracking the world state with",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,149.54930114746094,0.11538461538461539,104,P
sample_7.pdf,11,recurrent entity networks.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,159.37997436523438,0.0,26,P
sample_7.pdf,11,arXiv preprint arXiv:1612.03969,8.966400146484375,NimbusRomNo9L-ReguItal,False,209.35748291015625,159.2211456298828,0.06451612903225806,31,P
sample_7.pdf,11,", 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,330.2039794921875,159.37997436523438,0.0,7,P
sample_7.pdf,11,"Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in recurrent nets: the",8.997727394104004,NimbusRomNo9L-Regu,False,108.0,177.00819396972656,0.08411214953271028,107,P
sample_7.pdf,11,difﬁculty of learning long-term dependencies.,8.952940940856934,NimbusRomNo9L-Regu,False,117.96299743652344,186.80516052246094,0.0,45,P
sample_7.pdf,11,A Field Guide to Dynamical Recurrent Neural Networks,8.952940940856934,NimbusRomNo9L-ReguItal,False,280.0809326171875,186.64657592773438,0.1346153846153846,52,P
sample_7.pdf,11,", 2003.",8.952940940856934,NimbusRomNo9L-Regu,False,481.260986328125,186.80516052246094,0.0,7,P
sample_7.pdf,11,A. Joulin and T. Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets. In,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,204.37828063964844,0.0625,96,P
sample_7.pdf,11,Advances in,9.055620193481445,NimbusRomNo9L-ReguItal,False,457.9705505371094,204.21788024902344,0.09090909090909091,11,P
sample_7.pdf,11,"Neural Information Processing Systems, (NIPS)",8.966400146484375,NimbusRomNo9L-ReguItal,False,117.66699981689453,214.0501251220703,0.17777777777777778,45,P
sample_7.pdf,11,", 2015.",8.966400146484375,NimbusRomNo9L-Regu,False,287.42498779296875,214.20895385742188,0.0,7,P
sample_7.pdf,11,Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,231.79331970214844,0.13636363636363635,66,P
sample_7.pdf,11,International Conference on Learning,9.055620193481445,NimbusRomNo9L-ReguItal,False,362.0317077636719,231.63291931152344,0.08333333333333333,36,P
sample_7.pdf,11,Representations (ICLR),8.966400146484375,NimbusRomNo9L-ReguItal,False,117.68499755859375,241.4651641845703,0.22727272727272727,22,P
sample_7.pdf,11,", 2016. URL",8.966400146484375,NimbusRomNo9L-Regu,False,202.32598876953125,241.62399291992188,0.2727272727272727,11,P
sample_7.pdf,11,https://arxiv.org/abs/1511.08228,8.966400146484375,NimbusMonL-Regu,False,247.24766540527344,241.16494750976562,0.0,32,P
sample_7.pdf,11,"Łukasz Kaiser, Aidan N. Gomez, and Francois Chollet. Depthwise separable convolutions for neural machine",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,259.20733642578125,0.07692307692307693,104,P
sample_7.pdf,11,translation.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,269.0389709472656,0.0,12,P
sample_7.pdf,11,CoRR,8.966400146484375,NimbusRomNo9L-ReguItal,False,158.06072998046875,268.8801574707031,0.75,4,P
sample_7.pdf,11,", abs/1706.03059, 2017. URL",8.966400146484375,NimbusRomNo9L-Regu,False,182.25999450683594,269.0389709472656,0.1111111111111111,27,P
sample_7.pdf,11,http://arxiv.org/abs/1706.03059,8.966400146484375,NimbusMonL-Regu,False,288.2518005371094,268.5799255371094,0.0,31,P
sample_7.pdf,11,"Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain",8.889859199523926,NimbusRomNo9L-Regu,False,108.0,286.7480163574219,0.1388888888888889,108,P
sample_7.pdf,11,"Paulus, and Richard Socher. Ask me anything: Dynamic memory networks for natural language processing.",9.037846565246582,NimbusRomNo9L-Regu,False,117.96299743652344,296.3987731933594,0.04950495049504951,101,P
sample_7.pdf,11,International Conference on Machine Learning,8.966400146484375,NimbusRomNo9L-ReguItal,False,125.4320068359375,306.05816650390625,0.09090909090909091,44,P
sample_7.pdf,11,", pp. 1378–1387, 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,295.8089904785156,306.21697998046875,0.0,22,P
sample_7.pdf,11,"Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio.",8.943955421447754,NimbusRomNo9L-Regu,False,108.0,323.885009765625,0.14563106796116504,103,P
sample_7.pdf,11,A structured self-attentive sentence embedding.,8.966400146484375,NimbusRomNo9L-Regu,False,117.63999938964844,333.6309814453125,0.02127659574468085,47,P
sample_7.pdf,11,arXiv preprint arXiv:1703.03130,8.966400146484375,NimbusRomNo9L-ReguItal,False,286.5579528808594,333.47216796875,0.06451612903225806,31,P
sample_7.pdf,11,", 2017.",8.966400146484375,NimbusRomNo9L-Regu,False,407.40301513671875,333.6309814453125,0.0,7,P
sample_7.pdf,11,"Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. Assessing the ability of lstms to learn syntax-sensitive",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,351.2143249511719,0.0673076923076923,104,P
sample_7.pdf,11,dependencies.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,361.0459899902344,0.0,13,P
sample_7.pdf,11,Transactions of the Association of Computational Linguistics,8.966400146484375,NimbusRomNo9L-ReguItal,False,168.506591796875,360.8871765136719,0.06666666666666667,60,P
sample_7.pdf,11,", 4(1):521–535, 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,388.16998291015625,361.0459899902344,0.0,21,P
sample_7.pdf,11,"Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Ngoc Quan Pham, Raffaella Bernardi, Sandro Pezzelle,",8.903413772583008,NimbusRomNo9L-Regu,False,108.0,378.7447509765625,0.12264150943396226,106,P
sample_7.pdf,11,"Marco Baroni, Gemma Boleda, and Raquel Fernandez. The lambada dataset: Word prediction requiring a",9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,388.392333984375,0.08163265306122448,98,P
sample_7.pdf,11,broad discourse context. In,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,398.15631103515625,0.037037037037037035,27,P
sample_7.pdf,11,Proceedings of the 54th Annual Meeting of the Association for Computational,9.055620193481445,NimbusRomNo9L-ReguItal,False,218.0263671875,397.99591064453125,0.06666666666666667,75,P
sample_7.pdf,11,Linguistics (Volume 1: Long Papers),8.966400146484375,NimbusRomNo9L-ReguItal,False,117.71199798583984,407.8281555175781,0.11428571428571428,35,P
sample_7.pdf,11,", volume 1, pp. 1525–1534, 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,247.6510009765625,407.9869689941406,0.0,32,P
sample_7.pdf,11,"Ankur Parikh,",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,425.5703125,0.15384615384615385,13,P
sample_7.pdf,11,"Oscar Täckström,",9.055620193481445,NimbusRomNo9L-Regu,False,171.08721923828125,425.5703125,0.125,16,P
sample_7.pdf,11,"Dipanjan Das,",9.055620193481445,NimbusRomNo9L-Regu,False,247.51806640625,425.5703125,0.15384615384615385,13,P
sample_7.pdf,11,and Jakob Uszkoreit.,9.055620193481445,NimbusRomNo9L-Regu,False,311.2455139160156,425.5703125,0.1,20,P
sample_7.pdf,11,A decomposable atten-,9.055620193481445,NimbusRomNo9L-Regu,False,413.1746826171875,425.5703125,0.047619047619047616,21,P
sample_7.pdf,11,tion model.,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,435.3343200683594,0.0,11,P
sample_7.pdf,11,Empirical Methods in Natural Language Processing,9.055620193481445,NimbusRomNo9L-ReguItal,False,187.3607635498047,435.1739196777344,0.10416666666666667,48,P
sample_7.pdf,11,", 2016.",9.055620193481445,NimbusRomNo9L-Regu,False,403.75799560546875,435.3343200683594,0.0,7,P
sample_7.pdf,11,URL,9.055620193481445,NimbusRomNo9L-Regu,False,450.0903015136719,435.3343200683594,1.0,3,P
sample_7.pdf,11,https:,8.966400146484375,NimbusMonL-Regu,False,468.3725891113281,434.94293212890625,0.0,6,P
sample_7.pdf,11,//arxiv.org/pdf/1606.01933.pdf,8.966400146484375,NimbusMonL-Regu,False,117.42501831054688,444.7059326171875,0.0,30,P
sample_7.pdf,11,"Jack Rae, Jonathan J Hunt, Ivo Danihelka, Timothy Harley, Andrew W Senior, Gregory Wayne, Alex Graves,",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,462.7483215332031,0.1568627450980392,102,P
sample_7.pdf,11,and Tim Lillicrap. Scaling memory-augmented neural networks with sparse reads and writes. In,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,472.5123291015625,0.043478260869565216,92,P
sample_7.pdf,11,Advances,9.055620193481445,NimbusRomNo9L-ReguItal,False,467.0189514160156,472.3519287109375,0.125,8,P
sample_7.pdf,11,in Neural Information Processing Systems,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,482.1841735839844,0.1,40,P
sample_7.pdf,11,", pp. 3621–3629, 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,267.5559997558594,482.3429870605469,0.0,22,P
sample_7.pdf,11,"Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Query-reduction networks for question",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,499.92633056640625,0.09090909090909091,99,P
sample_7.pdf,11,answering.,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,509.7569885253906,0.0,10,P
sample_7.pdf,11,arXiv preprint arXiv:1606.04582,8.966400146484375,NimbusRomNo9L-ReguItal,False,157.05648803710938,509.5981750488281,0.06451612903225806,31,P
sample_7.pdf,11,", 2016.",8.966400146484375,NimbusRomNo9L-Regu,False,277.9029846191406,509.7569885253906,0.0,7,P
sample_7.pdf,11,"Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout:",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,527.34130859375,0.11428571428571428,105,P
sample_7.pdf,11,a simple way to prevent neural networks from overﬁtting.,9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,537.1043090820312,0.0,56,P
sample_7.pdf,11,Journal of Machine Learning Research,9.055620193481445,NimbusRomNo9L-ReguItal,False,329.2841796875,536.9439086914062,0.1111111111111111,36,P
sample_7.pdf,11,", 15(1):",9.055620193481445,NimbusRomNo9L-Regu,False,478.0350036621094,537.1043090820312,0.0,8,P
sample_7.pdf,11,"1929–1958, 2014.",8.966400146484375,NimbusRomNo9L-Regu,False,117.29000091552734,546.9349365234375,0.0,16,P
sample_7.pdf,11,"Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus.",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,564.519287109375,0.09230769230769231,65,P
sample_7.pdf,11,End-to-end memory networks.,9.055620193481445,NimbusRomNo9L-Regu,False,389.0208435058594,564.519287109375,0.037037037037037035,27,P
sample_7.pdf,11,"In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett (eds.),",9.055620193481445,NimbusRomNo9L-Regu,False,117.96299743652344,574.2823486328125,0.17105263157894737,76,P
sample_7.pdf,11,Advances in,9.055620193481445,NimbusRomNo9L-ReguItal,False,450.1542053222656,574.1219482421875,0.09090909090909091,11,P
sample_7.pdf,11,Neural Information Processing Systems 28,9.055620193481445,NimbusRomNo9L-ReguItal,False,117.66699981689453,583.8848876953125,0.1,40,P
sample_7.pdf,11,", pp. 2440–2448. Curran Associates, Inc., 2015.",9.055620193481445,NimbusRomNo9L-Regu,False,283.52398681640625,584.0452880859375,0.06382978723404255,47,P
sample_7.pdf,11,URL,9.055620193481445,NimbusRomNo9L-Regu,False,486.14776611328125,584.0452880859375,1.0,3,P
sample_7.pdf,11,http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf,8.966400146484375,NimbusMonL-Regu,False,117.96299743652344,593.4179077148438,0.0,63,P
sample_7.pdf,11,"Ilya Sutskever, Oriol Vinyals, and Quoc V. Le.",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,611.4603271484375,0.15217391304347827,46,P
sample_7.pdf,11,Sequence to sequence learning with neural net-,9.055620193481445,NimbusRomNo9L-Regu,False,314.6934814453125,611.4603271484375,0.021739130434782608,46,P
sample_7.pdf,11,works.,9.055620193481445,NimbusRomNo9L-Regu,False,117.63999938964844,621.2233276367188,0.0,6,P
sample_7.pdf,11,Advances in Neural Information Processing Systems,9.055620193481445,NimbusRomNo9L-ReguItal,False,163.97227478027344,621.0629272460938,0.10204081632653061,49,P
sample_7.pdf,11,", pp. 3104–3112, 2014.",9.055620193481445,NimbusRomNo9L-Regu,False,376.40899658203125,621.2233276367188,0.0,22,P
sample_7.pdf,11,URL,9.055620193481445,NimbusRomNo9L-Regu,False,486.1488342285156,621.2233276367188,1.0,3,P
sample_7.pdf,11,http://arxiv.org/abs/1409.3215,8.966400146484375,NimbusMonL-Regu,False,117.96299743652344,630.5958862304688,0.0,30,P
sample_7.pdf,11,"Ke Tran, Arianna Bisazza, and Christof Monz. The importance of being recurrent for modeling hierarchical",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,648.6383056640625,0.0673076923076923,104,P
sample_7.pdf,11,structure. In,8.966400146484375,NimbusRomNo9L-Regu,False,117.96299743652344,658.4689331054688,0.07692307692307693,13,P
sample_7.pdf,11,Proceedings of NAACL’18,8.966400146484375,NimbusRomNo9L-ReguItal,False,161.82662963867188,658.3101196289062,0.2608695652173913,23,P
sample_7.pdf,11,", 2018.",8.966400146484375,NimbusRomNo9L-Regu,False,257.9449768066406,658.4689331054688,0.0,7,P
sample_7.pdf,11,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and",8.889859199523926,NimbusRomNo9L-Regu,False,108.0,676.177978515625,0.14018691588785046,107,P
sample_7.pdf,11,Illia Polosukhin. Attention is all you need.,8.907927513122559,NimbusRomNo9L-Regu,False,117.96299743652344,685.9283447265625,0.06818181818181818,44,P
sample_7.pdf,11,CoRR,8.907927513122559,NimbusRomNo9L-ReguItal,False,266.39239501953125,685.7705688476562,0.75,4,P
sample_7.pdf,11,", 2017. URL",8.907927513122559,NimbusRomNo9L-Regu,False,290.3139953613281,685.9283447265625,0.2727272727272727,11,P
sample_7.pdf,11,http://arxiv.org/abs/1706.03762,8.966400146484375,NimbusMonL-Regu,False,334.7136535644531,685.4249267578125,0.0,31,P
sample_7.pdf,11,"Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N. Gomez, Stephan Gouws, Llion",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,703.4673461914062,0.14285714285714285,98,P
sample_7.pdf,11,"Jones, Łukasz Kaiser, Nal Kalchbrenner, Niki Parmar, Ryan Sepassi, Noam Shazeer, and Jakob Uszkoreit.",9.055620193481445,NimbusRomNo9L-Regu,False,117.79199981689453,713.2303466796875,0.12871287128712872,101,P
sample_7.pdf,11,Tensor2tensor for neural machine translation.,8.966400146484375,NimbusRomNo9L-Regu,False,117.68499755859375,723.0619506835938,0.022222222222222223,45,P
sample_7.pdf,11,CoRR,8.966400146484375,NimbusRomNo9L-ReguItal,False,278.8648986816406,722.9031372070312,0.75,4,P
sample_7.pdf,11,", abs/1803.07416, 2018.",8.966400146484375,NimbusRomNo9L-Regu,False,303.06298828125,723.0619506835938,0.0,23,P
sample_7.pdf,12,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,12,"Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M Rush, Bart van Merriënboer, Armand Joulin, and",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,84.95629119873047,0.12745098039215685,102,P
sample_7.pdf,12,Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks.,9.055620193481445,NimbusRomNo9L-Regu,False,117.68499755859375,94.72032928466797,0.04597701149425287,87,P
sample_7.pdf,12,arXiv preprint,9.055620193481445,NimbusRomNo9L-ReguItal,False,447.5531005859375,94.55992889404297,0.07142857142857142,14,P
sample_7.pdf,12,arXiv:1502.05698,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.96299743652344,104.39217376708984,0.0625,16,P
sample_7.pdf,12,", 2015.",8.966400146484375,NimbusRomNo9L-Regu,False,183.46200561523438,104.55099487304688,0.0,7,P
sample_7.pdf,12,"Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, and Phil Blunsom.",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,122.21733856201172,0.14285714285714285,98,P
sample_7.pdf,12,Memory architectures in recurrent neural network language models. In,8.939459800720215,NimbusRomNo9L-Regu,False,117.96299743652344,132.0684356689453,0.029411764705882353,68,P
sample_7.pdf,12,International Conference on Learning,8.939459800720215,NimbusRomNo9L-ReguItal,False,367.4801330566406,131.91009521484375,0.08333333333333333,36,P
sample_7.pdf,12,Representations,8.966400146484375,NimbusRomNo9L-ReguItal,False,117.68499755859375,141.6521759033203,0.06666666666666667,15,P
sample_7.pdf,12,", 2018. URL",8.966400146484375,NimbusRomNo9L-Regu,False,175.13099670410156,141.81100463867188,0.2727272727272727,11,P
sample_7.pdf,12,https://openreview.net/forum?id=SkFqf0lAZ,8.966400146484375,NimbusMonL-Regu,False,220.0526580810547,141.35195922851562,0.0975609756097561,41,P
sample_7.pdf,12,Wojciech Zaremba and Ilya Sutskever.,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,159.47727966308594,0.1111111111111111,36,P
sample_7.pdf,12,Learning to execute.,9.055620193481445,NimbusRomNo9L-Regu,False,271.0499572753906,159.47727966308594,0.05,20,P
sample_7.pdf,12,CoRR,9.055620193481445,NimbusRomNo9L-ReguItal,False,362.9649963378906,159.31687927246094,0.75,4,P
sample_7.pdf,12,", abs/1410.4615, 2015.",9.055620193481445,NimbusRomNo9L-Regu,False,384.8139953613281,159.47727966308594,0.0,22,P
sample_7.pdf,12,URL,9.055620193481445,NimbusRomNo9L-Regu,False,486.1488037109375,159.47727966308594,1.0,3,P
sample_7.pdf,12,http://arxiv.org/abs/1410.4615,8.966400146484375,NimbusMonL-Regu,False,117.96299743652344,168.84890747070312,0.0,30,P
sample_7.pdf,13,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,13,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,84.57066345214844,1.0,7,H3
sample_7.pdf,13,ETAILED,9.56410026550293,NimbusRomNo9L-Regu,False,194.84100341796875,84.57066345214844,1.0,7,H3
sample_7.pdf,13,CHEMA OF THE,9.56410026550293,NimbusRomNo9L-Regu,False,248.0889892578125,84.57066345214844,0.8333333333333334,12,H3
sample_7.pdf,13,NIVERSAL,9.56410026550293,NimbusRomNo9L-Regu,False,335.74298095703125,84.57066345214844,1.0,8,H3
sample_7.pdf,13,RANSFORMER,9.56410026550293,NimbusRomNo9L-Regu,False,398.03997802734375,84.57066345214844,1.0,10,H3
sample_7.pdf,13,Input Sequence,6.45851993560791,HelveticaNeue,False,181.6444091796875,485.8271789550781,0.14285714285714285,14,P
sample_7.pdf,13,Embed Input Symbols,6.45851993560791,HelveticaNeue,False,172.4281005859375,465.509765625,0.15789473684210525,19,P
sample_7.pdf,13,Position embedding,6.45851993560791,HelveticaNeue,False,126.76293182373047,434.19573974609375,0.05555555555555555,18,P
sample_7.pdf,13,Timestep embedding,6.45851993560791,HelveticaNeue,False,123.4690933227539,415.2238464355469,0.05555555555555555,18,P
sample_7.pdf,13,Multihead Self-Attention,6.45851993560791,HelveticaNeue,False,169.505615234375,387.4693298339844,0.125,24,P
sample_7.pdf,13,Transition Function,6.45851993560791,HelveticaNeue,False,177.100830078125,311.5816955566406,0.10526315789473684,19,P
sample_7.pdf,13,Dropout,6.45851993560791,HelveticaNeue,False,192.95570373535156,369.91021728515625,0.14285714285714285,7,P
sample_7.pdf,13,Layer Normalization,6.45851993560791,HelveticaNeue,False,175.73486328125,330.5536193847656,0.10526315789473684,19,P
sample_7.pdf,13,Dropout,6.45851993560791,HelveticaNeue,False,192.71107482910156,293.2544860839844,0.14285714285714285,7,P
sample_7.pdf,13,Layer Normalization,6.45851993560791,HelveticaNeue,False,175.73486328125,254.6659698486328,0.10526315789473684,19,P
sample_7.pdf,13,Multihead Attention,6.45851993560791,HelveticaNeue,False,386.1561584472656,311.5816955566406,0.10526315789473684,19,P
sample_7.pdf,13,Target Sequence (right-shifted by one),6.45851993560791,HelveticaNeue,False,359.0925598144531,485.8271789550781,0.05263157894736842,38,P
sample_7.pdf,13,Embed Target Symbols,6.45851993560791,HelveticaNeue,False,380.6188049316406,465.509765625,0.15,20,P
sample_7.pdf,13,Position embedding,6.45851993560791,HelveticaNeue,False,336.41326904296875,434.19573974609375,0.05555555555555555,18,P
sample_7.pdf,13,Timestep embedding,6.45851993560791,HelveticaNeue,False,333.1194152832031,415.2238464355469,0.05555555555555555,18,P
sample_7.pdf,13,Multihead Self-Attention,6.45851993560791,HelveticaNeue,False,379.15594482421875,387.4693298339844,0.125,24,P
sample_7.pdf,13,Transition Function,6.45851993560791,HelveticaNeue,False,386.75115966796875,236.98342895507812,0.10526315789473684,19,P
sample_7.pdf,13,Dropout,6.45851993560791,HelveticaNeue,False,402.60601806640625,369.91021728515625,0.14285714285714285,7,P
sample_7.pdf,13,Layer Normalization,6.45851993560791,HelveticaNeue,False,385.38519287109375,330.5536193847656,0.10526315789473684,19,P
sample_7.pdf,13,Dropout,6.45851993560791,HelveticaNeue,False,402.60601806640625,218.01153564453125,0.14285714285714285,7,P
sample_7.pdf,13,Layer Normalization,6.45851993560791,HelveticaNeue,False,385.38519287109375,180.0677490234375,0.10526315789473684,19,P
sample_7.pdf,13,Dropout,6.45851993560791,HelveticaNeue,False,402.60601806640625,292.60980224609375,0.14285714285714285,7,P
sample_7.pdf,13,Layer Normalization,6.45851993560791,HelveticaNeue,False,385.6297912597656,255.95533752441406,0.10526315789473684,19,P
sample_7.pdf,13,Softmax,6.45851993560791,HelveticaNeue,False,435.4085998535156,131.62518310546875,0.14285714285714285,7,P
sample_7.pdf,13,Output Probabilities,6.45851993560791,HelveticaNeue,False,418.8360290527344,112.57855224609375,0.1,20,P
sample_7.pdf,13,After T steps,6.45851993560791,HelveticaNeue,False,279.83563232421875,305.2577209472656,0.15384615384615385,13,P
sample_7.pdf,13,After T steps,6.45851993560791,HelveticaNeue,False,453.0198974609375,147.980712890625,0.15384615384615385,13,P
sample_7.pdf,13,For T steps,6.45851993560791,HelveticaNeue,False,273.5299987792969,362.7148742675781,0.18181818181818182,11,P
sample_7.pdf,13,For T steps,6.45851993560791,HelveticaNeue,False,482.5331726074219,362.7148742675781,0.18181818181818182,11,P
sample_7.pdf,13,Recurrent,6.45851993560791,HelveticaNeue-Bold,True,122.23018646240234,248.67562866210938,0.1111111111111111,9,P
sample_7.pdf,13,Encoder,6.45851993560791,HelveticaNeue-Bold,True,122.23018646240234,256.9361267089844,0.14285714285714285,7,P
sample_7.pdf,13,Block,6.45851993560791,HelveticaNeue-Bold,True,122.23018646240234,265.1966247558594,0.2,5,P
sample_7.pdf,13,Recurrent,6.45851993560791,HelveticaNeue-Bold,True,331.8805236816406,173.86447143554688,0.1111111111111111,9,P
sample_7.pdf,13,Decoder,6.45851993560791,HelveticaNeue-Bold,True,331.8805236816406,182.12496948242188,0.14285714285714285,7,P
sample_7.pdf,13,Block,6.45851993560791,HelveticaNeue-Bold,True,331.8805236816406,190.3854522705078,0.2,5,P
sample_7.pdf,13,Figure 4: The Universal Transformer with position and step embeddings as well as dropout and layer,9.977532386779785,NimbusRomNo9L-Regu,False,108.0,501.9951477050781,0.04081632653061224,98,H3
sample_7.pdf,13,normalization.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,512.9654541015625,0.0,14,H3
sample_7.pdf,13,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,551.396728515625,1.0,7,H3
sample_7.pdf,13,N THE,9.56410026550293,NimbusRomNo9L-Regu,False,194.1840057373047,551.396728515625,0.8,5,H3
sample_7.pdf,13,OMPUTATIONAL,9.56410026550293,NimbusRomNo9L-Regu,False,235.3930206298828,551.396728515625,1.0,12,H3
sample_7.pdf,13,OWER OF,9.56410026550293,NimbusRomNo9L-Regu,False,325.8080139160156,551.396728515625,0.8571428571428571,7,H3
sample_7.pdf,13,RANSFORMER,9.56410026550293,NimbusRomNo9L-Regu,False,417.40802001953125,551.396728515625,1.0,10,H3
sample_7.pdf,13,"With respect to their computational power, the key difference between the Transformer and the Universal",9.055620193481445,NimbusRomNo9L-Regu,False,107.5790023803711,575.4583129882812,0.02912621359223301,103,P
sample_7.pdf,13,Transformer lies in the number of sequential steps of computation (i.e. in depth). While a standard Transformer,9.015580177307129,NimbusRomNo9L-Regu,False,107.72200012207031,585.2516479492188,0.02702702702702703,111,P
sample_7.pdf,13,"executes a total number of operations that scales with the input size, the number of sequential operations is",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,594.9843139648438,0.0,109,P
sample_7.pdf,13,"constant, independent of the input size and determined solely by the number of layers. Assuming ﬁnite precision,",8.943955421447754,NimbusRomNo9L-Regu,False,108.0,604.8329467773438,0.008928571428571428,112,P
sample_7.pdf,13,this property implies that the standard Transformer cannot be computationally universal. When choosing a number,8.876283645629883,NimbusRomNo9L-Regu,False,108.0,614.6473388671875,0.018018018018018018,111,P
sample_7.pdf,13,"of steps as a function of the input length, however, the Universal Transformer does not suffer from this limitation.",8.952940940856934,NimbusRomNo9L-Regu,False,108.0,624.3521728515625,0.017241379310344827,116,P
sample_7.pdf,13,Note that this holds independently of whether or not adaptive computation time is employed but does assume,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,634.038330078125,0.009433962264150943,106,P
sample_7.pdf,13,"a non-constant, even if possibly deterministic, number of steps. Varying the number of steps dynamically after",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,643.8013305664062,0.00909090909090909,110,P
sample_7.pdf,13,training is enabled by sharing weights across sequential computation steps in the Universal Transformer.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,653.6319580078125,0.019230769230769232,104,P
sample_7.pdf,13,An intuitive example are functions whose execution requires the,9.055620193481445,NimbusRomNo9L-Regu,False,107.677001953125,669.3052978515625,0.015873015873015872,63,P
sample_7.pdf,13,"sequential processing of each input element. In this case, for any",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,679.0693359375,0.015151515151515152,66,P
sample_7.pdf,13,given choice of depth,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,688.8323364257812,0.0,21,P
sample_7.pdf,13,", one can construct an input sequence of",9.055620193481445,NimbusRomNo9L-Regu,False,196.85899353027344,688.8323364257812,0.0,40,P
sample_7.pdf,13,length,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,698.5953369140625,0.0,6,P
sample_7.pdf,13,N > T,8.966400146484375,CMMI9,False,130.86431884765625,698.4555053710938,0.4,5,P
sample_7.pdf,13,that cannot be processed correctly by a standard,9.055620193481445,NimbusRomNo9L-Regu,False,161.177490234375,698.5953369140625,0.0,48,P
sample_7.pdf,13,"Transformer. With an appropriate, input-length dependent choice of",8.925959587097168,NimbusRomNo9L-Regu,False,107.72200012207031,708.4576416015625,0.030303030303030304,66,P
sample_7.pdf,13,"sequential steps, however, a Universal Transformer, RNNs or Neural",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,718.25830078125,0.09090909090909091,66,P
sample_7.pdf,13,GPUs can execute such a function.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,727.9529418945312,0.09090909090909091,33,P
sample_7.pdf,14,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,14,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,84.57066345214844,1.0,7,H3
sample_7.pdf,14,WITH,9.56410026550293,NimbusRomNo9L-Regu,False,201.4891357421875,84.57066345214844,1.0,4,H3
sample_7.pdf,14,YNAMIC,9.56410026550293,NimbusRomNo9L-Regu,False,242.84100341796875,84.57066345214844,1.0,6,H3
sample_7.pdf,14,ALTING,9.56410026550293,NimbusRomNo9L-Regu,False,296.47100830078125,84.57066345214844,1.0,6,H3
sample_7.pdf,14,"We implement the dynamic halting based on ACT (Graves, 2016) as follows in TensorFlow. In each step of the UT",8.880810737609863,NimbusRomNo9L-Regu,False,107.5790023803711,107.15386199951172,0.09174311926605505,109,P
sample_7.pdf,14,"with dynamic halting, we are given the halting probabilities, remainders, number of updates up to that point, and",8.975361824035645,NimbusRomNo9L-Regu,False,107.677001953125,116.84516143798828,0.0,113,P
sample_7.pdf,14,"the previous state (all initialized as zeros), as well as a scalar threshold between 0 and 1 (a hyper-parameter). We",8.970882415771484,NimbusRomNo9L-Regu,False,108.0,126.61259460449219,0.008620689655172414,116,P
sample_7.pdf,14,then compute the new state for each position and calculate the new per-position halting probabilities based on the,8.934962272644043,NimbusRomNo9L-Regu,False,108.0,136.40283203125,0.0,114,P
sample_7.pdf,14,"state for each position. The UT then decides to halt for some positions that crossed the threshold, and updates the",8.943955421447754,NimbusRomNo9L-Regu,False,108.0,146.1590118408203,0.02608695652173913,115,P
sample_7.pdf,14,state of other positions until the model halts for all positions or reaches a predeﬁned maximum number of steps:,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,155.90597534179688,0.0,112,P
sample_7.pdf,14,# While,8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,172.09396362304688,0.14285714285714285,7,P
sample_7.pdf,14,loop,8.966400146484375,NimbusRomNo9L-Regu,False,152.15399169921875,172.09396362304688,0.0,4,P
sample_7.pdf,14,s t o p s,8.966400146484375,NimbusRomNo9L-Regu,False,179.34909057617188,172.09396362304688,0.0,9,P
sample_7.pdf,14,when,8.966400146484375,NimbusRomNo9L-Regu,False,210.641845703125,172.09396362304688,0.0,4,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,238.8321990966797,172.09396362304688,0.0,7,P
sample_7.pdf,14,p r e d i c a t e,8.966400146484375,NimbusRomNo9L-Regu,False,265.57000732421875,172.09396362304688,0.0,17,P
sample_7.pdf,14,i s FALSE,8.966400146484375,NimbusRomNo9L-Regu,False,319.4131774902344,172.09396362304688,0.5555555555555556,9,P
sample_7.pdf,14,i . e .,8.966400146484375,NimbusRomNo9L-Regu,False,120.20294952392578,181.85696411132812,0.0,7,P
sample_7.pdf,14,a l l,8.966400146484375,NimbusRomNo9L-Regu,False,147.45184326171875,181.85696411132812,0.0,5,P
sample_7.pdf,14,( ( p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,168.77392578125,181.85696411132812,0.0,25,P
sample_7.pdf,14,< t h r e s h o l d ) & ( c o u n t e r < max_steps ) ),8.966400146484375,NimbusRomNo9L-Regu,False,242.7108154296875,181.85696411132812,0.0,55,P
sample_7.pdf,14,are,8.966400146484375,NimbusRomNo9L-Regu,False,448.2296447753906,181.85696411132812,0.0,3,P
sample_7.pdf,14,f a l s e,8.966400146484375,NimbusRomNo9L-Regu,False,470.11663818359375,181.85696411132812,0.0,9,P
sample_7.pdf,14,def,8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,191.61996459960938,0.0,3,P
sample_7.pdf,14,"should_continue ( u0 ,",8.966400146484375,NimbusRomNo9L-Regu,False,130.86170959472656,191.61996459960938,0.0,22,P
sample_7.pdf,14,"u1 ,",8.966400146484375,NimbusRomNo9L-Regu,False,237.5618896484375,191.61996459960938,0.0,4,P
sample_7.pdf,14,"h a l t i n g _ p r o b a b i l i t y ,",8.966400146484375,NimbusRomNo9L-Regu,False,260.22894287109375,191.61996459960938,0.0,39,P
sample_7.pdf,14,"u2 ,",8.966400146484375,NimbusRomNo9L-Regu,False,372.0666809082031,191.61996459960938,0.0,4,P
sample_7.pdf,14,"n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,394.2315979003906,191.61996459960938,0.0,11,P
sample_7.pdf,14,u3 ) :,8.966400146484375,NimbusRomNo9L-Regu,False,452.90765380859375,191.61996459960938,0.0,6,P
sample_7.pdf,14,r e t u r n,8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,201.38400268554688,0.0,11,P
sample_7.pdf,14,t f . reduce_any (,8.966400146484375,NimbusRomNo9L-Regu,False,147.41810607910156,201.38400268554688,0.0,18,P
sample_7.pdf,14,t f . l o g i c a l _ a n d (,8.966400146484375,NimbusRomNo9L-Regu,False,174.31900024414062,211.14700317382812,0.0,29,P
sample_7.pdf,14,"t f . l e s s ( h a l t i n g _ p r o b a b i l i t y ,",8.966400146484375,NimbusRomNo9L-Regu,False,195.8389892578125,220.91000366210938,0.0,55,P
sample_7.pdf,14,"t h r e s h o l d ) ,",8.966400146484375,NimbusRomNo9L-Regu,False,351.6032409667969,220.91000366210938,0.0,21,P
sample_7.pdf,14,"t f . l e s s ( n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,195.8389892578125,230.67398071289062,0.0,27,P
sample_7.pdf,14,max_steps ) ) ),8.966400146484375,NimbusRomNo9L-Regu,False,297.3565673828125,230.67398071289062,0.0,15,P
sample_7.pdf,14,# Do while,8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,240.43698120117188,0.1,10,P
sample_7.pdf,14,loop,8.966400146484375,NimbusRomNo9L-Regu,False,168.29872131347656,240.43698120117188,0.0,4,P
sample_7.pdf,14,i t e r a t i o n s,8.966400146484375,NimbusRomNo9L-Regu,False,195.93316650390625,240.43698120117188,0.0,19,P
sample_7.pdf,14,u n t i l,8.966400146484375,NimbusRomNo9L-Regu,False,255.0038299560547,240.43698120117188,0.0,9,P
sample_7.pdf,14,p r e d i c a t e,8.966400146484375,NimbusRomNo9L-Regu,False,287.0945129394531,240.43698120117188,0.0,17,P
sample_7.pdf,14,above,8.966400146484375,NimbusRomNo9L-Regu,False,340.24725341796875,240.43698120117188,0.0,5,P
sample_7.pdf,14,i s,8.966400146484375,NimbusRomNo9L-Regu,False,373.2077331542969,240.43698120117188,0.0,3,P
sample_7.pdf,14,f a l s e,8.966400146484375,NimbusRomNo9L-Regu,False,389.4189453125,240.43698120117188,0.0,9,P
sample_7.pdf,14,"( _ ,",8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,250.19998168945312,0.0,5,P
sample_7.pdf,14,"_ ,",8.966400146484375,NimbusRomNo9L-Regu,False,129.81971740722656,250.19998168945312,0.0,3,P
sample_7.pdf,14,"_ ,",8.966400146484375,NimbusRomNo9L-Regu,False,145.95924377441406,250.19998168945312,0.0,3,P
sample_7.pdf,14,"remainder ,",8.966400146484375,NimbusRomNo9L-Regu,False,162.8967742919922,250.19998168945312,0.0,11,P
sample_7.pdf,14,"n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,222.0750274658203,250.19998168945312,0.0,11,P
sample_7.pdf,14,new_state ) =,8.966400146484375,NimbusRomNo9L-Regu,False,281.4146728515625,250.19998168945312,0.0,13,P
sample_7.pdf,14,t f . while_loop (,8.966400146484375,NimbusRomNo9L-Regu,False,351.8547668457031,250.19998168945312,0.0,18,P
sample_7.pdf,14,"should_continue ,",8.966400146484375,NimbusRomNo9L-Regu,False,130.77999877929688,259.9639587402344,0.0,17,P
sample_7.pdf,14,"ut_with_dynamic_halting ,",8.966400146484375,NimbusRomNo9L-Regu,False,222.2373046875,259.9639587402344,0.0,25,P
sample_7.pdf,14,"( s t a t e ,",8.966400146484375,NimbusRomNo9L-Regu,False,356.6703186035156,259.9639587402344,0.0,13,P
sample_7.pdf,14,"step ,",8.966400146484375,NimbusRomNo9L-Regu,False,130.69900512695312,269.7269592285156,0.0,6,P
sample_7.pdf,14,"h a l t i n g _ p r o b a b i l i t y ,",8.966400146484375,NimbusRomNo9L-Regu,False,163.39047241210938,269.7269592285156,0.0,39,P
sample_7.pdf,14,"remainders ,",8.966400146484375,NimbusRomNo9L-Regu,False,275.936767578125,269.7269592285156,0.0,12,P
sample_7.pdf,14,"n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,340.43194580078125,269.7269592285156,0.0,11,P
sample_7.pdf,14,p r e v i o u s _ s t a t e ) ),8.966400146484375,NimbusRomNo9L-Regu,False,400.0853576660156,269.7269592285156,0.0,31,P
sample_7.pdf,14,Listing 1: UT with dynamic halting.,9.962599754333496,NimbusRomNo9L-Regu,False,234.99200439453125,282.9234313964844,0.08571428571428572,35,H3
sample_7.pdf,14,The following shows the computations in each step:,8.966400146484375,NimbusRomNo9L-Regu,False,107.72200775146484,309.05596923828125,0.02,50,P
sample_7.pdf,14,def,8.966400146484375,NimbusRomNo9L-Regu,False,103.018798828125,325.2439880371094,0.0,3,P
sample_7.pdf,14,"ut_with_dynamic_halting ( s t a t e ,",8.966400146484375,NimbusRomNo9L-Regu,False,130.83480834960938,325.2439880371094,0.0,37,P
sample_7.pdf,14,"step ,",8.966400146484375,NimbusRomNo9L-Regu,False,297.4751892089844,325.2439880371094,0.0,6,P
sample_7.pdf,14,"h a l t i n g _ p r o b a b i l i t y ,",8.966400146484375,NimbusRomNo9L-Regu,False,330.1666259765625,325.2439880371094,0.0,39,P
sample_7.pdf,14,"remainders ,",8.966400146484375,NimbusRomNo9L-Regu,False,259.79998779296875,335.00799560546875,0.0,12,P
sample_7.pdf,14,"n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,324.295166015625,335.00799560546875,0.0,11,P
sample_7.pdf,14,p r e v i o u s _ s t a t e ) :,8.966400146484375,NimbusRomNo9L-Regu,False,383.9396057128906,335.00799560546875,0.0,31,P
sample_7.pdf,14,C a l c u l a t e,8.966400146484375,NimbusRomNo9L-Regu,False,141.73191833496094,344.77099609375,0.058823529411764705,17,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,195.3778839111328,344.77099609375,0.0,3,P
sample_7.pdf,14,p r o b a b i l i t i e s,8.966400146484375,NimbusRomNo9L-Regu,False,217.39039611816406,344.77099609375,0.0,25,P
sample_7.pdf,14,based on,8.966400146484375,NimbusRomNo9L-Regu,False,291.9996643066406,344.77099609375,0.0,8,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,340.6333312988281,344.77099609375,0.0,3,P
sample_7.pdf,14,s t a t e,8.966400146484375,NimbusRomNo9L-Regu,False,362.60101318359375,344.77099609375,0.0,9,P
sample_7.pdf,14,"p = common_layers . dense ( s t a t e ,",8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,354.53399658203125,0.0,39,P
sample_7.pdf,14,"1 ,",8.966400146484375,NimbusRomNo9L-Regu,False,297.3078918457031,354.53399658203125,0.0,3,P
sample_7.pdf,14,"a c t i v a t i o n = t f . nn . sigmoid ,",8.966400146484375,NimbusRomNo9L-Regu,False,314.11090087890625,354.53399658203125,0.0,42,P
sample_7.pdf,14,u se _ bi a s =True ),8.966400146484375,NimbusRomNo9L-Regu,False,152.38999938964844,364.2979736328125,0.047619047619047616,21,P
sample_7.pdf,14,# Mask f o r,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,374.06097412109375,0.08333333333333333,12,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,190.1773681640625,374.06097412109375,0.0,11,P
sample_7.pdf,14,which have,8.966400146484375,NimbusRomNo9L-Regu,False,227.19070434570312,374.06097412109375,0.0,10,P
sample_7.pdf,14,not,8.966400146484375,NimbusRomNo9L-Regu,False,286.709716796875,374.06097412109375,0.0,3,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,308.5339050292969,374.06097412109375,0.0,11,P
sample_7.pdf,14,yet,8.966400146484375,NimbusRomNo9L-Regu,False,346.013427734375,374.06097412109375,0.0,3,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,131.24099731445312,383.823974609375,0.0,25,P
sample_7.pdf,14,t f . c a s t (,8.966400146484375,NimbusRomNo9L-Regu,False,217.35423278808594,383.823974609375,0.0,15,P
sample_7.pdf,14,"t f . l e s s ( h a l t i n g _ p r o b a b i l i t y , 1 . 0 ) ,",8.966400146484375,NimbusRomNo9L-Regu,False,152.8000030517578,393.5879821777344,0.0,65,P
sample_7.pdf,14,t f . f l o a t 3 2 ),8.966400146484375,NimbusRomNo9L-Regu,False,335.7144470214844,393.5879821777344,0.0,21,P
sample_7.pdf,14,# Mask of,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,403.3509826660156,0.1111111111111111,9,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,184.79754638671875,403.3509826660156,0.0,11,P
sample_7.pdf,14,which,8.966400146484375,NimbusRomNo9L-Regu,False,221.81088256835938,403.3509826660156,0.0,5,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,254.73550415039062,403.3509826660156,0.0,11,P
sample_7.pdf,14,a t,8.966400146484375,NimbusRomNo9L-Regu,False,292.3405456542969,403.3509826660156,0.0,3,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,308.7669677734375,403.3509826660156,0.0,7,P
sample_7.pdf,14,s t e p,8.966400146484375,NimbusRomNo9L-Regu,False,335.3702392578125,403.3509826660156,0.0,7,P
sample_7.pdf,14,new_halted =,8.966400146484375,NimbusRomNo9L-Regu,False,130.6529998779297,413.1139831542969,0.0,12,P
sample_7.pdf,14,t f . c a s t (,8.966400146484375,NimbusRomNo9L-Regu,False,201.21852111816406,413.1139831542969,0.0,15,P
sample_7.pdf,14,t f . g r e a t e r ( h a l t i n g _ p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,152.7989959716797,422.87799072265625,0.0,59,P
sample_7.pdf,14,+ p,8.966400146484375,NimbusRomNo9L-Regu,False,317.97802734375,422.87799072265625,0.0,3,P
sample_7.pdf,14,"s t i l l _ r u n n i n g ,",8.966400146484375,NimbusRomNo9L-Regu,False,351.7010192871094,422.87799072265625,0.0,27,P
sample_7.pdf,14,"t h r e s h o l d ) ,",8.966400146484375,NimbusRomNo9L-Regu,False,432.29986572265625,422.87799072265625,0.0,21,P
sample_7.pdf,14,t f . f l o a t 3 2 ),8.966400146484375,NimbusRomNo9L-Regu,False,174.31900024414062,432.6409912109375,0.0,21,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,249.59799194335938,432.6409912109375,0.0,25,P
sample_7.pdf,14,# Mask of,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,442.40399169921875,0.1111111111111111,9,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,184.79754638671875,442.40399169921875,0.0,11,P
sample_7.pdf,14,which haven ’ t,8.966400146484375,NimbusRomNo9L-Regu,False,221.81088256835938,442.40399169921875,0.0,15,P
sample_7.pdf,14,"halted ,",8.966400146484375,NimbusRomNo9L-Regu,False,297.5949401855469,442.40399169921875,0.0,8,P
sample_7.pdf,14,and,8.966400146484375,NimbusRomNo9L-Regu,False,340.13153076171875,442.40399169921875,0.0,3,P
sample_7.pdf,14,didn ’ t,8.966400146484375,NimbusRomNo9L-Regu,False,361.9736328125,442.40399169921875,0.0,8,P
sample_7.pdf,14,h a l t,8.966400146484375,NimbusRomNo9L-Regu,False,400.12567138671875,442.40399169921875,0.0,7,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,427.12347412109375,442.40399169921875,0.0,7,P
sample_7.pdf,14,s t e p,8.966400146484375,NimbusRomNo9L-Regu,False,453.72674560546875,442.40399169921875,0.0,7,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,131.24099731445312,452.16796875,0.0,25,P
sample_7.pdf,14,t f . c a s t (,8.966400146484375,NimbusRomNo9L-Regu,False,217.35423278808594,452.16796875,0.0,15,P
sample_7.pdf,14,t f . l e s s _ e q u a l ( h a l t i n g _ p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,152.7989959716797,461.93096923828125,0.0,65,P
sample_7.pdf,14,+ p,8.966400146484375,NimbusRomNo9L-Regu,False,334.11749267578125,461.93096923828125,0.0,3,P
sample_7.pdf,14,"s t i l l _ r u n n i n g ,",8.966400146484375,NimbusRomNo9L-Regu,False,367.84100341796875,461.93096923828125,0.0,27,P
sample_7.pdf,14,"t h r e s h o l d ) ,",8.966400146484375,NimbusRomNo9L-Regu,False,174.06300354003906,471.6939697265625,0.0,21,P
sample_7.pdf,14,t f . f l o a t 3 2 ),8.966400146484375,NimbusRomNo9L-Regu,False,238.8811492919922,471.6939697265625,0.0,21,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,314.1570129394531,471.6939697265625,0.0,25,P
sample_7.pdf,14,# Add the,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,481.4579772949219,0.1111111111111111,9,P
sample_7.pdf,14,h a l t i n g,8.966400146484375,NimbusRomNo9L-Regu,False,184.91409301757812,481.4579772949219,0.0,13,P
sample_7.pdf,14,p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,228.00662231445312,481.4579772949219,0.0,21,P
sample_7.pdf,14,f o r,8.966400146484375,NimbusRomNo9L-Regu,False,292.3404541015625,481.4579772949219,0.0,5,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,314.146728515625,481.4579772949219,0.0,7,P
sample_7.pdf,14,s t e p,8.966400146484375,NimbusRomNo9L-Regu,False,340.75,481.4579772949219,0.0,7,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,383.6720886230469,481.4579772949219,0.0,3,P
sample_7.pdf,14,h a l t i n g,8.966400146484375,NimbusRomNo9L-Regu,False,405.4873352050781,481.4579772949219,0.0,13,P
sample_7.pdf,14,p r o b a b i l i t i e s,8.966400146484375,NimbusRomNo9L-Regu,False,142.07264709472656,491.2209777832031,0.0,25,P
sample_7.pdf,14,f o r,8.966400146484375,NimbusRomNo9L-Regu,False,217.022705078125,491.2209777832031,0.0,5,P
sample_7.pdf,14,those,8.966400146484375,NimbusRomNo9L-Regu,False,238.4434356689453,491.2209777832031,0.0,5,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,270.8748779296875,491.2209777832031,0.0,11,P
sample_7.pdf,14,which haven ’ t,8.966400146484375,NimbusRomNo9L-Regu,False,307.8881530761719,491.2209777832031,0.0,15,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,383.8515319824219,491.2209777832031,0.0,11,P
sample_7.pdf,14,yet,8.966400146484375,NimbusRomNo9L-Regu,False,421.3310546875,491.2209777832031,0.0,3,P
sample_7.pdf,14,h a l t i n g _ p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,131.1929931640625,500.9839782714844,0.0,37,P
sample_7.pdf,14,+= p,8.966400146484375,NimbusRomNo9L-Regu,False,237.3282470703125,500.9839782714844,0.0,4,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,276.4980163574219,500.9839782714844,0.0,25,P
sample_7.pdf,14,# Compute,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,510.7479553222656,0.1111111111111111,9,P
sample_7.pdf,14,remainders,8.966400146484375,NimbusRomNo9L-Regu,False,184.59132385253906,510.7479553222656,0.0,10,P
sample_7.pdf,14,f o r,8.966400146484375,NimbusRomNo9L-Regu,False,243.92198181152344,510.7479553222656,0.0,5,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,265.3157958984375,510.7479553222656,0.0,3,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,287.0144958496094,510.7479553222656,0.0,11,P
sample_7.pdf,14,which,8.966400146484375,NimbusRomNo9L-Regu,False,324.0277404785156,510.7479553222656,0.0,5,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,356.95233154296875,510.7479553222656,0.0,11,P
sample_7.pdf,14,a t,8.966400146484375,NimbusRomNo9L-Regu,False,394.5663757324219,510.7479553222656,0.0,3,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,410.98382568359375,510.7479553222656,0.0,7,P
sample_7.pdf,14,s t e p,8.966400146484375,NimbusRomNo9L-Regu,False,437.58709716796875,510.7479553222656,0.0,7,P
sample_7.pdf,14,remainders += new_halted,8.966400146484375,NimbusRomNo9L-Regu,False,130.78900146484375,520.510986328125,0.0,24,P
sample_7.pdf,14,h a l t i n g _ p r o b a b i l i t y ),8.966400146484375,NimbusRomNo9L-Regu,False,303.3490295410156,520.510986328125,0.0,39,P
sample_7.pdf,14,# Add the,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,530.27392578125,0.1111111111111111,9,P
sample_7.pdf,14,remainders,8.966400146484375,NimbusRomNo9L-Regu,False,184.59129333496094,530.27392578125,0.0,10,P
sample_7.pdf,14,those,8.966400146484375,NimbusRomNo9L-Regu,False,259.96282958984375,530.27392578125,0.0,5,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,292.3942565917969,530.27392578125,0.0,11,P
sample_7.pdf,14,which,8.966400146484375,NimbusRomNo9L-Regu,False,329.4075012207031,530.27392578125,0.0,5,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,362.33209228515625,530.27392578125,0.0,11,P
sample_7.pdf,14,a t,8.966400146484375,NimbusRomNo9L-Regu,False,399.9461364746094,530.27392578125,0.0,3,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,416.36358642578125,530.27392578125,0.0,7,P
sample_7.pdf,14,s t e p,8.966400146484375,NimbusRomNo9L-Regu,False,442.96685791015625,530.27392578125,0.0,7,P
sample_7.pdf,14,h a l t i n g _ p r o b a b i l i t y,8.966400146484375,NimbusRomNo9L-Regu,False,131.1929931640625,540.0379638671875,0.0,37,P
sample_7.pdf,14,+= new_halted,8.966400146484375,NimbusRomNo9L-Regu,False,237.3282470703125,540.0379638671875,0.0,13,P
sample_7.pdf,14,remainders,8.966400146484375,NimbusRomNo9L-Regu,False,324.4639892578125,540.0379638671875,0.0,10,P
sample_7.pdf,14,# Increment,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,549.8009643554688,0.09090909090909091,11,P
sample_7.pdf,14,n_updates,8.966400146484375,NimbusRomNo9L-Regu,False,195.28819274902344,549.8009643554688,0.0,9,P
sample_7.pdf,14,f o r,8.966400146484375,NimbusRomNo9L-Regu,False,249.3017578125,549.8009643554688,0.0,5,P
sample_7.pdf,14,a l l,8.966400146484375,NimbusRomNo9L-Regu,False,271.188720703125,549.8009643554688,0.0,5,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,292.39422607421875,549.8009643554688,0.0,11,P
sample_7.pdf,14,which,8.966400146484375,NimbusRomNo9L-Regu,False,329.4075012207031,549.8009643554688,0.0,5,P
sample_7.pdf,14,are,8.966400146484375,NimbusRomNo9L-Regu,False,362.15277099609375,549.8009643554688,0.0,3,P
sample_7.pdf,14,s t i l l,8.966400146484375,NimbusRomNo9L-Regu,False,384.6136169433594,549.8009643554688,0.0,9,P
sample_7.pdf,14,running,8.966400146484375,NimbusRomNo9L-Regu,False,415.8704528808594,549.8009643554688,0.0,7,P
sample_7.pdf,14,n_updates +=,8.966400146484375,NimbusRomNo9L-Regu,False,130.7259979248047,559.56396484375,0.0,12,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,201.1839599609375,559.56396484375,0.0,25,P
sample_7.pdf,14,+ new_halted,8.966400146484375,NimbusRomNo9L-Regu,False,274.9415588378906,559.56396484375,0.0,12,P
sample_7.pdf,14,# Compute,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,569.3279418945312,0.1111111111111111,9,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,184.61822509765625,569.3279418945312,0.0,3,P
sample_7.pdf,14,weight,8.966400146484375,NimbusRomNo9L-Regu,False,205.95826721191406,569.3279418945312,0.0,6,P
sample_7.pdf,14,a p p l i e d,8.966400146484375,NimbusRomNo9L-Regu,False,276.1831359863281,569.3279418945312,0.0,13,P
sample_7.pdf,14,the new,8.966400146484375,NimbusRomNo9L-Regu,False,335.2536926269531,569.3279418945312,0.0,7,P
sample_7.pdf,14,s t a t e,8.966400146484375,NimbusRomNo9L-Regu,False,378.74078369140625,569.3279418945312,0.0,9,P
sample_7.pdf,14,and,8.966400146484375,NimbusRomNo9L-Regu,False,410.0693054199219,569.3279418945312,0.0,3,P
sample_7.pdf,14,o utput :,8.966400146484375,NimbusRomNo9L-Regu,False,432.12664794921875,569.3279418945312,0.0,9,P
sample_7.pdf,14,0 when the,8.966400146484375,NimbusRomNo9L-Regu,False,151.48736572265625,579.0909423828125,0.0,10,P
sample_7.pdf,14,i n p u t,8.966400146484375,NimbusRomNo9L-Regu,False,211.62501525878906,579.0909423828125,0.0,9,P
sample_7.pdf,14,has,8.966400146484375,NimbusRomNo9L-Regu,False,243.54541015625,579.0909423828125,0.0,3,P
sample_7.pdf,14,a l r e a d y,8.966400146484375,NimbusRomNo9L-Regu,False,265.4234313964844,579.0909423828125,0.0,13,P
sample_7.pdf,14,"halted ,",8.966400146484375,NimbusRomNo9L-Regu,False,308.3544921875,579.0909423828125,0.0,8,P
sample_7.pdf,14,p when the,8.966400146484375,NimbusRomNo9L-Regu,False,151.48736572265625,588.85498046875,0.0,10,P
sample_7.pdf,14,i n p u t,8.966400146484375,NimbusRomNo9L-Regu,False,211.62501525878906,588.85498046875,0.0,9,P
sample_7.pdf,14,hasn ’ t,8.966400146484375,NimbusRomNo9L-Regu,False,243.5185089111328,588.85498046875,0.0,8,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,281.6346130371094,588.85498046875,0.0,11,P
sample_7.pdf,14,"yet ,",8.966400146484375,NimbusRomNo9L-Regu,False,318.8541259765625,588.85498046875,0.0,5,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,152.33917236328125,598.617919921875,0.0,3,P
sample_7.pdf,14,remainders when,8.966400146484375,NimbusRomNo9L-Regu,False,173.83163452148438,598.617919921875,0.0,15,P
sample_7.pdf,14,i t,8.966400146484375,NimbusRomNo9L-Regu,False,260.5635986328125,598.617919921875,0.0,3,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,276.2547912597656,598.617919921875,0.0,11,P
sample_7.pdf,14,t h i s,8.966400146484375,NimbusRomNo9L-Regu,False,314.1467590332031,598.617919921875,0.0,7,P
sample_7.pdf,14,s t e p .,8.966400146484375,NimbusRomNo9L-Regu,False,340.75006103515625,598.617919921875,0.0,9,P
sample_7.pdf,14,update_weights =,8.966400146484375,NimbusRomNo9L-Regu,False,130.78900146484375,608.3809814453125,0.0,16,P
sample_7.pdf,14,t f . expand_dims ( p,8.966400146484375,NimbusRomNo9L-Regu,False,222.7394256591797,608.3809814453125,0.0,21,P
sample_7.pdf,14,s t i l l _ r u n n i n g,8.966400146484375,NimbusRomNo9L-Regu,False,324.9170227050781,608.3809814453125,0.0,25,P
sample_7.pdf,14,new_halted,8.966400146484375,NimbusRomNo9L-Regu,False,302.80902099609375,618.1449584960938,0.0,10,P
sample_7.pdf,14,"remainders ,",8.966400146484375,NimbusRomNo9L-Regu,False,372.77801513671875,618.1449584960938,0.0,12,P
sample_7.pdf,14,# Apply,8.966400146484375,NimbusRomNo9L-Regu,False,129.96800231933594,627.907958984375,0.14285714285714285,7,P
sample_7.pdf,14,t r a n s f o r m a t i o n,8.966400146484375,NimbusRomNo9L-Regu,False,174.06475830078125,627.907958984375,0.0,27,P
sample_7.pdf,14,the,8.966400146484375,NimbusRomNo9L-Regu,False,270.6957092285156,627.907958984375,0.0,3,P
sample_7.pdf,14,s t a t e,8.966400146484375,NimbusRomNo9L-Regu,False,292.66339111328125,627.907958984375,0.0,9,P
sample_7.pdf,14,t r a n s f o r m e d _ s t a t e =,8.966400146484375,NimbusRomNo9L-Regu,False,131.031005859375,637.6709594726562,0.0,35,P
sample_7.pdf,14,t r a n s i t i o n _ f u n c t i o n ( s e l f _ a t t e n t i o n ( s t a t e ) ),8.966400146484375,NimbusRomNo9L-Regu,False,238.81607055664062,637.6709594726562,0.0,83,P
sample_7.pdf,14,I n t e r p o l a t e,8.966400146484375,NimbusRomNo9L-Regu,False,141.97401428222656,647.4349365234375,0.047619047619047616,21,P
sample_7.pdf,14,transformed,8.966400146484375,NimbusRomNo9L-Regu,False,206.1555633544922,647.4349365234375,0.0,11,P
sample_7.pdf,14,and,8.966400146484375,NimbusRomNo9L-Regu,False,270.19354248046875,647.4349365234375,0.0,3,P
sample_7.pdf,14,p r e v i o u s,8.966400146484375,NimbusRomNo9L-Regu,False,292.2687683105469,647.4349365234375,0.0,15,P
sample_7.pdf,14,s t a t e s,8.966400146484375,NimbusRomNo9L-Regu,False,341.09967041015625,647.4349365234375,0.0,11,P
sample_7.pdf,14,f o r,8.966400146484375,NimbusRomNo9L-Regu,False,378.41778564453125,647.4349365234375,0.0,5,P
sample_7.pdf,14,non,8.966400146484375,NimbusRomNo9L-Regu,False,399.0494384765625,647.4349365234375,0.0,3,P
sample_7.pdf,14,h a l t e d,8.966400146484375,NimbusRomNo9L-Regu,False,421.51397705078125,647.4349365234375,0.0,11,P
sample_7.pdf,14,i n p u t s,8.966400146484375,NimbusRomNo9L-Regu,False,459.1728515625,647.4349365234375,0.0,11,P
sample_7.pdf,14,new_state = ( ( t r a n s f o r m e d _ s t a t e,8.966400146484375,NimbusRomNo9L-Regu,False,130.7760009765625,657.1979370117188,0.0,49,P
sample_7.pdf,14,update_weights ) +,8.966400146484375,NimbusRomNo9L-Regu,False,313.70501708984375,657.1979370117188,0.0,18,P
sample_7.pdf,14,( p r e v i o u s _ s t a t e,8.966400146484375,NimbusRomNo9L-Regu,False,200.65499877929688,666.9609375,0.0,29,P
sample_7.pdf,14,update_weights ) ) ),8.966400146484375,NimbusRomNo9L-Regu,False,324.4640197753906,666.9609375,0.0,20,P
sample_7.pdf,14,s t e p += 1,8.966400146484375,NimbusRomNo9L-Regu,False,130.9340057373047,676.7249755859375,0.0,12,P
sample_7.pdf,14,r e t u r n,8.966400146484375,NimbusRomNo9L-Regu,False,131.07199096679688,686.4879760742188,0.0,11,P
sample_7.pdf,14,"( t r a n s f o r m e d _ s t a t e ,",8.966400146484375,NimbusRomNo9L-Regu,False,168.3722381591797,686.4879760742188,0.0,37,P
sample_7.pdf,14,"step ,",8.966400146484375,NimbusRomNo9L-Regu,False,275.9601745605469,686.4879760742188,0.0,6,P
sample_7.pdf,14,"h a l t i n g _ p r o b a b i l i t y ,",8.966400146484375,NimbusRomNo9L-Regu,False,308.651611328125,686.4879760742188,0.0,39,P
sample_7.pdf,14,"remainders ,",8.966400146484375,NimbusRomNo9L-Regu,False,173.7220001220703,696.2509765625,0.0,12,P
sample_7.pdf,14,"n_updates ,",8.966400146484375,NimbusRomNo9L-Regu,False,238.2173309326172,696.2509765625,0.0,11,P
sample_7.pdf,14,new_state ),8.966400146484375,NimbusRomNo9L-Regu,False,297.5479736328125,696.2509765625,0.0,11,P
sample_7.pdf,14,Listing 2: Computations in each step of the UT with dynamic halting.,9.962599754333496,NimbusRomNo9L-Regu,False,169.7969970703125,709.4474487304688,0.058823529411764705,68,H3
sample_7.pdf,15,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,15,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,84.57066345214844,1.0,7,H3
sample_7.pdf,15,ESCRIPTION OF SOME OF THE,9.56410026550293,NimbusRomNo9L-Regu,False,194.84100341796875,84.57066345214844,0.84,25,H3
sample_7.pdf,15,ASKS,9.56410026550293,NimbusRomNo9L-Regu,False,350.9620056152344,84.57066345214844,1.0,4,H3
sample_7.pdf,15,ATASETS,9.56410026550293,NimbusRomNo9L-Regu,False,390.4850158691406,84.57066345214844,1.0,7,H3
sample_7.pdf,15,"Here, we provide some additional details on the bAbI, subject-verb agreement, LAMBADA language modeling,",8.975361824035645,NimbusRomNo9L-Regu,False,108.0,107.05719757080078,0.09615384615384616,104,P
sample_7.pdf,15,and learning to execute (LTE) tasks.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,116.82699584960938,0.08333333333333333,36,P
sample_7.pdf,15,D.1,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,140.4624786376953,0.3333333333333333,3,H3
sample_7.pdf,15,I Q,9.962599754333496,NimbusRomNo9L-Regu,False,153.3699951171875,140.4624786376953,0.6666666666666666,3,H3
sample_7.pdf,15,UESTION,7.970099925994873,NimbusRomNo9L-Regu,False,166.77899169921875,141.97357177734375,1.0,7,P
sample_7.pdf,15,NSWERING,7.970099925994873,NimbusRomNo9L-Regu,False,215.8149871826172,141.97357177734375,1.0,8,P
sample_7.pdf,15,"The bAbi question answering dataset (Weston et al., 2015) consists of 20 different synthetic tasks",9.055620193481445,NimbusRomNo9L-Regu,False,107.72200012207031,160.28330993652344,0.030612244897959183,98,P
sample_7.pdf,15,. The aim,9.055620193481445,NimbusRomNo9L-Regu,False,467.614990234375,160.28330993652344,0.1111111111111111,9,P
sample_7.pdf,15,"is that each task tests a unique aspect of language understanding and reasoning, including the ability of: reasoning",8.903413772583008,NimbusRomNo9L-Regu,False,108.0,170.1617431640625,0.0,116,P
sample_7.pdf,15,"from supporting facts in a story, answering true/false type questions, counting, understanding negation and",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,179.80931091308594,0.0,107,P
sample_7.pdf,15,"indeﬁnite knowledge, understanding coreferences, time reasoning, positional and size reasoning, path-ﬁnding, and",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,189.7093048095703,0.0,112,P
sample_7.pdf,15,"understanding motivations (to see examples for each of these tasks, please refer to Table 1 in (Weston et al., 2015)).",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,199.47230529785156,0.01694915254237288,118,P
sample_7.pdf,15,"There are two versions of the dataset, one with 1k training examples and the other with 10k examples. It is",9.055620193481445,NimbusRomNo9L-Regu,False,107.72200012207031,215.0773162841797,0.018691588785046728,107,P
sample_7.pdf,15,"important for a model to be data-efﬁcient to achieve good results using only the 1k training examples. Moreover,",8.970882415771484,NimbusRomNo9L-Regu,False,108.0,224.9045867919922,0.008928571428571428,112,P
sample_7.pdf,15,"the original idea is that a single model should be evaluated across all the tasks (not tuning per task), which is",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,234.6042938232422,0.0,113,P
sample_7.pdf,15,the,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,244.43496704101562,0.0,3,P
sample_7.pdf,15,train joint,8.966400146484375,NimbusRomNo9L-ReguItal,False,118.95693969726562,244.27613830566406,0.0,11,P
sample_7.pdf,15,"setup in Table 1, and the tables presented in Appendix E.",8.966400146484375,NimbusRomNo9L-Regu,False,156.2928009033203,244.43496704101562,0.05263157894736842,57,P
sample_7.pdf,15,D.2,9.962599754333496,NimbusRomNo9L-Regu,False,108.24900817871094,268.0694580078125,0.3333333333333333,3,H3
sample_7.pdf,15,UBJECT,7.970099925994873,NimbusRomNo9L-Regu,False,140.4080047607422,269.58056640625,1.0,6,P
sample_7.pdf,15,ERB,7.970099925994873,NimbusRomNo9L-Regu,False,183.27700805664062,269.58056640625,1.0,3,P
sample_7.pdf,15,GREEMENT,7.970099925994873,NimbusRomNo9L-Regu,False,209.5780029296875,269.58056640625,1.0,8,P
sample_7.pdf,15,Subject-verb agreement is the task of predicting number agreement between subject and verb in English sentences.,8.880810737609863,NimbusRomNo9L-Regu,False,108.0,288.02288818359375,0.017857142857142856,112,P
sample_7.pdf,15,Succeeding in this task is a strong indicator that a model can learn to approximate syntactic structure and therefore,8.885335922241211,NimbusRomNo9L-Regu,False,108.0,297.783447265625,0.008547008547008548,117,P
sample_7.pdf,15,it was proposed by Linzen et al. (2016) as proxy for assessing the ability of different models to capture hierarchical,8.876283645629883,NimbusRomNo9L-Regu,False,108.0,307.5533142089844,0.00847457627118644,118,P
sample_7.pdf,15,structure in natural language.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,317.24798583984375,0.0,30,P
sample_7.pdf,15,Two experimental setups were proposed by Linzen et al. (2016) for training a model on this task: 1) training,9.055620193481445,NimbusRomNo9L-Regu,False,107.72200012207031,332.92132568359375,0.018518518518518517,108,P
sample_7.pdf,15,"with a language modeling objective, i.e., next word prediction, and 2) as binary classiﬁcation, i.e. predicting",9.055620193481445,NimbusRomNo9L-Regu,False,107.677001953125,342.6853332519531,0.0,111,P
sample_7.pdf,15,"the number of the verb given the sentence. In this paper, we use the language modeling objective, meaning that",9.042293548583984,NimbusRomNo9L-Regu,False,108.0,352.45843505859375,0.00909090909090909,110,P
sample_7.pdf,15,we provide the model with an implicit supervision and evaluate based on the ranking accuracy of the correct,9.055620193481445,NimbusRomNo9L-Regu,False,107.677001953125,362.2113342285156,0.0,107,P
sample_7.pdf,15,form of the verb compared to the incorrect form of the verb.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,372.04296875,0.0,60,P
sample_7.pdf,15,"In this task, in order to have different levels of difﬁculty, “agreement attractors” are used, i.e. one or more",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,387.71533203125,0.009009009009009009,111,P
sample_7.pdf,15,"intervening nouns with the opposite number from the subject with the goal of confusing the model. In this case,",9.024493217468262,NimbusRomNo9L-Regu,False,108.0,397.5028991699219,0.009009009009009009,111,P
sample_7.pdf,15,the model needs to correctly identify the head of the syntactic subject that corresponds to a given verb and ignore,8.952940940856934,NimbusRomNo9L-Regu,False,108.0,407.3201599121094,0.0,115,P
sample_7.pdf,15,the intervening attractors in order to predict the correct form of that verb. Here are some examples for this task,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,417.0063171386719,0.008771929824561403,114,P
sample_7.pdf,15,in which subjects and the corresponding verbs are in boldface and agreement attractors are underlined:,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,426.83697509765625,0.0,102,P
sample_7.pdf,15,No attractor:,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,446.888671875,0.07692307692307693,13,P
sample_7.pdf,15,The,7.970099925994873,NimbusMonL-Regu,False,206.27200317382812,447.0655212402344,0.3333333333333333,3,P
sample_7.pdf,15,boy smiles,7.970099925994873,NimbusMonL-Bold,True,220.61817932128906,446.888671875,0.0,10,P
sample_7.pdf,15,One attractor:,7.970099925994873,NimbusMonL-Bold,True,113.97801208496094,454.8586730957031,0.07142857142857142,14,P
sample_7.pdf,15,The,7.970099925994873,NimbusMonL-Regu,False,206.27200317382812,455.0355224609375,0.3333333333333333,3,P
sample_7.pdf,15,number,7.970099925994873,NimbusMonL-Bold,True,220.61817932128906,454.8586730957031,0.0,6,P
sample_7.pdf,15,of men,7.970099925994873,NimbusMonL-Regu,False,253.13536071777344,455.0355224609375,0.0,6,P
sample_7.pdf,15,not clear.,7.970099925994873,NimbusMonL-Regu,False,298.087158203125,455.0355224609375,0.0,10,P
sample_7.pdf,15,Two attractors:,7.970099925994873,NimbusMonL-Bold,True,113.97802734375,462.82867431640625,0.06666666666666667,15,P
sample_7.pdf,15,The,7.970099925994873,NimbusMonL-Regu,False,206.27203369140625,463.0055236816406,0.3333333333333333,3,P
sample_7.pdf,15,ratio,7.970099925994873,NimbusMonL-Bold,True,220.6182098388672,462.82867431640625,0.0,5,P
sample_7.pdf,15,of men to women,7.970099925994873,NimbusMonL-Regu,False,248.35333251953125,463.0055236816406,0.0,15,P
sample_7.pdf,15,not clear.,7.970099925994873,NimbusMonL-Regu,False,334.43115234375,463.0055236816406,0.0,10,P
sample_7.pdf,15,Three attractors:,7.970099925994873,NimbusMonL-Bold,True,113.97801208496094,470.7986755371094,0.058823529411764705,17,P
sample_7.pdf,15,The,7.970099925994873,NimbusMonL-Regu,False,206.27200317382812,470.97552490234375,0.3333333333333333,3,P
sample_7.pdf,15,ratio,7.970099925994873,NimbusMonL-Bold,True,220.61817932128906,470.7986755371094,0.0,5,P
sample_7.pdf,15,of men to women and children,7.970099925994873,NimbusMonL-Regu,False,248.35330200195312,470.97552490234375,0.0,28,P
sample_7.pdf,15,not clear.,7.970099925994873,NimbusMonL-Regu,False,394.6851501464844,470.97552490234375,0.0,10,P
sample_7.pdf,15,D.3,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490234375,507.073486328125,0.3333333333333333,3,H3
sample_7.pdf,15,LAMBADA L,9.962599754333496,NimbusRomNo9L-Regu,False,134.37095642089844,507.073486328125,0.8888888888888888,9,H3
sample_7.pdf,15,ANGUAGE,7.970099925994873,NimbusRomNo9L-Regu,False,196.05001831054688,508.5845947265625,1.0,7,P
sample_7.pdf,15,ODELING,7.970099925994873,NimbusRomNo9L-Regu,False,249.59800720214844,508.5845947265625,1.0,7,P
sample_7.pdf,15,"The LAMBADA task (Paperno et al., 2016) is a broad context language modeling task. In this task, given a",9.055620193481445,NimbusRomNo9L-Regu,False,107.72200012207031,526.894287109375,0.09615384615384616,104,P
sample_7.pdf,15,"narrative passage, the goal is to predict the last word (target word) of the last sentence (target sentence) in the",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,536.6573486328125,0.0,115,P
sample_7.pdf,15,passage. These passages are speciﬁcally selected in a way that human subjects are easily able to guess their last,9.020037651062012,NimbusRomNo9L-Regu,False,108.0,546.447265625,0.008849557522123894,113,P
sample_7.pdf,15,"word if they are exposed to a long passage, but not if they only see the target sentence preceding the target word",8.970882415771484,NimbusRomNo9L-Regu,False,107.677001953125,557.2836303710938,0.0,114,P
sample_7.pdf,15,Here is a sample from the dataset:,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,567.0509643554688,0.029411764705882353,34,P
sample_7.pdf,15,Context,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,587.1016845703125,0.14285714285714285,7,P
sample_7.pdf,15,"“Yes, I thought I was going to lose the baby.”",7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,595.2495727539062,0.06521739130434782,46,P
sample_7.pdf,15,"“I was scared too,” he stated, sincerity flooding his eyes.",7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,603.2195434570312,0.01694915254237288,59,P
sample_7.pdf,15,“You were?”,7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,611.1895141601562,0.09090909090909091,11,P
sample_7.pdf,15,"“Yes, of course.",7.970099925994873,NimbusMonL-Regu,False,261.7429504394531,611.1895141601562,0.0625,16,P
sample_7.pdf,15,Why do you even ask?”,7.970099925994873,NimbusMonL-Regu,False,344.95098876953125,611.1895141601562,0.047619047619047616,21,P
sample_7.pdf,15,“This baby wasn’t exactly planned for.”,7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,619.1595458984375,0.02564102564102564,39,P
sample_7.pdf,15,Target sentence,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,626.9526977539062,0.06666666666666667,15,P
sample_7.pdf,15,“Do you honestly think that I would want you to have a ________?”,7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,635.0995483398438,0.03076923076923077,65,P
sample_7.pdf,15,Target word,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,642.8926391601562,0.09090909090909091,11,P
sample_7.pdf,15,miscarriage,7.970099925994873,NimbusMonL-Regu,False,201.48899841308594,651.03955078125,0.0,11,P
sample_7.pdf,15,"The LAMBADA task consists in predicting the target word given the whole passage (i.e., the context plus the",9.055620193481445,NimbusRomNo9L-Regu,False,107.72200012207031,673.1983032226562,0.07476635514018691,107,P
sample_7.pdf,15,target sentence). A “control set” is also provided which was constructed by randomly sampling passages of the,9.033397674560547,NimbusRomNo9L-Regu,False,108.0,682.9781494140625,0.009174311926605505,109,P
sample_7.pdf,15,"same shape and size as the ones used to build LAMBADA, but without ﬁltering them in any way. The control",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,692.725341796875,0.07692307692307693,104,P
sample_7.pdf,15,https://research.fb.com/downloads/babi,8.966400146484375,NimbusMonL-Regu,False,124.13899993896484,711.7518920898438,0.0,38,P
sample_7.pdf,15,http://clic.cimec.unitn.it/lambada/appendix_onefile.pdf,8.966400146484375,NimbusMonL-Regu,False,124.13899993896484,722.6029052734375,0.0,55,P
sample_7.pdf,16,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,16,"set is used to evaluate the models at standard language modeling before testing on the LAMBADA task, and",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,84.95629119873047,0.0673076923076923,104,P
sample_7.pdf,16,therefore to ensure that low performance on the latter cannot be attributed simply to poor language modeling.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,94.78799438476562,0.0,109,P
sample_7.pdf,16,The task is evaluated in two settings: as,9.028946876525879,NimbusRomNo9L-Regu,False,107.72200012207031,110.48152160644531,0.024390243902439025,41,P
sample_7.pdf,16,language modeling,9.028946876525879,NimbusRomNo9L-ReguItal,False,248.59234619140625,110.32159423828125,0.0,17,P
sample_7.pdf,16,(the standard setup) and as,9.028946876525879,NimbusRomNo9L-Regu,False,319.6836242675781,110.48152160644531,0.0,27,P
sample_7.pdf,16,reading comprehension,9.028946876525879,NimbusRomNo9L-ReguItal,False,416.5269775390625,110.32159423828125,0.0,21,P
sample_7.pdf,16,"In the former (more challenging) case, a model is simply trained for the next word prediction on the training",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,120.22429656982422,0.009174311926605505,109,P
sample_7.pdf,16,"data, and evaluated on the target words at test time (i.e. the model is trained to predict all words, not speciﬁcally",9.020037651062012,NimbusRomNo9L-Regu,False,108.0,130.0142822265625,0.0,117,P
sample_7.pdf,16,"challenging target words). In this paper, we report the results of the Universal Transformer in both setups.",8.966400146484375,NimbusRomNo9L-Regu,False,108.0,139.81900024414062,0.027777777777777776,108,P
sample_7.pdf,16,D.4,9.962599754333496,NimbusRomNo9L-Regu,False,108.2490005493164,163.04347229003906,0.3333333333333333,3,H3
sample_7.pdf,16,EARNING TO,7.970099925994873,NimbusRomNo9L-Regu,False,140.95599365234375,164.5545654296875,0.9,10,P
sample_7.pdf,16,XECUTE,7.970099925994873,NimbusRomNo9L-Regu,False,202.2949981689453,164.5545654296875,1.0,6,P
sample_7.pdf,16,(LTE),9.962599754333496,NimbusRomNo9L-Regu,False,236.18385314941406,163.04347229003906,0.6,5,H3
sample_7.pdf,16,LTE is a set of tasks indicating the ability of a model to learn to execute computer programs and was proposed,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,182.70030212402344,0.02727272727272727,110,P
sample_7.pdf,16,"by Zaremba & Sutskever (2015). These tasks include two subsets: 1) program evaluation tasks (program,",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,192.4633026123047,0.0297029702970297,101,P
sample_7.pdf,16,"control, and addition) that are designed to assess the ability of models for understanding numerical operations,",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,202.22630310058594,0.0,112,P
sample_7.pdf,16,"if-statements, variable assignments, the compositionality of operations, and more, as well as 2) memorization",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,211.9902801513672,0.0,109,P
sample_7.pdf,16,"tasks (copy, double, and reverse).",8.966400146484375,NimbusRomNo9L-Regu,False,108.0,221.82095336914062,0.0,34,P
sample_7.pdf,16,The difﬁculty of the program evaluation tasks is parameterized by their,8.952940940856934,NimbusRomNo9L-Regu,False,107.72200012207031,237.5721893310547,0.014084507042253521,71,P
sample_7.pdf,16,length,8.952940940856934,NimbusRomNo9L-ReguItal,False,357.4650573730469,237.41360473632812,0.0,6,P
sample_7.pdf,16,and,8.952940940856934,NimbusRomNo9L-Regu,False,381.6177673339844,237.5721893310547,0.0,3,P
sample_7.pdf,16,nesting,8.952940940856934,NimbusRomNo9L-ReguItal,False,396.32965087890625,237.41360473632812,0.0,7,P
sample_7.pdf,16,. The length parameter,8.952940940856934,NimbusRomNo9L-Regu,False,423.9590148925781,237.5721893310547,0.045454545454545456,22,P
sample_7.pdf,16,is the number of digits in the integers that appear in the programs (so the integers are chosen uniformly from,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,247.25730895996094,0.0,110,P
sample_7.pdf,16,"[1,",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,257.02130126953125,0.0,3,P
sample_7.pdf,16,length,9.055620193481445,NimbusRomNo9L-ReguItal,False,117.90481567382812,256.86090087890625,0.0,6,P
sample_7.pdf,16,"]), and the nesting parameter is the number of times we are allowed to combine the operations with",9.055620193481445,NimbusRomNo9L-Regu,False,143.0919952392578,257.02130126953125,0.0,98,P
sample_7.pdf,16,"each other. Higher values of nesting yield programs with deeper parse trees. For instance, here is a program that",8.99325942993164,NimbusRomNo9L-Regu,False,108.0,266.8315734863281,0.017699115044247787,113,P
sample_7.pdf,16,is generated with length = 4 and nesting = 3.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,276.614990234375,0.0,45,P
sample_7.pdf,16,Input,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,296.2616882324219,0.2,5,P
sample_7.pdf,16,j=8584,7.970099925994873,NimbusMonL-Regu,False,159.40699768066406,304.4085388183594,0.0,6,P
sample_7.pdf,16,for,7.970099925994873,NimbusMonL-Regu,False,159.40699768066406,312.3785400390625,0.0,3,P
sample_7.pdf,16,range(8):,7.970099925994873,NimbusMonL-Regu,False,195.7506561279297,312.3785400390625,0.0,9,P
sample_7.pdf,16,j+=920,7.970099925994873,NimbusMonL-Regu,False,167.05899047851562,320.3485412597656,0.0,6,P
sample_7.pdf,16,b=(1500+j),7.970099925994873,NimbusMonL-Regu,False,159.40699768066406,328.31854248046875,0.0,10,P
sample_7.pdf,16,print,7.970099925994873,NimbusMonL-Regu,False,159.40699768066406,336.2885437011719,0.0,5,P
sample_7.pdf,16,((b+7567)),7.970099925994873,NimbusMonL-Regu,False,183.31729125976562,336.2885437011719,0.0,10,P
sample_7.pdf,16,Target,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,344.0816955566406,0.16666666666666666,6,P
sample_7.pdf,16,25011,7.970099925994873,NimbusMonL-Regu,False,159.40699768066406,352.2285461425781,0.0,5,P
sample_7.pdf,17,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,17,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,84.57066345214844,1.0,7,H3
sample_7.pdf,17,I D,11.9552001953125,NimbusRomNo9L-Regu,False,207.08399963378906,82.75727844238281,0.6666666666666666,3,H3
sample_7.pdf,17,ETAILED,9.56410026550293,NimbusRomNo9L-Regu,False,223.2830047607422,84.57066345214844,1.0,7,H3
sample_7.pdf,17,ESULTS,9.56410026550293,NimbusRomNo9L-Regu,False,277.85699462890625,84.57066345214844,1.0,6,H3
sample_7.pdf,17,Best seed run for each task (out of 10 runs),9.962599754333496,NimbusRomNo9L-Regu,False,222.3350067138672,103.67646789550781,0.022727272727272728,44,H3
sample_7.pdf,17,Task id,9.962599754333496,NimbusRomNo9L-Regu,False,185.35400390625,125.11549377441406,0.14285714285714285,7,H3
sample_7.pdf,17,10K,9.962599754333496,NimbusRomNo9L-Regu,False,266.30401611328125,119.63648986816406,0.3333333333333333,3,H3
sample_7.pdf,17,train single,9.962599754333496,NimbusRomNo9L-Regu,False,227.61500549316406,135.39649963378906,0.0,12,H3
sample_7.pdf,17,train joint,9.962599754333496,NimbusRomNo9L-Regu,False,283.624755859375,135.39649963378906,0.0,11,H3
sample_7.pdf,17,train single,9.962599754333496,NimbusRomNo9L-Regu,False,334.10516357421875,135.39649963378906,0.0,12,H3
sample_7.pdf,17,train joint,9.962599754333496,NimbusRomNo9L-Regu,False,390.1148376464844,135.39649963378906,0.0,11,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,151.35646057128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,151.35646057128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,151.35646057128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,151.35646057128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,162.31544494628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,162.31544494628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,162.31544494628906,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,162.31544494628906,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,173.27442932128906,0.0,3,H3
sample_7.pdf,17,1.2,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,173.27442932128906,0.0,3,H3
sample_7.pdf,17,3.7,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,173.27442932128906,0.0,3,H3
sample_7.pdf,17,5.4,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,173.27442932128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,184.23341369628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,184.23341369628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,184.23341369628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,184.23341369628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,195.19239807128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,195.19239807128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,195.19239807128906,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,195.19239807128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,206.15138244628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,206.15138244628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,206.15138244628906,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,206.15138244628906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,217.11036682128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,217.11036682128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,217.11036682128906,0.0,3,H3
sample_7.pdf,17,3.2,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,217.11036682128906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,228.06837463378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,228.06837463378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,228.06837463378906,0.0,3,H3
sample_7.pdf,17,1.6,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,228.06837463378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41554260253906,239.02735900878906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556701660156,239.02735900878906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.90576171875,239.02735900878906,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,403.1459045410156,239.02735900878906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,249.98634338378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,249.98634338378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,249.98634338378906,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,249.98634338378906,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,260.9453125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,260.9453125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,260.9453125,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,260.9453125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,271.904296875,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,271.904296875,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,271.904296875,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,271.904296875,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,282.86328125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,282.86328125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,282.86328125,0.0,3,H3
sample_7.pdf,17,0.6,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,282.86328125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,293.822265625,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,293.822265625,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,293.822265625,0.0,3,H3
sample_7.pdf,17,3.8,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,293.822265625,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,304.78125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,304.78125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,304.78125,0.0,3,H3
sample_7.pdf,17,5.9,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,304.78125,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,315.740234375,0.0,3,H3
sample_7.pdf,17,1.2,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,315.740234375,0.0,3,H3
sample_7.pdf,17,5.8,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,315.740234375,0.0,3,H3
sample_7.pdf,17,15.4,9.962599754333496,NimbusRomNo9L-Regu,False,400.65521240234375,315.740234375,0.0,4,H3
sample_7.pdf,17,0.6,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,326.69921875,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,326.69921875,0.0,3,H3
sample_7.pdf,17,32.0,9.962599754333496,NimbusRomNo9L-Regu,False,347.41510009765625,326.69921875,0.0,4,H3
sample_7.pdf,17,42.9,9.962599754333496,NimbusRomNo9L-Regu,False,400.65521240234375,326.69921875,0.0,4,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,337.6572265625,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,337.6572265625,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,337.6572265625,0.0,3,H3
sample_7.pdf,17,4.1,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,337.6572265625,0.0,3,H3
sample_7.pdf,17,2.8,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,348.6162109375,0.0,3,H3
sample_7.pdf,17,3.1,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,348.6162109375,0.0,3,H3
sample_7.pdf,17,47.1,9.962599754333496,NimbusRomNo9L-Regu,False,347.41510009765625,348.6162109375,0.0,4,H3
sample_7.pdf,17,68.2,9.962599754333496,NimbusRomNo9L-Regu,False,400.65521240234375,348.6162109375,0.0,4,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,243.41552734375,359.5751953125,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,296.6556396484375,359.5751953125,0.0,3,H3
sample_7.pdf,17,2.4,9.962599754333496,NimbusRomNo9L-Regu,False,349.9057312011719,359.5751953125,0.0,3,H3
sample_7.pdf,17,2.4,9.962599754333496,NimbusRomNo9L-Regu,False,403.1458740234375,359.5751953125,0.0,3,H3
sample_7.pdf,17,avg err,9.962599754333496,NimbusRomNo9L-Regu,False,183.36099243164062,375.53546142578125,0.0,7,H3
sample_7.pdf,17,0.21,9.962599754333496,NimbusRomNo9L-Regu,False,240.92491149902344,375.53546142578125,0.0,4,H3
sample_7.pdf,17,0.29,9.962599754333496,NimbusRomNo9L-Regu,False,294.1650085449219,375.53546142578125,0.0,4,H3
sample_7.pdf,17,4.55,9.962599754333496,NimbusRomNo9L-Regu,False,347.41510009765625,375.53546142578125,0.0,4,H3
sample_7.pdf,17,7.78,9.962599754333496,NimbusRomNo9L-Regu,False,400.65521240234375,375.53546142578125,0.0,4,H3
sample_7.pdf,17,failed,9.962599754333496,NimbusRomNo9L-Regu,False,183.36099243164062,391.4954528808594,0.0,6,H3
sample_7.pdf,17,Average (,9.962599754333496,NimbusRomNo9L-Regu,False,222.7729949951172,426.48345947265625,0.1111111111111111,9,H3
sample_7.pdf,17,var) over all seeds (for 10 runs),9.962599754333496,NimbusRomNo9L-Regu,False,267.1659851074219,426.48345947265625,0.0,33,H3
sample_7.pdf,17,Task id,9.962599754333496,NimbusRomNo9L-Regu,False,178.3000030517578,447.9224548339844,0.14285714285714285,7,H3
sample_7.pdf,17,10K,9.962599754333496,NimbusRomNo9L-Regu,False,261.5320129394531,442.4434509277344,0.3333333333333333,3,H3
sample_7.pdf,17,train single,9.962599754333496,NimbusRomNo9L-Regu,False,220.56100463867188,458.2034606933594,0.0,12,H3
sample_7.pdf,17,train joint,9.962599754333496,NimbusRomNo9L-Regu,False,278.8521728515625,458.2034606933594,0.0,11,H3
sample_7.pdf,17,train single,9.962599754333496,NimbusRomNo9L-Regu,False,331.614013671875,458.2034606933594,0.0,12,H3
sample_7.pdf,17,train joint,9.962599754333496,NimbusRomNo9L-Regu,False,392.3957824707031,458.2034606933594,0.0,11,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,226.02037048339844,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,246.69801330566406,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,281.54718017578125,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239990234375,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,337.07318115234375,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,357.75,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,395.09979248046875,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,415.76800537109375,474.1634521484375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,226.02037048339844,485.1224365234375,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,246.69801330566406,485.1224365234375,0.0,3,H3
sample_7.pdf,17,1.7,9.962599754333496,NimbusRomNo9L-Regu,False,281.54718017578125,485.1224365234375,0.0,3,H3
sample_7.pdf,17,2.6,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239990234375,485.1224365234375,0.0,3,H3
sample_7.pdf,17,3.2,9.962599754333496,NimbusRomNo9L-Regu,False,337.07318115234375,485.1224365234375,0.0,3,H3
sample_7.pdf,17,4.1,9.962599754333496,NimbusRomNo9L-Regu,False,357.75,485.1224365234375,0.0,3,H3
sample_7.pdf,17,4.3,9.962599754333496,NimbusRomNo9L-Regu,False,392.609130859375,485.1224365234375,0.0,3,H3
sample_7.pdf,17,11.6,9.962599754333496,NimbusRomNo9L-Regu,False,413.2769775390625,485.1224365234375,0.0,4,H3
sample_7.pdf,17,1.8,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203399658203,496.0814208984375,0.0,3,H3
sample_7.pdf,17,1.8,9.962599754333496,NimbusRomNo9L-Regu,False,246.69798278808594,496.0814208984375,0.0,3,H3
sample_7.pdf,17,4.6,9.962599754333496,NimbusRomNo9L-Regu,False,281.5471496582031,496.0814208984375,0.0,3,H3
sample_7.pdf,17,7.3,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239685058594,496.0814208984375,0.0,3,H3
sample_7.pdf,17,9.1,9.962599754333496,NimbusRomNo9L-Regu,False,334.5824890136719,496.0814208984375,0.0,3,H3
sample_7.pdf,17,12.7,9.962599754333496,NimbusRomNo9L-Regu,False,355.25994873046875,496.0814208984375,0.0,4,H3
sample_7.pdf,17,14.3,9.962599754333496,NimbusRomNo9L-Regu,False,390.1091003417969,496.0814208984375,0.0,4,H3
sample_7.pdf,17,18.1,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,496.0814208984375,0.0,4,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.6,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,507.0394287109375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,517.9984130859375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,517.9984130859375,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,517.9984130859375,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,517.9984130859375,0.0,3,H3
sample_7.pdf,17,1.1,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,517.9984130859375,0.0,3,H3
sample_7.pdf,17,1.3,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,517.9984130859375,0.0,3,H3
sample_7.pdf,17,4.3,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,517.9984130859375,0.0,3,H3
sample_7.pdf,17,5.6,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,517.9984130859375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,528.9573974609375,0.0,3,H3
sample_7.pdf,17,1.2,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,528.9573974609375,0.0,3,H3
sample_7.pdf,17,2.1,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,528.9573974609375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,539.9163818359375,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,539.9163818359375,0.0,3,H3
sample_7.pdf,17,1.1,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,539.9163818359375,0.0,3,H3
sample_7.pdf,17,1.5,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,539.9163818359375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,539.9163818359375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,539.9163818359375,0.0,3,H3
sample_7.pdf,17,4.1,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,539.9163818359375,0.0,3,H3
sample_7.pdf,17,2.9,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,539.9163818359375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,550.8753662109375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,550.8753662109375,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,550.8753662109375,0.0,3,H3
sample_7.pdf,17,1.1,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,550.8753662109375,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,550.8753662109375,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,550.8753662109375,0.0,3,H3
sample_7.pdf,17,3.9,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,550.8753662109375,0.0,3,H3
sample_7.pdf,17,4.2,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,550.8753662109375,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,561.8344116210938,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.7,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,572.7933959960938,0.0,3,H3
sample_7.pdf,17,1.3,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,572.7933959960938,0.0,3,H3
sample_7.pdf,17,1.6,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,572.7933959960938,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.9,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,583.7523803710938,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.6,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.9,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,594.71142578125,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.9,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,605.67041015625,0.0,3,H3
sample_7.pdf,17,1.1,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,605.67041015625,0.0,3,H3
sample_7.pdf,17,0.9,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,605.67041015625,0.0,3,H3
sample_7.pdf,17,1.8,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,616.62939453125,0.0,3,H3
sample_7.pdf,17,2.6,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,616.62939453125,0.0,3,H3
sample_7.pdf,17,1.3,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,616.62939453125,0.0,3,H3
sample_7.pdf,17,1.6,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,616.62939453125,0.0,3,H3
sample_7.pdf,17,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,616.62939453125,0.0,3,H3
sample_7.pdf,17,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,616.62939453125,0.0,3,H3
sample_7.pdf,17,4.7,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,616.62939453125,0.0,3,H3
sample_7.pdf,17,5.2,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,616.62939453125,0.0,3,H3
sample_7.pdf,17,2.1,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,627.58740234375,0.0,3,H3
sample_7.pdf,17,3.4,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,627.58740234375,0.0,3,H3
sample_7.pdf,17,1.6,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,627.58740234375,0.0,3,H3
sample_7.pdf,17,2.8,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,627.58740234375,0.0,3,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,627.58740234375,0.0,3,H3
sample_7.pdf,17,0.5,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,627.58740234375,0.0,3,H3
sample_7.pdf,17,10.3,9.962599754333496,NimbusRomNo9L-Regu,False,392.60906982421875,627.58740234375,0.0,4,H3
sample_7.pdf,17,8.6,9.962599754333496,NimbusRomNo9L-Regu,False,418.2579650878906,627.58740234375,0.0,3,H3
sample_7.pdf,17,1.9,9.962599754333496,NimbusRomNo9L-Regu,False,226.02032470703125,638.54638671875,0.0,3,H3
sample_7.pdf,17,2.2,9.962599754333496,NimbusRomNo9L-Regu,False,246.69796752929688,638.54638671875,0.0,3,H3
sample_7.pdf,17,0.9,9.962599754333496,NimbusRomNo9L-Regu,False,281.5471496582031,638.54638671875,0.0,3,H3
sample_7.pdf,17,1.3,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239685058594,638.54638671875,0.0,3,H3
sample_7.pdf,17,9.1,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731506347656,638.54638671875,0.0,3,H3
sample_7.pdf,17,8.1,9.962599754333496,NimbusRomNo9L-Regu,False,357.7499694824219,638.54638671875,0.0,3,H3
sample_7.pdf,17,34.1,9.962599754333496,NimbusRomNo9L-Regu,False,390.11846923828125,638.54638671875,0.0,4,H3
sample_7.pdf,17,22.8,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,638.54638671875,0.0,4,H3
sample_7.pdf,17,1.6,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,649.50537109375,0.0,3,H3
sample_7.pdf,17,0.8,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,649.50537109375,0.0,3,H3
sample_7.pdf,17,1.4,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,649.50537109375,0.0,3,H3
sample_7.pdf,17,3.4,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,649.50537109375,0.0,3,H3
sample_7.pdf,17,43.7,9.962599754333496,NimbusRomNo9L-Regu,False,332.091796875,649.50537109375,0.0,4,H3
sample_7.pdf,17,18.6,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,649.50537109375,0.0,4,H3
sample_7.pdf,17,51.1,9.962599754333496,NimbusRomNo9L-Regu,False,390.118408203125,649.50537109375,0.0,4,H3
sample_7.pdf,17,12.9,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,649.50537109375,0.0,4,H3
sample_7.pdf,17,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,660.4644165039062,0.0,3,H3
sample_7.pdf,17,0.4,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,660.4644165039062,0.0,3,H3
sample_7.pdf,17,0.7,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,660.4644165039062,0.0,3,H3
sample_7.pdf,17,1.4,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,660.4644165039062,0.0,3,H3
sample_7.pdf,17,2.3,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,660.4644165039062,0.0,3,H3
sample_7.pdf,17,3.6,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,660.4644165039062,0.0,3,H3
sample_7.pdf,17,12.8,9.962599754333496,NimbusRomNo9L-Regu,False,392.60906982421875,660.4644165039062,0.0,4,H3
sample_7.pdf,17,9.0,9.962599754333496,NimbusRomNo9L-Regu,False,418.2579650878906,660.4644165039062,0.0,3,H3
sample_7.pdf,17,3.4,9.962599754333496,NimbusRomNo9L-Regu,False,226.02032470703125,671.4234008789062,0.0,3,H3
sample_7.pdf,17,4.0,9.962599754333496,NimbusRomNo9L-Regu,False,246.69796752929688,671.4234008789062,0.0,3,H3
sample_7.pdf,17,6.1,9.962599754333496,NimbusRomNo9L-Regu,False,281.5471496582031,671.4234008789062,0.0,3,H3
sample_7.pdf,17,7.3,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239685058594,671.4234008789062,0.0,3,H3
sample_7.pdf,17,50.2,9.962599754333496,NimbusRomNo9L-Regu,False,334.5824890136719,671.4234008789062,0.0,4,H3
sample_7.pdf,17,8.4,9.962599754333496,NimbusRomNo9L-Regu,False,360.240966796875,671.4234008789062,0.0,3,H3
sample_7.pdf,17,73.1,9.962599754333496,NimbusRomNo9L-Regu,False,390.10882568359375,671.4234008789062,0.0,4,H3
sample_7.pdf,17,23.9,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,671.4234008789062,0.0,4,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,226.0203094482422,682.3823852539062,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,246.6979522705078,682.3823852539062,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,281.547119140625,682.3823852539062,0.0,3,H3
sample_7.pdf,17,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,302.22393798828125,682.3823852539062,0.0,3,H3
sample_7.pdf,17,3.2,9.962599754333496,NimbusRomNo9L-Regu,False,337.0731201171875,682.3823852539062,0.0,3,H3
sample_7.pdf,17,2.5,9.962599754333496,NimbusRomNo9L-Regu,False,357.74993896484375,682.3823852539062,0.0,3,H3
sample_7.pdf,17,2.6,9.962599754333496,NimbusRomNo9L-Regu,False,395.0997314453125,682.3823852539062,0.0,3,H3
sample_7.pdf,17,2.8,9.962599754333496,NimbusRomNo9L-Regu,False,415.7679443359375,682.3823852539062,0.0,3,H3
sample_7.pdf,17,avg,9.962599754333496,NimbusRomNo9L-Regu,False,176.3070068359375,698.3424682617188,0.0,3,H3
sample_7.pdf,17,0.73,9.962599754333496,NimbusRomNo9L-Regu,False,221.03907775878906,698.3424682617188,0.0,4,H3
sample_7.pdf,17,0.89,9.962599754333496,NimbusRomNo9L-Regu,False,246.69801330566406,698.3424682617188,0.0,4,H3
sample_7.pdf,17,1.12,9.962599754333496,NimbusRomNo9L-Regu,False,276.56585693359375,698.3424682617188,0.0,4,H3
sample_7.pdf,17,1.62,9.962599754333496,NimbusRomNo9L-Regu,False,302.2239990234375,698.3424682617188,0.0,4,H3
sample_7.pdf,17,6.34,9.962599754333496,NimbusRomNo9L-Regu,False,332.09185791015625,698.3424682617188,0.0,4,H3
sample_7.pdf,17,3.32,9.962599754333496,NimbusRomNo9L-Regu,False,357.75,698.3424682617188,0.0,4,H3
sample_7.pdf,17,11.21,9.962599754333496,NimbusRomNo9L-Regu,False,387.6278381347656,698.3424682617188,0.0,5,H3
sample_7.pdf,17,6.65,9.962599754333496,NimbusRomNo9L-Regu,False,418.2580261230469,698.3424682617188,0.0,4,H3
sample_7.pdf,18,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,18,PPENDIX,9.56410026550293,NimbusRomNo9L-Regu,False,117.52799987792969,84.57066345214844,1.0,7,H3
sample_7.pdf,18,I A,11.9552001953125,NimbusRomNo9L-Regu,False,206.426025390625,82.75727844238281,0.6666666666666666,3,H3
sample_7.pdf,18,TTENTION,9.56410026550293,NimbusRomNo9L-Regu,False,221.44203186035156,84.57066345214844,1.0,8,H3
sample_7.pdf,18,ISUALIZATION,9.56410026550293,NimbusRomNo9L-Regu,False,285.0540466308594,84.57066345214844,1.0,12,H3
sample_7.pdf,18,We present a visualization of the attention distributions on bAbI tasks for a couple of examples. The visualization,8.925959587097168,NimbusRomNo9L-Regu,False,107.5790023803711,106.8486328125,0.034782608695652174,115,P
sample_7.pdf,18,of attention weights is over different time steps based on different heads over all the facts in the story and a,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,116.51329803466797,0.0,112,P
sample_7.pdf,18,question. Different color bars on the left side indicate attention weights based on different heads (4 heads in total).,8.912439346313477,NimbusRomNo9L-Regu,False,108.0,126.38488006591797,0.008403361344537815,119,P
sample_7.pdf,18,An example from tasks 1,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,145.99066162109375,0.043478260869565216,23,P
sample_7.pdf,18,(requiring one supportive fact to solve),7.970099925994873,NimbusMonL-Bold,True,236.8769989013672,145.99066162109375,0.0,40,P
sample_7.pdf,18,Story,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,161.9306640625,0.2,5,P
sample_7.pdf,18,John travelled to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,170.07748413085938,0.03333333333333333,30,P
sample_7.pdf,18,Mary journeyed to the bathroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,178.04745483398438,0.03225806451612903,31,P
sample_7.pdf,18,Daniel went back to the bathroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,186.01742553710938,0.030303030303030304,33,P
sample_7.pdf,18,John moved to the bedroom,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,193.98739624023438,0.04,25,P
sample_7.pdf,18,Question,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,209.75152587890625,0.125,8,P
sample_7.pdf,18,Where is Mary?,7.970099925994873,NimbusMonL-Regu,False,236.87698364257812,217.89834594726562,0.14285714285714285,14,P
sample_7.pdf,18,Model’s output,7.970099925994873,NimbusMonL-Bold,True,113.97798156738281,225.69146728515625,0.07142857142857142,14,P
sample_7.pdf,18,bathroom,7.970099925994873,NimbusMonL-Regu,False,236.87696838378906,233.83828735351562,0.0,8,P
sample_7.pdf,18,(a) Step 1,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,328.3509826660156,0.1,10,P
sample_7.pdf,18,(b) Step 2,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,402.8879699707031,0.1,10,P
sample_7.pdf,18,(c) Step 3,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,477.42498779296875,0.1,10,P
sample_7.pdf,18,(d) Step 4,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,551.9609375,0.1,10,P
sample_7.pdf,18,"Figure 5: Visualization of the attention distributions, when encoding the question:",9.90765380859375,NimbusRomNo9L-Regu,False,108.0,571.8701782226562,0.024096385542168676,83,H3
sample_7.pdf,18,“Where is Mary?”,9.90765380859375,NimbusRomNo9L-ReguItal,False,425.76947021484375,571.6947021484375,0.125,16,H3
sample_7.pdf,19,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,19,An example from tasks 2,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,181.51666259765625,0.043478260869565216,23,P
sample_7.pdf,19,(requiring two supportive facts to solve),7.970099925994873,NimbusMonL-Bold,True,236.8769989013672,181.51666259765625,0.0,41,P
sample_7.pdf,19,Story,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,197.4566650390625,0.2,5,P
sample_7.pdf,19,Sandra journeyed to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,205.60348510742188,0.03125,32,P
sample_7.pdf,19,Mary went to the bathroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,213.57345581054688,0.038461538461538464,26,P
sample_7.pdf,19,Mary took the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,221.54342651367188,0.038461538461538464,26,P
sample_7.pdf,19,Mary dropped the apple.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,229.51339721679688,0.043478260869565216,23,P
sample_7.pdf,19,Question,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,245.27752685546875,0.125,8,P
sample_7.pdf,19,Where is the apple?,7.970099925994873,NimbusMonL-Regu,False,236.87698364257812,253.42434692382812,0.05263157894736842,19,P
sample_7.pdf,19,Model’s output,7.970099925994873,NimbusMonL-Bold,True,113.97798156738281,261.21746826171875,0.07142857142857142,14,P
sample_7.pdf,19,bathroom,7.970099925994873,NimbusMonL-Regu,False,236.87696838378906,269.3642883300781,0.0,8,P
sample_7.pdf,19,(a) Step 1,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,363.8769836425781,0.1,10,P
sample_7.pdf,19,(b) Step 2,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,438.4139709472656,0.1,10,P
sample_7.pdf,19,(c) Step 3,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,512.950927734375,0.1,10,P
sample_7.pdf,19,(d) Step 4,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,587.4879150390625,0.1,10,P
sample_7.pdf,19,"Figure 6: Visualization of the attention distributions, when encoding the question:",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,607.279296875,0.024096385542168676,83,H3
sample_7.pdf,19,“Where is the,10.061732292175293,NimbusRomNo9L-ReguItal,False,443.4530334472656,607.10107421875,0.07692307692307693,13,H3
sample_7.pdf,19,apple?”,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0,618.1370239257812,0.0,7,H3
sample_7.pdf,20,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,20,An example from tasks 2,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,99.0556640625,0.043478260869565216,23,P
sample_7.pdf,20,(requiring two supportive facts to solve),7.970099925994873,NimbusMonL-Bold,True,236.8769989013672,99.0556640625,0.0,41,P
sample_7.pdf,20,Story,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,114.99566650390625,0.2,5,P
sample_7.pdf,20,John went to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,123.14249420166016,0.04,25,P
sample_7.pdf,20,John went back to the bathroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,131.11245727539062,0.03225806451612903,31,P
sample_7.pdf,20,John grabbed the milk there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,139.08346557617188,0.03571428571428571,28,P
sample_7.pdf,20,Sandra went back to the office.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,147.05343627929688,0.03225806451612903,31,P
sample_7.pdf,20,Sandra journeyed to the kitchen.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,155.02340698242188,0.03125,32,P
sample_7.pdf,20,Sandra got the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,162.99337768554688,0.037037037037037035,27,P
sample_7.pdf,20,Sandra dropped the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,170.96334838867188,0.03225806451612903,31,P
sample_7.pdf,20,John dropped the milk.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,178.93331909179688,0.045454545454545456,22,P
sample_7.pdf,20,Question,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,194.69647216796875,0.125,8,P
sample_7.pdf,20,Where is the milk?,7.970099925994873,NimbusMonL-Regu,False,236.87698364257812,202.84329223632812,0.05555555555555555,18,P
sample_7.pdf,20,Model’s output,7.970099925994873,NimbusMonL-Bold,True,113.97798156738281,210.637451171875,0.07142857142857142,14,P
sample_7.pdf,20,bathroom,7.970099925994873,NimbusMonL-Regu,False,236.87696838378906,218.78427124023438,0.0,8,P
sample_7.pdf,20,(a) Step 1,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,349.2969665527344,0.1,10,P
sample_7.pdf,20,(b) Step 2,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,459.833984375,0.1,10,P
sample_7.pdf,20,(c) Step 3,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,570.3709716796875,0.1,10,P
sample_7.pdf,20,(d) Step 4,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,680.906982421875,0.1,10,P
sample_7.pdf,20,"Figure 7: Visualization of the attention distributions, when encoding the question:",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,700.8504028320312,0.024096385542168676,83,H3
sample_7.pdf,20,“Where is the milk?”,9.862470626831055,NimbusRomNo9L-ReguItal,False,418.5722351074219,700.6757202148438,0.05,20,H3
sample_7.pdf,21,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,21,An example from tasks 3,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,221.4986572265625,0.043478260869565216,23,P
sample_7.pdf,21,(requiring three supportive facts to solve),7.970099925994873,NimbusMonL-Bold,True,236.8769989013672,221.4986572265625,0.0,43,P
sample_7.pdf,21,Story,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,237.43865966796875,0.2,5,P
sample_7.pdf,21,Mary got the milk.,7.970099925994873,NimbusMonL-Regu,False,113.97799682617188,245.58651733398438,0.05555555555555555,18,P
sample_7.pdf,21,John moved to the bedroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,253.55648803710938,0.038461538461538464,26,P
sample_7.pdf,21,Daniel journeyed to the office.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,261.5264587402344,0.03225806451612903,31,P
sample_7.pdf,21,John grabbed the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,269.4964294433594,0.034482758620689655,29,P
sample_7.pdf,21,John got the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,277.4664306640625,0.045454545454545456,22,P
sample_7.pdf,21,John journeyed to the garden.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,285.4364318847656,0.034482758620689655,29,P
sample_7.pdf,21,Mary left the milk.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,293.40643310546875,0.05263157894736842,19,P
sample_7.pdf,21,John left the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,301.3764343261719,0.043478260869565216,23,P
sample_7.pdf,21,Daniel moved to the garden.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,309.346435546875,0.037037037037037035,27,P
sample_7.pdf,21,Daniel grabbed the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,317.31744384765625,0.03571428571428571,28,P
sample_7.pdf,21,Mary moved to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,325.2874450683594,0.038461538461538464,26,P
sample_7.pdf,21,Mary went to the kitchen.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,333.2574462890625,0.04,25,P
sample_7.pdf,21,John put down the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,341.2274475097656,0.03333333333333333,30,P
sample_7.pdf,21,John picked up the apple.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,349.19744873046875,0.04,25,P
sample_7.pdf,21,Sandra moved to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,357.1674499511719,0.03571428571428571,28,P
sample_7.pdf,21,Daniel left the football there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,365.137451171875,0.03225806451612903,31,P
sample_7.pdf,21,Daniel took the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,373.1074523925781,0.04,25,P
sample_7.pdf,21,John travelled to the kitchen.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,381.07745361328125,0.03333333333333333,30,P
sample_7.pdf,21,Daniel dropped the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,389.0484619140625,0.03571428571428571,28,P
sample_7.pdf,21,John dropped the apple.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,397.0184631347656,0.043478260869565216,23,P
sample_7.pdf,21,John grabbed the apple.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,404.98846435546875,0.043478260869565216,23,P
sample_7.pdf,21,John went to the office.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,412.9584655761719,0.041666666666666664,24,P
sample_7.pdf,21,Sandra went back to the bedroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,420.928466796875,0.03125,32,P
sample_7.pdf,21,Sandra took the milk.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,428.8984680175781,0.047619047619047616,21,P
sample_7.pdf,21,John journeyed to the bathroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,436.86846923828125,0.03225806451612903,31,P
sample_7.pdf,21,John travelled to the office.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,444.8384704589844,0.034482758620689655,29,P
sample_7.pdf,21,Sandra left the milk.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,452.8084716796875,0.047619047619047616,21,P
sample_7.pdf,21,Mary went to the bedroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,460.77947998046875,0.04,25,P
sample_7.pdf,21,Mary moved to the office.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,468.7494812011719,0.04,25,P
sample_7.pdf,21,John travelled to the hallway.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,476.719482421875,0.03333333333333333,30,P
sample_7.pdf,21,Sandra moved to the garden.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,484.6894836425781,0.037037037037037035,27,P
sample_7.pdf,21,Mary moved to the kitchen.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,492.65948486328125,0.038461538461538464,26,P
sample_7.pdf,21,Daniel took the football.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,500.6294860839844,0.04,25,P
sample_7.pdf,21,Mary journeyed to the bedroom.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,508.5995178222656,0.03333333333333333,30,P
sample_7.pdf,21,Mary grabbed the milk there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,516.5695190429688,0.03571428571428571,28,P
sample_7.pdf,21,Mary discarded the milk.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,524.54052734375,0.041666666666666664,24,P
sample_7.pdf,21,John went to the garden.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,532.5105590820312,0.041666666666666664,24,P
sample_7.pdf,21,John discarded the apple there.,7.970099925994873,NimbusMonL-Regu,False,236.8769989013672,540.4805297851562,0.03225806451612903,31,P
sample_7.pdf,21,Question,7.970099925994873,NimbusMonL-Bold,True,113.97799682617188,556.24365234375,0.125,8,P
sample_7.pdf,21,Where was the apple before the bathroom?,7.970099925994873,NimbusMonL-Regu,False,236.87698364257812,564.3905639648438,0.025,40,P
sample_7.pdf,21,Model’s output,7.970099925994873,NimbusMonL-Bold,True,113.97798156738281,572.1836547851562,0.07142857142857142,14,P
sample_7.pdf,21,office,7.970099925994873,NimbusMonL-Regu,False,236.87696838378906,580.3305053710938,0.0,6,P
sample_7.pdf,22,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,22,(e) Step 1,8.966400146484375,NimbusRomNo9L-Regu,False,288.8699951171875,395.5749816894531,0.1,10,P
sample_7.pdf,22,(f) Step 2,8.966400146484375,NimbusRomNo9L-Regu,False,289.3680114746094,714.9109497070312,0.1,10,P
sample_7.pdf,23,Published as a conference paper at ICLR 2019,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,27.81348991394043,0.11363636363636363,44,H3
sample_7.pdf,23,(g) Step 3,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,390.4129943847656,0.1,10,P
sample_7.pdf,23,(h) Step 4,8.966400146484375,NimbusRomNo9L-Regu,False,288.6189880371094,709.7489624023438,0.1,10,P
sample_7.pdf,23,"Figure 7: Visualization of the attention distributions, when encoding the question:",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,729.541259765625,0.024096385542168676,83,H3
sample_7.pdf,23,“Where was the,10.061732292175293,NimbusRomNo9L-ReguItal,False,436.7970275878906,729.363037109375,0.07142857142857142,14,H3
sample_7.pdf,23,apple before the bathroom?”,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0,740.3989868164062,0.0,27,H3
sample_8.pdf,1,XLNet: Generalized Autoregressive Pretraining,17.21540069580078,NimbusRomNo9L-Medi,False,130.05999755859375,99.8338394165039,0.13333333333333333,45,TITLE
sample_8.pdf,1,for Language Understanding,17.21540069580078,NimbusRomNo9L-Medi,False,199.5659942626953,119.75882720947266,0.07692307692307693,26,TITLE
sample_8.pdf,1,Zhilin Yang,9.962599754333496,NimbusRomNo9L-Medi,False,170.17799377441406,181.08648681640625,0.18181818181818182,11,H3
sample_8.pdf,1,", Zihang Dai",9.962599754333496,NimbusRomNo9L-Medi,False,229.09999084472656,181.08648681640625,0.16666666666666666,12,H3
sample_8.pdf,1,", Yiming Yang",9.962599754333496,NimbusRomNo9L-Medi,False,294.49298095703125,181.08648681640625,0.15384615384615385,13,H3
sample_8.pdf,1,", Jaime Carbonell",9.962599754333496,NimbusRomNo9L-Medi,False,359.4649658203125,181.08648681640625,0.11764705882352941,17,H3
sample_8.pdf,1,Ruslan Salakhutdinov,9.962599754333496,NimbusRomNo9L-Medi,False,228.39596557617188,192.468505859375,0.1,20,H3
sample_8.pdf,1,", Quoc V. Le",9.962599754333496,NimbusRomNo9L-Medi,False,327.1699523925781,192.468505859375,0.25,12,H3
sample_8.pdf,1,"Carnegie Mellon University,",9.962599754333496,NimbusRomNo9L-Regu,False,202.4939422607422,203.9414825439453,0.1111111111111111,27,H3
sample_8.pdf,1,Google AI Brain Team,9.962599754333496,NimbusRomNo9L-Regu,False,322.5389404296875,203.9414825439453,0.25,20,H3
sample_8.pdf,1,"{zhiliny,dzihang,yiming,jgc,rsalakhu}@cs.cmu.edu, qvl@google.com",8.966400146484375,SFTT0900,False,154.28094482421875,215.82920837402344,0.0,64,P
sample_8.pdf,1,Abstract,11.9552001953125,NimbusRomNo9L-Medi,False,283.7579345703125,254.41217041015625,0.125,8,H3
sample_8.pdf,1,"With the capability of modeling bidirectional contexts, denoising autoencoding",10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,278.67730712890625,0.01282051282051282,78,H3
sample_8.pdf,1,based pretraining like BERT achieves better performance than pretraining ap-,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,289.5863037109375,0.05263157894736842,76,H3
sample_8.pdf,1,"proaches based on autoregressive language modeling. However, relying on corrupt-",9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,300.64642333984375,0.0125,80,H3
sample_8.pdf,1,"ing the input with masks, BERT neglects dependency between the masked positions",9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,311.555419921875,0.05063291139240506,79,H3
sample_8.pdf,1,"and suffers from a pretrain-ﬁnetune discrepancy. In light of these pros and cons, we",9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,322.46441650390625,0.011904761904761904,84,H3
sample_8.pdf,1,"propose XLNet, a generalized autoregressive pretraining method that (1) enables",10.007330894470215,NimbusRomNo9L-Regu,False,143.86599731445312,333.2635498046875,0.0379746835443038,79,H3
sample_8.pdf,1,learning bidirectional contexts by maximizing the expected likelihood over all,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,344.13128662109375,0.0,78,H3
sample_8.pdf,1,permutations of the factorization order and (2) overcomes the limitations of BERT,9.90765380859375,NimbusRomNo9L-Regu,False,143.86599731445312,355.1571350097656,0.04938271604938271,81,H3
sample_8.pdf,1,"thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas",10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,365.9502868652344,0.05194805194805195,77,H3
sample_8.pdf,1,"from Transformer-XL, the state-of-the-art autoregressive model, into pretraining.",10.017244338989258,NimbusRomNo9L-Regu,False,143.86599731445312,376.89300537109375,0.037037037037037035,81,H3
sample_8.pdf,1,"Empirically, under comparable experiment settings, XLNet outperforms BERT on",9.92266845703125,NimbusRomNo9L-Regu,False,143.86599731445312,387.8737487792969,0.10526315789473684,76,H3
sample_8.pdf,1,"20 tasks, often by a large margin, including question answering, natural language",9.977532386779785,NimbusRomNo9L-Regu,False,143.86599731445312,398.74114990234375,0.0,81,H3
sample_8.pdf,1,"inference, sentiment analysis, and document ranking.",9.962599754333496,NimbusRomNo9L-Regu,False,143.86599731445312,409.6614685058594,0.0,52,H3
sample_8.pdf,1,Introduction,11.9552001953125,NimbusRomNo9L-Medi,False,125.93276977539062,440.2031555175781,0.08333333333333333,12,H3
sample_8.pdf,1,Unsupervised representation learning has been highly successful in the domain of natural language,9.992443084716797,NimbusRomNo9L-Regu,False,108.0,464.59283447265625,0.010309278350515464,97,H3
sample_8.pdf,1,processing [,9.95761775970459,NimbusRomNo9L-Regu,False,108.0,475.5282287597656,0.0,12,H3
sample_8.pdf,1,"]. Typically, these methods ﬁrst pretrain neural networks on large-scale",9.95761775970459,NimbusRomNo9L-Regu,False,221.15499877929688,475.5282287597656,0.013888888888888888,72,H3
sample_8.pdf,1,"unlabeled text corpora, and then ﬁnetune the models or representations on downstream tasks. Under",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,486.4561767578125,0.010309278350515464,97,H3
sample_8.pdf,1,"this shared high-level idea, different unsupervised pretraining objectives have been explored in",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,497.2673034667969,0.0,96,H3
sample_8.pdf,1,"literature. Among them, autoregressive (AR) language modeling and autoencoding (AE) have been",9.977532386779785,NimbusRomNo9L-Regu,False,108.0,508.2401428222656,0.053763440860215055,93,H3
sample_8.pdf,1,the two most successful pretraining objectives.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,519.1614990234375,0.0,47,H3
sample_8.pdf,1,AR language modeling seeks to estimate the probability distribution of a text corpus with an au-,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,535.4742431640625,0.020833333333333332,96,H3
sample_8.pdf,1,toregressive model [,10.007330894470215,NimbusRomNo9L-Regu,False,108.0,546.424560546875,0.0,20,H3
sample_8.pdf,1,"]. Speciﬁcally, given a text sequence",10.007330894470215,NimbusRomNo9L-Regu,False,224.37600708007812,546.424560546875,0.02702702702702703,37,H3
sample_8.pdf,1,= (,9.962599754333496,CMR10,False,379.30029296875,546.2279663085938,0.0,3,H3
sample_8.pdf,1,", x",9.962599754333496,CMMI10,False,422.67431640625,546.2279663085938,0.0,3,H3
sample_8.pdf,1,", AR language",10.007330894470215,NimbusRomNo9L-Regu,False,446.2640075683594,546.424560546875,0.15384615384615385,13,H3
sample_8.pdf,1,modeling factorizes the likelihood into a forward product,10.037040710449219,NimbusRomNo9L-Regu,False,108.0,559.6640014648438,0.0,57,H3
sample_8.pdf,1,) =,9.962599754333496,CMR10,False,356.5459899902344,559.4899291992188,0.0,3,H3
sample_8.pdf,1,or a backward,10.037040710449219,NimbusRomNo9L-Regu,False,444.4154357910156,559.6640014648438,0.0,13,H3
sample_8.pdf,1,one,9.927669525146484,NimbusRomNo9L-Regu,False,108.0,573.2349853515625,0.0,3,H3
sample_8.pdf,1,) =,9.962599754333496,CMR10,False,139.7050018310547,572.9779663085938,0.0,3,H3
sample_8.pdf,1,. A parametric model (e.g. a neural network) is trained to model each,9.927669525146484,NimbusRomNo9L-Regu,False,229.3800048828125,573.2349853515625,0.014492753623188406,69,H3
sample_8.pdf,1,conditional distribution. Since an AR language model is only trained to encode a uni-directional con-,9.882577896118164,NimbusRomNo9L-Regu,False,108.0,584.1781616210938,0.0297029702970297,101,H3
sample_8.pdf,1,"text (either forward or backward), it is not effective at modeling deep bidirectional contexts. On the",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,595.0264892578125,0.00980392156862745,102,H3
sample_8.pdf,1,"contrary, downstream language understanding tasks often require bidirectional context information.",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,605.9165649414062,0.0,98,H3
sample_8.pdf,1,This results in a gap between AR language modeling and effective pretraining.,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,616.844482421875,0.03896103896103896,77,H3
sample_8.pdf,1,"In comparison, AE based pretraining does not perform explicit density estimation but instead aims to",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,633.2979736328125,0.03,100,H3
sample_8.pdf,1,reconstruct the original data from corrupted input. A notable example is BERT [,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,644.1803588867188,0.06329113924050633,79,H3
sample_8.pdf,1,"], which has been",9.9126615524292,NimbusRomNo9L-Regu,False,434.9330139160156,644.1803588867188,0.0,17,H3
sample_8.pdf,1,"the state-of-the-art pretraining approach. Given the input token sequence, a certain portion of tokens",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,655.0855712890625,0.00980392156862745,102,H3
sample_8.pdf,1,are replaced by a special symbol,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,666.036376953125,0.0,32,H3
sample_8.pdf,1,[MASK],9.962599754333496,SFTT1000,False,234.69898986816406,666.20849609375,0.6666666666666666,6,H3
sample_8.pdf,1,", and the model is trained to recover the original tokens from",9.862470626831055,NimbusRomNo9L-Regu,False,268.41900634765625,666.036376953125,0.0,62,H3
sample_8.pdf,1,"the corrupted version. Since density estimation is not part of the objective, BERT is allowed to utilize",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,676.9453735351562,0.04807692307692308,104,H3
sample_8.pdf,1,Equal contribution. Order determined by swapping the one in [9].,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,694.6599731445312,0.03125,64,P
sample_8.pdf,1,Pretrained models and code are available at,8.966400146484375,NimbusRomNo9L-Regu,False,124.13899993896484,705.5109252929688,0.023255813953488372,43,P
sample_8.pdf,1,https://github.com/zihangdai/xlnet,8.966400146484375,SFTT0900,False,279.6073913574219,705.7341918945312,0.0,34,P
sample_8.pdf,1,"33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.",8.966400146484375,NimbusRomNo9L-Regu,False,107.99998474121094,733.0769653320312,0.12087912087912088,91,P
sample_8.pdf,1,arXiv:1906.08237v2  [cs.CL]  2 Jan 2020,20.0,Times-Roman,False,10.940000534057617,221.70001220703125,0.10256410256410256,39,TITLE
sample_8.pdf,2,"bidirectional contexts for reconstruction. As an immediate beneﬁt, this closes the aforementioned",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,74.33230590820312,0.010309278350515464,97,H3
sample_8.pdf,2,"bidirectional information gap in AR language modeling, leading to improved performance. However,",9.882577896118164,NimbusRomNo9L-Regu,False,108.0,85.37716674804688,0.03125,96,H3
sample_8.pdf,2,the artiﬁcial symbols like,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,96.15029907226562,0.0,26,H3
sample_8.pdf,2,[MASK],9.962599754333496,SFTT1000,False,212.58578491210938,96.47350311279297,0.6666666666666666,6,H3
sample_8.pdf,2,used by BERT during pretraining are absent from real data at,10.061732292175293,NimbusRomNo9L-Regu,False,247.06617736816406,96.15029907226562,0.06666666666666667,60,H3
sample_8.pdf,2,"ﬁnetuning time, resulting in a pretrain-ﬁnetune discrepancy. Moreover, since the predicted tokens are",9.872529029846191,NimbusRomNo9L-Regu,False,108.0,107.2027816772461,0.009900990099009901,101,H3
sample_8.pdf,2,"masked in the input, BERT is not able to model the joint probability using the product rule as in AR",9.937662124633789,NimbusRomNo9L-Regu,False,108.0,118.06238555908203,0.06,100,H3
sample_8.pdf,2,"language modeling. In other words, BERT assumes the predicted tokens are independent of each",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,128.87728881835938,0.05434782608695652,92,H3
sample_8.pdf,2,"other given the unmasked tokens, which is oversimpliﬁed as high-order, long-range dependency is",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,139.8087615966797,0.0,95,H3
sample_8.pdf,2,prevalent in natural language [9].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,150.7704620361328,0.0,34,H3
sample_8.pdf,2,"Faced with the pros and cons of existing language pretraining objectives, in this work, we propose",10.037040710449219,NimbusRomNo9L-Regu,False,108.0,167.10304260253906,0.01020408163265306,98,H3
sample_8.pdf,2,"XLNet, a generalized autoregressive method that leverages the best of both AR language modeling",10.002370834350586,NimbusRomNo9L-Regu,False,107.64099884033203,178.038330078125,0.05263157894736842,95,H3
sample_8.pdf,2,and AE while avoiding their limitations.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,188.9774932861328,0.05,40,H3
sample_8.pdf,2,"Firstly, instead of using a ﬁxed forward or backward factorization order as in conventional AR mod-",9.862470626831055,NimbusRomNo9L-Regu,False,112.9813003540039,205.44239807128906,0.030303030303030304,99,H3
sample_8.pdf,2,"els, XLNet maximizes the expected log likelihood of a sequence w.r.t.",9.927669525146484,NimbusRomNo9L-Regu,False,117.96299743652344,216.3019561767578,0.043478260869565216,69,H3
sample_8.pdf,2,all possible permutations,9.962599754333496,NimbusRomNo9L-Medi,False,394.65631103515625,216.18450927734375,0.0,25,H3
sample_8.pdf,2,of the factorization order,9.962599754333496,NimbusRomNo9L-Medi,False,117.9630126953125,227.093505859375,0.0,26,H3
sample_8.pdf,2,". Thanks to the permutation operation, the context for each position can",9.862470626831055,NimbusRomNo9L-Regu,False,224.7899932861328,227.26039123535156,0.013888888888888888,72,H3
sample_8.pdf,2,"consist of tokens from both left and right. In expectation, each position learns to utilize contextual",9.89763069152832,NimbusRomNo9L-Regu,False,117.96299743652344,238.14273071289062,0.00980392156862745,102,H3
sample_8.pdf,2,"information from all positions, i.e., capturing bidirectional context.",9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,249.00245666503906,0.0,70,H3
sample_8.pdf,2,"Secondly, as a generalized AR language model, XLNet does not rely on data corruption. Hence,",10.02714729309082,NimbusRomNo9L-Regu,False,112.9813003540039,261.8544921875,0.07608695652173914,92,H3
sample_8.pdf,2,"XLNet does not suffer from the pretrain-ﬁnetune discrepancy that BERT is subject to. Meanwhile,",9.89763069152832,NimbusRomNo9L-Regu,False,117.60399627685547,272.86273193359375,0.08421052631578947,95,H3
sample_8.pdf,2,the autoregressive objective also provides a natural way to use the product rule for factorizing the,9.942654609680176,NimbusRomNo9L-Regu,False,117.96299743652344,283.73760986328125,0.0,100,H3
sample_8.pdf,2,"joint probability of the predicted tokens, eliminating the independence assumption made in BERT.",9.9126615524292,NimbusRomNo9L-Regu,False,117.96299743652344,294.6693420410156,0.041666666666666664,96,H3
sample_8.pdf,2,"In addition to a novel pretraining objective, XLNet improves architectural designs for pretraining.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,311.01947021484375,0.04040404040404041,99,H3
sample_8.pdf,2,"Inspired by the latest advancements in AR language modeling, XLNet integrates the segment",10.061732292175293,NimbusRomNo9L-Regu,False,112.9813003540039,327.3332824707031,0.06741573033707865,89,H3
sample_8.pdf,2,recurrence mechanism and relative encoding scheme of Transformer-XL [,9.862470626831055,NimbusRomNo9L-Regu,False,117.96299743652344,338.3934020996094,0.043478260869565216,69,H3
sample_8.pdf,2,"] into pretraining, which",9.862470626831055,NimbusRomNo9L-Regu,False,409.8599853515625,338.3934020996094,0.0,25,H3
sample_8.pdf,2,empirically improves the performance especially for tasks involving a longer text sequence.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,349.2264709472656,0.0,91,H3
sample_8.pdf,2,Naively applying a Transformer(-XL) architecture to permutation-based language modeling does,9.95761775970459,NimbusRomNo9L-Regu,False,112.9813003540039,362.1322326660156,0.043478260869565216,92,H3
sample_8.pdf,2,"not work because the factorization order is arbitrary and the target is ambiguous. As a solution, we",9.862470626831055,NimbusRomNo9L-Regu,False,117.96299743652344,373.1134033203125,0.01,100,H3
sample_8.pdf,2,propose to reparameterize the Transformer(-XL) network to remove the ambiguity.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,383.94647216796875,0.0379746835443038,79,H3
sample_8.pdf,2,"Empirically, under comparable experiment setting, XLNet consistently outperforms BERT [",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,400.3647766113281,0.09195402298850575,87,H3
sample_8.pdf,2,] on a,9.92266845703125,NimbusRomNo9L-Regu,False,481.4729919433594,400.3647766113281,0.0,6,H3
sample_8.pdf,2,"wide spectrum of problems including GLUE language understanding tasks, reading comprehension",9.96757984161377,NimbusRomNo9L-Regu,False,107.64099884033203,411.2397155761719,0.043478260869565216,92,H3
sample_8.pdf,2,"tasks like SQuAD and RACE, text classiﬁcation tasks such as Yelp and IMDB, and the ClueWeb09-B",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,422.2284240722656,0.1702127659574468,94,H3
sample_8.pdf,2,document ranking task.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,433.0624694824219,0.0,22,H3
sample_8.pdf,2,Related Work,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,449.3595275878906,0.16666666666666666,12,H3
sample_8.pdf,2,The idea of permutation-based AR modeling has been explored in [,9.872529029846191,NimbusRomNo9L-Regu,False,167.2874298095703,449.518798828125,0.046875,64,H3
sample_8.pdf,2,"], but there",9.872529029846191,NimbusRomNo9L-Regu,False,461.4639892578125,449.518798828125,0.0,12,H3
sample_8.pdf,2,"are several key differences. Firstly, previous models aim to improve density estimation by baking",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,460.2843017578125,0.010309278350515464,97,H3
sample_8.pdf,2,an “orderless” inductive bias into the model while XLNet is motivated by enabling AR language,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,471.19329833984375,0.053763440860215055,93,H3
sample_8.pdf,2,"models to learn bidirectional contexts. Technically, to construct a valid target-aware prediction",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,482.102294921875,0.010309278350515464,97,H3
sample_8.pdf,2,"distribution, XLNet incorporates the target position into the hidden state via two-stream attention",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,493.01129150390625,0.030303030303030304,99,H3
sample_8.pdf,2,while previous permutation-based AR models relied on implicit position awareness inherent to their,9.942654609680176,NimbusRomNo9L-Regu,False,107.64099884033203,504.0115966796875,0.02040816326530612,98,H3
sample_8.pdf,2,"MLP architectures. Finally, for both orderless NADE and XLNet, we would like to emphasize that",10.012289047241211,NimbusRomNo9L-Regu,False,108.0,514.8677978515625,0.11702127659574468,94,H3
sample_8.pdf,2,“orderless” does not mean that the input sequence can be randomly permuted but that the model,10.061732292175293,NimbusRomNo9L-Regu,False,106.67500305175781,525.7392578125,0.0,93,H3
sample_8.pdf,2,allows for different factorization orders of the distribution.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,536.7234497070312,0.0,62,H3
sample_8.pdf,2,Another related idea is to perform autoregressive denoising in the context of text generation [,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,553.0362548828125,0.010526315789473684,95,H3
sample_8.pdf,2,which only considers a ﬁxed order though.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,564.0204467773438,0.0,41,H3
sample_8.pdf,2,Proposed Method,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,597.4171752929688,0.13333333333333333,15,H3
sample_8.pdf,2,2.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,626.0335083007812,0.0,3,H3
sample_8.pdf,2,Background,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,626.0335083007812,0.1,10,H3
sample_8.pdf,2,"In this section, we ﬁrst review and compare the conventional AR language modeling and BERT for",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,648.7333984375,0.07446808510638298,94,H3
sample_8.pdf,2,language pretraining. Given a text sequence,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,659.582275390625,0.023255813953488372,43,H3
sample_8.pdf,2,= [,9.962599754333496,CMR10,False,297.789306640625,659.4269409179688,0.0,3,H3
sample_8.pdf,2,", x",9.962599754333496,CMMI10,False,341.49334716796875,659.4269409179688,0.0,3,H3
sample_8.pdf,2,", AR language modeling performs",10.061732292175293,NimbusRomNo9L-Regu,False,363.97601318359375,659.582275390625,0.06451612903225806,31,H3
sample_8.pdf,2,pretraining by maximizing the likelihood under the forward autoregressive factorization:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,670.5664672851562,0.0,88,H3
sample_8.pdf,2,max,9.962599754333496,CMR10,False,142.22999572753906,704.56494140625,0.0,3,H3
sample_8.pdf,2,log,9.962599754333496,CMR10,False,172.3939971923828,704.56494140625,0.0,3,H3
sample_8.pdf,2,) =,9.962599754333496,CMR10,False,206.36399841308594,704.56494140625,0.0,3,H3
sample_8.pdf,2,log,9.962599754333496,CMR10,False,239.57301330566406,704.56494140625,0.0,3,H3
sample_8.pdf,2,) =,9.962599754333496,CMR10,False,300.7809753417969,704.56494140625,0.0,3,H3
sample_8.pdf,2,log,9.962599754333496,CMR10,False,333.9889831542969,704.5648803710938,0.0,3,H3
sample_8.pdf,2,exp,9.962599754333496,CMR10,False,358.6089782714844,697.1929321289062,0.0,3,H3
sample_8.pdf,2,exp (,9.962599754333496,CMR10,False,366.9447326660156,711.39892578125,0.0,5,H3
sample_8.pdf,2,(1),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,704.7954711914062,0.0,3,H3
sample_8.pdf,3,where,9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,74.4834213256836,0.0,5,H3
sample_8.pdf,3,"is a context representation produced by neural models, such as RNNs or Transform-",9.862470626831055,NimbusRomNo9L-Regu,False,177.72447204589844,74.4834213256836,0.04938271604938271,81,H3
sample_8.pdf,3,"ers, and",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,85.39241790771484,0.0,8,H3
sample_8.pdf,3,denotes the embedding of,9.862470626831055,NimbusRomNo9L-Regu,False,158.61346435546875,85.39241790771484,0.0,24,H3
sample_8.pdf,3,". In comparison, BERT is based on denoising auto-encoding.",9.862470626831055,NimbusRomNo9L-Regu,False,269.0010070800781,85.39241790771484,0.08620689655172414,58,H3
sample_8.pdf,3,"Speciﬁcally, for a text sequence",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,96.21792602539062,0.03125,32,H3
sample_8.pdf,3,", BERT ﬁrst constructs a corrupted version",9.972557067871094,NimbusRomNo9L-Regu,False,242.9219970703125,96.21792602539062,0.09523809523809523,42,H3
sample_8.pdf,3,by randomly setting,9.972557067871094,NimbusRomNo9L-Regu,False,421.6883239746094,96.21792602539062,0.0,19,H3
sample_8.pdf,3,a portion (e.g. 15%) of tokens in,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,107.05929565429688,0.0,33,H3
sample_8.pdf,3,to a special symbol,10.061732292175293,NimbusRomNo9L-Regu,False,251.1802978515625,107.05929565429688,0.0,19,H3
sample_8.pdf,3,[MASK],8.966400146484375,SFTT0900,False,332.7585754394531,108.11320495605469,0.6666666666666666,6,P
sample_8.pdf,3,. Let the masked tokens be,10.061732292175293,NimbusRomNo9L-Regu,False,363.7449951171875,107.05929565429688,0.038461538461538464,26,H3
sample_8.pdf,3,. The,10.061732292175293,NimbusRomNo9L-Regu,False,481.7829895019531,107.05929565429688,0.2,5,H3
sample_8.pdf,3,training objective is to reconstruct,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,118.04347229003906,0.0,36,H3
sample_8.pdf,3,from,9.962599754333496,NimbusRomNo9L-Regu,False,252.2772979736328,118.04347229003906,0.0,4,H3
sample_8.pdf,3,max,9.962599754333496,CMR10,False,134.01100158691406,146.6879119873047,0.0,3,H3
sample_8.pdf,3,log,9.962599754333496,CMR10,False,164.1750030517578,146.6879119873047,0.0,3,H3
sample_8.pdf,3,log,9.962599754333496,CMR10,False,257.4626770019531,146.68797302246094,0.0,3,H3
sample_8.pdf,3,) =,9.962599754333496,CMR10,False,311.0909423828125,146.68797302246094,0.0,3,H3
sample_8.pdf,3,log,9.962599754333496,CMR10,False,356.0596618652344,146.6880340576172,0.0,3,H3
sample_8.pdf,3,exp,9.962599754333496,CMR10,False,383.5269775390625,139.31504821777344,0.0,3,H3
sample_8.pdf,3,exp,9.962599754333496,CMR10,False,391.1707458496094,154.0599822998047,0.0,3,H3
sample_8.pdf,3,(2),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,146.91847229003906,0.0,3,H3
sample_8.pdf,3,where,9.867501258850098,NimbusRomNo9L-Regu,False,107.64099884033203,174.9305877685547,0.0,5,H3
sample_8.pdf,3,= 1,9.962599754333496,CMR10,False,145.77267456054688,174.62791442871094,0.0,3,H3
sample_8.pdf,3,indicates,9.867501258850098,NimbusRomNo9L-Regu,False,164.55575561523438,174.9305877685547,0.0,9,H3
sample_8.pdf,3,"is masked, and",9.867501258850098,NimbusRomNo9L-Regu,False,212.9906768798828,174.9305877685547,0.0,14,H3
sample_8.pdf,3,is a Transformer that maps a length-,9.867501258850098,NimbusRomNo9L-Regu,False,288.3757629394531,174.9305877685547,0.027777777777777776,36,H3
sample_8.pdf,3,text sequence,9.867501258850098,NimbusRomNo9L-Regu,False,439.04815673828125,174.9305877685547,0.0,13,H3
sample_8.pdf,3,into a sequence of hidden vectors,10.032095909118652,NimbusRomNo9L-Regu,False,108.0,185.7157440185547,0.0,33,H3
sample_8.pdf,3,) = [,9.962599754333496,CMR10,False,267.8529968261719,185.5378875732422,0.0,5,H3
sample_8.pdf,3,", H",9.962599754333496,CMMI10,False,318.85198974609375,185.5378875732422,0.3333333333333333,3,H3
sample_8.pdf,3,", H",9.962599754333496,CMMI10,False,370.38726806640625,185.5378875732422,0.3333333333333333,3,H3
sample_8.pdf,3,. The pros and cons of,10.032095909118652,NimbusRomNo9L-Regu,False,413.760986328125,185.7157440185547,0.045454545454545456,22,H3
sample_8.pdf,3,the two pretraining objectives are compared in the following aspects:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,196.6774444580078,0.0,69,H3
sample_8.pdf,3,Independence Assumption,9.962599754333496,NimbusRomNo9L-Medi,False,112.9813003540039,212.9744873046875,0.08695652173913043,23,H3
sample_8.pdf,3,: As emphasized by the,10.032095909118652,NimbusRomNo9L-Regu,False,230.60000610351562,213.0127410888672,0.045454545454545456,22,H3
sample_8.pdf,3,"sign in Eq. (2), BERT factorizes the joint",10.032095909118652,NimbusRomNo9L-Regu,False,338.010009765625,213.0127410888672,0.11904761904761904,42,H3
sample_8.pdf,3,conditional probability,10.041984558105469,NimbusRomNo9L-Regu,False,117.96299743652344,223.91429138183594,0.0,23,H3
sample_8.pdf,3,based on an independence assumption that all masked tokens,10.041984558105469,NimbusRomNo9L-Regu,False,246.08445739746094,223.91429138183594,0.0,58,H3
sample_8.pdf,3,"are separately reconstructed. In comparison, the AR language modeling objective",10.051863670349121,NimbusRomNo9L-Regu,False,117.96299743652344,234.8157958984375,0.0379746835443038,79,H3
sample_8.pdf,3,(1),9.962599754333496,NimbusRomNo9L-Regu,False,448.0928649902344,234.8834991455078,0.0,3,H3
sample_8.pdf,3,factorizes,10.051863670349121,NimbusRomNo9L-Regu,False,462.193359375,234.8157958984375,0.0,10,H3
sample_8.pdf,3,using the product rule that holds universally without such an independence assumption.,9.962599754333496,NimbusRomNo9L-Regu,False,141.27944946289062,245.79249572753906,0.0,86,H3
sample_8.pdf,3,Input noise,9.962599754333496,NimbusRomNo9L-Medi,False,112.9813003540039,258.86956787109375,0.09090909090909091,11,H3
sample_8.pdf,3,: The input to BERT contains artiﬁcial symbols like,10.061732292175293,NimbusRomNo9L-Regu,False,167.1510009765625,258.8852844238281,0.09803921568627451,51,H3
sample_8.pdf,3,[MASK],8.966400146484375,SFTT0900,False,388.92333984375,259.939208984375,0.6666666666666666,6,P
sample_8.pdf,3,that never occur in,10.061732292175293,NimbusRomNo9L-Regu,False,420.9591979980469,258.8852844238281,0.0,19,H3
sample_8.pdf,3,"downstream tasks, which creates a pretrain-ﬁnetune discrepancy. Replacing",9.96757984161377,NimbusRomNo9L-Regu,False,117.96299743652344,269.8656921386719,0.0136986301369863,73,H3
sample_8.pdf,3,[MASK],8.966400146484375,SFTT0900,False,419.5730895996094,270.84820556640625,0.6666666666666666,6,P
sample_8.pdf,3,with original,9.96757984161377,NimbusRomNo9L-Regu,False,450.294189453125,269.8656921386719,0.0,13,H3
sample_8.pdf,3,tokens as in [,9.872529029846191,NimbusRomNo9L-Regu,False,117.96299743652344,280.8477783203125,0.0,14,H3
sample_8.pdf,3,] does not solve the problem because original tokens can be only used with a small,9.872529029846191,NimbusRomNo9L-Regu,False,179.87600708007812,280.8477783203125,0.0,82,H3
sample_8.pdf,3,"probability — otherwise Eq. (2) will be trivial to optimize. In comparison, AR language modeling",9.877554893493652,NimbusRomNo9L-Regu,False,117.96299743652344,291.7529602050781,0.041666666666666664,96,H3
sample_8.pdf,3,does not rely on any input corruption and does not suffer from this issue.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,302.59747314453125,0.0,74,H3
sample_8.pdf,3,Context dependency,9.962599754333496,NimbusRomNo9L-Medi,False,112.9813003540039,315.6745300292969,0.05555555555555555,18,H3
sample_8.pdf,3,: The AR representation,10.061732292175293,NimbusRomNo9L-Regu,False,204.97300720214844,315.6903076171875,0.13043478260869565,23,H3
sample_8.pdf,3,is only conditioned on the tokens up,10.061732292175293,NimbusRomNo9L-Regu,False,351.79443359375,315.6903076171875,0.0,36,H3
sample_8.pdf,3,to position,10.061732292175293,NimbusRomNo9L-Regu,False,117.96299743652344,326.59930419921875,0.0,11,H3
sample_8.pdf,3,"(i.e. tokens to the left), while the BERT representation",10.061732292175293,NimbusRomNo9L-Regu,False,168.45249938964844,326.59930419921875,0.07142857142857142,56,H3
sample_8.pdf,3,has access to the,10.061732292175293,NimbusRomNo9L-Regu,False,431.2096862792969,326.59930419921875,0.0,17,H3
sample_8.pdf,3,"contextual information on both sides. As a result, the BERT objective allows the model to be",10.061732292175293,NimbusRomNo9L-Regu,False,117.96299743652344,337.50830078125,0.05434782608695652,92,H3
sample_8.pdf,3,pretrained to better capture bidirectional context.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,348.4924621582031,0.0,51,H3
sample_8.pdf,3,2.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,373.4585266113281,0.0,3,H3
sample_8.pdf,3,Objective: Permutation Language Modeling,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,373.4585266113281,0.1,40,H3
sample_8.pdf,3,"According to the comparison above, AR language modeling and BERT possess their unique advan-",9.997407913208008,NimbusRomNo9L-Regu,False,107.64099884033203,393.7380676269531,0.07608695652173914,92,H3
sample_8.pdf,3,tages over the other. A natural question to ask is whether there exists a pretraining objective that,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,404.5982971191406,0.01,100,H3
sample_8.pdf,3,brings the advantages of both while avoiding their weaknesses.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,415.58245849609375,0.0,62,H3
sample_8.pdf,3,Borrowing ideas from orderless NADE [,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,432.04742431640625,0.13513513513513514,37,H3
sample_8.pdf,3,"], we propose the permutation language modeling objective",9.862470626831055,NimbusRomNo9L-Regu,False,274.7250061035156,432.04742431640625,0.0,57,H3
sample_8.pdf,3,that not only retains the beneﬁts of AR models but also allows models to capture bidirectional,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,442.8052978515625,0.02127659574468085,94,H3
sample_8.pdf,3,"contexts. Speciﬁcally, for a sequence",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,453.7630615234375,0.02702702702702703,37,H3
sample_8.pdf,3,of length,9.997407913208008,NimbusRomNo9L-Regu,False,265.018310546875,453.7630615234375,0.0,9,H3
sample_8.pdf,3,", there are",9.997407913208008,NimbusRomNo9L-Regu,False,313.11199951171875,453.7630615234375,0.0,11,H3
sample_8.pdf,3,different orders to perform a valid,9.997407913208008,NimbusRomNo9L-Regu,False,365.3505859375,453.7630615234375,0.0,35,H3
sample_8.pdf,3,"autoregressive factorization. Intuitively, if model parameters are shared across all factorization orders,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,464.7744140625,0.009433962264150943,106,H3
sample_8.pdf,3,"in expectation, the model will learn to gather information from all positions on both sides.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,475.6074523925781,0.0,92,H3
sample_8.pdf,3,"To formalize the idea, let",9.972557067871094,NimbusRomNo9L-Regu,False,107.69100189208984,491.9889221191406,0.038461538461538464,26,H3
sample_8.pdf,3,be the set of all possible permutations of the length-,9.972557067871094,NimbusRomNo9L-Regu,False,221.9683074951172,491.9889221191406,0.0,54,H3
sample_8.pdf,3,index sequence,9.972557067871094,NimbusRomNo9L-Regu,False,438.99713134765625,491.9889221191406,0.0,14,H3
sample_8.pdf,3,", . . . , T",9.962599754333496,CMMI10,False,125.15800476074219,502.6749267578125,0.09090909090909091,11,H3
sample_8.pdf,3,. We use,9.862470626831055,NimbusRomNo9L-Regu,False,157.27000427246094,502.9814147949219,0.125,8,H3
sample_8.pdf,3,and,9.862470626831055,NimbusRomNo9L-Regu,False,200.1366729736328,502.9814147949219,0.0,3,H3
sample_8.pdf,3,to denote the,9.862470626831055,NimbusRomNo9L-Regu,False,233.1362762451172,502.9814147949219,0.0,13,H3
sample_8.pdf,3,-th element and the ﬁrst,9.862470626831055,NimbusRomNo9L-Regu,False,290.9320068359375,502.9814147949219,0.0,24,H3
sample_8.pdf,3,elements of a permutation,9.862470626831055,NimbusRomNo9L-Regu,False,401.49029541015625,502.9814147949219,0.0,25,H3
sample_8.pdf,3,". Then, our proposed permutation language modeling objective can be expressed as follows:",9.89261531829834,NimbusRomNo9L-Regu,False,137.19631958007812,513.8675537109375,0.011235955056179775,89,H3
sample_8.pdf,3,max,9.962599754333496,CMR10,False,225.0449981689453,542.4579467773438,0.0,3,H3
sample_8.pdf,3,log,9.962599754333496,CMR10,False,305.7060546875,542.4579467773438,0.0,3,H3
sample_8.pdf,3,(3),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840637207031,542.6884765625,0.0,3,H3
sample_8.pdf,3,"Essentially, for a text sequence",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,570.5012817382812,0.03125,32,H3
sample_8.pdf,3,", we sample a factorization order",10.061732292175293,NimbusRomNo9L-Regu,False,242.9550018310547,570.5012817382812,0.0,33,H3
sample_8.pdf,3,at a time and decompose the,10.061732292175293,NimbusRomNo9L-Regu,False,384.8838806152344,570.5012817382812,0.0,27,H3
sample_8.pdf,3,likelihood,9.882577896118164,NimbusRomNo9L-Regu,False,108.0,581.5462036132812,0.0,10,H3
sample_8.pdf,3,according to factorization order. Since the same model parameter,9.882577896118164,NimbusRomNo9L-Regu,False,173.4724578857422,581.5462036132812,0.015625,64,H3
sample_8.pdf,3,is shared across,9.882577896118164,NimbusRomNo9L-Regu,False,439.61346435546875,581.5462036132812,0.0,16,H3
sample_8.pdf,3,"all factorization orders during training, in expectation,",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,592.4513549804688,0.0,57,H3
sample_8.pdf,3,has seen every possible element,9.887598037719727,NimbusRomNo9L-Regu,False,331.7687072753906,592.4513549804688,0.0,31,H3
sample_8.pdf,3,"the sequence, hence being able to capture the bidirectional context. Moreover, as this objective ﬁts",10.017244338989258,NimbusRomNo9L-Regu,False,108.0,603.2620239257812,0.01,100,H3
sample_8.pdf,3,"into the AR framework, it naturally avoids the independence assumption and the pretrain-ﬁnetune",10.056798934936523,NimbusRomNo9L-Regu,False,108.0,614.1410522460938,0.021052631578947368,95,H3
sample_8.pdf,3,discrepancy discussed in Section 2.1.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,625.1214599609375,0.02702702702702703,37,H3
sample_8.pdf,3,Remark on Permutation,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,641.4195556640625,0.09523809523809523,21,H3
sample_8.pdf,3,"The proposed objective only permutes the factorization order, not the",10.061732292175293,NimbusRomNo9L-Regu,False,212.8762664794922,641.4352416992188,0.014492753623188406,69,H3
sample_8.pdf,3,"sequence order. In other words, we keep the original sequence order, use the positional encodings",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,652.34423828125,0.010309278350515464,97,H3
sample_8.pdf,3,"corresponding to the original sequence, and rely on a proper attention mask in Transformers to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,663.2532958984375,0.010638297872340425,94,H3
sample_8.pdf,3,"achieve permutation of the factorization order. Note that this choice is necessary, since the model",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,674.1622314453125,0.010101010101010102,99,H3
sample_8.pdf,3,will only encounter text sequences with the natural order during ﬁnetuning.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,685.146484375,0.0,75,H3
sample_8.pdf,3,"To provide an overall picture, we show an example of predicting the token",10.007330894470215,NimbusRomNo9L-Regu,False,107.69100189208984,701.5015258789062,0.0136986301369863,73,H3
sample_8.pdf,3,given the same input,10.007330894470215,NimbusRomNo9L-Regu,False,417.9860534667969,701.5015258789062,0.0,20,H3
sample_8.pdf,3,sequence,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,712.4444580078125,0.0,8,H3
sample_8.pdf,3,but under different factorization orders in the Appendix A.7 with Figure 4.,9.962599754333496,NimbusRomNo9L-Regu,False,153.05029296875,712.4444580078125,0.04,75,H3
sample_8.pdf,4,2.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,74.31652069091797,0.0,3,H3
sample_8.pdf,4,Architecture: Two-Stream Self-Attention for Target-Aware Representations,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,74.31652069091797,0.1111111111111111,72,H3
sample_8.pdf,4,Sample a factorization order:,5.303199768066406,CMUSerif-Roman,False,402.1644287109375,244.29945373535156,0.034482758620689655,29,P
sample_8.pdf,4,Attention Masks,5.303199768066406,CMUSerif-Roman,False,415.9972229003906,145.52735900878906,0.13333333333333333,15,P
sample_8.pdf,4,e(x,4.6402997970581055,CambriaMath,False,261.4117126464844,248.49560546875,0.0,3,P
sample_8.pdf,4,e(x,4.6402997970581055,CambriaMath,False,295.716796875,248.49560546875,0.0,3,P
sample_8.pdf,4,e(x,4.6402997970581055,CambriaMath,False,330.0218505859375,248.49560546875,0.0,3,P
sample_8.pdf,4,e(x,4.6402997970581055,CambriaMath,False,364.32696533203125,248.49560546875,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,265.38909912109375,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,278.8934326171875,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,299.6942138671875,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,313.1985168457031,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,333.999267578125,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,347.50360107421875,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,368.3043212890625,187.1442108154297,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,381.80865478515625,187.1442108154297,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,265.38909912109375,126.8203353881836,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,278.8934326171875,126.8203353881836,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,299.6942138671875,126.8203353881836,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,313.1985168457031,126.8203353881836,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,333.999267578125,126.48888397216797,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,347.50360107421875,126.48888397216797,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,368.3043212890625,126.8203353881836,0.0,3,P
sample_8.pdf,4,('),3.9773998260498047,CambriaMath,False,381.80865478515625,126.8203353881836,0.0,3,P
sample_8.pdf,4,Content stream:,5.303199768066406,CMUSerif-Roman,False,453.5517883300781,166.7401580810547,0.06666666666666667,15,P
sample_8.pdf,4,can see self,5.303199768066406,CMUSerif-Roman,False,459.5178527832031,173.03770446777344,0.0,12,P
sample_8.pdf,4,Query stream:,5.303199768066406,CMUSerif-Roman,False,456.038330078125,203.1996612548828,0.07692307692307693,13,P
sample_8.pdf,4,cannot see self,5.303199768066406,CMUSerif-Roman,False,455.7068786621094,209.49720764160156,0.0,15,P
sample_8.pdf,4,Masked Two-stream Attention,5.303199768066406,CMUSerif-Bold,True,283.7196960449219,160.10055541992188,0.1111111111111111,27,P
sample_8.pdf,4,Masked Two-stream Attention,5.303199768066406,CMUSerif-Bold,True,283.7196960449219,220.4244384765625,0.1111111111111111,27,P
sample_8.pdf,4,(c),5.303199768066406,CMUSerif-Bold,True,372.98297119140625,262.1871643066406,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,122.89738464355469,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,136.40170288085938,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,157.20245361328125,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,170.706787109375,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,191.5075225830078,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,205.0118865966797,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,225.81259155273438,247.79954528808594,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,239.31692504882812,247.79954528808594,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,122.89741516113281,188.13856506347656,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,136.4017333984375,188.13856506347656,0.0,3,P
sample_8.pdf,4,Attention,5.303199768066406,CMUSerif-Bold,True,169.2930145263672,212.46963500976562,0.1111111111111111,9,P
sample_8.pdf,4,"K, V",5.303199768066406,CMUSerif-Roman,False,187.34471130371094,223.41810607910156,0.5,4,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,122.89741516113281,100.96721649169922,0.0,3,P
sample_8.pdf,4,($),3.9773998260498047,CambriaMath,False,136.4017333984375,100.96721649169922,0.0,3,P
sample_8.pdf,4,Attention,5.303199768066406,CMUSerif-Bold,True,151.32968139648438,125.6297607421875,0.1111111111111111,9,P
sample_8.pdf,4,"K, V",5.303199768066406,CMUSerif-Roman,False,169.38137817382812,136.5782012939453,0.5,4,P
sample_8.pdf,4,(b),5.303199768066406,CMUSerif-Bold,True,177.9525146484375,262.1871643066406,0.0,3,P
sample_8.pdf,4,(a),5.303199768066406,CMUSerif-Bold,True,178.0331268310547,173.027099609375,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,122.89738464355469,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,136.40170288085938,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,157.20245361328125,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,170.706787109375,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,191.5075225830078,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,205.0118865966797,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,225.81259155273438,160.9596710205078,0.0,3,P
sample_8.pdf,4,"(,)",3.9773998260498047,CambriaMath,False,239.31692504882812,160.9596710205078,0.0,3,P
sample_8.pdf,4,"Figure 1: (a): Content stream attention, which is the same as the standard self-attention. (b): Query",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,279.1673889160156,0.0297029702970297,101,H3
sample_8.pdf,4,"stream attention, which does not have access information about the content",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,290.1483459472656,0.0,74,H3
sample_8.pdf,4,. (c): Overview of the,9.887598037719727,NimbusRomNo9L-Regu,False,418.3349914550781,290.1483459472656,0.045454545454545456,22,H3
sample_8.pdf,4,permutation language modeling training with two-stream attention.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,301.0004577636719,0.0,65,H3
sample_8.pdf,4,"While the permutation language modeling objective has desired properties, naive implementation with",9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,314.8114013671875,0.010101010101010102,99,H3
sample_8.pdf,4,"standard Transformer parameterization may not work. To see the problem, assume we parameterize",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,325.65203857421875,0.02127659574468085,94,H3
sample_8.pdf,4,the next-token distribution,10.051863670349121,NimbusRomNo9L-Regu,False,108.0,336.48675537109375,0.0,27,H3
sample_8.pdf,4,"using the standard Softmax formulation, i.e.,",10.051863670349121,NimbusRomNo9L-Regu,False,278.2974548339844,336.48675537109375,0.022222222222222223,45,H3
sample_8.pdf,4,) =,9.962599754333496,CMR10,False,143.63096618652344,353.3639221191406,0.0,3,H3
sample_8.pdf,4,exp,6.973800182342529,CMR7,False,174.13597106933594,349.3737487792969,0.0,3,P
sample_8.pdf,4,exp,6.973800182342529,CMR7,False,178.86573791503906,360.53173828125,0.0,3,P
sample_8.pdf,4,where,10.061732292175293,NimbusRomNo9L-Regu,False,260.45159912109375,353.519287109375,0.0,5,H3
sample_8.pdf,4,denotes the hidden representation of,10.061732292175293,NimbusRomNo9L-Regu,False,328.7984619140625,353.519287109375,0.0,36,H3
sample_8.pdf,4,produced by the shared Transformer network after proper masking. Now notice that the representation,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,369.4914245605469,0.020202020202020204,99,H3
sample_8.pdf,4,"does not depend on which position it will predict, i.e., the value of",10.041984558105469,NimbusRomNo9L-Regu,False,145.262451171875,380.2642822265625,0.0,69,H3
sample_8.pdf,4,". Consequently, the",10.041984558105469,NimbusRomNo9L-Regu,False,425.94500732421875,380.2642822265625,0.05263157894736842,19,H3
sample_8.pdf,4,"same distribution is predicted regardless of the target position, which is not able to learn useful",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,391.1582946777344,0.0,99,H3
sample_8.pdf,4,"representations (see Appendix A.1 for a concrete example). To avoid this problem, we propose to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,402.0672912597656,0.031578947368421054,95,H3
sample_8.pdf,4,re-parameterize the next-token distribution to be target position aware:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,413.05145263671875,0.0,72,H3
sample_8.pdf,4,) =,9.962599754333496,CMR10,False,272.1570129394531,437.7479248046875,0.0,3,H3
sample_8.pdf,4,exp,9.962599754333496,CMR10,False,301.1600036621094,430.37493896484375,0.0,3,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,379.8130187988281,430.37493896484375,0.0,3,H3
sample_8.pdf,4,exp (,9.962599754333496,CMR10,False,307.7417297363281,444.5809020996094,0.0,5,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,391.15399169921875,444.5809020996094,0.0,3,H3
sample_8.pdf,4,(4),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,437.9774169921875,0.0,3,H3
sample_8.pdf,4,where,9.942654609680176,NimbusRomNo9L-Regu,False,107.64099884033203,462.2215881347656,0.0,5,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,166.76100158691406,461.9759216308594,0.0,3,H3
sample_8.pdf,4,denotes a new type of representations which additionally take the target position,9.942654609680176,NimbusRomNo9L-Regu,False,183.20545959472656,462.2215881347656,0.0,81,H3
sample_8.pdf,4,as input.,9.962599754333496,NimbusRomNo9L-Regu,False,115.64568328857422,473.1154479980469,0.0,9,H3
sample_8.pdf,4,Two-Stream Self-Attention,9.962599754333496,NimbusRomNo9L-Medi,False,107.67100524902344,489.4125061035156,0.16,25,H3
sample_8.pdf,4,While the idea of target-aware representations removes the ambiguity,9.96757984161377,NimbusRomNo9L-Regu,False,222.03172302246094,489.49969482421875,0.014705882352941176,68,H3
sample_8.pdf,4,"in target prediction, how to formulate",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,500.3372802734375,0.0,38,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,299.2020263671875,500.1819152832031,0.0,3,H3
sample_8.pdf,4,remains a non-trivial problem. Among other,10.061732292175293,NimbusRomNo9L-Regu,False,315.646484375,500.3372802734375,0.023809523809523808,42,H3
sample_8.pdf,4,"possibilities, we propose to “stand” at the target position",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,511.2472839355469,0.0,59,H3
sample_8.pdf,4,and rely on the position,10.061732292175293,NimbusRomNo9L-Regu,False,352.1366882324219,511.2472839355469,0.0,24,H3
sample_8.pdf,4,to gather,10.061732292175293,NimbusRomNo9L-Regu,False,464.33868408203125,511.2472839355469,0.0,9,H3
sample_8.pdf,4,information from the context,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,522.307373046875,0.0,28,H3
sample_8.pdf,4,"through attention. For this parameterization to work, there are two",9.862470626831055,NimbusRomNo9L-Regu,False,241.7052001953125,522.307373046875,0.014925373134328358,67,H3
sample_8.pdf,4,requirements that are contradictory in a standard Transformer architecture: (1) to predict the token,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,533.0952758789062,0.01,100,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,159.30899047851562,543.8189086914062,0.0,3,H3
sample_8.pdf,4,should only use the,10.061732292175293,NimbusRomNo9L-Regu,False,175.75344848632812,543.9742431640625,0.0,19,H3
sample_8.pdf,4,position,10.061732292175293,NimbusRomNo9L-ReguItal,False,258.6869812011719,543.7960205078125,0.0,8,H3
sample_8.pdf,4,and not the,10.061732292175293,NimbusRomNo9L-Regu,False,304.9856872558594,543.9742431640625,0.0,11,H3
sample_8.pdf,4,content,10.061732292175293,NimbusRomNo9L-ReguItal,False,354.41339111328125,543.7960205078125,0.0,7,H3
sample_8.pdf,4,", otherwise the objective",10.061732292175293,NimbusRomNo9L-Regu,False,403.7120056152344,543.9742431640625,0.0,25,H3
sample_8.pdf,4,becomes trivial; (2) to predict the other tokens,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,554.89453125,0.0,48,H3
sample_8.pdf,4,with,10.046924591064453,NimbusRomNo9L-Regu,False,309.9380187988281,554.89453125,0.0,4,H3
sample_8.pdf,4,j > t,9.962599754333496,CMMI10,False,331.7306213378906,554.7279663085938,0.0,5,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,393.19097900390625,554.7279663085938,0.0,3,H3
sample_8.pdf,4,should also encode the,10.046924591064453,NimbusRomNo9L-Regu,False,409.6344299316406,554.89453125,0.0,22,H3
sample_8.pdf,4,content,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,565.943359375,0.0,7,H3
sample_8.pdf,4,"to provide full contextual information. To resolve such a contradiction, we propose to use",9.862470626831055,NimbusRomNo9L-Regu,False,151.4654541015625,565.943359375,0.011111111111111112,90,H3
sample_8.pdf,4,two sets of hidden representations instead of one:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,576.7764892578125,0.0,50,H3
sample_8.pdf,4,The content representation,10.061732292175293,NimbusRomNo9L-Regu,False,112.9813003540039,593.0902709960938,0.038461538461538464,26,H3
sample_8.pdf,4,", or abbreviated as",10.061732292175293,NimbusRomNo9L-Regu,False,267.8760070800781,593.0902709960938,0.0,19,H3
sample_8.pdf,4,", which serves a similar role to the",10.061732292175293,NimbusRomNo9L-Regu,False,360.4989929199219,593.0902709960938,0.0,36,H3
sample_8.pdf,4,standard hidden states in Transformer. This representation encodes,9.92266845703125,NimbusRomNo9L-Regu,False,117.96299743652344,604.104736328125,0.030303030303030304,66,H3
sample_8.pdf,4,both,9.92266845703125,NimbusRomNo9L-ReguItal,False,382.38970947265625,603.9290161132812,0.0,4,H3
sample_8.pdf,4,the context and,9.92266845703125,NimbusRomNo9L-Regu,False,402.4487609863281,604.104736328125,0.0,15,H3
sample_8.pdf,4,itself.,9.92266845703125,NimbusRomNo9L-Regu,False,480.0144348144531,604.104736328125,0.0,7,H3
sample_8.pdf,4,The query representation,9.942654609680176,NimbusRomNo9L-Regu,False,112.9813003540039,616.8865966796875,0.041666666666666664,24,H3
sample_8.pdf,4,", z",9.962599754333496,CMMI10,False,252.05398559570312,616.6409301757812,0.0,3,H3
sample_8.pdf,4,", or abbreviated as",9.942654609680176,NimbusRomNo9L-Regu,False,268.49700927734375,616.8865966796875,0.0,19,H3
sample_8.pdf,4,", which only has access to the contex-",9.942654609680176,NimbusRomNo9L-Regu,False,355.8550109863281,616.8865966796875,0.0,38,H3
sample_8.pdf,4,tual information,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,627.7804565429688,0.0,16,H3
sample_8.pdf,4,and the position,9.962599754333496,NimbusRomNo9L-Regu,False,203.2001953125,627.7804565429688,0.0,16,H3
sample_8.pdf,4,", but not the content",9.962599754333496,NimbusRomNo9L-Regu,False,280.968994140625,627.7804565429688,0.0,21,H3
sample_8.pdf,4,", as discussed above.",9.962599754333496,NimbusRomNo9L-Regu,False,375.9859924316406,627.7804565429688,0.0,21,H3
sample_8.pdf,4,"Computationally, the ﬁrst layer query stream is initialized with a trainable vector, i.e.",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,647.5802612304688,0.011235955056179775,89,H3
sample_8.pdf,4,(0),6.973800182342529,CMR7,False,469.2239990234375,644.5857543945312,0.0,3,P
sample_8.pdf,4,"while the content stream is set to the corresponding word embedding, i.e.",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,661.7582397460938,0.0,73,H3
sample_8.pdf,4,(0),6.973800182342529,CMR7,False,416.2989807128906,658.7637329101562,0.0,3,P
sample_8.pdf,4,. For each,10.061732292175293,NimbusRomNo9L-Regu,False,462.45599365234375,661.7582397460938,0.1,10,H3
sample_8.pdf,4,self-attention layer,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,673.875244140625,0.0,20,H3
sample_8.pdf,4,= 1,9.962599754333496,CMR10,False,195.92715454101562,673.7199096679688,0.0,3,H3
sample_8.pdf,4,", . . . , M",9.962599754333496,CMMI10,False,214.67799377441406,673.7199096679688,0.09090909090909091,11,H3
sample_8.pdf,4,", the two streams of representations are",10.061732292175293,NimbusRomNo9L-Regu,False,247.5679931640625,673.875244140625,0.0,40,H3
sample_8.pdf,4,schematically,10.061732292175293,NimbusRomNo9L-ReguItal,False,406.8653869628906,673.697021484375,0.0,13,H3
sample_8.pdf,4,updated,10.061732292175293,NimbusRomNo9L-Regu,False,471.8280029296875,673.875244140625,0.0,7,H3
sample_8.pdf,4,"To avoid clutter, we omit the implementation details including multi-head attention, residual connection,",9.051180839538574,NimbusRomNo9L-Regu,False,124.13999938964844,693.210693359375,0.009523809523809525,105,P
sample_8.pdf,4,layer normalization and position-wise feed-forward as used in Transformer(-XL). The details are included in,9.046737670898438,NimbusRomNo9L-Regu,False,108.0,703.176025390625,0.037383177570093455,107,P
sample_8.pdf,4,Appendix A.2 for reference.,8.966400146484375,NimbusRomNo9L-Regu,False,107.677001953125,713.199951171875,0.07407407407407407,27,P
sample_8.pdf,5,with a shared set of parameters as follows (illustrated in Figures 1 (a) and (b)):,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,74.40748596191406,0.012195121951219513,82,H3
sample_8.pdf,5,Attention,9.962599754333496,NimbusRomNo9L-Regu,False,151.26698303222656,94.56648254394531,0.1111111111111111,9,H3
sample_8.pdf,5,query stream: use,9.962599754333496,NimbusRomNo9L-Regu,False,335.302978515625,94.56648254394531,0.0,17,H3
sample_8.pdf,5,but cannot see,9.962599754333496,NimbusRomNo9L-Regu,False,416.31268310546875,94.56648254394531,0.0,14,H3
sample_8.pdf,5,Attention,9.962599754333496,NimbusRomNo9L-Regu,False,151.26693725585938,111.85743713378906,0.1111111111111111,9,H3
sample_8.pdf,5,content stream: use both,9.962599754333496,NimbusRomNo9L-Regu,False,335.3030090332031,111.85749816894531,0.0,24,H3
sample_8.pdf,5,and,9.962599754333496,NimbusRomNo9L-Regu,False,443.16168212890625,111.85749816894531,0.0,3,H3
sample_8.pdf,5,"where Q, K, V denote the query, key, and value in an attention operation [",9.902643203735352,NimbusRomNo9L-Regu,False,107.64099884033203,132.0529327392578,0.04054054054054054,74,H3
sample_8.pdf,5,]. The update rule of the,9.902643203735352,NimbusRomNo9L-Regu,False,408.1400146484375,132.0529327392578,0.04,25,H3
sample_8.pdf,5,"content representations is exactly the same as the standard self-attention, so during ﬁnetuning, we",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,142.84127807617188,0.0,99,H3
sample_8.pdf,5,"can simply drop the query stream and use the content stream as a normal Transformer(-XL). Finally,",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,153.85194396972656,0.04081632653061224,98,H3
sample_8.pdf,5,we can use the last-layer query representation,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,167.3844757080078,0.0,46,H3
sample_8.pdf,5,to compute Eq. (4).,9.962599754333496,NimbusRomNo9L-Regu,False,314.83697509765625,167.3844757080078,0.05263157894736842,19,H3
sample_8.pdf,5,Partial Prediction,9.962599754333496,NimbusRomNo9L-Medi,False,107.99996948242188,183.6815185546875,0.1111111111111111,18,H3
sample_8.pdf,5,While the permutation language modeling objective,9.872529029846191,NimbusRomNo9L-Regu,False,183.82533264160156,183.84078979492188,0.02040816326530612,49,H3
sample_8.pdf,5,(3),9.962599754333496,NimbusRomNo9L-Regu,False,392.2025146484375,183.77247619628906,0.0,3,H3
sample_8.pdf,5,"has several beneﬁts, it is",9.872529029846191,NimbusRomNo9L-Regu,False,406.3143615722656,183.84078979492188,0.0,26,H3
sample_8.pdf,5,a much more challenging optimization problem due to the permutation and causes slow convergence,9.902643203735352,NimbusRomNo9L-Regu,False,108.0,194.72792053222656,0.0,95,H3
sample_8.pdf,5,"in preliminary experiments. To reduce the optimization difﬁculty, we choose to only predict the last",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,205.5989990234375,0.01,100,H3
sample_8.pdf,5,"tokens in a factorization order. Formally, we split",10.02714729309082,NimbusRomNo9L-Regu,False,108.0,216.45155334472656,0.0196078431372549,51,H3
sample_8.pdf,5,into a non-target subsequence,10.02714729309082,NimbusRomNo9L-Regu,False,314.3128662109375,216.45155334472656,0.0,29,H3
sample_8.pdf,5,and a target,10.02714729309082,NimbusRomNo9L-Regu,False,454.16363525390625,216.45155334472656,0.0,12,H3
sample_8.pdf,5,subsequence,9.887598037719727,NimbusRomNo9L-Regu,False,108.0,227.4663848876953,0.0,11,H3
sample_8.pdf,5,", where",9.887598037719727,NimbusRomNo9L-Regu,False,175.46499633789062,227.4663848876953,0.0,7,H3
sample_8.pdf,5,is the cutting point. The objective is to maximize the log-likelihood of the,9.887598037719727,NimbusRomNo9L-Regu,False,211.1898193359375,227.4663848876953,0.013157894736842105,76,H3
sample_8.pdf,5,"target subsequence conditioned on the non-target subsequence, i.e.,",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,238.31849670410156,0.0,67,H3
sample_8.pdf,5,max,9.962599754333496,CMR10,False,154.6179962158203,269.32696533203125,0.0,3,H3
sample_8.pdf,5,log,9.962599754333496,CMR10,False,218.12100219726562,269.32696533203125,0.0,3,H3
sample_8.pdf,5,log,9.962599754333496,CMR10,False,375.3039245605469,269.326904296875,0.0,3,H3
sample_8.pdf,5,(5),9.962599754333496,NimbusRomNo9L-Regu,False,492.3839111328125,269.5572509765625,0.0,3,H3
sample_8.pdf,5,Note that,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,300.4894104003906,0.1111111111111111,9,H3
sample_8.pdf,5,is chosen as the target because it possesses the longest context in the sequence given the,9.862470626831055,NimbusRomNo9L-Regu,False,160.9792022705078,300.4894104003906,0.0,90,H3
sample_8.pdf,5,current factorization order,10.002370834350586,NimbusRomNo9L-Regu,False,108.0,311.29229736328125,0.0,27,H3
sample_8.pdf,5,. A hyperparameter,10.002370834350586,NimbusRomNo9L-Regu,False,220.8489990234375,311.29229736328125,0.05555555555555555,18,H3
sample_8.pdf,5,is used such that about,10.002370834350586,NimbusRomNo9L-Regu,False,310.10723876953125,311.29229736328125,0.0,23,H3
sample_8.pdf,5,tokens are selected,10.002370834350586,NimbusRomNo9L-Regu,False,425.08154296875,311.29229736328125,0.0,19,H3
sample_8.pdf,5,"for predictions; i.e.,",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,322.2239074707031,0.0,22,H3
sample_8.pdf,5,". For unselected tokens, their query representations need not",9.972557067871094,NimbusRomNo9L-Regu,False,263.56500244140625,322.2239074707031,0.01639344262295082,61,H3
sample_8.pdf,5,"be computed, which saves speed and memory.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,333.1404724121094,0.0,42,H3
sample_8.pdf,5,2.4,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,358.2835388183594,0.0,3,H3
sample_8.pdf,5,Incorporating Ideas from Transformer-XL,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,358.2835388183594,0.1282051282051282,39,H3
sample_8.pdf,5,"Since our objective function ﬁts in the AR framework, we incorporate the state-of-the-art AR",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,378.58428955078125,0.05434782608695652,92,H3
sample_8.pdf,5,"language model, Transformer-XL [",9.937662124633789,NimbusRomNo9L-Regu,False,108.0,389.5873718261719,0.09375,32,H3
sample_8.pdf,5,"], into our pretraining framework, and name our method after it.",9.937662124633789,NimbusRomNo9L-Regu,False,252.33599853515625,389.5873718261719,0.0,64,H3
sample_8.pdf,5,"We integrate two important techniques in Transformer-XL, namely the relative positional encoding",9.992443084716797,NimbusRomNo9L-Regu,False,107.53199768066406,400.454833984375,0.041666666666666664,96,H3
sample_8.pdf,5,scheme and the segment recurrence mechanism. We apply relative positional encodings based on the,9.887598037719727,NimbusRomNo9L-Regu,False,108.0,411.4433288574219,0.010416666666666666,96,H3
sample_8.pdf,5,"original sequence as discussed earlier, which is straightforward. Now we discuss how to integrate the",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,422.36761474609375,0.009900990099009901,101,H3
sample_8.pdf,5,recurrence mechanism into the proposed permutation setting and enable the model to reuse hidden,10.017244338989258,NimbusRomNo9L-Regu,False,108.0,433.16302490234375,0.0,95,H3
sample_8.pdf,5,"states from previous segments. Without loss of generality, suppose we have two segments taken from",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,444.18560791015625,0.01020408163265306,98,H3
sample_8.pdf,5,a long sequence,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,454.9472961425781,0.0,15,H3
sample_8.pdf,5,"; i.e.,",10.061732292175293,NimbusRomNo9L-Regu,False,181.0500030517578,454.9472961425781,0.0,7,H3
sample_8.pdf,5,and,10.061732292175293,NimbusRomNo9L-Regu,False,241.25732421875,454.9472961425781,0.0,3,H3
sample_8.pdf,5,+1:2,6.973800182342529,CMR7,False,293.3872985839844,458.62274169921875,0.0,4,P
sample_8.pdf,5,. Let,10.061732292175293,NimbusRomNo9L-Regu,False,315.47930908203125,454.9472961425781,0.2,5,H3
sample_8.pdf,5,and,10.061732292175293,NimbusRomNo9L-Regu,False,345.452880859375,454.9472961425781,0.0,3,H3
sample_8.pdf,5,be permutations of,10.061732292175293,NimbusRomNo9L-Regu,False,371.0238952636719,454.9472961425781,0.0,18,H3
sample_8.pdf,5,and,10.061732292175293,NimbusRomNo9L-Regu,False,486.4255676269531,454.9472961425781,0.0,3,H3
sample_8.pdf,5,+ 1,9.962599754333496,CMR10,False,116.58515930175781,465.700927734375,0.0,3,H3
sample_8.pdf,5,"respectively. Then, based on the permutation",9.867501258850098,NimbusRomNo9L-Regu,False,165.01260375976562,466.00360107421875,0.022727272727272728,44,H3
sample_8.pdf,5,", we process the ﬁrst segment, and then",9.867501258850098,NimbusRomNo9L-Regu,False,350.4729919433594,466.00360107421875,0.0,39,H3
sample_8.pdf,5,cache the obtained content representations,9.932666778564453,NimbusRomNo9L-Regu,False,108.0,478.7241516113281,0.0,42,H3
sample_8.pdf,5,for each layer,9.932666778564453,NimbusRomNo9L-Regu,False,300.9440002441406,478.7241516113281,0.0,14,H3
sample_8.pdf,5,". Then, for the next segment",9.932666778564453,NimbusRomNo9L-Regu,False,366.64300537109375,478.7241516113281,0.03571428571428571,28,H3
sample_8.pdf,5,", the",9.932666778564453,NimbusRomNo9L-Regu,False,486.9339904785156,478.7241516113281,0.0,5,H3
sample_8.pdf,5,attention update with memory can be written as,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,489.6104431152344,0.0,46,H3
sample_8.pdf,5,Attention,9.962599754333496,NimbusRomNo9L-Regu,False,217.7030029296875,511.8834228515625,0.1111111111111111,9,H3
sample_8.pdf,5,where,10.056798934936523,NimbusRomNo9L-Regu,False,107.64099884033203,534.4190673828125,0.0,5,H3
sample_8.pdf,5,"., .",9.962599754333496,CMMI10,False,137.71200561523438,534.2599487304688,0.0,4,H3
sample_8.pdf,5,denotes concatenation along the sequence dimension. Notice that positional encodings,10.056798934936523,NimbusRomNo9L-Regu,False,150.44461059570312,534.4190673828125,0.011904761904761904,84,H3
sample_8.pdf,5,"only depend on the actual positions in the original sequence. Thus, the above attention update is",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,545.3242797851562,0.010309278350515464,97,H3
sample_8.pdf,5,independent of,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,557.76025390625,0.0,14,H3
sample_8.pdf,5,once the representations,10.061732292175293,NimbusRomNo9L-Regu,False,176.347900390625,557.76025390625,0.0,24,H3
sample_8.pdf,5,are obtained. This allows caching and reusing the,10.061732292175293,NimbusRomNo9L-Regu,False,302.4330139160156,557.76025390625,0.02040816326530612,49,H3
sample_8.pdf,5,"memory without knowing the factorization order of the previous segment. In expectation, the model",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,568.7709350585938,0.010309278350515464,97,H3
sample_8.pdf,5,learns to utilize the memory over all factorization orders of the last segment. The query stream can,10.002370834350586,NimbusRomNo9L-Regu,False,108.0,579.623291015625,0.01,100,H3
sample_8.pdf,5,"be computed in the same way. Finally, Figure 1 (c) presents an overview of the proposed permutation",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,590.6383666992188,0.020202020202020204,99,H3
sample_8.pdf,5,language modeling with two-stream attention (see Appendix A.7 for more detailed illustration).,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,601.471435546875,0.02127659574468085,94,H3
sample_8.pdf,5,2.5,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,626.613525390625,0.0,3,H3
sample_8.pdf,5,Modeling Multiple Segments,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,626.613525390625,0.11538461538461539,26,H3
sample_8.pdf,5,"Many downstream tasks have multiple input segments, e.g., a question and a context paragraph in",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,646.9142456054688,0.010526315789473684,95,H3
sample_8.pdf,5,question answering. We now discuss how we pretrain XLNet to model multiple segments in the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,657.8242797851562,0.044444444444444446,90,H3
sample_8.pdf,5,"autoregressive framework. During the pretraining phase, following BERT, we randomly sample two",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,668.8311767578125,0.05319148936170213,94,H3
sample_8.pdf,5,segments (either from the same context or not) and treat the concatenation of two segments as one,10.037040710449219,NimbusRomNo9L-Regu,False,108.0,679.6610107421875,0.0,97,H3
sample_8.pdf,5,sequence to perform permutation language modeling. We only reuse the memory that belongs to,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,690.55126953125,0.01098901098901099,91,H3
sample_8.pdf,5,"the same context. Speciﬁcally, the input to our model is the same as BERT: [CLS, A, SEP, B, SEP],",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,701.5278930664062,0.16494845360824742,97,H3
sample_8.pdf,5,where “SEP” and “CLS” are two special symbols and “A” and “B” are the two segments. Although,9.982504844665527,NimbusRomNo9L-Regu,False,107.64099884033203,712.4293823242188,0.09782608695652174,92,H3
sample_8.pdf,6,"we follow the two-segment data format, XLNet-Large does not use the objective of next sentence",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,74.33230590820312,0.0425531914893617,94,H3
sample_8.pdf,6,prediction [10] as it does not show consistent improvement in our ablation study (see Section 3.4).,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,85.31648254394531,0.010101010101010102,99,H3
sample_8.pdf,6,Relative Segment Encodings,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,101.61351776123047,0.11538461538461539,26,H3
sample_8.pdf,6,"Architecturally, different from BERT that adds an absolute segment",9.987475395202637,NimbusRomNo9L-Regu,False,228.46774291992188,101.68561553955078,0.07575757575757576,66,H3
sample_8.pdf,6,"embedding to the word embedding at each position, we extend the idea of relative encodings from",10.037040710449219,NimbusRomNo9L-Regu,False,108.0,112.55702209472656,0.0,95,H3
sample_8.pdf,6,Transformer-XL to also encode the segments. Given a pair of positions,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,123.44729614257812,0.057971014492753624,69,H3
sample_8.pdf,6,and,10.061732292175293,NimbusRomNo9L-Regu,False,402.9111022949219,123.44729614257812,0.0,3,H3
sample_8.pdf,6,"in the sequence, if",10.061732292175293,NimbusRomNo9L-Regu,False,426.82159423828125,123.44729614257812,0.0,19,H3
sample_8.pdf,6,and,10.061732292175293,NimbusRomNo9L-Regu,False,111.43709564208984,134.35726928710938,0.0,3,H3
sample_8.pdf,6,"are from the same segment, we use a segment encoding",10.061732292175293,NimbusRomNo9L-Regu,False,135.99359130859375,134.35726928710938,0.0,52,H3
sample_8.pdf,6,or otherwise,10.061732292175293,NimbusRomNo9L-Regu,False,408.01007080078125,134.35726928710938,0.0,12,H3
sample_8.pdf,6,where,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,145.26626586914062,0.0,5,H3
sample_8.pdf,6,and,10.061732292175293,NimbusRomNo9L-Regu,False,145.6170196533203,145.26626586914062,0.0,3,H3
sample_8.pdf,6,"are learnable model parameters for each attention head. In other words, we only",10.061732292175293,NimbusRomNo9L-Regu,False,179.57899475097656,145.26626586914062,0.012658227848101266,79,H3
sample_8.pdf,6,consider whether the two positions are,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,156.17532348632812,0.0,38,H3
sample_8.pdf,6,within the same segment,10.061732292175293,NimbusRomNo9L-ReguItal,False,264.7669677734375,155.99710083007812,0.0,23,H3
sample_8.pdf,6,", as opposed to considering",10.061732292175293,NimbusRomNo9L-Regu,False,366.7229919433594,156.17532348632812,0.0,27,H3
sample_8.pdf,6,which,10.061732292175293,NimbusRomNo9L-ReguItal,False,477.2840881347656,155.99710083007812,0.0,5,H3
sample_8.pdf,6,speciﬁc segments they are from,9.942654609680176,NimbusRomNo9L-ReguItal,False,108.0,166.99850463867188,0.0,30,H3
sample_8.pdf,6,". This is consistent with the core idea of relative encodings; i.e., only",9.942654609680176,NimbusRomNo9L-Regu,False,231.10699462890625,167.17462158203125,0.0136986301369863,73,H3
sample_8.pdf,6,modeling the relationships between positions. When,9.9176664352417,NimbusRomNo9L-Regu,False,108.0,178.10256958007812,0.02,50,H3
sample_8.pdf,6,attends to,9.9176664352417,NimbusRomNo9L-Regu,False,321.47808837890625,178.10256958007812,0.0,10,H3
sample_8.pdf,6,", the segment encoding",9.9176664352417,NimbusRomNo9L-Regu,False,369.2969970703125,178.10256958007812,0.0,22,H3
sample_8.pdf,6,is used,9.9176664352417,NimbusRomNo9L-Regu,False,473.41802978515625,178.10256958007812,0.0,7,H3
sample_8.pdf,6,to compute an attention weight,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,190.29830932617188,0.0,30,H3
sample_8.pdf,6,= (,9.962599754333496,CMR10,False,248.49203491210938,190.14292907714844,0.0,3,H3
sample_8.pdf,6,", where",10.061732292175293,NimbusRomNo9L-Regu,False,317.5589904785156,190.29830932617188,0.0,7,H3
sample_8.pdf,6,is the query vector as in a standard,10.061732292175293,NimbusRomNo9L-Regu,False,359.1903991699219,190.29830932617188,0.0,36,H3
sample_8.pdf,6,attention operation and,10.041984558105469,NimbusRomNo9L-Regu,False,108.0,201.22227478027344,0.0,23,H3
sample_8.pdf,6,"is a learnable head-speciﬁc bias vector. Finally, the value",10.041984558105469,NimbusRomNo9L-Regu,False,210.11810302734375,201.22227478027344,0.01694915254237288,59,H3
sample_8.pdf,6,is added to,10.041984558105469,NimbusRomNo9L-Regu,False,456.8230285644531,201.22227478027344,0.0,11,H3
sample_8.pdf,6,"the normal attention weight. There are two beneﬁts of using relative segment encodings. First, the",10.041984558105469,NimbusRomNo9L-Regu,False,108.0,212.1312713623047,0.02040816326530612,98,H3
sample_8.pdf,6,inductive bias of relative encodings improves generalization [,9.992443084716797,NimbusRomNo9L-Regu,False,108.0,223.07785034179688,0.0,62,H3
sample_8.pdf,6,"]. Second, it opens the possibility of",9.992443084716797,NimbusRomNo9L-Regu,False,359.2539978027344,223.07785034179688,0.02631578947368421,38,H3
sample_8.pdf,6,"ﬁnetuning on tasks that have more than two input segments, which is not possible using absolute",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,233.93429565429688,0.0,95,H3
sample_8.pdf,6,segment encodings.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,244.91847229003906,0.0,18,H3
sample_8.pdf,6,2.6,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,269.39752197265625,0.0,3,H3
sample_8.pdf,6,Discussion,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,269.39752197265625,0.1,10,H3
sample_8.pdf,6,"Comparing Eq. (2) and (5), we observe that both BERT and XLNet perform partial prediction, i.e.,",10.012289047241211,NimbusRomNo9L-Regu,False,108.0,289.4707946777344,0.09375,96,H3
sample_8.pdf,6,only predicting a subset of tokens in the sequence. This is a necessary choice for BERT because if all,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,300.493408203125,0.049019607843137254,102,H3
sample_8.pdf,6,"tokens are masked, it is impossible to make any meaningful predictions. In addition, for both BERT",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,311.3377990722656,0.05102040816326531,98,H3
sample_8.pdf,6,"and XLNet, partial prediction plays a role of reducing optimization difﬁculty by only predicting",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,322.1602783203125,0.03125,96,H3
sample_8.pdf,6,"tokens with sufﬁcient context. However, the independence assumption discussed in Section 2.1",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,333.0693054199219,0.021739130434782608,92,H3
sample_8.pdf,6,disables BERT to model dependency between targets.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,344.053466796875,0.08,50,H3
sample_8.pdf,6,"To better understand the difference, let’s consider a concrete example [New, York, is, a, city]. Suppose",9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,360.5184020996094,0.038461538461538464,104,H3
sample_8.pdf,6,"both BERT and XLNet select the two tokens [New, York] as the prediction targets and maximize",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,371.27630615234375,0.09782608695652174,92,H3
sample_8.pdf,6,log,9.962599754333496,CMR10,False,108.0,382.0299377441406,0.0,3,H3
sample_8.pdf,6,New York,9.962599754333496,NimbusRomNo9L-Regu,False,131.41600036621094,382.2604675292969,0.25,8,H3
sample_8.pdf,6,is a city,9.962599754333496,NimbusRomNo9L-Regu,False,178.4086151123047,382.2604675292969,0.0,9,H3
sample_8.pdf,6,". Also suppose that XLNet samples the factorization order [is, a, city,",10.061732292175293,NimbusRomNo9L-Regu,False,217.06900024414062,382.185302734375,0.056338028169014086,71,H3
sample_8.pdf,6,"New, York]. In this case, BERT and XLNet respectively reduce to the following objectives:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,393.1694641113281,0.11235955056179775,89,H3
sample_8.pdf,6,BERT,6.973800182342529,NimbusRomNo9L-Regu,False,200.75599670410156,414.91314697265625,1.0,4,P
sample_8.pdf,6,= log,9.962599754333496,CMR10,False,218.16258239746094,410.9209289550781,0.0,5,H3
sample_8.pdf,6,New,9.962599754333496,NimbusRomNo9L-Regu,False,255.3599853515625,411.1514587402344,0.3333333333333333,3,H3
sample_8.pdf,6,is a city,9.962599754333496,NimbusRomNo9L-Regu,False,279.45758056640625,411.1514587402344,0.0,9,H3
sample_8.pdf,6,) + log,9.962599754333496,CMR10,False,313.2159729003906,410.9209289550781,0.0,7,H3
sample_8.pdf,6,York,9.962599754333496,NimbusRomNo9L-Regu,False,352.6819763183594,411.1514587402344,0.25,4,H3
sample_8.pdf,6,is a city,9.962599754333496,NimbusRomNo9L-Regu,False,377.5965576171875,411.1514587402344,0.0,9,H3
sample_8.pdf,6,XLNet,6.973800182342529,NimbusRomNo9L-Regu,False,188.2819366455078,433.0441589355469,0.6,5,P
sample_8.pdf,6,= log,9.962599754333496,CMR10,False,207.64817810058594,429.05194091796875,0.0,5,H3
sample_8.pdf,6,New,9.962599754333496,NimbusRomNo9L-Regu,False,244.84593200683594,429.282470703125,0.3333333333333333,3,H3
sample_8.pdf,6,is a city,9.962599754333496,NimbusRomNo9L-Regu,False,268.9425354003906,429.282470703125,0.0,9,H3
sample_8.pdf,6,) + log,9.962599754333496,CMR10,False,302.7009582519531,429.05194091796875,0.0,7,H3
sample_8.pdf,6,York,9.962599754333496,NimbusRomNo9L-Regu,False,342.1679382324219,429.282470703125,0.25,4,H3
sample_8.pdf,6,New,9.962599754333496,NimbusRomNo9L-Regu,False,367.08154296875,429.282470703125,0.3333333333333333,3,H3
sample_8.pdf,6,is a city,9.962599754333496,NimbusRomNo9L-Regu,False,391.1765441894531,429.282470703125,0.0,9,H3
sample_8.pdf,6,"Notice that XLNet is able to capture the dependency between the pair (New, York), which is omitted",9.902643203735352,NimbusRomNo9L-Regu,False,108.0,444.3709411621094,0.061224489795918366,98,H3
sample_8.pdf,6,"by BERT. Although in this example, BERT learns some dependency pairs such as (New, city) and",10.056798934936523,NimbusRomNo9L-Regu,False,108.0,455.16400146484375,0.10869565217391304,92,H3
sample_8.pdf,6,"(York, city), it is obvious that XLNet always learns",9.862470626831055,NimbusRomNo9L-Regu,False,107.6709976196289,466.2204284667969,0.07692307692307693,52,H3
sample_8.pdf,6,more,9.962599754333496,NimbusRomNo9L-Medi,False,307.26318359375,466.05352783203125,0.0,4,H3
sample_8.pdf,6,dependency pairs given the same target and,9.862470626831055,NimbusRomNo9L-Regu,False,331.6936340332031,466.2204284667969,0.0,42,H3
sample_8.pdf,6,contains “denser” effective training signals.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,477.053466796875,0.0,45,H3
sample_8.pdf,6,"For more formal analysis and further discussion, please refer to Appendix A.5.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,493.44146728515625,0.038461538461538464,78,H3
sample_8.pdf,6,Experiments,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,520.326171875,0.09090909090909091,11,H3
sample_8.pdf,6,3.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,545.0364990234375,0.0,3,H3
sample_8.pdf,6,Pretraining and Implementation,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,545.0364990234375,0.06666666666666667,30,H3
sample_8.pdf,6,Following BERT [,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,565.222412109375,0.3125,16,H3
sample_8.pdf,6,"], we use the BooksCorpus [",9.862470626831055,NimbusRomNo9L-Regu,False,190.052001953125,565.222412109375,0.07407407407407407,27,H3
sample_8.pdf,6,] and English Wikipedia as part of our pretraining,9.862470626831055,NimbusRomNo9L-Regu,False,310.30499267578125,565.222412109375,0.04,50,H3
sample_8.pdf,6,"data, which have 13GB plain text combined. In addition, we include Giga5 (16GB text) [",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,575.980224609375,0.06976744186046512,86,H3
sample_8.pdf,6,ClueWeb 2012-B (extended from [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,586.8902587890625,0.0967741935483871,31,H3
sample_8.pdf,6,"]), and Common Crawl [",10.061732292175293,NimbusRomNo9L-Regu,False,255.08900451660156,586.8902587890625,0.09090909090909091,22,H3
sample_8.pdf,6,] for pretraining. We use heuristics,10.061732292175293,NimbusRomNo9L-Regu,False,361.0,586.8902587890625,0.027777777777777776,36,H3
sample_8.pdf,6,"to aggressively ﬁlter out short or low-quality articles for ClueWeb 2012-B and Common Crawl,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,597.7992553710938,0.05434782608695652,92,H3
sample_8.pdf,6,which results in 19GB and 110GB text respectively. After tokenization with SentencePiece [,9.932666778564453,NimbusRomNo9L-Regu,False,107.64099884033203,608.80615234375,0.07777777777777778,90,H3
sample_8.pdf,6,"], we",9.932666778564453,NimbusRomNo9L-Regu,False,484.1940002441406,608.80615234375,0.0,5,H3
sample_8.pdf,6,"obtain 2.78B, 1.09B, 4.75B, 4.30B, and 19.97B subword pieces for Wikipedia, BooksCorpus, Giga5,",9.89261531829834,NimbusRomNo9L-Regu,False,108.0,619.7455444335938,0.09473684210526316,95,H3
sample_8.pdf,6,"ClueWeb, and Common Crawl respectively, which are 32.89B in total.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,630.6014404296875,0.07575757575757576,66,H3
sample_8.pdf,6,"Our largest model XLNet-Large has the same architecture hyperparameters as BERT-Large, which",10.002370834350586,NimbusRomNo9L-Regu,False,108.0,646.9592895507812,0.10869565217391304,92,H3
sample_8.pdf,6,"results in a similar model size. During pretraining, we always use a full sequence length of 512.",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,657.8242797851562,0.010309278350515464,97,H3
sample_8.pdf,6,"Firstly, to provide a fair comparison with BERT (section 3.2), we also trained XLNet-Large-wikibooks",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,668.8843994140625,0.09,100,H3
sample_8.pdf,6,"on BooksCorpus and Wikipedia only, where we reuse all pretraining hyper-parameters as in the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,679.6422729492188,0.03260869565217391,92,H3
sample_8.pdf,6,"original BERT. Then, we scale up the training of XLNet-Large by using all the datasets described",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,690.55126953125,0.09375,96,H3
sample_8.pdf,6,"above. Speciﬁcally, we train on 512 TPU v3 chips for 500K steps with an Adam weight decay",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,701.4602661132812,0.06741573033707865,89,H3
sample_8.pdf,6,"optimizer, linear learning rate decay, and a batch size of 8192, which takes about 5.5 days. It was",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,712.3692626953125,0.010101010101010102,99,H3
sample_8.pdf,7,"observed that the model still underﬁts the data at the end of training. Finally, we perform ablation",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,74.33230590820312,0.01,100,H3
sample_8.pdf,7,study (section 3.4) based on the XLNet-Base-wikibooks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,85.31648254394531,0.07407407407407407,54,H3
sample_8.pdf,7,"Since the recurrence mechanism is introduced, we use a bidirectional data input pipeline where each",9.9126615524292,NimbusRomNo9L-Regu,False,108.0,101.74235534667969,0.010101010101010102,99,H3
sample_8.pdf,7,"of the forward and backward directions takes half of the batch size. For training XLNet-Large, we set",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,112.68941497802734,0.04950495049504951,101,H3
sample_8.pdf,7,the partial prediction constant,9.867501258850098,NimbusRomNo9L-Regu,False,108.0,123.59459686279297,0.0,31,H3
sample_8.pdf,7,as 6 (see Section 2.3). Our ﬁnetuning procedure follows BERT [,9.867501258850098,NimbusRomNo9L-Regu,False,235.51625061035156,123.59459686279297,0.0967741935483871,62,H3
sample_8.pdf,7,except otherwise speciﬁed,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,134.3872528076172,0.0,25,H3
sample_8.pdf,7,. We employ an idea of,10.022196769714355,NimbusRomNo9L-Regu,False,218.18800354003906,134.3872528076172,0.045454545454545456,22,H3
sample_8.pdf,7,span-based prediction,10.022196769714355,NimbusRomNo9L-ReguItal,False,311.8713073730469,134.20973205566406,0.0,21,H3
sample_8.pdf,7,", where we ﬁrst sample a",10.022196769714355,NimbusRomNo9L-Regu,False,403.87200927734375,134.3872528076172,0.0,24,H3
sample_8.pdf,7,length,9.92266845703125,NimbusRomNo9L-Regu,False,108.0,145.37173461914062,0.0,6,H3
sample_8.pdf,7,", and then randomly select a consecutive span of",9.92266845703125,NimbusRomNo9L-Regu,False,193.47000122070312,145.37173461914062,0.0,48,H3
sample_8.pdf,7,tokens as prediction targets,9.92266845703125,NimbusRomNo9L-Regu,False,393.8455505371094,145.37173461914062,0.0,28,H3
sample_8.pdf,7,within a context of,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,156.25050354003906,0.0,19,H3
sample_8.pdf,7,tokens.,9.962599754333496,NimbusRomNo9L-Regu,False,208.67445373535156,156.25050354003906,0.0,7,H3
sample_8.pdf,7,We use a variety of natural language understanding datasets to evaluate the performance of our,10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,172.56326293945312,0.010638297872340425,94,H3
sample_8.pdf,7,method. Detailed descriptions of the settings for all the datasets can be found in Appendix A.3.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,183.54750061035156,0.03125,96,H3
sample_8.pdf,7,3.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,210.37554931640625,0.0,3,H3
sample_8.pdf,7,Fair Comparison with BERT,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,210.37554931640625,0.24,25,H3
sample_8.pdf,7,Model,8.966400146484375,NimbusRomNo9L-Medi,False,110.98899841308594,242.43409729003906,0.2,5,P
sample_8.pdf,7,SQuAD1.1 SQuAD2.0 RACE MNLI QNLI QQP RTE SST-2 MRPC CoLA STS-B,8.966400146484375,NimbusRomNo9L-Regu,False,167.99000549316406,242.51596069335938,0.6451612903225806,62,P
sample_8.pdf,7,BERT-Large,9.055620193481445,NimbusRomNo9L-Regu,False,110.98899841308594,257.41131591796875,0.5,10,P
sample_8.pdf,7,(Best of 3),8.966400146484375,NimbusRomNo9L-Regu,False,110.69300079345703,267.4419860839844,0.09090909090909091,11,P
sample_8.pdf,7,86.7/92.8,8.966400146484375,NimbusRomNo9L-Regu,False,171.1009979248047,257.4789733886719,0.0,9,P
sample_8.pdf,7,82.8/85.5,8.966400146484375,NimbusRomNo9L-Regu,False,217.17933654785156,257.4789733886719,0.0,9,P
sample_8.pdf,7,75.1,8.966400146484375,NimbusRomNo9L-Regu,False,264.0736083984375,257.4789733886719,0.0,4,P
sample_8.pdf,7,87.3,8.966400146484375,NimbusRomNo9L-Regu,False,293.2771911621094,257.4789733886719,0.0,4,P
sample_8.pdf,7,93.0,8.966400146484375,NimbusRomNo9L-Regu,False,321.4227294921875,257.4789733886719,0.0,4,P
sample_8.pdf,7,91.4,8.966400146484375,NimbusRomNo9L-Regu,False,347.066650390625,257.4789733886719,0.0,4,P
sample_8.pdf,7,74.0,8.966400146484375,NimbusRomNo9L-Regu,False,370.2089538574219,257.4789733886719,0.0,4,P
sample_8.pdf,7,94.0,8.966400146484375,NimbusRomNo9L-Regu,False,395.4403991699219,257.4789733886719,0.0,4,P
sample_8.pdf,7,88.7,8.966400146484375,NimbusRomNo9L-Regu,False,424.9219055175781,257.4789733886719,0.0,4,P
sample_8.pdf,7,63.7,8.966400146484375,NimbusRomNo9L-Regu,False,454.5648193359375,257.4789733886719,0.0,4,P
sample_8.pdf,7,90.2,8.966400146484375,NimbusRomNo9L-Regu,False,483.9566955566406,257.4789733886719,0.0,4,P
sample_8.pdf,7,XLNet-Large-,9.055620193481445,NimbusRomNo9L-Regu,False,110.66600036621094,282.3373107910156,0.3333333333333333,12,P
sample_8.pdf,7,wikibooks,8.966400146484375,NimbusRomNo9L-Regu,False,110.66600036621094,292.36798095703125,0.0,9,P
sample_8.pdf,7,88.2/94.0,8.966400146484375,NimbusRomNo9L-Regu,False,171.1009979248047,282.40496826171875,0.0,9,P
sample_8.pdf,7,85.1/87.8,8.966400146484375,NimbusRomNo9L-Regu,False,217.17933654785156,282.40496826171875,0.0,9,P
sample_8.pdf,7,77.4,8.966400146484375,NimbusRomNo9L-Regu,False,264.0736083984375,282.40496826171875,0.0,4,P
sample_8.pdf,7,88.4,8.966400146484375,NimbusRomNo9L-Regu,False,293.2771911621094,282.40496826171875,0.0,4,P
sample_8.pdf,7,93.9,8.966400146484375,NimbusRomNo9L-Regu,False,321.4227294921875,282.40496826171875,0.0,4,P
sample_8.pdf,7,91.8,8.966400146484375,NimbusRomNo9L-Regu,False,347.066650390625,282.40496826171875,0.0,4,P
sample_8.pdf,7,81.2,8.966400146484375,NimbusRomNo9L-Regu,False,370.2089538574219,282.40496826171875,0.0,4,P
sample_8.pdf,7,94.4,8.966400146484375,NimbusRomNo9L-Regu,False,395.4403991699219,282.40496826171875,0.0,4,P
sample_8.pdf,7,90.0,8.966400146484375,NimbusRomNo9L-Regu,False,424.9219055175781,282.40496826171875,0.0,4,P
sample_8.pdf,7,65.2,8.966400146484375,NimbusRomNo9L-Regu,False,454.5648193359375,282.40496826171875,0.0,4,P
sample_8.pdf,7,91.1,8.966400146484375,NimbusRomNo9L-Regu,False,483.9566955566406,282.40496826171875,0.0,4,P
sample_8.pdf,7,Table 1:,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,304.6742858886719,0.125,8,H3
sample_8.pdf,7,Fair comparison with BERT. All models are trained using the same data and hyperparameters as in,9.055620193481445,NimbusRomNo9L-Regu,False,140.45281982421875,305.43731689453125,0.06315789473684211,95,P
sample_8.pdf,7,"BERT. We use the best of 3 BERT variants for comparison; i.e., the original BERT, BERT with whole word",9.055620193481445,NimbusRomNo9L-Regu,False,108.0,315.40032958984375,0.16666666666666666,102,P
sample_8.pdf,7,"masking, and BERT without next sentence prediction.",8.966400146484375,NimbusRomNo9L-Regu,False,108.0,325.42999267578125,0.0784313725490196,51,P
sample_8.pdf,7,"Here, we ﬁrst compare the performance of BERT and XLNet in a fair setting to decouple the effects",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,357.68914794921875,0.08247422680412371,97,H3
sample_8.pdf,7,"of using more data and the improvement from BERT to XLNet. In Table 1, we compare (1) best",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,368.50030517578125,0.1,90,H3
sample_8.pdf,7,performance of three different variants of BERT and (2) XLNet trained with the same data and,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,379.4093017578125,0.07608695652173914,92,H3
sample_8.pdf,7,"hyperparameters. As we can see, trained on the same data with an almost identical training recipe,",10.046924591064453,NimbusRomNo9L-Regu,False,108.0,390.32952880859375,0.01020408163265306,98,H3
sample_8.pdf,7,XLNet outperforms BERT by a sizable margin on all the considered datasets.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,401.3024597167969,0.0945945945945946,74,H3
sample_8.pdf,7,3.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,428.1305236816406,0.0,3,H3
sample_8.pdf,7,Comparison with RoBERTa: Scaling Up,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,428.1305236816406,0.22857142857142856,35,H3
sample_8.pdf,7,RACE,8.966400146484375,NimbusRomNo9L-Medi,False,128.1199951171875,460.1891174316406,1.0,4,P
sample_8.pdf,7,Accuracy,8.966400146484375,NimbusRomNo9L-Medi,False,215.91001892089844,460.1891174316406,0.125,8,P
sample_8.pdf,7,Middle,8.966400146484375,NimbusRomNo9L-Medi,False,264.2120056152344,460.1891174316406,0.16666666666666666,6,P
sample_8.pdf,7,High,8.966400146484375,NimbusRomNo9L-Medi,False,303.5655212402344,460.1891174316406,0.25,4,P
sample_8.pdf,7,Model,8.966400146484375,NimbusRomNo9L-Medi,False,334.4599914550781,460.1891174316406,0.2,5,P
sample_8.pdf,7,NDCG@20,8.966400146484375,NimbusRomNo9L-Medi,False,391.9884033203125,460.1891174316406,0.5714285714285714,7,P
sample_8.pdf,7,ERR@20,8.966400146484375,NimbusRomNo9L-Medi,False,447.65185546875,460.1891174316406,0.5,6,P
sample_8.pdf,7,GPT [28],8.966400146484375,NimbusRomNo9L-Regu,False,128.1199951171875,475.2339782714844,0.375,8,P
sample_8.pdf,7,59.0,8.966400146484375,NimbusRomNo9L-Regu,False,226.23931884765625,475.2339782714844,0.0,4,P
sample_8.pdf,7,62.9,8.966400146484375,NimbusRomNo9L-Regu,False,270.06707763671875,475.2339782714844,0.0,4,P
sample_8.pdf,7,57.4,8.966400146484375,NimbusRomNo9L-Regu,False,305.1884765625,475.2339782714844,0.0,4,P
sample_8.pdf,7,DRMM [13],8.966400146484375,NimbusRomNo9L-Regu,False,334.4599914550781,475.2339782714844,0.4444444444444444,9,P
sample_8.pdf,7,24.3,8.966400146484375,NimbusRomNo9L-Regu,False,405.99395751953125,475.2339782714844,0.0,4,P
sample_8.pdf,7,13.8,8.966400146484375,NimbusRomNo9L-Regu,False,457.91839599609375,475.2339782714844,0.0,4,P
sample_8.pdf,7,BERT [25],8.966400146484375,NimbusRomNo9L-Regu,False,128.1199951171875,485.1969909667969,0.4444444444444444,9,P
sample_8.pdf,7,72.0,8.966400146484375,NimbusRomNo9L-Regu,False,226.23931884765625,485.1969909667969,0.0,4,P
sample_8.pdf,7,76.6,8.966400146484375,NimbusRomNo9L-Regu,False,270.06707763671875,485.1969909667969,0.0,4,P
sample_8.pdf,7,70.1,8.966400146484375,NimbusRomNo9L-Regu,False,305.1884765625,485.1969909667969,0.0,4,P
sample_8.pdf,7,KNRM [8],8.966400146484375,NimbusRomNo9L-Regu,False,334.4599914550781,485.1969909667969,0.5,8,P
sample_8.pdf,7,26.9,8.966400146484375,NimbusRomNo9L-Regu,False,405.99395751953125,485.1969909667969,0.0,4,P
sample_8.pdf,7,14.9,8.966400146484375,NimbusRomNo9L-Regu,False,457.91839599609375,485.1969909667969,0.0,4,P
sample_8.pdf,7,BERT+DCMN,8.966400146484375,NimbusRomNo9L-Regu,False,128.1199951171875,495.15899658203125,0.8888888888888888,9,P
sample_8.pdf,7,[38],8.966400146484375,NimbusRomNo9L-Regu,False,189.0139923095703,495.15899658203125,0.0,4,P
sample_8.pdf,7,74.1,8.966400146484375,NimbusRomNo9L-Regu,False,226.2335205078125,495.15899658203125,0.0,4,P
sample_8.pdf,7,79.5,8.966400146484375,NimbusRomNo9L-Regu,False,270.07025146484375,495.15899658203125,0.0,4,P
sample_8.pdf,7,71.8,8.966400146484375,NimbusRomNo9L-Regu,False,305.191650390625,495.15899658203125,0.0,4,P
sample_8.pdf,7,Conv [8],8.966400146484375,NimbusRomNo9L-Regu,False,334.4599914550781,495.15899658203125,0.125,8,P
sample_8.pdf,7,28.7,8.966400146484375,NimbusRomNo9L-Regu,False,405.9939880371094,495.15899658203125,0.0,4,P
sample_8.pdf,7,18.1,8.966400146484375,NimbusRomNo9L-Regu,False,457.91839599609375,495.15899658203125,0.0,4,P
sample_8.pdf,7,RoBERTa [21],8.966400146484375,NimbusRomNo9L-Regu,False,128.1199951171875,506.1080017089844,0.4166666666666667,12,P
sample_8.pdf,7,83.2,8.966400146484375,NimbusRomNo9L-Regu,False,226.23931884765625,506.1080017089844,0.0,4,P
sample_8.pdf,7,86.5,8.966400146484375,NimbusRomNo9L-Regu,False,270.06707763671875,506.1080017089844,0.0,4,P
sample_8.pdf,7,81.8,8.966400146484375,NimbusRomNo9L-Regu,False,305.1884765625,506.1080017089844,0.0,4,P
sample_8.pdf,7,BERT,8.966400146484375,NimbusRomNo9L-Regu,False,334.4599914550781,506.1079406738281,1.0,4,P
sample_8.pdf,7,30.53,8.966400146484375,NimbusRomNo9L-Regu,False,403.7539978027344,506.1079406738281,0.0,5,P
sample_8.pdf,7,18.67,8.966400146484375,NimbusRomNo9L-Regu,False,455.6784362792969,506.1079406738281,0.0,5,P
sample_8.pdf,7,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,128.1199951171875,521.0719604492188,0.6,5,P
sample_8.pdf,7,85.4,8.966400146484375,NimbusRomNo9L-Medi,False,226.23599243164062,520.9901123046875,0.0,4,P
sample_8.pdf,7,88.6,8.966400146484375,NimbusRomNo9L-Medi,False,270.06378173828125,520.9901123046875,0.0,4,P
sample_8.pdf,7,84.0,8.966400146484375,NimbusRomNo9L-Medi,False,305.19415283203125,520.9901123046875,0.0,4,P
sample_8.pdf,7,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,334.4599914550781,521.0719604492188,0.6,5,P
sample_8.pdf,7,31.10,8.966400146484375,NimbusRomNo9L-Medi,False,403.7539978027344,520.9901123046875,0.0,5,P
sample_8.pdf,7,20.28,8.966400146484375,NimbusRomNo9L-Medi,False,455.6784362792969,520.9901123046875,0.0,5,P
sample_8.pdf,7,Table 2:,9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,533.5294189453125,0.125,8,H3
sample_8.pdf,7,"Comparison with state-of-the-art results on the test set of RACE, a reading comprehension task, and on",8.876283645629883,NimbusRomNo9L-Regu,False,139.1094512939453,534.27734375,0.049019607843137254,102,P
sample_8.pdf,7,"ClueWeb09-B, a document ranking task.",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,544.2402954101562,0.08108108108108109,37,P
sample_8.pdf,7,indicates using ensembles.,8.876283645629883,NimbusRomNo9L-Regu,False,259.69000244140625,544.2402954101562,0.0,26,P
sample_8.pdf,7,indicates our implementations. “Middle”,8.876283645629883,NimbusRomNo9L-Regu,False,359.7386474609375,544.2402954101562,0.02564102564102564,39,P
sample_8.pdf,7,"and “High” in RACE are two subsets representing middle and high school difﬁculty levels. All BERT, RoBERTa,",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,554.2023315429688,0.14018691588785046,107,P
sample_8.pdf,7,and XLNet results are obtained with a 24-layer architecture with similar model sizes (aka BERT-Large).,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,564.096923828125,0.0784313725490196,102,P
sample_8.pdf,7,"After the initial publication of our manuscript, a few other pretrained models were released such as",9.992443084716797,NimbusRomNo9L-Regu,False,107.64099884033203,596.3108520507812,0.01,100,H3
sample_8.pdf,7,RoBERTa [,9.982504844665527,NimbusRomNo9L-Regu,False,108.0,607.2273559570312,0.5555555555555556,9,H3
sample_8.pdf,7,] and ALBERT [,9.982504844665527,NimbusRomNo9L-Regu,False,164.07000732421875,607.2273559570312,0.42857142857142855,14,H3
sample_8.pdf,7,]. Since ALBERT involves increasing the model hidden size from,9.982504844665527,NimbusRomNo9L-Regu,False,240.91200256347656,607.2273559570312,0.11290322580645161,62,H3
sample_8.pdf,7,"1024 to 2048/4096 and thus substantially increases the amount of computation in terms of FLOPs, we",9.862470626831055,NimbusRomNo9L-Regu,False,107.25299835205078,618.2274169921875,0.04081632653061224,98,H3
sample_8.pdf,7,exclude ALBERT from the following results as it is hard to lead to scientiﬁc conclusions. To obtain,9.95761775970459,NimbusRomNo9L-Regu,False,108.0,629.064208984375,0.0707070707070707,99,H3
sample_8.pdf,7,"relatively fair comparison with RoBERTa, the experiment in this section is based on full data and",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,639.894287109375,0.05154639175257732,97,H3
sample_8.pdf,7,"reuses the hyper-parameters of RoBERTa, as described in section 3.1.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,650.8784790039062,0.07352941176470588,68,H3
sample_8.pdf,7,"The results are presented in Tables 2 (reading comprehension & document ranking), 3 (question",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,667.1922607421875,0.021505376344086023,93,H3
sample_8.pdf,7,"answering), 4 (text classiﬁcation) and 5 (natural language understanding), where XLNet generally",10.046924591064453,NimbusRomNo9L-Regu,False,108.0,678.1124877929688,0.03125,96,H3
sample_8.pdf,7,"outperforms BERT and RoBERTa. In addition, we make two more interesting observations:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,689.08544921875,0.11764705882352941,85,H3
sample_8.pdf,7,Hyperparameters for pretraining and ﬁnetuning are in Appendix A.4.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13999938964844,713.199951171875,0.045454545454545456,66,P
sample_8.pdf,8,SQuAD2.0,8.966400146484375,NimbusRomNo9L-Medi,False,169.41400146484375,75.67609405517578,0.5,8,P
sample_8.pdf,8,SQuAD1.1,8.966400146484375,NimbusRomNo9L-Medi,False,307.8819885253906,75.67609405517578,0.5,8,P
sample_8.pdf,8,Dev set results (single model),8.966400146484375,NimbusRomNo9L-ReguItal,False,169.41400146484375,90.5631332397461,0.03333333333333333,30,P
sample_8.pdf,8,BERT [10],8.966400146484375,NimbusRomNo9L-Regu,False,169.41400146484375,100.68392944335938,0.4444444444444444,9,P
sample_8.pdf,8,78.98,8.966400146484375,NimbusRomNo9L-Regu,False,236.8951416015625,100.68392944335938,0.0,5,P
sample_8.pdf,8,81.77,8.966400146484375,NimbusRomNo9L-Regu,False,273.513916015625,100.68392944335938,0.0,5,P
sample_8.pdf,8,BERT,8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,100.68399047851562,1.0,4,P
sample_8.pdf,8,[10],8.966400146484375,NimbusRomNo9L-Regu,False,334.3596496582031,100.68399047851562,0.0,4,P
sample_8.pdf,8,84.1,8.966400146484375,NimbusRomNo9L-Regu,False,379.6556396484375,100.68399047851562,0.0,4,P
sample_8.pdf,8,90.9,8.966400146484375,NimbusRomNo9L-Regu,False,420.3631286621094,100.68399047851562,0.0,4,P
sample_8.pdf,8,RoBERTa [21],8.966400146484375,NimbusRomNo9L-Regu,False,169.41400146484375,110.64700317382812,0.4166666666666667,12,P
sample_8.pdf,8,86.5,8.966400146484375,NimbusRomNo9L-Regu,False,239.13673400878906,110.64700317382812,0.0,4,P
sample_8.pdf,8,89.4,8.966400146484375,NimbusRomNo9L-Regu,False,275.7554931640625,110.64700317382812,0.0,4,P
sample_8.pdf,8,RoBERTa [21],8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,110.64700317382812,0.4166666666666667,12,P
sample_8.pdf,8,88.9,8.966400146484375,NimbusRomNo9L-Regu,False,379.6580505371094,110.64700317382812,0.0,4,P
sample_8.pdf,8,94.6,8.966400146484375,NimbusRomNo9L-Regu,False,420.3655090332031,110.64700317382812,0.0,4,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,169.4139862060547,120.60897827148438,0.6,5,P
sample_8.pdf,8,87.9,8.966400146484375,NimbusRomNo9L-Medi,False,239.13998413085938,120.52710723876953,0.0,4,P
sample_8.pdf,8,90.6,8.966400146484375,NimbusRomNo9L-Medi,False,275.74981689453125,120.52710723876953,0.0,4,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,120.60897827148438,0.6,5,P
sample_8.pdf,8,89.7,8.966400146484375,NimbusRomNo9L-Medi,False,379.6549987792969,120.52710723876953,0.0,4,P
sample_8.pdf,8,95.1,8.966400146484375,NimbusRomNo9L-Medi,False,420.3624572753906,120.52710723876953,0.0,4,P
sample_8.pdf,8,"Test set results on leaderboard (single model, as of Dec 14, 2019)",8.966400146484375,NimbusRomNo9L-ReguItal,False,169.41400146484375,135.4141387939453,0.030303030303030304,66,P
sample_8.pdf,8,BERT [10],8.966400146484375,NimbusRomNo9L-Regu,False,169.41400146484375,145.53598022460938,0.4444444444444444,9,P
sample_8.pdf,8,80.005,8.966400146484375,NimbusRomNo9L-Regu,False,234.65353393554688,145.53598022460938,0.0,6,P
sample_8.pdf,8,83.061,8.966400146484375,NimbusRomNo9L-Regu,False,271.2723388671875,145.53598022460938,0.0,6,P
sample_8.pdf,8,BERT [10],8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,145.53598022460938,0.4444444444444444,9,P
sample_8.pdf,8,85.083,8.966400146484375,NimbusRomNo9L-Regu,False,375.17486572265625,145.53598022460938,0.0,6,P
sample_8.pdf,8,91.835,8.966400146484375,NimbusRomNo9L-Regu,False,415.88238525390625,145.53598022460938,0.0,6,P
sample_8.pdf,8,RoBERTa [21],8.966400146484375,NimbusRomNo9L-Regu,False,169.4139862060547,155.49795532226562,0.4166666666666667,12,P
sample_8.pdf,8,86.820,8.966400146484375,NimbusRomNo9L-Regu,False,234.6535186767578,155.49795532226562,0.0,6,P
sample_8.pdf,8,89.795,8.966400146484375,NimbusRomNo9L-Regu,False,271.27227783203125,155.49795532226562,0.0,6,P
sample_8.pdf,8,BERT,8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,155.49795532226562,1.0,4,P
sample_8.pdf,8,[10],8.966400146484375,NimbusRomNo9L-Regu,False,336.82098388671875,155.49795532226562,0.0,4,P
sample_8.pdf,8,87.433,8.966400146484375,NimbusRomNo9L-Regu,False,375.1702880859375,155.49795532226562,0.0,6,P
sample_8.pdf,8,93.294,8.966400146484375,NimbusRomNo9L-Regu,False,415.8778076171875,155.49795532226562,0.0,6,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,169.4139862060547,165.46096801757812,0.6,5,P
sample_8.pdf,8,87.926,8.966400146484375,NimbusRomNo9L-Medi,False,234.65597534179688,165.3791046142578,0.0,6,P
sample_8.pdf,8,90.689,8.966400146484375,NimbusRomNo9L-Medi,False,271.26580810546875,165.3791046142578,0.0,6,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,307.8819885253906,165.46096801757812,0.6,5,P
sample_8.pdf,8,89.898,8.966400146484375,NimbusRomNo9L-Medi,False,373.1239929199219,165.3791046142578,0.0,6,P
sample_8.pdf,8,95.080,8.966400146484375,NimbusRomNo9L-Medi,False,413.8320007324219,165.3791046142578,0.0,6,P
sample_8.pdf,8,Table 3:,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,177.76730346679688,0.125,8,H3
sample_8.pdf,8,"Results on SQuAD, a reading comprehension dataset.",9.055620193481445,NimbusRomNo9L-Regu,False,140.99139404296875,178.5303192138672,0.1,50,P
sample_8.pdf,8,marks our runs with the ofﬁcial code.,9.055620193481445,NimbusRomNo9L-Regu,False,352.9316711425781,178.5303192138672,0.0,37,P
sample_8.pdf,8,indicates ensembles.,9.055620193481445,NimbusRomNo9L-Regu,False,108.0,188.4933319091797,0.0,20,P
sample_8.pdf,8,: We are not able to obtain the test results of our latest model on SQuAD1.1 from the,9.055620193481445,NimbusRomNo9L-Regu,False,190.7449951171875,188.4933319091797,0.058823529411764705,85,P
sample_8.pdf,8,"organizers after submitting our result for more than one month, and thus report the results of an older version for",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,198.59132385253906,0.0,115,P
sample_8.pdf,8,the SQuAD1.1 test set.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,208.48599243164062,0.18181818181818182,22,P
sample_8.pdf,8,Model,8.966400146484375,NimbusRomNo9L-Medi,False,127.48300170898438,243.8931427001953,0.2,5,P
sample_8.pdf,8,IMDB,8.966400146484375,NimbusRomNo9L-Medi,False,211.8030242919922,243.8931427001953,1.0,4,P
sample_8.pdf,8,Yelp-2,8.966400146484375,NimbusRomNo9L-Medi,False,248.17074584960938,243.8931427001953,0.16666666666666666,6,P
sample_8.pdf,8,Yelp-5,8.966400146484375,NimbusRomNo9L-Medi,False,284.52947998046875,243.8931427001953,0.16666666666666666,6,P
sample_8.pdf,8,DBpedia,8.966400146484375,NimbusRomNo9L-Medi,False,320.88824462890625,243.8931427001953,0.2857142857142857,7,P
sample_8.pdf,8,Amazon-2,8.966400146484375,NimbusRomNo9L-Medi,False,393.8747253417969,243.8931427001953,0.125,8,P
sample_8.pdf,8,Amazon-5,8.966400146484375,NimbusRomNo9L-Medi,False,445.17156982421875,243.8931427001953,0.125,8,P
sample_8.pdf,8,CNN [15],8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,258.9379577636719,0.375,8,P
sample_8.pdf,8,2.90,8.966400146484375,NimbusRomNo9L-Regu,False,252.52842712402344,258.9379577636719,0.0,4,P
sample_8.pdf,8,32.39,8.966400146484375,NimbusRomNo9L-Regu,False,286.6456298828125,258.9379577636719,0.0,5,P
sample_8.pdf,8,0.84,8.966400146484375,NimbusRomNo9L-Regu,False,329.7381896972656,258.9379577636719,0.0,4,P
sample_8.pdf,8,6.57,8.966400146484375,NimbusRomNo9L-Regu,False,366.2314453125,258.9379577636719,0.0,4,P
sample_8.pdf,8,3.79,8.966400146484375,NimbusRomNo9L-Regu,False,405.7015686035156,258.9379577636719,0.0,4,P
sample_8.pdf,8,36.24,8.966400146484375,NimbusRomNo9L-Regu,False,454.7567443847656,258.9379577636719,0.0,5,P
sample_8.pdf,8,DPCNN [15],8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,268.9009704589844,0.5,10,P
sample_8.pdf,8,2.64,8.966400146484375,NimbusRomNo9L-Regu,False,252.52842712402344,268.9009704589844,0.0,4,P
sample_8.pdf,8,30.58,8.966400146484375,NimbusRomNo9L-Regu,False,286.6456298828125,268.9009704589844,0.0,5,P
sample_8.pdf,8,0.88,8.966400146484375,NimbusRomNo9L-Regu,False,329.7381896972656,268.9009704589844,0.0,4,P
sample_8.pdf,8,6.87,8.966400146484375,NimbusRomNo9L-Regu,False,366.2314453125,268.9009704589844,0.0,4,P
sample_8.pdf,8,3.32,8.966400146484375,NimbusRomNo9L-Regu,False,405.7015686035156,268.9009704589844,0.0,4,P
sample_8.pdf,8,34.81,8.966400146484375,NimbusRomNo9L-Regu,False,454.7567443847656,268.9009704589844,0.0,5,P
sample_8.pdf,8,"Mixed VAT [31, 23]",8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,278.86297607421875,0.2222222222222222,18,P
sample_8.pdf,8,4.32,8.966400146484375,NimbusRomNo9L-Regu,False,216.16070556640625,278.86297607421875,0.0,4,P
sample_8.pdf,8,0.70,8.966400146484375,NimbusRomNo9L-Regu,False,329.73809814453125,278.86297607421875,0.0,4,P
sample_8.pdf,8,4.95,8.966400146484375,NimbusRomNo9L-Regu,False,366.23138427734375,278.86297607421875,0.0,4,P
sample_8.pdf,8,ULMFiT [14],8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,288.82598876953125,0.45454545454545453,11,P
sample_8.pdf,8,4.6,8.966400146484375,NimbusRomNo9L-Regu,False,218.40231323242188,288.82598876953125,0.0,3,P
sample_8.pdf,8,2.16,8.966400146484375,NimbusRomNo9L-Regu,False,252.52842712402344,288.82598876953125,0.0,4,P
sample_8.pdf,8,29.98,8.966400146484375,NimbusRomNo9L-Regu,False,286.6456298828125,288.82598876953125,0.0,5,P
sample_8.pdf,8,0.80,8.966400146484375,NimbusRomNo9L-Regu,False,329.7381896972656,288.82598876953125,0.0,4,P
sample_8.pdf,8,5.01,8.966400146484375,NimbusRomNo9L-Regu,False,366.2314453125,288.82598876953125,0.0,4,P
sample_8.pdf,8,BERT [35],8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,298.78900146484375,0.4444444444444444,9,P
sample_8.pdf,8,4.51,8.966400146484375,NimbusRomNo9L-Regu,False,216.16070556640625,298.78900146484375,0.0,4,P
sample_8.pdf,8,1.89,8.966400146484375,NimbusRomNo9L-Regu,False,252.52841186523438,298.78900146484375,0.0,4,P
sample_8.pdf,8,29.32,8.966400146484375,NimbusRomNo9L-Regu,False,286.64556884765625,298.78900146484375,0.0,5,P
sample_8.pdf,8,0.64,8.966400146484375,NimbusRomNo9L-Regu,False,329.7381286621094,298.78900146484375,0.0,4,P
sample_8.pdf,8,2.63,8.966400146484375,NimbusRomNo9L-Regu,False,405.70147705078125,298.78900146484375,0.0,4,P
sample_8.pdf,8,34.17,8.966400146484375,NimbusRomNo9L-Regu,False,454.7566833496094,298.78900146484375,0.0,5,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,127.48300170898438,313.7519836425781,0.6,5,P
sample_8.pdf,8,3.20,8.966400146484375,NimbusRomNo9L-Medi,False,216.16299438476562,313.67010498046875,0.0,4,P
sample_8.pdf,8,1.37,8.966400146484375,NimbusRomNo9L-Medi,False,252.52174377441406,313.67010498046875,0.0,4,P
sample_8.pdf,8,27.05,8.966400146484375,NimbusRomNo9L-Medi,False,286.6478576660156,313.67010498046875,0.0,5,P
sample_8.pdf,8,0.60,8.966400146484375,NimbusRomNo9L-Medi,False,329.7314147949219,313.67010498046875,0.0,4,P
sample_8.pdf,8,4.45,8.966400146484375,NimbusRomNo9L-Medi,False,366.22467041015625,313.67010498046875,0.0,4,P
sample_8.pdf,8,2.11,8.966400146484375,NimbusRomNo9L-Medi,False,405.7037658691406,313.67010498046875,0.0,4,P
sample_8.pdf,8,31.67,8.966400146484375,NimbusRomNo9L-Medi,False,454.7589416503906,313.67010498046875,0.0,5,P
sample_8.pdf,8,Table 4:,9.977532386779785,NimbusRomNo9L-Regu,False,107.69100189208984,326.12213134765625,0.125,8,H3
sample_8.pdf,8,Comparison with state-of-the-art error rates on the test sets of several text classiﬁcation datasets. All,8.979839324951172,NimbusRomNo9L-Regu,False,139.91677856445312,326.8787841796875,0.01904761904761905,105,P
sample_8.pdf,8,BERT and XLNet results are obtained with a 24-layer architecture with similar model sizes (aka BERT-Large).,8.943955421447754,NimbusRomNo9L-Regu,False,108.0,336.8690185546875,0.11214953271028037,107,P
sample_8.pdf,8,Model,8.966400146484375,NimbusRomNo9L-Medi,False,113.97799682617188,372.25811767578125,0.2,5,P
sample_8.pdf,8,MNLI,8.966400146484375,NimbusRomNo9L-Medi,False,190.2372283935547,372.25811767578125,1.0,4,P
sample_8.pdf,8,QNLI,8.966400146484375,NimbusRomNo9L-Medi,False,233.29388427734375,372.25811767578125,1.0,4,P
sample_8.pdf,8,QQP,8.966400146484375,NimbusRomNo9L-Medi,False,268.2628479003906,372.25811767578125,1.0,3,P
sample_8.pdf,8,RTE,8.966400146484375,NimbusRomNo9L-Medi,False,299.743896484375,372.25811767578125,1.0,3,P
sample_8.pdf,8,SST-2,8.966400146484375,NimbusRomNo9L-Medi,False,329.7813720703125,372.25811767578125,0.6,5,P
sample_8.pdf,8,MRPC,8.966400146484375,NimbusRomNo9L-Medi,False,364.32891845703125,372.25811767578125,1.0,4,P
sample_8.pdf,8,CoLA,8.966400146484375,NimbusRomNo9L-Medi,False,403.1714172363281,372.25811767578125,0.75,4,P
sample_8.pdf,8,STS-B,8.966400146484375,NimbusRomNo9L-Medi,False,438.534912109375,372.25811767578125,0.8,5,P
sample_8.pdf,8,WNLI,8.966400146484375,NimbusRomNo9L-Medi,False,475.4137268066406,372.25811767578125,1.0,4,P
sample_8.pdf,8,Single-task single models on dev,8.966400146484375,NimbusRomNo9L-ReguItal,False,113.97799682617188,387.1451721191406,0.03125,32,P
sample_8.pdf,8,BERT [2],8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,397.2669982910156,0.5,8,P
sample_8.pdf,8,86.6/-,8.966400146484375,NimbusRomNo9L-Regu,False,191.8511962890625,397.2669982910156,0.0,6,P
sample_8.pdf,8,92.3,8.966400146484375,NimbusRomNo9L-Regu,False,236.90736389160156,397.2669982910156,0.0,4,P
sample_8.pdf,8,91.3,8.966400146484375,NimbusRomNo9L-Regu,False,270.1368408203125,397.2669982910156,0.0,4,P
sample_8.pdf,8,70.4,8.966400146484375,NimbusRomNo9L-Regu,False,300.93646240234375,397.2669982910156,0.0,4,P
sample_8.pdf,8,93.2,8.966400146484375,NimbusRomNo9L-Regu,False,333.23345947265625,397.2669982910156,0.0,4,P
sample_8.pdf,8,88.0,8.966400146484375,NimbusRomNo9L-Regu,False,369.9239807128906,397.2669982910156,0.0,4,P
sample_8.pdf,8,60.6,8.966400146484375,NimbusRomNo9L-Regu,False,407.035888671875,397.2669982910156,0.0,4,P
sample_8.pdf,8,90.0,8.966400146484375,NimbusRomNo9L-Regu,False,443.152587890625,397.2669982910156,0.0,4,P
sample_8.pdf,8,RoBERTa [21],8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,407.22900390625,0.4166666666666667,12,P
sample_8.pdf,8,90.2/90.2,8.966400146484375,NimbusRomNo9L-Regu,False,185.5029754638672,407.22900390625,0.0,9,P
sample_8.pdf,8,94.7,8.966400146484375,NimbusRomNo9L-Regu,False,236.9073486328125,407.22900390625,0.0,4,P
sample_8.pdf,8,92.2,8.966400146484375,NimbusRomNo9L-Regu,False,270.1368408203125,407.22900390625,0.0,4,P
sample_8.pdf,8,86.6,8.966400146484375,NimbusRomNo9L-Medi,False,300.93798828125,407.1471252441406,0.0,4,P
sample_8.pdf,8,96.4,8.966400146484375,NimbusRomNo9L-Regu,False,333.22900390625,407.22900390625,0.0,4,P
sample_8.pdf,8,90.9,8.966400146484375,NimbusRomNo9L-Medi,False,369.9259948730469,407.1471252441406,0.0,4,P
sample_8.pdf,8,68.0,8.966400146484375,NimbusRomNo9L-Regu,False,407.031982421875,407.22900390625,0.0,4,P
sample_8.pdf,8,92.4,8.966400146484375,NimbusRomNo9L-Regu,False,443.148681640625,407.22900390625,0.0,4,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,417.1920166015625,0.6,5,P
sample_8.pdf,8,90.8/90.8,8.966400146484375,NimbusRomNo9L-Medi,False,185.5019989013672,417.1101379394531,0.0,9,P
sample_8.pdf,8,94.9,8.966400146484375,NimbusRomNo9L-Medi,False,236.9063720703125,417.1101379394531,0.0,4,P
sample_8.pdf,8,92.3,8.966400146484375,NimbusRomNo9L-Medi,False,270.1358642578125,417.1101379394531,0.0,4,P
sample_8.pdf,8,85.9,8.966400146484375,NimbusRomNo9L-Regu,False,300.93798828125,417.1920166015625,0.0,4,P
sample_8.pdf,8,97.0,8.966400146484375,NimbusRomNo9L-Medi,False,333.22900390625,417.1101379394531,0.0,4,P
sample_8.pdf,8,90.8,8.966400146484375,NimbusRomNo9L-Regu,False,369.9259948730469,417.1920166015625,0.0,4,P
sample_8.pdf,8,69.0,8.966400146484375,NimbusRomNo9L-Medi,False,407.031982421875,417.1101379394531,0.0,4,P
sample_8.pdf,8,92.5,8.966400146484375,NimbusRomNo9L-Medi,False,443.148681640625,417.1101379394531,0.0,4,P
sample_8.pdf,8,"Multi-task ensembles on test (from leaderboard as of Oct 28, 2019)",8.966400146484375,NimbusRomNo9L-ReguItal,False,113.97799682617188,431.99615478515625,0.030303030303030304,66,P
sample_8.pdf,8,MT-DNN,8.966400146484375,NimbusRomNo9L-Regu,False,113.97799682617188,442.11798095703125,0.8333333333333334,6,P
sample_8.pdf,8,[20],8.966400146484375,NimbusRomNo9L-Regu,False,155.56800842285156,442.11798095703125,0.0,4,P
sample_8.pdf,8,87.9/87.4,8.966400146484375,NimbusRomNo9L-Regu,False,185.4978485107422,442.11798095703125,0.0,9,P
sample_8.pdf,8,96.0,8.966400146484375,NimbusRomNo9L-Regu,False,236.91119384765625,442.11798095703125,0.0,4,P
sample_8.pdf,8,89.9,8.966400146484375,NimbusRomNo9L-Regu,False,270.1317138671875,442.11798095703125,0.0,4,P
sample_8.pdf,8,86.3,8.966400146484375,NimbusRomNo9L-Regu,False,300.9402770996094,442.11798095703125,0.0,4,P
sample_8.pdf,8,96.5,8.966400146484375,NimbusRomNo9L-Regu,False,333.228271484375,442.11798095703125,0.0,4,P
sample_8.pdf,8,92.7,8.966400146484375,NimbusRomNo9L-Regu,False,369.9277648925781,442.11798095703125,0.0,4,P
sample_8.pdf,8,68.4,8.966400146484375,NimbusRomNo9L-Regu,False,407.0307312011719,442.11798095703125,0.0,4,P
sample_8.pdf,8,91.1,8.966400146484375,NimbusRomNo9L-Regu,False,443.1563415527344,442.11798095703125,0.0,4,P
sample_8.pdf,8,89.0,8.966400146484375,NimbusRomNo9L-Regu,False,480.0172119140625,442.11798095703125,0.0,4,P
sample_8.pdf,8,RoBERTa,8.966400146484375,NimbusRomNo9L-Regu,False,113.97801208496094,452.08099365234375,0.7142857142857143,7,P
sample_8.pdf,8,[21],8.966400146484375,NimbusRomNo9L-Regu,False,156.64401245117188,452.08099365234375,0.0,4,P
sample_8.pdf,8,90.8/90.2,8.966400146484375,NimbusRomNo9L-Regu,False,185.4978790283203,452.08099365234375,0.0,9,P
sample_8.pdf,8,98.9,8.966400146484375,NimbusRomNo9L-Regu,False,236.91122436523438,452.08099365234375,0.0,4,P
sample_8.pdf,8,90.2,8.966400146484375,NimbusRomNo9L-Regu,False,270.1317443847656,452.08099365234375,0.0,4,P
sample_8.pdf,8,88.2,8.966400146484375,NimbusRomNo9L-Regu,False,300.9402770996094,452.08099365234375,0.0,4,P
sample_8.pdf,8,96.7,8.966400146484375,NimbusRomNo9L-Regu,False,333.228271484375,452.08099365234375,0.0,4,P
sample_8.pdf,8,92.3,8.966400146484375,NimbusRomNo9L-Regu,False,369.9277648925781,452.08099365234375,0.0,4,P
sample_8.pdf,8,67.8,8.966400146484375,NimbusRomNo9L-Regu,False,407.0307312011719,452.08099365234375,0.0,4,P
sample_8.pdf,8,92.2,8.966400146484375,NimbusRomNo9L-Regu,False,443.1563415527344,452.08099365234375,0.0,4,P
sample_8.pdf,8,89.0,8.966400146484375,NimbusRomNo9L-Regu,False,480.0172119140625,452.08099365234375,0.0,4,P
sample_8.pdf,8,XLNet,8.966400146484375,NimbusRomNo9L-Regu,False,113.97801208496094,463.0299987792969,0.6,5,P
sample_8.pdf,8,90.9/90.9,8.966400146484375,NimbusRomNo9L-Medi,False,183.53701782226562,462.9481201171875,0.0,9,P
sample_8.pdf,8,99.0,8.966400146484375,NimbusRomNo9L-Medi,False,234.9450225830078,462.9481201171875,0.0,4,P
sample_8.pdf,8,90.4,8.966400146484375,NimbusRomNo9L-Medi,False,268.16900634765625,462.9481201171875,0.0,4,P
sample_8.pdf,8,88.5,8.966400146484375,NimbusRomNo9L-Medi,False,300.93798828125,462.9481201171875,0.0,4,P
sample_8.pdf,8,97.1,8.966400146484375,NimbusRomNo9L-Medi,False,331.26239013671875,462.9481201171875,0.0,4,P
sample_8.pdf,8,92.9,8.966400146484375,NimbusRomNo9L-Medi,False,369.9259948730469,462.9481201171875,0.0,4,P
sample_8.pdf,8,70.2,8.966400146484375,NimbusRomNo9L-Medi,False,407.0289611816406,462.9481201171875,0.0,4,P
sample_8.pdf,8,93.0,8.966400146484375,NimbusRomNo9L-Medi,False,443.1545715332031,462.9481201171875,0.0,4,P
sample_8.pdf,8,92.5,8.966400146484375,NimbusRomNo9L-Medi,False,480.01544189453125,462.9481201171875,0.0,4,P
sample_8.pdf,8,Table 5:,10.002370834350586,NimbusRomNo9L-Regu,False,107.69100189208984,475.3813171386719,0.125,8,H3
sample_8.pdf,8,Results on GLUE.,9.00219440460205,NimbusRomNo9L-Regu,False,140.04730224609375,476.13983154296875,0.3125,16,P
sample_8.pdf,8,"indicates using ensembles, and",9.00219440460205,NimbusRomNo9L-Regu,False,218.6750030517578,476.13983154296875,0.0,30,P
sample_8.pdf,8,denotes single-task results in a multi-task row.,9.00219440460205,NimbusRomNo9L-Regu,False,336.37567138671875,476.13983154296875,0.0,48,P
sample_8.pdf,8,All dev results are the median of 10 runs. The upper section shows direct comparison on dev data and the lower,8.916949272155762,NimbusRomNo9L-Regu,False,107.677001953125,486.1664733886719,0.01818181818181818,110,P
sample_8.pdf,8,section shows comparison with state-of-the-art results on the public leaderboard.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,496.09197998046875,0.0,81,P
sample_8.pdf,8,"For explicit reasoning tasks like SQuAD and RACE that involve longer context, the performance",9.96757984161377,NimbusRomNo9L-Regu,False,112.9813003540039,538.1956787109375,0.0967741935483871,93,H3
sample_8.pdf,8,gain of XLNet is usually larger. This superiority at dealing with longer context could come from,9.987475395202637,NimbusRomNo9L-Regu,False,117.96299743652344,549.089599609375,0.041666666666666664,96,H3
sample_8.pdf,8,the Transformer-XL backbone in XLNet.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,560.0174560546875,0.16216216216216217,37,H3
sample_8.pdf,8,"For classiﬁcation tasks that already have abundant supervised examples such as MNLI (>390K),",10.017244338989258,NimbusRomNo9L-Regu,False,112.9813003540039,574.384033203125,0.06521739130434782,92,H3
sample_8.pdf,8,"Yelp (>560K) and Amazon (>3M), XLNet still lead to substantial gains.",9.962599754333496,NimbusRomNo9L-Regu,False,117.38500213623047,585.33447265625,0.10144927536231885,69,H3
sample_8.pdf,8,3.4,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,613.091552734375,0.0,3,H3
sample_8.pdf,8,Ablation Study,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,613.091552734375,0.14285714285714285,14,H3
sample_8.pdf,8,We perform an ablation study to understand the importance of each design choice based on four,10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,634.437255859375,0.010752688172043012,93,H3
sample_8.pdf,8,"datasets with diverse characteristics. Speciﬁcally, there are three main aspects we hope to study:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,645.4214477539062,0.01020408163265306,98,H3
sample_8.pdf,8,"The effectiveness of the permutation language modeling objective alone, especially compared to",9.997407913208008,NimbusRomNo9L-Regu,False,112.9813003540039,661.7840576171875,0.010638297872340425,94,H3
sample_8.pdf,8,the denoising auto-encoding objective used by BERT.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,672.719482421875,0.0784313725490196,51,H3
sample_8.pdf,8,The importance of using Transformer-XL as the backbone neural architecture.,9.962599754333496,NimbusRomNo9L-Regu,False,112.9813003540039,687.12744140625,0.05333333333333334,75,H3
sample_8.pdf,8,"The necessity of some implementation details including span-based prediction, the bidirectional",10.017244338989258,NimbusRomNo9L-Regu,False,112.9813003540039,701.4940185546875,0.010526315789473684,95,H3
sample_8.pdf,8,"input pipeline, and next-sentence prediction.",9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,712.4444580078125,0.0,45,H3
sample_8.pdf,9,"With these purposes in mind, in Table 6, we compare 6 XLNet-Base variants with different implemen-",9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,74.4834213256836,0.061224489795918366,98,H3
sample_8.pdf,9,"tation details (rows 3 - 8), the original BERT-Base model (row 1), and an additional Transformer-XL",9.89763069152832,NimbusRomNo9L-Regu,False,108.0,85.36575317382812,0.08080808080808081,99,H3
sample_8.pdf,9,baseline trained with the denoising auto-encoding (DAE) objective used in BERT but with the bidi-,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,96.20661163330078,0.07216494845360824,97,H3
sample_8.pdf,9,"rectional input pipeline (row 2). For fair comparison, all models are based on a 12-layer architecture",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,107.16854858398438,0.00980392156862745,102,H3
sample_8.pdf,9,with the same model hyper-parameters as BERT-Base and are trained on only Wikipedia and the,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,117.96829223632812,0.06593406593406594,91,H3
sample_8.pdf,9,BooksCorpus. All results reported are the median of 5 runs.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,128.9524688720703,0.05084745762711865,59,H3
sample_8.pdf,9,Model,8.966400146484375,NimbusRomNo9L-Medi,False,175.5484161376953,153.35011291503906,0.2,5,P
sample_8.pdf,9,RACE,8.966400146484375,NimbusRomNo9L-Medi,False,274.37200927734375,153.35011291503906,1.0,4,P
sample_8.pdf,9,SQuAD2.0,8.966400146484375,NimbusRomNo9L-Medi,False,316.8369140625,153.35011291503906,0.5,8,P
sample_8.pdf,9,MNLI,8.966400146484375,NimbusRomNo9L-Medi,False,384.71258544921875,153.35011291503906,1.0,4,P
sample_8.pdf,9,SST-2,8.966400146484375,NimbusRomNo9L-Medi,False,430.288818359375,153.35011291503906,0.6,5,P
sample_8.pdf,9,m/mm,8.966400146484375,NimbusRomNo9L-Regu,False,385.2088317871094,163.39498901367188,0.0,4,P
sample_8.pdf,9,BERT-Base,8.966400146484375,NimbusRomNo9L-Regu,False,175.5484161376953,178.35800170898438,0.5555555555555556,9,P
sample_8.pdf,9,64.3,8.966400146484375,NimbusRomNo9L-Regu,False,278.9809875488281,178.35800170898438,0.0,4,P
sample_8.pdf,9,76.30,8.966400146484375,NimbusRomNo9L-Regu,False,311.2331237792969,178.35800170898438,0.0,5,P
sample_8.pdf,9,73.66,8.966400146484375,NimbusRomNo9L-Regu,False,343.36871337890625,178.35800170898438,0.0,5,P
sample_8.pdf,9,84.34/84.65,8.966400146484375,NimbusRomNo9L-Regu,False,375.495361328125,178.35800170898438,0.0,11,P
sample_8.pdf,9,92.78,8.966400146484375,NimbusRomNo9L-Regu,False,431.4995422363281,178.35800170898438,0.0,5,P
sample_8.pdf,9,DAE + Transformer-XL,8.966400146484375,NimbusRomNo9L-Regu,False,175.54840087890625,188.32101440429688,0.3,20,P
sample_8.pdf,9,65.03,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,188.32095336914062,0.0,5,P
sample_8.pdf,9,79.56,8.966400146484375,NimbusRomNo9L-Regu,False,311.2337646484375,188.32095336914062,0.0,5,P
sample_8.pdf,9,76.80,8.966400146484375,NimbusRomNo9L-Regu,False,343.369384765625,188.32095336914062,0.0,5,P
sample_8.pdf,9,84.88/84.45,8.966400146484375,NimbusRomNo9L-Regu,False,375.49603271484375,188.32095336914062,0.0,11,P
sample_8.pdf,9,92.60,8.966400146484375,NimbusRomNo9L-Regu,False,431.5002136230469,188.32095336914062,0.0,5,P
sample_8.pdf,9,XLNet-Base (,8.966400146484375,NimbusRomNo9L-Regu,False,175.54840087890625,198.28292846679688,0.3333333333333333,12,P
sample_8.pdf,9,= 7,8.966400146484375,CMR9,False,233.89576721191406,198.07542419433594,0.0,3,P
sample_8.pdf,9,66.05,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,198.28298950195312,0.0,5,P
sample_8.pdf,9,81.33,8.966400146484375,NimbusRomNo9L-Medi,False,311.2359924316406,198.2011260986328,0.0,5,P
sample_8.pdf,9,78.46,8.966400146484375,NimbusRomNo9L-Medi,False,343.36260986328125,198.2011260986328,0.0,5,P
sample_8.pdf,9,85.84/85.43,8.966400146484375,NimbusRomNo9L-Medi,False,375.49822998046875,198.2011260986328,0.0,11,P
sample_8.pdf,9,92.66,8.966400146484375,NimbusRomNo9L-Regu,False,431.5019836425781,198.28298950195312,0.0,5,P
sample_8.pdf,9,XLNet-Base (,8.966400146484375,NimbusRomNo9L-Regu,False,175.5483856201172,208.24600219726562,0.3333333333333333,12,P
sample_8.pdf,9,= 6,8.966400146484375,CMR9,False,233.89573669433594,208.0384979248047,0.0,3,P
sample_8.pdf,9,66.66,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,208.24600219726562,0.0,5,P
sample_8.pdf,9,80.98,8.966400146484375,NimbusRomNo9L-Regu,False,311.2337646484375,208.24600219726562,0.0,5,P
sample_8.pdf,9,78.18,8.966400146484375,NimbusRomNo9L-Regu,False,343.369384765625,208.24600219726562,0.0,5,P
sample_8.pdf,9,85.63/85.12,8.966400146484375,NimbusRomNo9L-Regu,False,375.49603271484375,208.24600219726562,0.0,11,P
sample_8.pdf,9,93.35,8.966400146484375,NimbusRomNo9L-Medi,False,431.5019836425781,208.1641387939453,0.0,5,P
sample_8.pdf,9,- memory,8.966400146484375,NimbusRomNo9L-Regu,False,184.51478576660156,218.20901489257812,0.0,8,P
sample_8.pdf,9,65.55,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,218.20895385742188,0.0,5,P
sample_8.pdf,9,80.15,8.966400146484375,NimbusRomNo9L-Regu,False,311.2337646484375,218.20895385742188,0.0,5,P
sample_8.pdf,9,77.27,8.966400146484375,NimbusRomNo9L-Regu,False,343.369384765625,218.20895385742188,0.0,5,P
sample_8.pdf,9,85.32/85.05,8.966400146484375,NimbusRomNo9L-Regu,False,375.49603271484375,218.20895385742188,0.0,11,P
sample_8.pdf,9,92.78,8.966400146484375,NimbusRomNo9L-Regu,False,431.5002136230469,218.20895385742188,0.0,5,P
sample_8.pdf,9,- span-based pred,8.966400146484375,NimbusRomNo9L-Regu,False,184.51480102539062,228.17092895507812,0.0,17,P
sample_8.pdf,9,65.95,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,228.17098999023438,0.0,5,P
sample_8.pdf,9,80.61,8.966400146484375,NimbusRomNo9L-Regu,False,311.2337646484375,228.17098999023438,0.0,5,P
sample_8.pdf,9,77.91,8.966400146484375,NimbusRomNo9L-Regu,False,343.369384765625,228.17098999023438,0.0,5,P
sample_8.pdf,9,85.49/85.02,8.966400146484375,NimbusRomNo9L-Regu,False,375.49603271484375,228.17098999023438,0.0,11,P
sample_8.pdf,9,93.12,8.966400146484375,NimbusRomNo9L-Regu,False,431.5002136230469,228.17098999023438,0.0,5,P
sample_8.pdf,9,- bidirectional data,8.966400146484375,NimbusRomNo9L-Regu,False,184.51480102539062,238.13400268554688,0.0,20,P
sample_8.pdf,9,66.34,8.966400146484375,NimbusRomNo9L-Regu,False,276.739990234375,238.13400268554688,0.0,5,P
sample_8.pdf,9,80.65,8.966400146484375,NimbusRomNo9L-Regu,False,311.2337646484375,238.13400268554688,0.0,5,P
sample_8.pdf,9,77.87,8.966400146484375,NimbusRomNo9L-Regu,False,343.369384765625,238.13400268554688,0.0,5,P
sample_8.pdf,9,85.31/84.99,8.966400146484375,NimbusRomNo9L-Regu,False,375.49603271484375,238.13400268554688,0.0,11,P
sample_8.pdf,9,92.66,8.966400146484375,NimbusRomNo9L-Regu,False,431.5002136230469,238.13400268554688,0.0,5,P
sample_8.pdf,9,+ next-sent pred,8.966400146484375,NimbusRomNo9L-Regu,False,184.51480102539062,248.09701538085938,0.0,16,P
sample_8.pdf,9,66.76,8.966400146484375,NimbusRomNo9L-Medi,False,276.739990234375,248.0150909423828,0.0,5,P
sample_8.pdf,9,79.83,8.966400146484375,NimbusRomNo9L-Regu,False,311.2359924316406,248.09695434570312,0.0,5,P
sample_8.pdf,9,76.94,8.966400146484375,NimbusRomNo9L-Regu,False,343.36260986328125,248.09695434570312,0.0,5,P
sample_8.pdf,9,85.32/85.09,8.966400146484375,NimbusRomNo9L-Regu,False,375.49822998046875,248.09695434570312,0.0,11,P
sample_8.pdf,9,92.89,8.966400146484375,NimbusRomNo9L-Regu,False,431.5024108886719,248.09695434570312,0.0,5,P
sample_8.pdf,9,Table 6:,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,260.4032897949219,0.125,8,H3
sample_8.pdf,9,The results of BERT on RACE are taken from [,9.055620193481445,NimbusRomNo9L-Regu,False,140.7068634033203,261.16632080078125,0.20454545454545456,44,P
sample_8.pdf,9,]. We run BERT on the other datasets using the,9.055620193481445,NimbusRomNo9L-Regu,False,329.1600036621094,261.16632080078125,0.10869565217391304,46,P
sample_8.pdf,9,ofﬁcial implementation and the same hyperparameter search space as XLNet.,8.934962272644043,NimbusRomNo9L-Regu,False,108.0,271.21978759765625,0.0410958904109589,73,P
sample_8.pdf,9,is a hyperparameter to control,8.934962272644043,NimbusRomNo9L-Regu,False,394.32177734375,271.21978759765625,0.0,30,P
sample_8.pdf,9,the optimization difﬁculty (see Section 2.3).,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,281.15899658203125,0.022222222222222223,45,P
sample_8.pdf,9,"Examining rows 1 - 4 of Table 6, we can see both Transformer-XL and the permutation LM clearly",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,310.1086120605469,0.07446808510638298,94,H3
sample_8.pdf,9,"contribute the superior performance of XLNet over BERT. Moreover, if we remove the memory",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,320.9613037109375,0.0898876404494382,89,H3
sample_8.pdf,9,"caching mechanism (row 5), the performance clearly drops, especially for RACE which involves the",9.9126615524292,NimbusRomNo9L-Regu,False,108.0,331.98333740234375,0.041666666666666664,96,H3
sample_8.pdf,9,"longest context among the 4 tasks. In addition, rows 6 - 7 show that both span-based prediction and",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,342.8544616699219,0.010101010101010102,99,H3
sample_8.pdf,9,"the bidirectional input pipeline play important roles in XLNet. Finally, we unexpectedly ﬁnd the the",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,353.7861633300781,0.04,100,H3
sample_8.pdf,9,next-sentence prediction objective proposed in the original BERT does not necessarily lead to an,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,364.5972900390625,0.041666666666666664,96,H3
sample_8.pdf,9,"improvement in our setting. Hence, we exclude the next-sentence prediction objective from XLNet.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,375.58245849609375,0.041666666666666664,96,H3
sample_8.pdf,9,"Finally, we also perform a qualitative study of the attention patterns, which is included in Appendix",9.95761775970459,NimbusRomNo9L-Regu,False,108.0,391.9742431640625,0.019801980198019802,101,H3
sample_8.pdf,9,A.6 due to page limit.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,402.87945556640625,0.045454545454545456,22,H3
sample_8.pdf,9,Conclusions,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,429.2271423339844,0.09090909090909091,11,H3
sample_8.pdf,9,XLNet is a generalized AR pretraining method that uses a permutation language modeling objective,9.927669525146484,NimbusRomNo9L-Regu,False,107.64099884033203,453.5609436035156,0.052083333333333336,96,H3
sample_8.pdf,9,to combine the advantages of AR and AE methods. The neural architecture of XLNet is developed to,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,464.5194091796875,0.08333333333333333,96,H3
sample_8.pdf,9,"work seamlessly with the AR objective, including integrating Transformer-XL and the careful design",9.882577896118164,NimbusRomNo9L-Regu,False,107.64099884033203,475.4141540527344,0.05102040816326531,98,H3
sample_8.pdf,9,of the two-stream attention mechanism. XLNet achieves substantial improvement over previous,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,486.1872863769531,0.03296703296703297,91,H3
sample_8.pdf,9,pretraining objectives on various tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,497.17144775390625,0.0,40,H3
sample_8.pdf,9,Acknowledgments,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,519.7675170898438,0.06666666666666667,15,H3
sample_8.pdf,9,The authors would like to thank Qizhe Xie and Adams Wei Yu for providing useful feedback on the,9.952631950378418,NimbusRomNo9L-Regu,False,107.69100189208984,538.4960327148438,0.06315789473684211,95,H3
sample_8.pdf,9,"project, Jamie Callan for providing the ClueWeb dataset, Youlong Cheng, Yanping Huang and Shibo",9.89763069152832,NimbusRomNo9L-Regu,False,108.0,549.4467163085938,0.09473684210526316,95,H3
sample_8.pdf,9,"Wang for providing ideas to improve our TPU implementation, Chenyan Xiong and Zhuyun Dai",10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,560.2322998046875,0.09090909090909091,88,H3
sample_8.pdf,9,for clarifying the setting of the document ranking task. ZY and RS were supported by the Ofﬁce of,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,571.1975708007812,0.05154639175257732,97,H3
sample_8.pdf,9,"Naval Research grant N000141812861, the National Science Foundation (NSF) grant IIS1763562,",10.02714729309082,NimbusRomNo9L-Regu,False,108.0,582.0765380859375,0.13186813186813187,91,H3
sample_8.pdf,9,"the Nvidia fellowship, and the Siebel scholarship. ZD and YY were supported in part by NSF under",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,593.05712890625,0.09375,96,H3
sample_8.pdf,9,the grant IIS-1546329 and by the DOE-Ofﬁce of Science under the grant ASCR #KJ040201.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,603.9434814453125,0.16470588235294117,85,H3
sample_8.pdf,9,References,11.9552001953125,NimbusRomNo9L-Medi,False,108.0,630.2911376953125,0.1,10,H3
sample_8.pdf,9,[1],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,650.87548828125,0.0,3,H3
sample_8.pdf,9,"Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, and Llion Jones. Character-level",10.02714729309082,NimbusRomNo9L-Regu,False,124.5973892211914,650.8265380859375,0.1411764705882353,85,H3
sample_8.pdf,9,language modeling with deeper self-attention.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,661.784423828125,0.0,45,H3
sample_8.pdf,9,arXiv preprint arXiv:1808.04444,9.962599754333496,NimbusRomNo9L-ReguItal,False,312.4723205566406,661.6079711914062,0.06451612903225806,31,H3
sample_8.pdf,9,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,448.240966796875,661.784423828125,0.0,7,H3
sample_8.pdf,9,[2],9.962599754333496,NimbusRomNo9L-Regu,False,112.98095703125,676.2054443359375,0.0,3,H3
sample_8.pdf,9,Anonymous. Bam! born-again multi-task networks for natural language understanding. anony-,9.90765380859375,NimbusRomNo9L-Regu,False,124.59734344482422,676.2471313476562,0.02247191011235955,89,H3
sample_8.pdf,9,"mous preprint under review, 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,687.1144409179688,0.0,33,H3
sample_8.pdf,9,[3],9.962599754333496,NimbusRomNo9L-Regu,False,112.98099517822266,701.5354614257812,0.0,3,H3
sample_8.pdf,9,Alexei Baevski and Michael Auli. Adaptive input representations for neural language modeling.,9.862470626831055,NimbusRomNo9L-Regu,False,124.59738159179688,701.6113891601562,0.053763440860215055,93,H3
sample_8.pdf,9,arXiv preprint arXiv:1809.10853,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,712.2680053710938,0.06451612903225806,31,H3
sample_8.pdf,9,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,261.7619934082031,712.4444580078125,0.0,7,H3
sample_8.pdf,10,[4],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,74.40748596191406,0.0,3,H3
sample_8.pdf,10,Yoshua Bengio and Samy Bengio. Modeling high-dimensional discrete data with multi-layer,10.022196769714355,NimbusRomNo9L-Regu,False,124.5973892211914,74.36228942871094,0.05747126436781609,87,H3
sample_8.pdf,10,neural networks. In,9.882577896118164,NimbusRomNo9L-Regu,False,129.57899475097656,85.37716674804688,0.05263157894736842,19,H3
sample_8.pdf,10,Advances in Neural Information Processing Systems,9.882577896118164,NimbusRomNo9L-ReguItal,False,206.57330322265625,85.20211791992188,0.10204081632653061,49,H3
sample_8.pdf,10,", pages 400–406, 2000.",9.882577896118164,NimbusRomNo9L-Regu,False,414.71099853515625,85.37716674804688,0.0,22,H3
sample_8.pdf,10,"[5] Jamie Callan, Mark Hoy, Changkuk Yoo, and Le Zhao. Clueweb09 data set, 2009.",9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,100.11445617675781,0.1125,80,H3
sample_8.pdf,10,[6] Common Crawl. Common crawl.,9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,114.91242980957031,0.0967741935483871,31,H3
sample_8.pdf,10,URl: http://http://commoncrawl. org,9.962599754333496,NimbusRomNo9L-ReguItal,False,263.4859313964844,114.7359619140625,0.05714285714285714,35,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,412.9930419921875,114.91242980957031,0.0,7,H3
sample_8.pdf,10,[7],9.962599754333496,NimbusRomNo9L-Regu,False,112.98104858398438,129.71144104003906,0.0,3,H3
sample_8.pdf,10,Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. In,10.061732292175293,NimbusRomNo9L-Regu,False,124.5974349975586,129.63626098632812,0.12307692307692308,65,H3
sample_8.pdf,10,Advances in neural,10.061732292175293,NimbusRomNo9L-ReguItal,False,422.6368408203125,129.45809936523438,0.05555555555555555,18,H3
sample_8.pdf,10,information processing systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,140.44403076171875,0.0,30,H3
sample_8.pdf,10,", pages 3079–3087, 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,254.76800537109375,140.62049865722656,0.0,24,H3
sample_8.pdf,10,[8],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,155.41847229003906,0.0,3,H3
sample_8.pdf,10,"Zhuyun Dai, Chenyan Xiong, Jamie Callan, and Zhiyuan Liu. Convolutional neural networks",9.992443084716797,NimbusRomNo9L-Regu,False,124.5973892211914,155.39584350585938,0.10344827586206896,87,H3
sample_8.pdf,10,for soft-matching n-grams in ad-hoc search. In,9.927669525146484,NimbusRomNo9L-Regu,False,129.57899475097656,166.3539581298828,0.021739130434782608,46,H3
sample_8.pdf,10,Proceedings of the eleventh ACM international,9.927669525146484,NimbusRomNo9L-ReguItal,False,315.1690368652344,166.17811584472656,0.08888888888888889,45,H3
sample_8.pdf,10,conference on web search and data mining,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,177.05999755859375,0.0,40,H3
sample_8.pdf,10,", pages 126–134. ACM, 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,300.24798583984375,177.23646545410156,0.1111111111111111,27,H3
sample_8.pdf,10,[9],9.962599754333496,NimbusRomNo9L-Regu,False,112.98098754882812,192.0354766845703,0.0,3,H3
sample_8.pdf,10,"Zihang Dai, Zhilin Yang, Yiming Yang, William W Cohen, Jaime Carbonell, Quoc V Le,",10.061732292175293,NimbusRomNo9L-Regu,False,124.59737396240234,191.96029663085938,0.17073170731707318,82,H3
sample_8.pdf,10,and Ruslan Salakhutdinov. Transformer-xl: Attentive language models beyond a ﬁxed-length,10.002370834350586,NimbusRomNo9L-Regu,False,129.57899475097656,202.914306640625,0.045454545454545456,88,H3
sample_8.pdf,10,context.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,213.8534698486328,0.0,8,H3
sample_8.pdf,10,arXiv preprint arXiv:1901.02860,9.962599754333496,NimbusRomNo9L-ReguItal,False,161.25009155273438,213.677001953125,0.06451612903225806,31,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,297.0199890136719,213.8534698486328,0.0,7,H3
sample_8.pdf,10,[10],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,228.6514434814453,0.0,4,H3
sample_8.pdf,10,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of",10.061732292175293,NimbusRomNo9L-Regu,False,124.59767150878906,228.57626342773438,0.12643678160919541,87,H3
sample_8.pdf,10,deep bidirectional transformers for language understanding.,9.947644233703613,NimbusRomNo9L-Regu,False,129.57899475097656,239.57183837890625,0.0,59,H3
sample_8.pdf,10,arXiv preprint arXiv:1810.04805,9.947644233703613,NimbusRomNo9L-ReguItal,False,367.38812255859375,239.39564514160156,0.06451612903225806,31,H3
sample_8.pdf,10,2018.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,250.46949768066406,0.0,5,H3
sample_8.pdf,10,[11],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,265.26849365234375,0.0,4,H3
sample_8.pdf,10,"William Fedus, Ian Goodfellow, and Andrew M Dai. Maskgan: better text generation via ﬁlling",9.862470626831055,NimbusRomNo9L-Regu,False,124.5976791381836,265.3443908691406,0.08791208791208792,91,H3
sample_8.pdf,10,in the_.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,276.1774597167969,0.0,8,H3
sample_8.pdf,10,arXiv preprint arXiv:1801.07736,9.962599754333496,NimbusRomNo9L-ReguItal,False,159.46678161621094,276.0010070800781,0.06451612903225806,31,H3
sample_8.pdf,10,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,295.2359924316406,276.1774597167969,0.0,7,H3
sample_8.pdf,10,[12],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,290.9754638671875,0.0,4,H3
sample_8.pdf,10,"Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle. Made: Masked autoencoder",9.862470626831055,NimbusRomNo9L-Regu,False,124.59768676757812,291.0514221191406,0.11235955056179775,89,H3
sample_8.pdf,10,for distribution estimation. In,9.937662124633789,NimbusRomNo9L-Regu,False,129.57899475097656,301.90338134765625,0.03225806451612903,31,H3
sample_8.pdf,10,International Conference on Machine Learning,9.937662124633789,NimbusRomNo9L-ReguItal,False,247.21400451660156,301.72735595703125,0.09090909090909091,44,H3
sample_8.pdf,10,", pages 881–889,",9.937662124633789,NimbusRomNo9L-Regu,False,438.06201171875,301.90338134765625,0.0,16,H3
sample_8.pdf,10,2015.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,312.79345703125,0.0,5,H3
sample_8.pdf,10,[13],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,327.5914611816406,0.0,4,H3
sample_8.pdf,10,"Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Croft. A deep relevance matching model for",9.862470626831055,NimbusRomNo9L-Regu,False,124.5976791381836,327.66741943359375,0.10989010989010989,91,H3
sample_8.pdf,10,ad-hoc retrieval. In,9.952631950378418,NimbusRomNo9L-Regu,False,129.57899475097656,338.509033203125,0.05,20,H3
sample_8.pdf,10,Proceedings of the 25th ACM International on Conference on Information,9.952631950378418,NimbusRomNo9L-ReguItal,False,206.14761352539062,338.332763671875,0.1,70,H3
sample_8.pdf,10,and Knowledge Management,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,349.2340087890625,0.08333333333333333,24,H3
sample_8.pdf,10,", pages 55–64. ACM, 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,246.052001953125,349.41046142578125,0.12,25,H3
sample_8.pdf,10,[14],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,364.2084655761719,0.0,4,H3
sample_8.pdf,10,Jeremy Howard and Sebastian Ruder. Universal language model ﬁne-tuning for text classiﬁca-,9.947644233703613,NimbusRomNo9L-Regu,False,124.59768676757812,364.2198181152344,0.05555555555555555,90,H3
sample_8.pdf,10,tion.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,375.1174621582031,0.0,5,H3
sample_8.pdf,10,arXiv preprint arXiv:1801.06146,9.962599754333496,NimbusRomNo9L-ReguItal,False,147.57144165039062,374.9410095214844,0.06451612903225806,31,H3
sample_8.pdf,10,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,283.34100341796875,375.1174621582031,0.0,7,H3
sample_8.pdf,10,[15],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,389.91546630859375,0.0,4,H3
sample_8.pdf,10,Rie Johnson and Tong Zhang. Deep pyramid convolutional neural networks for text catego-,10.061732292175293,NimbusRomNo9L-Regu,False,124.59768676757812,389.8403015136719,0.05747126436781609,87,H3
sample_8.pdf,10,rization. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,400.7492980957031,0.08333333333333333,12,H3
sample_8.pdf,10,Proceedings of the 55th Annual Meeting of the Association for Computational,10.061732292175293,NimbusRomNo9L-ReguItal,False,177.32955932617188,400.5710754394531,0.06666666666666667,75,H3
sample_8.pdf,10,Linguistics (Volume 1: Long Papers),9.962599754333496,NimbusRomNo9L-ReguItal,False,129.3000030517578,411.5580139160156,0.11428571428571428,35,H3
sample_8.pdf,10,", pages 562–570, 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,275.66998291015625,411.7344665527344,0.0,22,H3
sample_8.pdf,10,[16],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,426.532470703125,0.0,4,H3
sample_8.pdf,10,"Vid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu, Yordan Yordanov, and Thomas",10.061732292175293,NimbusRomNo9L-Regu,False,124.59767150878906,426.4573059082031,0.14285714285714285,77,H3
sample_8.pdf,10,Lukasiewicz. A surprisingly robust trick for winograd schema challenge.,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,437.3663024902344,0.028169014084507043,71,H3
sample_8.pdf,10,arXiv preprint,10.061732292175293,NimbusRomNo9L-ReguItal,False,437.6661682128906,437.1880798339844,0.07142857142857142,14,H3
sample_8.pdf,10,arXiv:1905.06290,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,448.17401123046875,0.0625,16,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,448.3504638671875,0.0,7,H3
sample_8.pdf,10,[17],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,463.1484680175781,0.0,4,H3
sample_8.pdf,10,Taku Kudo and John Richardson. Sentencepiece: A simple and language independent subword,9.902643203735352,NimbusRomNo9L-Regu,False,124.59767150878906,463.1939392089844,0.06896551724137931,87,H3
sample_8.pdf,10,tokenizer and detokenizer for neural text processing.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,474.0574645996094,0.0,53,H3
sample_8.pdf,10,arXiv preprint arXiv:1808.06226,9.962599754333496,NimbusRomNo9L-ReguItal,False,338.6640319824219,473.8810119628906,0.06451612903225806,31,H3
sample_8.pdf,10,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,474.4329833984375,474.0574645996094,0.0,7,H3
sample_8.pdf,10,[18],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,488.8564758300781,0.0,4,H3
sample_8.pdf,10,"Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. Race: Large-scale",10.061732292175293,NimbusRomNo9L-Regu,False,124.59765625,488.7812805175781,0.14457831325301204,83,H3
sample_8.pdf,10,reading comprehension dataset from examinations.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,499.7654724121094,0.0,48,H3
sample_8.pdf,10,arXiv preprint arXiv:1704.04683,9.962599754333496,NimbusRomNo9L-ReguItal,False,332.7961120605469,499.5890197753906,0.06451612903225806,31,H3
sample_8.pdf,10,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,468.56500244140625,499.7654724121094,0.0,7,H3
sample_8.pdf,10,[19],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,514.5634765625,0.0,4,H3
sample_8.pdf,10,"Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu",9.932666778564453,NimbusRomNo9L-Regu,False,124.59768676757812,514.586181640625,0.13095238095238096,84,H3
sample_8.pdf,10,Soricut. Albert: A lite bert for self-supervised learning of language representations.,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,525.3972778320312,0.03488372093023256,86,H3
sample_8.pdf,10,arXiv,10.061732292175293,NimbusRomNo9L-ReguItal,False,476.0882568359375,525.2190551757812,0.2,5,H3
sample_8.pdf,10,preprint arXiv:1909.11942,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,536.2050170898438,0.04,25,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,237.13499450683594,536.3814697265625,0.0,7,H3
sample_8.pdf,10,[20],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,551.180419921875,0.0,4,H3
sample_8.pdf,10,"Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks",9.862470626831055,NimbusRomNo9L-Regu,False,124.59768676757812,551.25634765625,0.1,90,H3
sample_8.pdf,10,for natural language understanding.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,562.0894775390625,0.0,35,H3
sample_8.pdf,10,arXiv preprint arXiv:1901.11504,9.962599754333496,NimbusRomNo9L-ReguItal,False,271.2371826171875,561.9130249023438,0.06451612903225806,31,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,407.0059814453125,562.0894775390625,0.0,7,H3
sample_8.pdf,10,[21],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,576.887451171875,0.0,4,H3
sample_8.pdf,10,"Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike",9.867501258850098,NimbusRomNo9L-Regu,False,124.59765625,576.9595947265625,0.17045454545454544,88,H3
sample_8.pdf,10,"Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining",9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,587.8723754882812,0.07526881720430108,93,H3
sample_8.pdf,10,approach.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,598.7054443359375,0.0,9,H3
sample_8.pdf,10,arXiv preprint arXiv:1907.11692,9.962599754333496,NimbusRomNo9L-ReguItal,False,168.5825653076172,598.5289916992188,0.06451612903225806,31,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,304.35198974609375,598.7054443359375,0.0,7,H3
sample_8.pdf,10,"[22] Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation:",9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,613.5044555664062,0.10752688172043011,93,H3
sample_8.pdf,10,Contextualized word vectors. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,624.3382568359375,0.06451612903225806,31,H3
sample_8.pdf,10,Advances in Neural Information Processing Systems,10.061732292175293,NimbusRomNo9L-ReguItal,False,260.51446533203125,624.1600341796875,0.10204081632653061,49,H3
sample_8.pdf,10,", pages",10.061732292175293,NimbusRomNo9L-Regu,False,475.8290100097656,624.3382568359375,0.0,7,H3
sample_8.pdf,10,"6294–6305, 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,635.3224487304688,0.0,16,H3
sample_8.pdf,10,[23],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,650.1204833984375,0.0,4,H3
sample_8.pdf,10,"Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semi-",10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,650.0452880859375,0.09195402298850575,87,H3
sample_8.pdf,10,supervised text classiﬁcation.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,661.0294799804688,0.0,30,H3
sample_8.pdf,10,arXiv preprint arXiv:1605.07725,9.962599754333496,NimbusRomNo9L-ReguItal,False,246.4801788330078,660.85302734375,0.06451612903225806,31,H3
sample_8.pdf,10,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,382.2489929199219,661.0294799804688,0.0,7,H3
sample_8.pdf,10,[24],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,675.8274536132812,0.0,4,H3
sample_8.pdf,10,"Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural",10.061732292175293,NimbusRomNo9L-Regu,False,124.59768676757812,675.7522583007812,0.08433734939759036,83,H3
sample_8.pdf,10,networks.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,686.7374267578125,0.0,9,H3
sample_8.pdf,10,arXiv preprint arXiv:1601.06759,9.962599754333496,NimbusRomNo9L-ReguItal,False,168.49290466308594,686.5609741210938,0.06451612903225806,31,H3
sample_8.pdf,10,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,304.2619934082031,686.7374267578125,0.0,7,H3
sample_8.pdf,10,[25],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,701.5354614257812,0.0,4,H3
sample_8.pdf,10,"Xiaoman Pan, Kai Sun, Dian Yu, Heng Ji, and Dong Yu. Improving question answering with",10.02714729309082,NimbusRomNo9L-Regu,False,124.59768676757812,701.4865112304688,0.12790697674418605,86,H3
sample_8.pdf,10,external knowledge.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,712.4444580078125,0.0,19,H3
sample_8.pdf,10,arXiv preprint arXiv:1902.00993,9.962599754333496,NimbusRomNo9L-ReguItal,False,209.96719360351562,712.2680053710938,0.06451612903225806,31,H3
sample_8.pdf,10,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,345.73699951171875,712.4444580078125,0.0,7,H3
sample_8.pdf,11,[26],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,74.40748596191406,0.0,4,H3
sample_8.pdf,11,"Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. English gigaword",10.061732292175293,NimbusRomNo9L-Regu,False,124.59768676757812,74.33230590820312,0.13095238095238096,84,H3
sample_8.pdf,11,"ﬁfth edition, linguistic data consortium.",10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,85.24130249023438,0.0,41,H3
sample_8.pdf,11,"Technical report, Technical Report. Linguistic Data",10.061732292175293,NimbusRomNo9L-ReguItal,False,290.5834655761719,85.06307983398438,0.09803921568627451,51,H3
sample_8.pdf,11,"Consortium, Philadelphia, Tech. Rep.",9.962599754333496,NimbusRomNo9L-ReguItal,False,129.25,96.04901123046875,0.1111111111111111,36,H3
sample_8.pdf,11,", 2011.",9.962599754333496,NimbusRomNo9L-Regu,False,279.00701904296875,96.22547912597656,0.0,7,H3
sample_8.pdf,11,[27],9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,111.11946105957031,0.0,4,H3
sample_8.pdf,11,"Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Ken-",10.061732292175293,NimbusRomNo9L-Regu,False,124.59770202636719,111.04428100585938,0.14634146341463414,82,H3
sample_8.pdf,11,"ton Lee, and Luke Zettlemoyer. Deep contextualized word representations.",10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,121.95327758789062,0.05555555555555555,72,H3
sample_8.pdf,11,arXiv preprint,10.061732292175293,NimbusRomNo9L-ReguItal,False,439.9322814941406,121.77505493164062,0.07142857142857142,14,H3
sample_8.pdf,11,arXiv:1802.05365,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,132.760986328125,0.0625,16,H3
sample_8.pdf,11,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,132.9374542236328,0.0,7,H3
sample_8.pdf,11,[28],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,147.83143615722656,0.0,4,H3
sample_8.pdf,11,"Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language",10.061732292175293,NimbusRomNo9L-Regu,False,124.59767150878906,147.75625610351562,0.10465116279069768,86,H3
sample_8.pdf,11,understanding by generative pre-training.,9.987475395202637,NimbusRomNo9L-Regu,False,129.57899475097656,158.72161865234375,0.0,41,H3
sample_8.pdf,11,URL https://s3-us-west-2. amazonaws. com/openai-,9.987475395202637,NimbusRomNo9L-ReguItal,False,294.88397216796875,158.5447235107422,0.0625,48,H3
sample_8.pdf,11,assets/research-covers/languageunsupervised/language understanding paper. pdf,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,169.4730224609375,0.0,77,H3
sample_8.pdf,11,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,453.4110107421875,169.6494903564453,0.0,7,H3
sample_8.pdf,11,[29],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,184.5445098876953,0.0,4,H3
sample_8.pdf,11,"Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable",10.061732292175293,NimbusRomNo9L-Regu,False,124.59768676757812,184.46926879882812,0.09523809523809523,84,H3
sample_8.pdf,11,questions for squad.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,195.4534454345703,0.0,20,H3
sample_8.pdf,11,arXiv preprint arXiv:1806.03822,9.962599754333496,NimbusRomNo9L-ReguItal,False,209.54876708984375,195.2769775390625,0.06451612903225806,31,H3
sample_8.pdf,11,", 2018.",9.962599754333496,NimbusRomNo9L-Regu,False,345.3179931640625,195.4534454345703,0.0,7,H3
sample_8.pdf,11,[30],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,210.34742736816406,0.0,4,H3
sample_8.pdf,11,"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions",9.862470626831055,NimbusRomNo9L-Regu,False,124.59768676757812,210.42335510253906,0.09782608695652174,92,H3
sample_8.pdf,11,for machine comprehension of text.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,221.25648498535156,0.0,34,H3
sample_8.pdf,11,arXiv preprint arXiv:1606.05250,9.962599754333496,NimbusRomNo9L-ReguItal,False,271.36669921875,221.08001708984375,0.06451612903225806,31,H3
sample_8.pdf,11,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,407.135986328125,221.25648498535156,0.0,7,H3
sample_8.pdf,11,[31],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,236.1504669189453,0.0,4,H3
sample_8.pdf,11,"Devendra Singh Sachan, Manzil Zaheer, and Ruslan Salakhutdinov. Revisiting lstm networks",9.992443084716797,NimbusRomNo9L-Regu,False,124.59768676757812,236.12783813476562,0.09090909090909091,88,H3
sample_8.pdf,11,for semi-supervised text classiﬁcation via mixed objective function. 2018.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,247.05946350097656,0.0,74,H3
sample_8.pdf,11,[32],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,261.95343017578125,0.0,4,H3
sample_8.pdf,11,"Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural",9.90765380859375,NimbusRomNo9L-Regu,False,124.5976791381836,261.9951171875,0.1348314606741573,89,H3
sample_8.pdf,11,autoregressive distribution estimation.,9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,272.93841552734375,0.0,39,H3
sample_8.pdf,11,The Journal of Machine Learning Research,9.862470626831055,NimbusRomNo9L-ReguItal,False,278.3431396484375,272.7637023925781,0.125,40,H3
sample_8.pdf,11,", 17(1):7184–",9.862470626831055,NimbusRomNo9L-Regu,False,452.3009948730469,272.93841552734375,0.0,13,H3
sample_8.pdf,11,"7220, 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,129.3300018310547,283.7714538574219,0.0,11,H3
sample_8.pdf,11,[33],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,298.66644287109375,0.0,4,H3
sample_8.pdf,11,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,",9.997407913208008,NimbusRomNo9L-Regu,False,124.59768676757812,298.6400451660156,0.14942528735632185,87,H3
sample_8.pdf,11,"Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In",9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,309.65142822265625,0.09090909090909091,66,H3
sample_8.pdf,11,Advances in neural information,9.862470626831055,NimbusRomNo9L-ReguItal,False,379.5207824707031,309.4767150878906,0.03333333333333333,30,H3
sample_8.pdf,11,processing systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,320.3080139160156,0.0,18,H3
sample_8.pdf,11,", pages 5998–6008, 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,205.2239990234375,320.4844665527344,0.0,24,H3
sample_8.pdf,11,[34],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,335.37847900390625,0.0,4,H3
sample_8.pdf,11,"Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman.",9.89261531829834,NimbusRomNo9L-Regu,False,124.59768676757812,335.4315490722656,0.14772727272727273,88,H3
sample_8.pdf,11,GLUE: A multi-task benchmark and analysis platform for natural language understanding. 2019.,9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,346.3634033203125,0.05434782608695652,92,H3
sample_8.pdf,11,In the Proceedings of ICLR.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,357.19647216796875,0.2222222222222222,27,H3
sample_8.pdf,11,[35],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,372.0904846191406,0.0,4,H3
sample_8.pdf,11,"Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le. Unsupervised data",9.887598037719727,NimbusRomNo9L-Regu,False,124.5976791381836,372.1473388671875,0.14942528735632185,87,H3
sample_8.pdf,11,augmentation.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,382.99945068359375,0.0,13,H3
sample_8.pdf,11,arXiv preprint arXiv:1904.12848,9.962599754333496,NimbusRomNo9L-ReguItal,False,186.3060302734375,382.822998046875,0.06451612903225806,31,H3
sample_8.pdf,11,", 2019.",9.962599754333496,NimbusRomNo9L-Regu,False,322.07501220703125,382.99945068359375,0.0,7,H3
sample_8.pdf,11,[36],9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,397.8934631347656,0.0,4,H3
sample_8.pdf,11,"Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural",9.862470626831055,NimbusRomNo9L-Regu,False,124.59770202636719,397.96942138671875,0.12222222222222222,90,H3
sample_8.pdf,11,ad-hoc ranking with kernel pooling. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,408.7283020019531,0.02631578947368421,38,H3
sample_8.pdf,11,Proceedings of the 40th International ACM SIGIR,10.061732292175293,NimbusRomNo9L-ReguItal,False,292.5141906738281,408.5500793457031,0.2127659574468085,47,H3
sample_8.pdf,11,conference on research and development in information retrieval,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,419.5360107421875,0.0,63,H3
sample_8.pdf,11,", pages 55–64. ACM, 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,388.0269775390625,419.71246337890625,0.12,25,H3
sample_8.pdf,11,[37],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,434.6064758300781,0.0,4,H3
sample_8.pdf,11,"Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William W Cohen. Breaking the softmax",9.947644233703613,NimbusRomNo9L-Regu,False,124.59765625,434.6177978515625,0.11363636363636363,88,H3
sample_8.pdf,11,bottleneck: A high-rank rnn language model.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,445.5154724121094,0.023255813953488372,43,H3
sample_8.pdf,11,arXiv preprint arXiv:1711.03953,9.962599754333496,NimbusRomNo9L-ReguItal,False,309.4736633300781,445.3390197753906,0.06451612903225806,31,H3
sample_8.pdf,11,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,445.24298095703125,445.5154724121094,0.0,7,H3
sample_8.pdf,11,[38],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,460.40948486328125,0.0,4,H3
sample_8.pdf,11,"Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, and Xiang Zhou. Dual co-",9.862470626831055,NimbusRomNo9L-Regu,False,124.59765625,460.48541259765625,0.14772727272727273,88,H3
sample_8.pdf,11,matching network for multi-choice reading comprehension.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,471.3184509277344,0.0,56,H3
sample_8.pdf,11,arXiv preprint arXiv:1901.09381,9.962599754333496,NimbusRomNo9L-ReguItal,False,366.92791748046875,471.1419982910156,0.06451612903225806,31,H3
sample_8.pdf,11,2019.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57901000976562,482.2274475097656,0.0,5,H3
sample_8.pdf,11,[39],9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,497.1214599609375,0.0,4,H3
sample_8.pdf,11,"Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text",10.02714729309082,NimbusRomNo9L-Regu,False,124.59769439697266,497.072509765625,0.09090909090909091,88,H3
sample_8.pdf,11,classiﬁcation. In,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,508.03045654296875,0.058823529411764705,17,H3
sample_8.pdf,11,Advances in neural information processing systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,195.97975158691406,507.85400390625,0.02040816326530612,49,H3
sample_8.pdf,11,", pages 649–657, 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,402.9210205078125,508.03045654296875,0.0,22,H3
sample_8.pdf,11,[40],9.962599754333496,NimbusRomNo9L-Regu,False,108.00003051757812,522.9254150390625,0.0,4,H3
sample_8.pdf,11,"Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba,",9.872529029846191,NimbusRomNo9L-Regu,False,124.59771728515625,522.9937133789062,0.13333333333333333,90,H3
sample_8.pdf,11,and Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,533.75927734375,0.046511627906976744,86,H3
sample_8.pdf,11,watching movies and reading books. In,10.017244338989258,NimbusRomNo9L-Regu,False,129.22000122070312,544.7020263671875,0.02702702702702703,37,H3
sample_8.pdf,11,Proceedings of the IEEE international conference on,10.017244338989258,NimbusRomNo9L-ReguItal,False,288.23956298828125,544.5245971679688,0.09803921568627451,51,H3
sample_8.pdf,11,computer vision,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,555.4760131835938,0.0,15,H3
sample_8.pdf,11,", pages 19–27, 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,193.49899291992188,555.6524658203125,0.0,20,H3
sample_8.pdf,12,Target-Aware Representation via Two-Stream Self-Attention,11.9552001953125,NimbusRomNo9L-Medi,False,128.58685302734375,72.78716278076172,0.12280701754385964,57,H3
sample_8.pdf,12,A.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,96.70153045654297,0.3333333333333333,3,H3
sample_8.pdf,12,A Concrete Example of How Standard LM Parameterization Fails,9.962599754333496,NimbusRomNo9L-Medi,False,132.62754821777344,96.70153045654297,0.15,60,H3
sample_8.pdf,12,"In this section, we provide a concrete example to show how the standard language model parameteri-",9.89261531829834,NimbusRomNo9L-Regu,False,108.0,116.82054138183594,0.01020408163265306,98,H3
sample_8.pdf,12,"zation fails under the permutation objective, as discussed in Section 2.3. Speciﬁcally, let’s consider",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,127.65760040283203,0.0196078431372549,102,H3
sample_8.pdf,12,two different permutations,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,139.6754913330078,0.0,26,H3
sample_8.pdf,12,(1),6.973800182342529,CMR7,False,221.48399353027344,138.16578674316406,0.0,3,P
sample_8.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,234.67098999023438,139.6754913330078,0.0,3,H3
sample_8.pdf,12,(2),6.973800182342529,CMR7,False,256.6399841308594,138.16578674316406,0.0,3,P
sample_8.pdf,12,satisfying the following relationship,9.962599754333496,NimbusRomNo9L-Regu,False,269.82598876953125,139.6754913330078,0.0,37,H3
sample_8.pdf,12,(1),6.973800182342529,CMR7,False,217.24998474121094,153.09376525878906,0.0,3,P
sample_8.pdf,12,(2),6.973800182342529,CMR7,False,246.32098388671875,153.09376525878906,0.0,3,P
sample_8.pdf,12,but,9.962599754333496,NimbusRomNo9L-Regu,False,295.0889892578125,156.16346740722656,0.0,3,H3
sample_8.pdf,12,(1),6.973800182342529,CMR7,False,322.656005859375,153.09376525878906,0.0,3,P
sample_8.pdf,12,(2),6.973800182342529,CMR7,False,386.3790283203125,153.09376525878906,0.0,3,P
sample_8.pdf,12,"Then, substituting the two permutations respectively into the naive parameterization, we have",9.962599754333496,NimbusRomNo9L-Regu,False,107.6910400390625,170.00245666503906,0.010752688172043012,93,H3
sample_8.pdf,12,(1),4.981299877166748,CMR5,False,174.1179962158203,210.31997680664062,0.0,3,P
sample_8.pdf,12,(1),4.981299877166748,CMR5,False,200.989990234375,210.31997680664062,0.0,3,P
sample_8.pdf,12,(1),4.981299877166748,CMR5,False,263.0,210.31997680664062,0.0,3,P
sample_8.pdf,12,(2),4.981299877166748,CMR5,False,290.3240051269531,210.31997680664062,0.0,3,P
sample_8.pdf,12,exp,9.962599754333496,CMR10,False,351.93701171875,184.3219451904297,0.0,3,H3
sample_8.pdf,12,exp (,9.962599754333496,CMR10,False,358.51873779296875,198.5289764404297,0.0,5,H3
sample_8.pdf,12,"Effectively, two different target positions",9.937662124633789,NimbusRomNo9L-Regu,False,108.0,224.5203857421875,0.023255813953488372,43,H3
sample_8.pdf,12,and,9.937662124633789,NimbusRomNo9L-Regu,False,276.0251159667969,224.5203857421875,0.0,3,H3
sample_8.pdf,12,"share exactly the same model prediction. However,",9.937662124633789,NimbusRomNo9L-Regu,False,299.4435729980469,224.5203857421875,0.02040816326530612,49,H3
sample_8.pdf,12,the ground-truth distribution of two positions should certainly be different.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,235.4104766845703,0.0,77,H3
sample_8.pdf,12,A.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,259.04949951171875,0.3333333333333333,3,H3
sample_8.pdf,12,Two-Stream Attention,9.962599754333496,NimbusRomNo9L-Medi,False,132.62754821777344,259.04949951171875,0.15,20,H3
sample_8.pdf,12,"Here, we provide the implementation details of the two-stream attention with a Transformer-XL",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,279.040283203125,0.043010752688172046,93,H3
sample_8.pdf,12,backbone.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,290.0244445800781,0.0,9,H3
sample_8.pdf,12,Initial represetation:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,303.8034362792969,0.045454545454545456,22,H3
sample_8.pdf,12,= 1,9.962599754333496,CMR10,False,145.28250122070312,317.4118957519531,0.0,3,H3
sample_8.pdf,12,", . . . , T",9.962599754333496,CMMI10,False,163.54800415039062,317.4118957519531,0.09090909090909091,11,H3
sample_8.pdf,12,and,9.962599754333496,NimbusRomNo9L-Regu,False,265.2409973144531,317.6424255371094,0.0,3,H3
sample_8.pdf,12,Cached layer-,9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,334.1234130859375,0.07692307692307693,13,H3
sample_8.pdf,12,content represetation (memory) from previous segment:,9.962599754333496,NimbusRomNo9L-Regu,False,172.14913940429688,334.1234130859375,0.0,53,H3
sample_8.pdf,12,For the Transformer-XL layer,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,346.8793029785156,0.14285714285714285,28,H3
sample_8.pdf,12,= 1,9.962599754333496,CMR10,False,245.5631561279297,346.72393798828125,0.0,3,H3
sample_8.pdf,12,", M",9.962599754333496,CMMI10,False,284.50030517578125,346.72393798828125,0.3333333333333333,3,H3
sample_8.pdf,12,", attention with relative positional encoding and",10.061732292175293,NimbusRomNo9L-Regu,False,302.99700927734375,346.8793029785156,0.0,49,H3
sample_8.pdf,12,position-wise feed-forward are consecutively employed to update the represetntations:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,357.86346435546875,0.0,85,H3
sample_8.pdf,12,= 1,9.962599754333496,CMR10,False,134.99549865722656,375.1729431152344,0.0,3,H3
sample_8.pdf,12,", . . . , T",9.962599754333496,CMMI10,False,153.2620086669922,375.1729431152344,0.09090909090909091,11,H3
sample_8.pdf,12,LayerNorm,9.962599754333496,NimbusRomNo9L-Regu,False,230.92393493652344,375.4034423828125,0.2222222222222222,9,H3
sample_8.pdf,12,RelAttn,9.962599754333496,NimbusRomNo9L-Regu,False,325.8109436035156,375.4034118652344,0.2857142857142857,7,H3
sample_8.pdf,12,LayerNorm,9.962599754333496,NimbusRomNo9L-Regu,False,230.92404174804688,397.3213195800781,0.2222222222222222,9,H3
sample_8.pdf,12,PosFF,9.962599754333496,NimbusRomNo9L-Regu,False,315.6130676269531,397.3212890625,0.6,5,H3
sample_8.pdf,12,LayerNorm,9.962599754333496,NimbusRomNo9L-Regu,False,230.92410278320312,419.2392272949219,0.2222222222222222,9,H3
sample_8.pdf,12,RelAttn,9.962599754333496,NimbusRomNo9L-Regu,False,325.1801452636719,419.23919677734375,0.2857142857142857,7,H3
sample_8.pdf,12,LayerNorm,9.962599754333496,NimbusRomNo9L-Regu,False,230.92320251464844,441.1571044921875,0.2222222222222222,9,H3
sample_8.pdf,12,PosFF,9.962599754333496,NimbusRomNo9L-Regu,False,314.98223876953125,441.1570739746094,0.6,5,H3
sample_8.pdf,12,Target-aware prediction distribution:,9.962599754333496,NimbusRomNo9L-Regu,False,107.69134521484375,458.31304931640625,0.02702702702702703,37,H3
sample_8.pdf,12,) =,9.962599754333496,CMR10,False,216.53135681152344,485.9835205078125,0.0,3,H3
sample_8.pdf,12,exp,9.962599754333496,CMR10,False,246.22535705566406,475.6225280761719,0.0,3,H3
sample_8.pdf,12,exp,9.962599754333496,CMR10,False,252.11476135253906,496.34490966796875,0.0,3,H3
sample_8.pdf,12,A.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.00004577636719,523.6414794921875,0.3333333333333333,3,H3
sample_8.pdf,12,Datasets,9.962599754333496,NimbusRomNo9L-Medi,False,132.62759399414062,523.6414794921875,0.125,8,H3
sample_8.pdf,12,A.3.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.00004577636719,543.6174926757812,0.2,5,H3
sample_8.pdf,12,RACE Dataset,9.962599754333496,NimbusRomNo9L-Medi,False,140.0995330810547,543.6174926757812,0.4166666666666667,12,H3
sample_8.pdf,12,The RACE dataset [,9.96757984161377,NimbusRomNo9L-Regu,False,107.69100189208984,562.3346557617188,0.2777777777777778,18,H3
sample_8.pdf,12,] contains near 100K questions taken from the English exams for middle and,9.96757984161377,NimbusRomNo9L-Regu,False,197.86500549316406,562.3346557617188,0.02702702702702703,74,H3
sample_8.pdf,12,"high school Chinese students in the age range between 12 to 18, with the answers generated by human",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,573.3233642578125,0.010101010101010102,99,H3
sample_8.pdf,12,experts. This is one of the most difﬁcult reading comprehension datasets that involve challenging,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,584.081298828125,0.010309278350515464,97,H3
sample_8.pdf,12,"reasoning questions. Moreover, the average length of the passages in RACE are longer than 300,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,594.990234375,0.05319148936170213,94,H3
sample_8.pdf,12,which is signiﬁcantly longer than other popular reading comprehension datasets such as SQuAD [,9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,606.0504150390625,0.0425531914893617,94,H3
sample_8.pdf,12,"As a result, this dataset serves as a challenging benchmark for long text understanding. We use a",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,616.8082275390625,0.020618556701030927,97,H3
sample_8.pdf,12,sequence length of 512 during ﬁnetuning.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,627.79248046875,0.0,40,H3
sample_8.pdf,12,A.3.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,650.0875244140625,0.2,5,H3
sample_8.pdf,12,SQuAD,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,650.0875244140625,0.8,5,H3
sample_8.pdf,12,SQuAD is a large-scale reading comprehension dataset with two tasks. SQuAD1.1 [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,668.7332763671875,0.10126582278481013,79,H3
sample_8.pdf,12,] contains,10.061732292175293,NimbusRomNo9L-Regu,False,463.9169921875,668.7332763671875,0.0,10,H3
sample_8.pdf,12,"questions that always have a corresponding answer in the given passages, while SQuAD2.0 [",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,679.6422729492188,0.0449438202247191,89,H3
sample_8.pdf,12,"introduces unanswerable questions. To ﬁnetune an XLNet on SQuAD2.0, we jointly apply a logis-",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,690.5737915039062,0.08602150537634409,93,H3
sample_8.pdf,12,tic regression loss for answerability prediction similar to classiﬁcation tasks and a standard span,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,701.4602661132812,0.0,99,H3
sample_8.pdf,12,extraction loss for question answering [10].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,712.4444580078125,0.0,44,H3
sample_8.pdf,13,A.3.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,74.31652069091797,0.2,5,H3
sample_8.pdf,13,Text classiﬁcation Datasets,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,74.31652069091797,0.07407407407407407,27,H3
sample_8.pdf,13,Following previous work on text classiﬁcation [,9.95761775970459,NimbusRomNo9L-Regu,False,108.0,93.88526153564453,0.02127659574468085,47,H3
sample_8.pdf,13,"], we evaluate XLNet on the following bench-",9.95761775970459,NimbusRomNo9L-Regu,False,322.81500244140625,93.88526153564453,0.06818181818181818,44,H3
sample_8.pdf,13,"marks: IMDB, Yelp-2, Yelp-5, DBpedia, AG, Amazon-2, and Amazon-5.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,104.79048156738281,0.18461538461538463,65,H3
sample_8.pdf,13,A.3.4,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,129.92352294921875,0.2,5,H3
sample_8.pdf,13,GLUE Dataset,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,129.92352294921875,0.4166666666666667,12,H3
sample_8.pdf,13,The GLUE dataset [,9.95761775970459,NimbusRomNo9L-Regu,False,107.69100189208984,149.49322509765625,0.2777777777777778,18,H3
sample_8.pdf,13,] is a collection of 9 natural language understanding tasks. The test set labels,9.95761775970459,NimbusRomNo9L-Regu,False,198.10800170898438,149.49322509765625,0.0125,80,H3
sample_8.pdf,13,"are removed from the publicly released version, and all the practitioners must submit their predictions",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,160.47438049316406,0.0,103,H3
sample_8.pdf,13,"on the evaluation server to obtain test set results. In Table 5, we present results of multiple settings,",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,171.2810516357422,0.01904761904761905,105,H3
sample_8.pdf,13,"including single-task and multi-task, as well as single models and ensembles. In the multi-task setting,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,182.29237365722656,0.009615384615384616,104,H3
sample_8.pdf,13,"we jointly train an XLNet on the four largest datasets—MNLI, SST-2, QNLI, and QQP—and ﬁnetune",9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,193.20143127441406,0.1827956989247312,93,H3
sample_8.pdf,13,the network on the other datasets. Only single-task training is employed for the four large datasets.,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,203.9893035888672,0.009900990099009901,101,H3
sample_8.pdf,13,"For QNLI, we employed a pairwise relevance ranking scheme as in [",9.977532386779785,NimbusRomNo9L-Regu,False,108.0,214.9321746826172,0.07692307692307693,65,H3
sample_8.pdf,13,] for our test set submission.,9.977532386779785,NimbusRomNo9L-Regu,False,392.4960021972656,214.9321746826172,0.0,30,H3
sample_8.pdf,13,"However, for fair comparison with BERT, our result on the QNLI dev set is based on a standard",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,225.77731323242188,0.0967741935483871,93,H3
sample_8.pdf,13,"classiﬁcation paradigm. For WNLI, we use the loss described in [16].",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,236.76148986816406,0.07352941176470588,68,H3
sample_8.pdf,13,A.3.5,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,261.89453125,0.2,5,H3
sample_8.pdf,13,ClueWeb09-B Dataset,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,261.89453125,0.21052631578947367,19,H3
sample_8.pdf,13,Following the setting in previous work [,10.007330894470215,NimbusRomNo9L-Regu,False,108.0,281.4265441894531,0.025,40,H3
sample_8.pdf,13,"], we use the ClueWeb09-B dataset to evaluate the perfor-",10.007330894470215,NimbusRomNo9L-Regu,False,274.02099609375,281.4265441894531,0.05263157894736842,57,H3
sample_8.pdf,13,mance on document ranking. The queries were created by the TREC 2009-2012 Web Tracks based on,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,292.4454040527344,0.07526881720430108,93,H3
sample_8.pdf,13,50M documents and the task is to rerank the top 100 documents retrieved using a standard retrieval,9.977532386779785,NimbusRomNo9L-Regu,False,108.0,303.26715087890625,0.01020408163265306,98,H3
sample_8.pdf,13,"method. Since document ranking, or ad-hoc retrieval, mainly concerns the low-level representations",9.937662124633789,NimbusRomNo9L-Regu,False,108.0,314.2063903808594,0.01020408163265306,98,H3
sample_8.pdf,13,"instead of high-level semantics, this dataset serves as a testbed for evaluating the quality of word",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,325.02130126953125,0.0,100,H3
sample_8.pdf,13,embeddings. We use a pretrained XLNet to extract word embeddings for the documents and queries,9.932666778564453,NimbusRomNo9L-Regu,False,108.0,336.0281677246094,0.0425531914893617,94,H3
sample_8.pdf,13,"without ﬁnetuning, and employ a kernel pooling network [36] to rank the documents.",9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,346.9144592285156,0.0,82,H3
sample_8.pdf,13,A.4,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,373.3935241699219,0.3333333333333333,3,H3
sample_8.pdf,13,Hyperparameters,9.962599754333496,NimbusRomNo9L-Medi,False,132.62754821777344,373.3935241699219,0.06666666666666667,15,H3
sample_8.pdf,13,A.4.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,394.2125244140625,0.2,5,H3
sample_8.pdf,13,Pretraining Hyperparameters,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,394.2125244140625,0.07407407407407407,27,H3
sample_8.pdf,13,Hparam,8.966400146484375,NimbusRomNo9L-Medi,False,240.00599670410156,424.47509765625,0.16666666666666666,6,P
sample_8.pdf,13,Value,8.966400146484375,NimbusRomNo9L-Medi,False,348.8670959472656,424.47509765625,0.2,5,P
sample_8.pdf,13,Number of layers,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,439.5199890136719,0.0625,16,P
sample_8.pdf,13,Hidden size,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,449.4830017089844,0.09090909090909091,11,P
sample_8.pdf,13,1024,8.966400146484375,NimbusRomNo9L-Regu,False,350.6961669921875,449.4830017089844,0.0,4,P
sample_8.pdf,13,Number of attention heads,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,459.44500732421875,0.04,25,P
sample_8.pdf,13,Attention head size,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,469.40802001953125,0.05263157894736842,19,P
sample_8.pdf,13,FFN inner hidden size,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,479.37103271484375,0.14285714285714285,21,P
sample_8.pdf,13,4096,8.966400146484375,NimbusRomNo9L-Regu,False,350.69622802734375,479.37103271484375,0.0,4,P
sample_8.pdf,13,Hidden Dropout,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,489.3330383300781,0.14285714285714285,14,P
sample_8.pdf,13,0.1,8.966400146484375,NimbusRomNo9L-Regu,False,354.0586853027344,489.3330383300781,0.0,3,P
sample_8.pdf,13,GeLU Dropout,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,499.2960510253906,0.3333333333333333,12,P
sample_8.pdf,13,0.0,8.966400146484375,NimbusRomNo9L-Regu,False,354.05865478515625,499.2960510253906,0.0,3,P
sample_8.pdf,13,Attention dropout,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,509.2590637207031,0.058823529411764705,17,P
sample_8.pdf,13,0.1,8.966400146484375,NimbusRomNo9L-Regu,False,354.05859375,509.2590637207031,0.0,3,P
sample_8.pdf,13,Partial prediction,8.966400146484375,NimbusRomNo9L-Regu,False,240.00599670410156,519.2210693359375,0.05555555555555555,18,P
sample_8.pdf,13,Max sequence length,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,529.18408203125,0.05263157894736842,19,P
sample_8.pdf,13,512,8.966400146484375,NimbusRomNo9L-Regu,False,352.93780517578125,529.18408203125,0.0,3,P
sample_8.pdf,13,Batch size,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,539.1470336914062,0.1,10,P
sample_8.pdf,13,8192,8.966400146484375,NimbusRomNo9L-Regu,False,350.6961975097656,539.1470336914062,0.0,4,P
sample_8.pdf,13,Learning rate,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,549.1090698242188,0.07692307692307693,13,P
sample_8.pdf,13,4e-4,8.966400146484375,NimbusRomNo9L-Regu,False,351.700439453125,549.1090698242188,0.0,4,P
sample_8.pdf,13,Number of steps,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,559.072021484375,0.06666666666666667,15,P
sample_8.pdf,13,500K,8.966400146484375,NimbusRomNo9L-Regu,False,349.7008972167969,559.072021484375,0.25,4,P
sample_8.pdf,13,Warmup steps,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,569.0350341796875,0.08333333333333333,12,P
sample_8.pdf,13,"40,000",8.966400146484375,NimbusRomNo9L-Regu,False,347.3337707519531,569.0350341796875,0.0,6,P
sample_8.pdf,13,Learning rate decay,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,578.9970703125,0.05263157894736842,19,P
sample_8.pdf,13,linear,8.966400146484375,NimbusRomNo9L-Regu,False,349.4588623046875,578.9970703125,0.0,6,P
sample_8.pdf,13,Adam epsilon,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,588.9600830078125,0.08333333333333333,12,P
sample_8.pdf,13,1e-6,8.966400146484375,NimbusRomNo9L-Regu,False,351.7004699707031,588.9600830078125,0.0,4,P
sample_8.pdf,13,Weight decay,8.966400146484375,NimbusRomNo9L-Regu,False,240.00601196289062,598.9220581054688,0.08333333333333333,12,P
sample_8.pdf,13,0.01,8.966400146484375,NimbusRomNo9L-Regu,False,351.8170471191406,598.9220581054688,0.0,4,P
sample_8.pdf,13,Table 7:,9.962599754333496,NimbusRomNo9L-Regu,False,229.10400390625,611.304443359375,0.125,8,H3
sample_8.pdf,13,Hyperparameters for pretraining.,8.966400146484375,NimbusRomNo9L-Regu,False,261.2333679199219,612.0599365234375,0.03125,32,P
sample_8.pdf,13,The hyperparameters used for pretraining XLNet are shown in Table 7.,9.962599754333496,NimbusRomNo9L-Regu,False,107.69099426269531,635.0184326171875,0.07352941176470588,68,H3
sample_8.pdf,13,A.4.2,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,660.1514892578125,0.2,5,H3
sample_8.pdf,13,Hyperparameters for Finetuning,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,660.1514892578125,0.06666666666666667,30,H3
sample_8.pdf,13,The hyperparameters used for ﬁnetuning XLNet on various tasks are shown in Table 8. “Layer-wise,9.937662124633789,NimbusRomNo9L-Regu,False,107.69100189208984,679.7363891601562,0.06315789473684211,95,H3
sample_8.pdf,13,decay” means exponentially decaying the learning rates of individual layers in a top-down manner.,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,690.581298828125,0.0,97,H3
sample_8.pdf,13,"For example, suppose the",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,701.5430297851562,0.041666666666666664,24,H3
sample_8.pdf,13,-th layer uses a learning rate,9.952631950378418,NimbusRomNo9L-Regu,False,221.78700256347656,701.5430297851562,0.0,30,H3
sample_8.pdf,13,", and the Layer-wise decay rate is",9.952631950378418,NimbusRomNo9L-Regu,False,339.8330078125,701.5430297851562,0.029411764705882353,34,H3
sample_8.pdf,13,", then",9.952631950378418,NimbusRomNo9L-Regu,False,481.90399169921875,701.5430297851562,0.0,6,H3
sample_8.pdf,13,the learning rate of layer,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,712.4444580078125,0.0,26,H3
sample_8.pdf,14,Hparam,8.966400146484375,NimbusRomNo9L-Medi,False,192.18499755859375,75.67609405517578,0.16666666666666666,6,P
sample_8.pdf,14,RACE,8.966400146484375,NimbusRomNo9L-Medi,False,280.33367919921875,75.67609405517578,1.0,4,P
sample_8.pdf,14,SQuAD,8.966400146484375,NimbusRomNo9L-Medi,False,317.20355224609375,75.67609405517578,0.8,5,P
sample_8.pdf,14,MNLI,8.966400146484375,NimbusRomNo9L-Medi,False,359.0497741699219,75.67609405517578,1.0,4,P
sample_8.pdf,14,Yelp-5,8.966400146484375,NimbusRomNo9L-Medi,False,395.4085388183594,75.67609405517578,0.16666666666666666,6,P
sample_8.pdf,14,Dropout,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,90.72195434570312,0.14285714285714285,7,P
sample_8.pdf,14,0.1,8.966400146484375,NimbusRomNo9L-Regu,False,344.4703369140625,90.72195434570312,0.0,3,P
sample_8.pdf,14,Attention dropout,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,100.68392944335938,0.058823529411764705,17,P
sample_8.pdf,14,0.1,8.966400146484375,NimbusRomNo9L-Regu,False,344.4703369140625,100.68392944335938,0.0,3,P
sample_8.pdf,14,Max sequence length,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,110.64694213867188,0.05263157894736842,19,P
sample_8.pdf,14,512,8.966400146484375,NimbusRomNo9L-Regu,False,286.0632019042969,110.64694213867188,0.0,3,P
sample_8.pdf,14,512,8.966400146484375,NimbusRomNo9L-Regu,False,325.42572021484375,110.64694213867188,0.0,3,P
sample_8.pdf,14,128,8.966400146484375,NimbusRomNo9L-Regu,False,364.5282287597656,110.64694213867188,0.0,3,P
sample_8.pdf,14,512,8.966400146484375,NimbusRomNo9L-Regu,False,400.8869934082031,110.64694213867188,0.0,3,P
sample_8.pdf,14,Batch size,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,120.60891723632812,0.1,10,P
sample_8.pdf,14,128,8.966400146484375,NimbusRomNo9L-Regu,False,364.5281982421875,120.60891723632812,0.0,3,P
sample_8.pdf,14,128,8.966400146484375,NimbusRomNo9L-Regu,False,400.8869934082031,120.60891723632812,0.0,3,P
sample_8.pdf,14,Learning rate,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,130.57192993164062,0.07692307692307693,13,P
sample_8.pdf,14,2e-5,8.966400146484375,NimbusRomNo9L-Regu,False,284.8258361816406,130.57192993164062,0.0,4,P
sample_8.pdf,14,3e-5,8.966400146484375,NimbusRomNo9L-Regu,False,324.1793212890625,130.57192993164062,0.0,4,P
sample_8.pdf,14,2e-5,8.966400146484375,NimbusRomNo9L-Regu,False,363.28179931640625,130.57192993164062,0.0,4,P
sample_8.pdf,14,1e-5,8.966400146484375,NimbusRomNo9L-Regu,False,399.6495056152344,130.57192993164062,0.0,4,P
sample_8.pdf,14,Number of steps,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,140.53494262695312,0.06666666666666667,15,P
sample_8.pdf,14,12K,8.966400146484375,NimbusRomNo9L-Regu,False,285.06793212890625,140.53494262695312,0.3333333333333333,3,P
sample_8.pdf,14,10K,8.966400146484375,NimbusRomNo9L-Regu,False,363.532958984375,140.53494262695312,0.3333333333333333,3,P
sample_8.pdf,14,10K,8.966400146484375,NimbusRomNo9L-Regu,False,399.8917541503906,140.53494262695312,0.3333333333333333,3,P
sample_8.pdf,14,Learning rate decay,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,150.49691772460938,0.05263157894736842,19,P
sample_8.pdf,14,linear,8.966400146484375,NimbusRomNo9L-Regu,False,339.87060546875,150.49691772460938,0.0,6,P
sample_8.pdf,14,Weight decay,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,160.45993041992188,0.08333333333333333,12,P
sample_8.pdf,14,0.01,8.966400146484375,NimbusRomNo9L-Regu,False,342.2287292480469,160.45993041992188,0.0,4,P
sample_8.pdf,14,Adam epsilon,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,170.42294311523438,0.08333333333333333,12,P
sample_8.pdf,14,1e-6,8.966400146484375,NimbusRomNo9L-Regu,False,284.82586669921875,170.42294311523438,0.0,4,P
sample_8.pdf,14,1e-6,8.966400146484375,NimbusRomNo9L-Regu,False,324.17938232421875,170.42294311523438,0.0,4,P
sample_8.pdf,14,1e-6,8.966400146484375,NimbusRomNo9L-Regu,False,363.2818603515625,170.42294311523438,0.0,4,P
sample_8.pdf,14,1e-6,8.966400146484375,NimbusRomNo9L-Regu,False,399.6495666503906,170.42294311523438,0.0,4,P
sample_8.pdf,14,Layer-wise lr decay,8.966400146484375,NimbusRomNo9L-Regu,False,192.18499755859375,180.38491821289062,0.05263157894736842,19,P
sample_8.pdf,14,1.0,8.966400146484375,NimbusRomNo9L-Regu,False,287.1840515136719,180.38491821289062,0.0,3,P
sample_8.pdf,14,0.75,8.966400146484375,NimbusRomNo9L-Regu,False,324.304931640625,180.38491821289062,0.0,4,P
sample_8.pdf,14,1.0,8.966400146484375,NimbusRomNo9L-Regu,False,365.6490173339844,180.38491821289062,0.0,3,P
sample_8.pdf,14,1.0,8.966400146484375,NimbusRomNo9L-Regu,False,402.00775146484375,180.38491821289062,0.0,3,P
sample_8.pdf,14,Table 8:,9.962599754333496,NimbusRomNo9L-Regu,False,230.5919952392578,192.76747131347656,0.125,8,H3
sample_8.pdf,14,Hyperparameters for ﬁnetuning.,8.966400146484375,NimbusRomNo9L-Regu,False,262.72137451171875,193.52297973632812,0.03333333333333333,30,P
sample_8.pdf,14,A.5,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,223.24853515625,0.3333333333333333,3,H3
sample_8.pdf,14,Discussion and Analysis,9.962599754333496,NimbusRomNo9L-Medi,False,132.62754821777344,223.24853515625,0.08695652173913043,23,H3
sample_8.pdf,14,A.5.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,243.2235107421875,0.2,5,H3
sample_8.pdf,14,Comparison with BERT,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,243.2235107421875,0.25,20,H3
sample_8.pdf,14,"To prove a general point beyond one example, we now turn to more formal expressions. Inspired",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,261.8702697753906,0.021505376344086023,93,H3
sample_8.pdf,14,by previous work [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,272.779296875,0.0,18,H3
sample_8.pdf,14,"], given a sequence",10.061732292175293,NimbusRomNo9L-Regu,False,194.85400390625,272.779296875,0.0,19,H3
sample_8.pdf,14,= [,9.962599754333496,CMR10,False,281.20928955078125,272.6239318847656,0.0,3,H3
sample_8.pdf,14,", x",9.962599754333496,CMMI10,False,323.9002990722656,272.6239318847656,0.0,3,H3
sample_8.pdf,14,", we deﬁne a set of target-context pairs",10.061732292175293,NimbusRomNo9L-Regu,False,346.38299560546875,272.779296875,0.0,40,H3
sample_8.pdf,14,"of interest,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,283.68829345703125,0.0,12,H3
sample_8.pdf,14,", where",10.061732292175293,NimbusRomNo9L-Regu,False,209.5679931640625,283.68829345703125,0.0,7,H3
sample_8.pdf,14,is a set of tokens in,10.061732292175293,NimbusRomNo9L-Regu,False,248.59059143066406,283.68829345703125,0.0,21,H3
sample_8.pdf,14,that form a context of,10.061732292175293,NimbusRomNo9L-Regu,False,339.8113098144531,283.68829345703125,0.0,22,H3
sample_8.pdf,14,". Intuitively, we",10.061732292175293,NimbusRomNo9L-Regu,False,439.36199951171875,283.68829345703125,0.058823529411764705,17,H3
sample_8.pdf,14,want the model to learn the dependency of,9.982504844665527,NimbusRomNo9L-Regu,False,107.64099884033203,294.6573791503906,0.0,41,H3
sample_8.pdf,14,through a pretraining loss term,9.982504844665527,NimbusRomNo9L-Regu,False,307.0256042480469,294.6573791503906,0.0,31,H3
sample_8.pdf,14,log,9.962599754333496,CMR10,False,433.8261413574219,294.4419250488281,0.0,3,H3
sample_8.pdf,14,| U,9.962599754333496,CMSY10,False,465.4286193847656,294.31280517578125,0.3333333333333333,3,H3
sample_8.pdf,14,. For,9.982504844665527,NimbusRomNo9L-Regu,False,484.83099365234375,294.6573791503906,0.2,5,H3
sample_8.pdf,14,"example, given the above sentence, the pairs of interest",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,305.5814514160156,0.0,56,H3
sample_8.pdf,14,could be instantiated as:,9.962599754333496,NimbusRomNo9L-Regu,False,335.3056335449219,305.5814514160156,0.0,25,H3
sample_8.pdf,14,York,9.962599754333496,NimbusRomNo9L-Regu,False,158.4329071044922,326.7764892578125,0.25,4,H3
sample_8.pdf,14,New,9.962599754333496,NimbusRomNo9L-Regu,False,210.4929962158203,326.7764892578125,0.3333333333333333,3,H3
sample_8.pdf,14,York,9.962599754333496,NimbusRomNo9L-Regu,False,266.57391357421875,326.7764892578125,0.25,4,H3
sample_8.pdf,14,city,9.962599754333496,NimbusRomNo9L-Regu,False,318.63299560546875,326.7764892578125,0.0,4,H3
sample_8.pdf,14,York,9.962599754333496,NimbusRomNo9L-Regu,False,371.097900390625,326.7764892578125,0.25,4,H3
sample_8.pdf,14,"New, city",9.962599754333496,NimbusRomNo9L-Regu,False,423.1569519042969,326.7764892578125,0.1111111111111111,9,H3
sample_8.pdf,14,Note that,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,347.5653076171875,0.1111111111111111,9,H3
sample_8.pdf,14,"is merely a virtual notion without unique ground truth, and our analysis will hold",10.061732292175293,NimbusRomNo9L-Regu,False,155.73361206054688,347.5653076171875,0.0,82,H3
sample_8.pdf,14,regardless of how,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,358.5494689941406,0.0,17,H3
sample_8.pdf,14,is instantiated.,9.962599754333496,NimbusRomNo9L-Regu,False,186.2956085205078,358.5494689941406,0.0,16,H3
sample_8.pdf,14,Given a set of target tokens,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,374.86328125,0.03571428571428571,28,H3
sample_8.pdf,14,and a set of non-target tokens,10.061732292175293,NimbusRomNo9L-Regu,False,229.29161071777344,374.86328125,0.0,30,H3
sample_8.pdf,14,", BERT and XLNet both",10.061732292175293,NimbusRomNo9L-Regu,False,400.6329040527344,374.86328125,0.3333333333333333,21,H3
sample_8.pdf,14,maximize,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,385.84747314453125,0.0,8,H3
sample_8.pdf,14,log,9.962599754333496,CMR10,False,147.29251098632812,385.616943359375,0.0,3,H3
sample_8.pdf,14,T | N,9.962599754333496,CMSY10,False,173.197998046875,385.4878234863281,0.4,5,H3
sample_8.pdf,14,but with different formulations:,9.962599754333496,NimbusRomNo9L-Regu,False,202.97645568847656,385.84747314453125,0.0,32,H3
sample_8.pdf,14,BERT,6.973800182342529,NimbusRomNo9L-Regu,False,183.9400177001953,410.1401672363281,1.0,4,P
sample_8.pdf,14,log,9.962599754333496,CMR10,False,233.0280303955078,406.1489562988281,0.0,3,H3
sample_8.pdf,14,| N,9.962599754333496,CMSY10,False,262.1416320800781,406.01983642578125,0.3333333333333333,3,H3
sample_8.pdf,14,XLNet,6.973800182342529,NimbusRomNo9L-Regu,False,305.0990295410156,410.1401672363281,0.6,5,P
sample_8.pdf,14,log,9.962599754333496,CMR10,False,356.1460266113281,406.1489562988281,0.0,3,H3
sample_8.pdf,14,| N ∪T,9.962599754333496,CMSY10,False,385.2606201171875,406.01983642578125,0.3333333333333333,6,H3
sample_8.pdf,14,where,10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,434.1222839355469,0.0,5,H3
sample_8.pdf,14,denote tokens in,10.061732292175293,NimbusRomNo9L-Regu,False,151.63262939453125,434.1222839355469,0.0,16,H3
sample_8.pdf,14,that have a factorization order prior to,10.061732292175293,NimbusRomNo9L-Regu,False,230.95960998535156,434.1222839355469,0.0,40,H3
sample_8.pdf,14,. Both objectives consist,10.061732292175293,NimbusRomNo9L-Regu,False,402.0769958496094,434.1222839355469,0.04,25,H3
sample_8.pdf,14,of multiple,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,445.0312805175781,0.0,11,H3
sample_8.pdf,14,loss terms,10.061732292175293,NimbusRomNo9L-ReguItal,False,153.03733825683594,444.8530578613281,0.0,10,H3
sample_8.pdf,14,in the form of,10.061732292175293,NimbusRomNo9L-Regu,False,196.8113555908203,445.0312805175781,0.0,14,H3
sample_8.pdf,14,log,9.962599754333496,CMR10,False,256.1116943359375,444.87591552734375,0.0,3,H3
sample_8.pdf,14,| V,9.962599754333496,CMSY10,False,287.922607421875,444.7467956542969,0.3333333333333333,3,H3
sample_8.pdf,14,". Intuitively, if there exists a target-context pair",10.061732292175293,NimbusRomNo9L-Regu,False,311.9580078125,445.0312805175781,0.019230769230769232,52,H3
sample_8.pdf,14,such that,10.061732292175293,NimbusRomNo9L-Regu,False,152.23622131347656,455.9403076171875,0.0,9,H3
sample_8.pdf,14,U ⊆V,9.962599754333496,CMSY10,False,193.2767791748047,455.65582275390625,0.5,4,H3
sample_8.pdf,14,", then the loss term",10.061732292175293,NimbusRomNo9L-Regu,False,230.82400512695312,455.9403076171875,0.0,20,H3
sample_8.pdf,14,log,9.962599754333496,CMR10,False,310.7774963378906,455.7849426269531,0.0,3,H3
sample_8.pdf,14,| V,9.962599754333496,CMSY10,False,343.1145935058594,455.65582275390625,0.3333333333333333,3,H3
sample_8.pdf,14,provides a training signal to the,10.061732292175293,NimbusRomNo9L-Regu,False,369.10943603515625,455.9403076171875,0.0,33,H3
sample_8.pdf,14,dependency between,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,466.8792724609375,0.0,18,H3
sample_8.pdf,14,and,10.022196769714355,NimbusRomNo9L-Regu,False,200.28761291503906,466.8792724609375,0.0,3,H3
sample_8.pdf,14,". For convenience, we say a target-context pair",10.022196769714355,NimbusRomNo9L-Regu,False,227.05799865722656,466.8792724609375,0.02127659574468085,47,H3
sample_8.pdf,14,covered,10.022196769714355,NimbusRomNo9L-ReguItal,False,470.06280517578125,466.7017517089844,0.0,7,H3
sample_8.pdf,14,by a model (objective) if,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,477.8334655761719,0.0,25,H3
sample_8.pdf,14,U ⊆V,9.962599754333496,CMSY10,False,206.1017303466797,477.47381591796875,0.5,4,H3
sample_8.pdf,14,"Given the deﬁnition, let’s consider two cases:",9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,494.22247314453125,0.021739130434782608,46,H3
sample_8.pdf,14,U ⊆N,9.962599754333496,CMSY10,False,124.59809875488281,510.2508239746094,0.5,4,H3
sample_8.pdf,14,", the dependency",9.962599754333496,NimbusRomNo9L-Regu,False,157.23800659179688,510.6104736328125,0.0,16,H3
sample_8.pdf,14,is covered by both BERT and XLNet.,9.962599754333496,NimbusRomNo9L-Regu,False,251.90347290039062,510.6104736328125,0.20588235294117646,34,H3
sample_8.pdf,14,U ⊆N ∪T,9.962599754333496,CMSY10,False,124.51846313476562,523.11376953125,0.42857142857142855,7,H3
sample_8.pdf,14,and,9.902643203735352,NimbusRomNo9L-Regu,False,184.38563537597656,523.5189208984375,0.0,3,H3
sample_8.pdf,14,U ∩T,9.962599754333496,CMSY10,False,201.58335876464844,523.11376953125,0.5,4,H3
sample_8.pdf,14,", the dependency can only be covered by XLNet but not BERT.",9.902643203735352,NimbusRomNo9L-Regu,False,257.2860107421875,523.5189208984375,0.11864406779661017,59,H3
sample_8.pdf,14,"As a result, XLNet is able to cover more dependencies than BERT. In other words, the XLNet",10.061732292175293,NimbusRomNo9L-Regu,False,117.60399627685547,534.3072509765625,0.13333333333333333,90,H3
sample_8.pdf,14,"objective contains more effective training signals, which empirically leads to better performance in",9.862470626831055,NimbusRomNo9L-Regu,False,117.96299743652344,545.3673706054688,0.0,100,H3
sample_8.pdf,14,Section 3.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,556.200439453125,0.1,10,H3
sample_8.pdf,14,A.5.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,579.1535034179688,0.2,5,H3
sample_8.pdf,14,Comparison with Language Modeling,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,579.1535034179688,0.09090909090909091,33,H3
sample_8.pdf,14,"Borrowing examples and notations from Section A.5.1, a standard AR language model like GPT",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,597.7992553710938,0.08888888888888889,90,H3
sample_8.pdf,14,] is only able to cover the dependency,9.862470626831055,NimbusRomNo9L-Regu,False,121.21399688720703,608.859375,0.0,38,H3
sample_8.pdf,14,York,9.962599754333496,NimbusRomNo9L-Regu,False,292.0179138183594,608.783447265625,0.25,4,H3
sample_8.pdf,14,New,9.962599754333496,NimbusRomNo9L-Regu,False,344.0840148925781,608.783447265625,0.3333333333333333,3,H3
sample_8.pdf,14,but not,9.862470626831055,NimbusRomNo9L-Regu,False,371.50146484375,608.859375,0.0,7,H3
sample_8.pdf,14,New,9.962599754333496,NimbusRomNo9L-Regu,False,423.8208923339844,608.783447265625,0.3333333333333333,3,H3
sample_8.pdf,14,York,9.962599754333496,NimbusRomNo9L-Regu,False,475.0699768066406,608.783447265625,0.25,4,H3
sample_8.pdf,14,"XLNet, on the other hand, is able to cover both in expectation over all factorization orders. Such a",10.037040710449219,NimbusRomNo9L-Regu,False,107.64099884033203,619.635986328125,0.04,100,H3
sample_8.pdf,14,"limitation of AR language modeling can be critical in real-world applications. For example, consider",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,630.6583251953125,0.03,100,H3
sample_8.pdf,14,a span extraction question answering task with the context “Thom Yorke is the singer of Radiohead”,9.932666778564453,NimbusRomNo9L-Regu,False,108.0,641.5331420898438,0.030612244897959183,98,H3
sample_8.pdf,14,and the question “Who is the singer of Radiohead”. The representations of “Thom Yorke” are not,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,652.34423828125,0.05319148936170213,94,H3
sample_8.pdf,14,dependent on “Radiohead” with AR language modeling and thus they will not be chosen as the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,663.2532958984375,0.03333333333333333,90,H3
sample_8.pdf,14,"answer by the standard approach that employs softmax over all token representations. More formally,",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,674.3095703125,0.010101010101010102,99,H3
sample_8.pdf,14,consider a context-target pair,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,685.146484375,0.0,30,H3
sample_8.pdf,14,U ̸⊆T,9.962599754333496,CMSY10,False,124.73078918457031,701.17578125,0.4,5,H3
sample_8.pdf,14,", where",10.061732292175293,NimbusRomNo9L-Regu,False,168.05499267578125,701.4602661132812,0.0,7,H3
sample_8.pdf,14,denotes the tokens prior to,10.061732292175293,NimbusRomNo9L-Regu,False,218.32362365722656,701.4602661132812,0.0,27,H3
sample_8.pdf,14,"in the original sequence, AR language",10.061732292175293,NimbusRomNo9L-Regu,False,341.6826171875,701.4602661132812,0.05405405405405406,37,H3
sample_8.pdf,14,modeling is not able to cover the dependency.,9.962599754333496,NimbusRomNo9L-Regu,False,117.96299743652344,712.4444580078125,0.0,45,H3
sample_8.pdf,15,"In comparison, XLNet is able to cover all dependencies in expectation.",9.962599754333496,NimbusRomNo9L-Regu,False,112.9813003540039,74.40748596191406,0.05714285714285714,70,H3
sample_8.pdf,15,Approaches like ELMo [,9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,90.87142181396484,0.18181818181818182,22,H3
sample_8.pdf,15,"] concatenate forward and backward language models in a shallow manner,",9.862470626831055,NimbusRomNo9L-Regu,False,214.17100524902344,90.87142181396484,0.0,71,H3
sample_8.pdf,15,which is not sufﬁcient for modeling deep interactions between the two directions.,9.962599754333496,NimbusRomNo9L-Regu,False,107.64099884033203,101.70448303222656,0.0,81,H3
sample_8.pdf,15,A.5.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,135.78350830078125,0.2,5,H3
sample_8.pdf,15,Bridging the Gap Between Language Modeling and Pretraining,9.962599754333496,NimbusRomNo9L-Medi,False,140.0994873046875,135.78350830078125,0.10344827586206896,58,H3
sample_8.pdf,15,With a deep root in density estimation,9.867501258850098,NimbusRomNo9L-Regu,False,107.53199768066406,158.9995574951172,0.02631578947368421,38,H3
sample_8.pdf,15,"], language modeling has been a rapidly-developing",9.867501258850098,NimbusRomNo9L-Regu,False,301.30499267578125,158.9995574951172,0.0,50,H3
sample_8.pdf,15,research area [,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,169.77255249023438,0.0,15,H3
sample_8.pdf,15,"]. However, there has been a gap between language modeling and pretraining",10.046924591064453,NimbusRomNo9L-Regu,False,191.9199981689453,169.77255249023438,0.013513513513513514,74,H3
sample_8.pdf,15,"due to the lack of the capability of bidirectional context modeling, as analyzed in Section A.5.2. It",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,180.6927947998047,0.0297029702970297,101,H3
sample_8.pdf,15,has even been challenged by some machine learning practitioners whether language modeling is a,10.046924591064453,NimbusRomNo9L-Regu,False,108.0,191.59054565429688,0.0,94,H3
sample_8.pdf,15,meaningful pursuit if it does not directly improve downstream tasks,9.972557067871094,NimbusRomNo9L-Regu,False,108.0,202.55593872070312,0.0,67,H3
sample_8.pdf,15,. XLNet generalizes language,9.972557067871094,NimbusRomNo9L-Regu,False,384.7760009765625,202.55593872070312,0.10714285714285714,28,H3
sample_8.pdf,15,"modeling and bridges such a gap. As a result, it further “justiﬁes” language modeling research.",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,213.39828491210938,0.010526315789473684,95,H3
sample_8.pdf,15,"Moreover, it becomes possible to leverage the rapid progress of language modeling research for",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,224.30728149414062,0.010638297872340425,94,H3
sample_8.pdf,15,"pretraining. As an example, we integrate Transformer-XL into XLNet to demonstrate the usefulness",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,235.3179473876953,0.07291666666666667,96,H3
sample_8.pdf,15,of the latest language modeling progress.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,246.20045471191406,0.0,41,H3
sample_8.pdf,15,A.6,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,281.62451171875,0.3333333333333333,3,H3
sample_8.pdf,15,Qualitative Analysis of Attention Patterns,9.962599754333496,NimbusRomNo9L-Medi,False,132.62754821777344,281.62451171875,0.09523809523809523,42,H3
sample_8.pdf,15,"We compare the attention pattern of BERT and XLNet without ﬁnetuning. Firstly, we found 4 typical",9.867501258850098,NimbusRomNo9L-Regu,False,107.53199768066406,306.18560791015625,0.09278350515463918,97,H3
sample_8.pdf,15,"patterns shared by both, as shown in Fig. 2.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,317.0224609375,0.022727272727272728,44,H3
sample_8.pdf,15,(a) Content stripes,8.966400146484375,NimbusRomNo9L-Regu,False,118.29100036621094,431.0469665527344,0.05263157894736842,19,P
sample_8.pdf,15,(b) Local/Self focus,8.966400146484375,NimbusRomNo9L-Regu,False,218.18699645996094,431.0469665527344,0.1,20,P
sample_8.pdf,15,(c) Two segments,8.966400146484375,NimbusRomNo9L-Regu,False,325.0220031738281,431.0469665527344,0.0625,16,P
sample_8.pdf,15,(d) Content-based symme-,8.876283645629883,NimbusRomNo9L-Regu,False,412.6260070800781,421.1523132324219,0.041666666666666664,24,P
sample_8.pdf,15,try,8.966400146484375,NimbusRomNo9L-Regu,False,412.9219970703125,431.0469665527344,0.0,3,P
sample_8.pdf,15,Figure 2:,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,444.8262939453125,0.1111111111111111,9,H3
sample_8.pdf,15,Attention patterns,9.055620193481445,NimbusRomNo9L-Regu,False,146.0459747314453,445.5893249511719,0.05555555555555555,18,P
sample_8.pdf,15,shared by XLNet and BERT,8.966400146484375,NimbusRomNo9L-Medi,False,218.11964416503906,445.5751037597656,0.2916666666666667,24,P
sample_8.pdf,15,. Rows and columns represent query and key,9.055620193481445,NimbusRomNo9L-Regu,False,333.9630126953125,445.5893249511719,0.023809523809523808,42,P
sample_8.pdf,15,respectively.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,455.6189880371094,0.0,13,P
sample_8.pdf,15,"More interestingly, in Fig. 3, we present 3 patterns that only appear in XLNet but not BERT: (a) The",9.902643203735352,NimbusRomNo9L-Regu,False,108.0,478.9699401855469,0.1,100,H3
sample_8.pdf,15,"self-exclusion pattern attends to all other tokens but itself, probably offering a fast way to gather",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,489.75830078125,0.0,101,H3
sample_8.pdf,15,global information; (b) The relative-stride pattern attends to positions every a few stride apart,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,500.81842041015625,0.010309278350515464,97,H3
sample_8.pdf,15,relative,9.862470626831055,NimbusRomNo9L-ReguItal,False,472.1142883300781,500.6437072753906,0.0,8,H3
sample_8.pdf,15,to the query position; (c) The one-side masked pattern is very similar to the lower-left part of Fig.,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,511.5763244628906,0.019801980198019802,101,H3
sample_8.pdf,15,"1-(d), with the upper-right triangle masked out. It seems that the model learns not to attend the",10.061732292175293,NimbusRomNo9L-Regu,False,107.25299835205078,522.4852294921875,0.010309278350515464,97,H3
sample_8.pdf,15,relative,9.962599754333496,NimbusRomNo9L-ReguItal,False,108.0,533.2930297851562,0.0,8,H3
sample_8.pdf,15,right half. Note that all these three unique patterns involve the,9.962599754333496,NimbusRomNo9L-Regu,False,138.067138671875,533.469482421875,0.015384615384615385,65,H3
sample_8.pdf,15,relative,9.962599754333496,NimbusRomNo9L-ReguItal,False,387.5756530761719,533.2930297851562,0.0,8,H3
sample_8.pdf,15,positions rather than,9.962599754333496,NimbusRomNo9L-Regu,False,420.1380920410156,533.469482421875,0.0,21,H3
sample_8.pdf,15,"absolute ones, and hence are likely enabled by the “relative attention” mechanism in XLNet. We",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,544.3032836914062,0.0425531914893617,94,H3
sample_8.pdf,15,conjecture these unique patterns contribute to the performance advantage of XLNet. On the other,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,555.2122802734375,0.042105263157894736,95,H3
sample_8.pdf,15,"hand, the proposed permutation LM objective mostly contributes to a better data efﬁciency, whose",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,566.143798828125,0.020833333333333332,96,H3
sample_8.pdf,15,effects may not be obvious from qualitative visualization.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,577.10546875,0.0,58,H3
sample_8.pdf,15,(a) Self exclusion,8.966400146484375,NimbusRomNo9L-Regu,False,119.8550033569336,678.7989501953125,0.05555555555555555,18,P
sample_8.pdf,15,(b) Relative stride,8.966400146484375,NimbusRomNo9L-Regu,False,273.65899658203125,678.7989501953125,0.05263157894736842,19,P
sample_8.pdf,15,(c) One-side masked,8.966400146484375,NimbusRomNo9L-Regu,False,423.239013671875,678.7989501953125,0.05263157894736842,19,P
sample_8.pdf,15,Figure 3:,10.017244338989258,NimbusRomNo9L-Regu,False,108.0,692.6119995117188,0.1111111111111111,9,H3
sample_8.pdf,15,Attention patterns that,9.015580177307129,NimbusRomNo9L-Regu,False,144.63253784179688,693.3716430664062,0.043478260869565216,23,P
sample_8.pdf,15,appear only in XLNet,8.966400146484375,NimbusRomNo9L-Medi,False,228.7723846435547,693.3270874023438,0.15,20,P
sample_8.pdf,15,. Rows and columns represent query and key respec-,9.015580177307129,NimbusRomNo9L-Regu,False,314.47198486328125,693.3716430664062,0.02,50,P
sample_8.pdf,15,tively.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,703.3719482421875,0.0,7,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,271.026611328125,143.9006805419922,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,162.54119873046875,144.3401641845703,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,198.79296875,144.3401641845703,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,271.026611328125,105.22468566894531,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,162.54119873046875,105.22468566894531,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,198.79296875,105.22468566894531,0.0,3,P
sample_8.pdf,16,Factorization order: 3,7.0320000648498535,CMUSerif-Roman,False,160.82534790039062,203.42657470703125,0.045454545454545456,22,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,162.54119873046875,304.7576599121094,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,271.026611328125,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,162.54119873046875,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,198.79296875,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,234.747314453125,265.6421813964844,0.0,3,P
sample_8.pdf,16,Factorization order: 1,7.0320000648498535,CMUSerif-Roman,False,160.71530151367188,363.84405517578125,0.045454545454545456,22,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,271.026611328125,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,198.79296875,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,234.747314453125,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,234.747314453125,143.9006805419922,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,234.747314453125,105.22468566894531,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,111.05985260009766,184.86207580566406,0.0,3,P
sample_8.pdf,16,(+),5.27400016784668,CambriaMath,False,126.44235229492188,183.8951873779297,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,110.53829956054688,345.27960205078125,0.0,3,P
sample_8.pdf,16,(+),5.27400016784668,CambriaMath,False,125.9207992553711,344.3126525878906,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,493.5796203613281,143.9006805419922,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,385.09423828125,144.3401641845703,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,493.5796203613281,105.22468566894531,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,385.09423828125,105.22468566894531,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,457.3004150390625,105.22468566894531,0.0,3,P
sample_8.pdf,16,Factorization order: 2,7.0320000648498535,CMUSerif-Roman,False,383.2684020996094,203.42657470703125,0.045454545454545456,22,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,421.3460693359375,144.3401641845703,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,457.3004150390625,143.9006805419922,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,421.3460693359375,105.22468566894531,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,493.5796203613281,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,385.09423828125,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,421.3460693359375,304.7576599121094,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,457.3004150390625,304.7576599121094,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,493.5796203613281,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,385.09423828125,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,421.3460693359375,265.6421813964844,0.0,3,P
sample_8.pdf,16,($),5.27400016784668,CambriaMath,False,457.3004150390625,265.6421813964844,0.0,3,P
sample_8.pdf,16,Factorization order: 4,7.0320000648498535,CMUSerif-Roman,False,383.2684020996094,363.84405517578125,0.045454545454545456,22,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,333.09136962890625,345.27960205078125,0.0,3,P
sample_8.pdf,16,(+),5.27400016784668,CambriaMath,False,348.473876953125,344.3126525878906,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,333.416259765625,184.86207580566406,0.0,3,P
sample_8.pdf,16,(+),5.27400016784668,CambriaMath,False,348.79876708984375,183.8951873779297,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,333.416259765625,146.1860809326172,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,348.79876708984375,145.2191619873047,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,111.05985260009766,146.1860809326172,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,126.44235229492188,145.2191619873047,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,110.53829956054688,306.60357666015625,0.0,3,P
sample_8.pdf,16,(#),5.27400016784668,CambriaMath,False,125.9207992553711,305.6366271972656,0.0,3,P
sample_8.pdf,16,mem,7.0320000648498535,CambriaMath,False,333.09136962890625,306.60357666015625,0.0,3,P
sample_8.pdf,16,(+),5.27400016784668,CambriaMath,False,348.473876953125,305.6366271972656,0.0,3,P
sample_8.pdf,16,Figure 4: Illustration of the permutation language modeling objective for predicting,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,383.5513000488281,0.023809523809523808,84,H3
sample_8.pdf,16,given the,10.061732292175293,NimbusRomNo9L-Regu,False,463.3190612792969,383.5513000488281,0.0,9,H3
sample_8.pdf,16,same input sequence,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,394.53546142578125,0.0,19,H3
sample_8.pdf,16,but with different factorization orders.,9.962599754333496,NimbusRomNo9L-Regu,False,198.98831176757812,394.53546142578125,0.0,40,H3
sample_8.pdf,16,A.7,9.962599754333496,NimbusRomNo9L-Medi,False,108.00001525878906,427.60552978515625,0.3333333333333333,3,H3
sample_8.pdf,16,Visualizing Memory and Permutation,9.962599754333496,NimbusRomNo9L-Medi,False,132.6275634765625,427.60552978515625,0.08823529411764706,34,H3
sample_8.pdf,16,"In this section, we provide a detailed visualization of the proposed permutation language modeling",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,447.6450500488281,0.01020408163265306,98,H3
sample_8.pdf,16,"objective, including the mechanism of reusing memory (aka the recurrence mechanism), how we use",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,458.6373291015625,0.0,95,H3
sample_8.pdf,16,"attention masks to permute the factorization order, and the difference of the two attention streams.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,469.4894714355469,0.0,100,H3
sample_8.pdf,16,"As shown in Figure 5 and 6, given the current position",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,485.80328369140625,0.037037037037037035,54,H3
sample_8.pdf,16,", the attention mask is decided by the",10.061732292175293,NimbusRomNo9L-Regu,False,347.7770080566406,485.80328369140625,0.0,38,H3
sample_8.pdf,16,permutation (or factorization order),9.862470626831055,NimbusRomNo9L-Regu,False,108.0,496.8634033203125,0.0,36,H3
sample_8.pdf,16,such that only tokens the occur before,9.862470626831055,NimbusRomNo9L-Regu,False,254.0048828125,496.8634033203125,0.0,38,H3
sample_8.pdf,16,in the permutation can,9.862470626831055,NimbusRomNo9L-Regu,False,413.99267578125,496.8634033203125,0.0,22,H3
sample_8.pdf,16,"be attended; i.e., positions",10.02714729309082,NimbusRomNo9L-Regu,False,108.0,507.64752197265625,0.0,28,H3
sample_8.pdf,16,with,10.02714729309082,NimbusRomNo9L-Regu,False,223.25540161132812,507.64752197265625,0.0,4,H3
sample_8.pdf,16,i < t,9.962599754333496,CMMI10,False,244.1917724609375,507.4659423828125,0.0,5,H3
sample_8.pdf,16,". Moreover, comparing Figure 5 and 6, we can see how the",10.02714729309082,NimbusRomNo9L-Regu,False,267.0060119628906,507.64752197265625,0.03571428571428571,56,H3
sample_8.pdf,16,query stream and the content stream work differently with a speciﬁc permutation through attention,10.007330894470215,NimbusRomNo9L-Regu,False,108.0,518.571533203125,0.0,97,H3
sample_8.pdf,16,masks. The main difference is that the query stream cannot do self-attention and does not have access,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,529.5903930664062,0.009900990099009901,101,H3
sample_8.pdf,16,"to the token at the position, while the content stream performs normal self-attention.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,540.4234619140625,0.0,86,H3
sample_8.pdf,16,The problem of language modeling is essentially density estimation for text data.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13999938964844,702.3489379882812,0.012345679012345678,81,P
sample_8.pdf,16,https://openreview.net/forum?id=HJePno0cYm,8.966400146484375,SFTT0900,False,124.13999938964844,713.4232177734375,0.09523809523809523,42,P
sample_8.pdf,17,Position-3 View,6.584479808807373,CMUSerif-Roman,False,177.97157287597656,451.7834167480469,0.13333333333333333,15,P
sample_8.pdf,17,Position-2 View,6.584479808807373,CMUSerif-Roman,False,392.6632385253906,451.7834167480469,0.13333333333333333,15,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,280.5815124511719,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,164.48863220214844,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,203.2825469970703,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,280.5815124511719,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,164.48863220214844,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,203.2825469970703,350.00146484375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,241.75819396972656,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,241.75819396972656,350.00146484375,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,112.38438415527344,435.6937561035156,0.0,3,P
sample_8.pdf,17,(+),4.703199863433838,CambriaMath,False,126.49398040771484,435.12933349609375,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,112.21721649169922,392.4242858886719,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,126.32681274414062,391.85992431640625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,265.71484375,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,149.62191772460938,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,188.41583251953125,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,226.89154052734375,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,265.71484375,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,149.62191772460938,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,188.41583251953125,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,226.89154052734375,350.00146484375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,495.2732238769531,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,379.1802978515625,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,417.9742126464844,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,495.2732238769531,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,379.1802978515625,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,417.9742126464844,350.00146484375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,456.4499206542969,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,456.4499206542969,350.00146484375,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,326.90887451171875,434.2828063964844,0.0,3,P
sample_8.pdf,17,(+),4.703199863433838,CambriaMath,False,341.01849365234375,433.71844482421875,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,326.90887451171875,392.4242858886719,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,341.01849365234375,391.85992431640625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,480.406494140625,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,364.3135681152344,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,403.1075134277344,391.38958740234375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,441.58319091796875,391.38958740234375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,480.406494140625,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,364.3135681152344,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,403.1075134277344,350.00146484375,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,441.58319091796875,350.00146484375,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,280.5815124511719,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,164.48863220214844,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,203.2825469970703,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,280.5815124511719,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,164.48863220214844,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,203.2825469970703,481.22076416015625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,241.75819396972656,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,241.75819396972656,481.22076416015625,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,112.21721649169922,565.5020751953125,0.0,3,P
sample_8.pdf,17,(+),4.703199863433838,CambriaMath,False,126.32681274414062,564.937744140625,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,112.21721649169922,524.1138916015625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,126.32681274414062,523.549560546875,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,265.71484375,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,149.62191772460938,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,188.41583251953125,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,226.89154052734375,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,265.71484375,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,149.62191772460938,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,188.41583251953125,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,226.89154052734375,481.22076416015625,0.0,3,P
sample_8.pdf,17,Position-4 View,6.584479808807373,CMUSerif-Roman,False,177.97157287597656,583.943359375,0.13333333333333333,15,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,495.2732238769531,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,379.1802978515625,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,417.9742126464844,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,495.2732238769531,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,379.1802978515625,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,417.9742126464844,481.22076416015625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,456.4499206542969,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,456.4499206542969,481.22076416015625,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,326.90887451171875,565.5020751953125,0.0,3,P
sample_8.pdf,17,(+),4.703199863433838,CambriaMath,False,341.01849365234375,564.937744140625,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,326.90887451171875,524.1138916015625,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,341.01849365234375,523.549560546875,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,480.406494140625,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,364.3135681152344,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,403.1075134277344,523.0792236328125,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,441.58319091796875,523.0792236328125,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,480.406494140625,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,364.3135681152344,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,403.1075134277344,481.22076416015625,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,441.58319091796875,481.22076416015625,0.0,3,P
sample_8.pdf,17,Position-1 View,6.584479808807373,CMUSerif-Roman,False,392.6632385253906,583.943359375,0.13333333333333333,15,P
sample_8.pdf,17,Split View of the Content Stream,6.584479808807373,CMUSerif-Roman,False,256.02001953125,599.9342041015625,0.125,32,P
sample_8.pdf,17,(Factorization order: 3,6.584479808807373,CMUSerif-Roman,False,249.43556213378906,607.9296875,0.043478260869565216,23,P
sample_8.pdf,17,Joint View of the Content Stream,6.584479808807373,CMUSerif-Roman,False,256.41741943359375,265.0663757324219,0.125,32,P
sample_8.pdf,17,(Factorization order: 3,6.584479808807373,CMUSerif-Roman,False,250.30325317382812,273.0617980957031,0.043478260869565216,23,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,219.56304931640625,244.27352905273438,0.0,3,P
sample_8.pdf,17,(+),4.703199863433838,CambriaMath,False,233.6726531982422,243.70912170410156,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,387.9273376464844,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,271.83447265625,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,310.6283874511719,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,349.1040954589844,183.50819396972656,0.0,3,P
sample_8.pdf,17,mem,6.584479808807373,CambriaMath,False,219.56304931640625,184.54287719726562,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,233.6726531982422,183.97853088378906,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,373.0606689453125,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,256.9677429199219,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,295.76165771484375,183.50819396972656,0.0,3,P
sample_8.pdf,17,(%),4.703199863433838,CambriaMath,False,334.23736572265625,183.50819396972656,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,387.9273376464844,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,271.83447265625,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,310.6283874511719,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,349.1040954589844,123.30719757080078,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,373.0606689453125,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,256.9677429199219,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,295.76165771484375,123.77753448486328,0.0,3,P
sample_8.pdf,17,('),4.703199863433838,CambriaMath,False,334.23736572265625,123.30719757080078,0.0,3,P
sample_8.pdf,17,Split View,8.46575927734375,CMUSerif-Bold,True,282.990478515625,308.441162109375,0.2,10,P
sample_8.pdf,17,Figure 5: A detailed illustration of the,9.95761775970459,NimbusRomNo9L-Regu,False,108.0,626.7882080078125,0.05,40,H3
sample_8.pdf,17,content stream,9.962599754333496,NimbusRomNo9L-Medi,False,259.5587463378906,626.6934814453125,0.0,14,H3
sample_8.pdf,17,of the proposed objective with both the joint,9.95761775970459,NimbusRomNo9L-Regu,False,325.2288818359375,626.7882080078125,0.0,45,H3
sample_8.pdf,17,"view and split views based on a length-4 sequence under the factorization order [3, 2, 4, 1].",9.962599754333496,NimbusRomNo9L-Regu,False,107.7509994506836,637.6934814453125,0.0,93,H3
sample_8.pdf,17,"Note that if we ignore the query representation, the computation in this ﬁgure is simply the standard",9.932666778564453,NimbusRomNo9L-Regu,False,108.0,648.6251831054688,0.009900990099009901,101,H3
sample_8.pdf,17,"self-attention, though with a particular attention mask.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,659.511474609375,0.0,56,H3
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,280.5815124511719,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,164.48863220214844,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,203.2825469970703,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,280.5815124511719,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,164.48863220214844,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,203.2825469970703,349.5304870605469,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,241.75819396972656,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,241.75819396972656,349.5304870605469,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,112.38438415527344,435.22283935546875,0.0,3,P
sample_8.pdf,18,(+),4.703199863433838,CambriaMath,False,126.49398040771484,434.6584167480469,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,112.21721649169922,391.953369140625,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,126.32681274414062,391.3889465332031,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,265.71484375,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,149.62191772460938,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,188.41583251953125,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,226.89154052734375,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,265.71484375,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,149.62191772460938,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,188.41583251953125,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,226.89154052734375,349.5304870605469,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,495.2732238769531,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,379.1802978515625,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,417.9742126464844,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,495.2732238769531,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,379.1802978515625,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,417.9742126464844,349.5304870605469,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,456.4499206542969,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,456.4499206542969,349.5304870605469,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,326.90887451171875,433.81182861328125,0.0,3,P
sample_8.pdf,18,(+),4.703199863433838,CambriaMath,False,341.01849365234375,433.2474670410156,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,326.90887451171875,391.953369140625,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,341.01849365234375,391.3889465332031,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,480.406494140625,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,364.3135681152344,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,403.1075134277344,390.9186706542969,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,441.58319091796875,390.9186706542969,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,480.406494140625,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,364.3135681152344,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,403.1075134277344,349.5304870605469,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,441.58319091796875,349.5304870605469,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,495.2732238769531,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,379.1802978515625,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,417.9742126464844,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,495.2732238769531,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,379.1802978515625,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,417.9742126464844,480.7497863769531,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,456.4499206542969,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,456.4499206542969,480.7497863769531,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,326.90887451171875,565.0310668945312,0.0,3,P
sample_8.pdf,18,(+),4.703199863433838,CambriaMath,False,341.01849365234375,564.4667358398438,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,326.90887451171875,523.6430053710938,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,341.01849365234375,523.0785522460938,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,480.406494140625,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,364.3135681152344,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,403.1075134277344,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,441.58319091796875,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,480.406494140625,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,364.3135681152344,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,403.1075134277344,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,441.58319091796875,480.7497863769531,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,280.5815124511719,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,164.48863220214844,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,203.2825469970703,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,280.5815124511719,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,164.48863220214844,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,203.2825469970703,480.7497863769531,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,241.75819396972656,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,241.75819396972656,480.7497863769531,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,112.21721649169922,565.0310668945312,0.0,3,P
sample_8.pdf,18,(+),4.703199863433838,CambriaMath,False,126.32681274414062,564.4667358398438,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,112.21721649169922,523.6430053710938,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,126.32681274414062,523.0785522460938,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,265.71484375,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,149.62191772460938,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,188.41583251953125,522.6083374023438,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,226.89154052734375,522.6083374023438,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,265.71484375,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,149.62191772460938,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,188.41583251953125,480.7497863769531,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,226.89154052734375,480.7497863769531,0.0,3,P
sample_8.pdf,18,Position-3 View,6.584479808807373,CMUSerif-Roman,False,177.97157287597656,451.31243896484375,0.13333333333333333,15,P
sample_8.pdf,18,Position-2 View,6.584479808807373,CMUSerif-Roman,False,392.6632385253906,451.31243896484375,0.13333333333333333,15,P
sample_8.pdf,18,Position-4 View,6.584479808807373,CMUSerif-Roman,False,177.97157287597656,583.4723510742188,0.13333333333333333,15,P
sample_8.pdf,18,Position-1 View,6.584479808807373,CMUSerif-Roman,False,392.6632385253906,583.4723510742188,0.13333333333333333,15,P
sample_8.pdf,18,Split View of the Query Stream,6.584479808807373,CMUSerif-Roman,False,258.84197998046875,599.4633178710938,0.13333333333333333,30,P
sample_8.pdf,18,(Factorization order: 3,6.584479808807373,CMUSerif-Roman,False,249.43556213378906,607.4586791992188,0.043478260869565216,23,P
sample_8.pdf,18,Split View,8.46575927734375,CMUSerif-Bold,True,282.990478515625,307.9702453613281,0.2,10,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,218.54721069335938,245.21356201171875,0.0,3,P
sample_8.pdf,18,(+),4.703199863433838,CambriaMath,False,232.6568145751953,244.64915466308594,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,386.91156005859375,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,270.818603515625,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,309.612548828125,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,348.0882568359375,184.44822692871094,0.0,3,P
sample_8.pdf,18,mem,6.584479808807373,CambriaMath,False,218.54721069335938,185.0125732421875,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,232.6568145751953,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,372.0448303222656,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,255.9519500732422,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,294.7458190917969,184.44822692871094,0.0,3,P
sample_8.pdf,18,(%),4.703199863433838,CambriaMath,False,333.2215270996094,184.44822692871094,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,386.91156005859375,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,270.818603515625,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,309.612548828125,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,348.0882568359375,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,372.0448303222656,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,255.9519500732422,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,294.7458190917969,124.24723052978516,0.0,3,P
sample_8.pdf,18,('),4.703199863433838,CambriaMath,False,333.2215270996094,124.24723052978516,0.0,3,P
sample_8.pdf,18,Joint View of the Query Stream,6.584479808807373,CMUSerif-Roman,False,258.37164306640625,266.00640869140625,0.13333333333333333,30,P
sample_8.pdf,18,(Factorization order: 3,6.584479808807373,CMUSerif-Roman,False,249.43556213378906,274.0018310546875,0.043478260869565216,23,P
sample_8.pdf,18,Figure 6: A detailed illustration of the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,626.23828125,0.05,40,H3
sample_8.pdf,18,query stream,9.962599754333496,NimbusRomNo9L-Medi,False,262.60247802734375,626.2225341796875,0.0,12,H3
sample_8.pdf,18,of the proposed objective with both the joint,10.061732292175293,NimbusRomNo9L-Regu,False,321.6846923828125,626.23828125,0.0,45,H3
sample_8.pdf,18,"view and split views based on a length-4 sequence under the factorization order [3, 2, 4, 1].",9.962599754333496,NimbusRomNo9L-Regu,False,107.7509994506836,637.2234497070312,0.0,93,H3
sample_8.pdf,18,"The dash arrows indicate that the query stream cannot access the token (content) at the same position,",9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,648.2083740234375,0.00980392156862745,102,H3
sample_8.pdf,18,but only the location information.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,659.0414428710938,0.0,34,H3
sample_9.pdf,1,Attention Is All You Need,17.21540069580078,NimbusRomNo9L-Medi,False,211.48800659179688,99.8338394165039,0.2,25,TITLE
sample_9.pdf,1,Ashish Vaswani,9.962599754333496,NimbusRomNo9L-Medi,False,132.9080047607422,186.051513671875,0.14285714285714285,14,H3
sample_9.pdf,1,Google Brain,9.962599754333496,NimbusRomNo9L-Regu,False,139.37899780273438,197.05250549316406,0.16666666666666666,12,H3
sample_9.pdf,1,avaswani@google.com,9.962599754333496,SFTT1000,False,116.68099975585938,208.20953369140625,0.0,19,H3
sample_9.pdf,1,Noam Shazeer,9.962599754333496,NimbusRomNo9L-Medi,False,239.06199645996094,186.051513671875,0.16666666666666666,12,H3
sample_9.pdf,1,Google Brain,9.962599754333496,NimbusRomNo9L-Regu,False,242.9320068359375,197.05250549316406,0.16666666666666666,12,H3
sample_9.pdf,1,noam@google.com,9.962599754333496,SFTT1000,False,230.69200134277344,208.20953369140625,0.0,15,H3
sample_9.pdf,1,Niki Parmar,9.962599754333496,NimbusRomNo9L-Medi,False,338.6920166015625,186.051513671875,0.18181818181818182,11,H3
sample_9.pdf,1,Google Research,9.962599754333496,NimbusRomNo9L-Regu,False,331.4540100097656,197.05250549316406,0.13333333333333333,15,H3
sample_9.pdf,1,nikip@google.com,9.962599754333496,SFTT1000,False,323.7870178222656,208.20953369140625,0.0,16,H3
sample_9.pdf,1,Jakob Uszkoreit,9.962599754333496,NimbusRomNo9L-Medi,False,424.3000183105469,186.051513671875,0.13333333333333333,15,H3
sample_9.pdf,1,Google Research,9.962599754333496,NimbusRomNo9L-Regu,False,424.54901123046875,197.05250549316406,0.13333333333333333,15,H3
sample_9.pdf,1,usz@google.com,9.962599754333496,SFTT1000,False,422.11199951171875,208.20953369140625,0.0,14,H3
sample_9.pdf,1,Llion Jones,9.962599754333496,NimbusRomNo9L-Medi,False,144.2919921875,236.049560546875,0.18181818181818182,11,H3
sample_9.pdf,1,Google Research,9.962599754333496,NimbusRomNo9L-Regu,False,134.54800415039062,247.0495147705078,0.13333333333333333,15,H3
sample_9.pdf,1,llion@google.com,9.962599754333496,SFTT1000,False,126.88200378417969,258.20654296875,0.0,16,H3
sample_9.pdf,1,Aidan N. Gomez,9.962599754333496,NimbusRomNo9L-Medi,False,248.76100158691406,236.049560546875,0.21428571428571427,14,H3
sample_9.pdf,1,University of Toronto,9.962599754333496,NimbusRomNo9L-Regu,False,244.57498168945312,247.0495147705078,0.09523809523809523,21,H3
sample_9.pdf,1,aidan@cs.toronto.edu,9.962599754333496,SFTT1000,False,235.406982421875,258.20654296875,0.0,20,H3
sample_9.pdf,1,Łukasz Kaiser,9.962599754333496,NimbusRomNo9L-Medi,False,394.125,236.049560546875,0.15384615384615385,13,H3
sample_9.pdf,1,Google Brain,9.962599754333496,NimbusRomNo9L-Regu,False,398.0050048828125,247.0495147705078,0.16666666666666666,12,H3
sample_9.pdf,1,lukaszkaiser@google.com,9.962599754333496,SFTT1000,False,364.8489990234375,258.20654296875,0.0,23,H3
sample_9.pdf,1,Illia Polosukhin,9.962599754333496,NimbusRomNo9L-Medi,False,268.8070068359375,286.04656982421875,0.125,16,H3
sample_9.pdf,1,illia.polosukhin@gmail.com,9.962599754333496,SFTT1000,False,238.02200317382812,297.2955627441406,0.0,26,H3
sample_9.pdf,1,Abstract,11.9552001953125,NimbusRomNo9L-Medi,False,283.75799560546875,336.60821533203125,0.125,8,H3
sample_9.pdf,1,The dominant sequence transduction models are based on complex recurrent or,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,362.0052795410156,0.013333333333333334,75,H3
sample_9.pdf,1,convolutional neural networks that include an encoder and a decoder. The best,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,372.914306640625,0.012987012987012988,77,H3
sample_9.pdf,1,performing models also connect the encoder and decoder through an attention,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,383.82330322265625,0.0,75,H3
sample_9.pdf,1,"mechanism. We propose a new simple network architecture, the Transformer,",10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,394.7322998046875,0.0273972602739726,73,H3
sample_9.pdf,1,"based solely on attention mechanisms, dispensing with recurrence and convolutions",9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,405.79241943359375,0.0,81,H3
sample_9.pdf,1,entirely. Experiments on two machine translation tasks show these models to,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,416.55029296875,0.013333333333333334,75,H3
sample_9.pdf,1,be superior in quality while being more parallelizable and requiring signiﬁcantly,10.022196769714355,NimbusRomNo9L-Regu,False,143.86599731445312,427.4892578125,0.0,81,H3
sample_9.pdf,1,less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,438.3682861328125,0.1232876712328767,73,H3
sample_9.pdf,1,"to-German translation task, improving over the existing best results, including",10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,449.2782897949219,0.012658227848101266,79,H3
sample_9.pdf,1,"ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,",9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,460.3384094238281,0.1282051282051282,78,H3
sample_9.pdf,1,our model establishes a new single-model state-of-the-art BLEU score of 41.8 after,9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,471.2474060058594,0.04878048780487805,82,H3
sample_9.pdf,1,"training for 3.5 days on eight GPUs, a small fraction of the training costs of the",10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,482.0052795410156,0.036585365853658534,82,H3
sample_9.pdf,1,best models from the literature. We show that the Transformer generalizes well to,9.942654609680176,NimbusRomNo9L-Regu,False,143.86599731445312,493.0046081542969,0.024691358024691357,81,H3
sample_9.pdf,1,other tasks by applying it successfully to English constituency parsing both with,10.037040710449219,NimbusRomNo9L-Regu,False,143.86599731445312,503.842041015625,0.012345679012345678,81,H3
sample_9.pdf,1,large and limited training data.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86599731445312,514.8074951171875,0.0,32,H3
sample_9.pdf,1,Introduction,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,547.1621704101562,0.08333333333333333,12,H3
sample_9.pdf,1,"Recurrent neural networks, long short-term memory [",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,572.0362548828125,0.0196078431372549,51,H3
sample_9.pdf,1,] and gated recurrent [,10.061732292175293,NimbusRomNo9L-Regu,False,336.9159851074219,572.0362548828125,0.0,23,H3
sample_9.pdf,1,] neural networks,10.061732292175293,NimbusRomNo9L-Regu,False,432.7030029296875,572.0362548828125,0.0,17,H3
sample_9.pdf,1,"in particular, have been ﬁrmly established as state of the art approaches in sequence modeling and",10.046924591064453,NimbusRomNo9L-Regu,False,108.0,582.9564819335938,0.0,98,H3
sample_9.pdf,1,Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started,8.880810737609863,NimbusRomNo9L-Regu,False,124.13999938964844,602.2298583984375,0.05660377358490566,106,P
sample_9.pdf,1,"the effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and",9.00219440460205,NimbusRomNo9L-Regu,False,108.0,612.099853515625,0.02727272727272727,110,P
sample_9.pdf,1,"has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,622.1583251953125,0.008928571428571428,112,P
sample_9.pdf,1,attention and the parameter-free position representation and became the other person involved in nearly every,9.015580177307129,NimbusRomNo9L-Regu,False,108.0,632.0156860351562,0.0,109,P
sample_9.pdf,1,"detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and",8.957428932189941,NimbusRomNo9L-Regu,False,108.0,642.0217895507812,0.009174311926605505,109,P
sample_9.pdf,1,"tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and",8.930462837219238,NimbusRomNo9L-Regu,False,108.0,652.0052490234375,0.009009009009009009,111,P
sample_9.pdf,1,efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and,8.876283645629883,NimbusRomNo9L-Regu,False,108.0,662.00927734375,0.017857142857142856,112,P
sample_9.pdf,1,"implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating",8.876283645629883,NimbusRomNo9L-Regu,False,108.0,671.9713134765625,0.0,112,P
sample_9.pdf,1,our research.,8.966400146484375,NimbusRomNo9L-Regu,False,108.0,681.865966796875,0.0,13,P
sample_9.pdf,1,Work performed while at Google Brain.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13999938964844,692.81494140625,0.08108108108108109,37,P
sample_9.pdf,1,Work performed while at Google Research.,8.966400146484375,NimbusRomNo9L-Regu,False,124.13999938964844,703.763916015625,0.075,40,P
sample_9.pdf,1,"31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.",8.966400146484375,NimbusRomNo9L-Regu,False,108.0,733.0769653320312,0.17777777777777778,90,P
sample_9.pdf,1,arXiv:1706.03762v5  [cs.CL]  6 Dec 2017,20.0,Times-Roman,False,10.940000534057617,216.15997314453125,0.10256410256410256,39,TITLE
sample_9.pdf,2,transduction problems such as language modeling and machine translation [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,74.33230590820312,0.0,73,H3
sample_9.pdf,2,]. Numerous,10.061732292175293,NimbusRomNo9L-Regu,False,451.23199462890625,74.33230590820312,0.09090909090909091,11,H3
sample_9.pdf,2,efforts have since continued to push the boundaries of recurrent language models and encoder-decoder,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,85.39241790771484,0.0,100,H3
sample_9.pdf,2,"architectures [38, 24, 15].",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,96.22547912597656,0.0,27,H3
sample_9.pdf,2,Recurrent models typically factor computation along the symbol positions of the input and output,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,112.53829956054688,0.010416666666666666,96,H3
sample_9.pdf,2,"sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,123.50737762451172,0.01020408163265306,98,H3
sample_9.pdf,2,states,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,134.47032165527344,0.0,6,H3
sample_9.pdf,2,", as a function of the previous hidden state",9.9126615524292,NimbusRomNo9L-Regu,False,141.6540069580078,134.47032165527344,0.0,44,H3
sample_9.pdf,2,and the input for position,9.9126615524292,NimbusRomNo9L-Regu,False,329.8720397949219,134.47032165527344,0.0,26,H3
sample_9.pdf,2,. This inherently,9.9126615524292,NimbusRomNo9L-Regu,False,438.7720031738281,134.47032165527344,0.058823529411764705,17,H3
sample_9.pdf,2,"sequential nature precludes parallelization within training examples, which becomes critical at longer",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,145.41737365722656,0.0,102,H3
sample_9.pdf,2,"sequence lengths, as memory constraints limit batching across examples. Recent work has achieved",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,156.2618408203125,0.010416666666666666,96,H3
sample_9.pdf,2,signiﬁcant improvements in computational efﬁciency through factorization tricks [,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,167.2354278564453,0.0,81,H3
sample_9.pdf,2,] and conditional,9.862470626831055,NimbusRomNo9L-Regu,False,438.2409973144531,167.2354278564453,0.0,17,H3
sample_9.pdf,2,computation [,10.051863670349121,NimbusRomNo9L-Regu,False,108.0,178.00079345703125,0.0,13,H3
sample_9.pdf,2,"], while also improving model performance in case of the latter. The fundamental",10.051863670349121,NimbusRomNo9L-Regu,False,174.53900146484375,178.00079345703125,0.0125,80,H3
sample_9.pdf,2,"constraint of sequential computation, however, remains.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,188.9774932861328,0.0,55,H3
sample_9.pdf,2,Attention mechanisms have become an integral part of compelling sequence modeling and transduc-,9.932666778564453,NimbusRomNo9L-Regu,False,107.64099884033203,205.38917541503906,0.010526315789473684,95,H3
sample_9.pdf,2,"tion models in various tasks, allowing modeling of dependencies without regard to their distance in",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,216.2603759765625,0.0,99,H3
sample_9.pdf,2,the input or output sequences [,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,227.26039123535156,0.0,31,H3
sample_9.pdf,2,]. In all but a few cases [,9.862470626831055,NimbusRomNo9L-Regu,False,247.61700439453125,227.26039123535156,0.037037037037037035,27,H3
sample_9.pdf,2,"], however, such attention mechanisms",9.862470626831055,NimbusRomNo9L-Regu,False,353.3800048828125,227.26039123535156,0.0,37,H3
sample_9.pdf,2,are used in conjunction with a recurrent network.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,238.0934600830078,0.0,49,H3
sample_9.pdf,2,"In this work we propose the Transformer, a model architecture eschewing recurrence and instead",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,254.40628051757812,0.02127659574468085,94,H3
sample_9.pdf,2,relying entirely on an attention mechanism to draw global dependencies between input and output.,10.032095909118652,NimbusRomNo9L-Regu,False,108.0,265.3377380371094,0.0,96,H3
sample_9.pdf,2,The Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,276.2994689941406,0.02,100,H3
sample_9.pdf,2,translation quality after being trained for as little as twelve hours on eight P100 GPUs.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,287.20947265625,0.0449438202247191,89,H3
sample_9.pdf,2,Background,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,319.191162109375,0.1,10,H3
sample_9.pdf,2,The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU,9.902643203735352,NimbusRomNo9L-Regu,False,107.69100189208984,347.0949401855469,0.0625,96,H3
sample_9.pdf,2,"], ByteNet [",9.862470626831055,NimbusRomNo9L-Regu,False,121.21399688720703,358.034423828125,0.16666666666666666,12,H3
sample_9.pdf,2,] and ConvS2S [,9.862470626831055,NimbusRomNo9L-Regu,False,177.35800170898438,358.034423828125,0.2,15,H3
sample_9.pdf,2,"], all of which use convolutional neural networks as basic building",9.862470626831055,NimbusRomNo9L-Regu,False,246.43600463867188,358.034423828125,0.0,67,H3
sample_9.pdf,2,"block, computing hidden representations in parallel for all input and output positions. In these models,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,368.94342041015625,0.009615384615384616,104,H3
sample_9.pdf,2,the number of operations required to relate signals from two arbitrary input or output positions grows,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,379.8534240722656,0.0,102,H3
sample_9.pdf,2,"in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes",9.877554893493652,NimbusRomNo9L-Regu,False,108.0,390.7509765625,0.06060606060606061,99,H3
sample_9.pdf,2,it more difﬁcult to learn dependencies between distant positions [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,401.5202941894531,0.0,66,H3
sample_9.pdf,2,]. In the Transformer this is,10.061732292175293,NimbusRomNo9L-Regu,False,388.1319885253906,401.5202941894531,0.06896551724137931,29,H3
sample_9.pdf,2,"reduced to a constant number of operations, albeit at the cost of reduced effective resolution due",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,412.4292907714844,0.0,98,H3
sample_9.pdf,2,"to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,423.3382873535156,0.031578947368421054,95,H3
sample_9.pdf,2,described in section 3.2.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,434.32244873046875,0.0,25,H3
sample_9.pdf,2,"Self-attention, sometimes called intra-attention is an attention mechanism relating different positions",9.89261531829834,NimbusRomNo9L-Regu,False,108.0,450.7635498046875,0.009708737864077669,103,H3
sample_9.pdf,2,of a single sequence in order to compute a representation of the sequence. Self-attention has been,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,461.5452880859375,0.01020408163265306,98,H3
sample_9.pdf,2,"used successfully in a variety of tasks including reading comprehension, abstractive summarization,",9.95761775970459,NimbusRomNo9L-Regu,False,108.0,472.5332336425781,0.0,99,H3
sample_9.pdf,2,"textual entailment and learning task-independent sentence representations [4, 27, 28, 22].",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,483.4384460449219,0.0,90,H3
sample_9.pdf,2,End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,499.75128173828125,0.010869565217391304,92,H3
sample_9.pdf,2,aligned recurrence and have been shown to perform well on simple-language question answering and,9.867501258850098,NimbusRomNo9L-Regu,False,108.0,510.8076171875,0.0,96,H3
sample_9.pdf,2,language modeling tasks [34].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,521.6444702148438,0.0,29,H3
sample_9.pdf,2,"To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying",10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,537.958251953125,0.021505376344086023,93,H3
sample_9.pdf,2,entirely on self-attention to compute representations of its input and output without using sequence-,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,548.9424438476562,0.0,101,H3
sample_9.pdf,2,"aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,559.86279296875,0.05102040816326531,98,H3
sample_9.pdf,2,"self-attention and discuss its advantages over models such as [17, 18] and [9].",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,570.7604370117188,0.0,79,H3
sample_9.pdf,2,Model Architecture,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,602.7421264648438,0.1111111111111111,18,H3
sample_9.pdf,2,Most competitive neural sequence transduction models have an encoder-decoder structure [,9.937662124633789,NimbusRomNo9L-Regu,False,108.0,630.620361328125,0.011363636363636364,88,H3
sample_9.pdf,2,"Here, the encoder maps an input sequence of symbol representations",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,641.4352416992188,0.015151515151515152,66,H3
sample_9.pdf,2,", ..., x",9.962599754333496,CMMI10,False,412.0419921875,641.2799072265625,0.0,8,H3
sample_9.pdf,2,to a sequence,10.061732292175293,NimbusRomNo9L-Regu,False,444.19244384765625,641.4352416992188,0.0,13,H3
sample_9.pdf,2,of continuous representations,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,652.34423828125,0.0,29,H3
sample_9.pdf,2,= (,9.962599754333496,CMR10,False,238.7489013671875,652.1889038085938,0.0,3,H3
sample_9.pdf,2,", ..., z",9.962599754333496,CMMI10,False,269.4570007324219,652.1889038085938,0.0,8,H3
sample_9.pdf,2,. Given,10.061732292175293,NimbusRomNo9L-Regu,False,300.5450134277344,652.34423828125,0.14285714285714285,7,H3
sample_9.pdf,2,", the decoder then generates an output",10.061732292175293,NimbusRomNo9L-Regu,False,342.9960021972656,652.34423828125,0.0,38,H3
sample_9.pdf,2,sequence,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,663.2532958984375,0.0,8,H3
sample_9.pdf,2,", ..., y",9.962599754333496,CMMI10,False,161.0299835205078,663.0979614257812,0.0,8,H3
sample_9.pdf,2,of symbols one element at a time. At each step the model is auto-regressive,10.061732292175293,NimbusRomNo9L-Regu,False,194.51544189453125,663.2532958984375,0.013333333333333334,75,H3
sample_9.pdf,2,"[10], consuming the previously generated symbols as additional input when generating the next.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,674.2374267578125,0.0,94,H3
sample_9.pdf,2,"The Transformer follows this overall architecture using stacked self-attention and point-wise, fully",10.022196769714355,NimbusRomNo9L-Regu,False,107.69100189208984,690.581298828125,0.02,100,H3
sample_9.pdf,2,"connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,701.4602661132812,0.01020408163265306,98,H3
sample_9.pdf,2,respectively.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,712.4444580078125,0.0,13,H3
sample_9.pdf,3,Figure 1: The Transformer - model architecture.,9.962599754333496,NimbusRomNo9L-Regu,False,210.01100158691406,404.7454528808594,0.06382978723404255,47,H3
sample_9.pdf,3,3.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,442.6025085449219,0.0,3,H3
sample_9.pdf,3,Encoder and Decoder Stacks,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,442.6025085449219,0.11538461538461539,26,H3
sample_9.pdf,3,Encoder:,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,465.2335205078125,0.125,8,H3
sample_9.pdf,3,The encoder is composed of a stack of,10.061732292175293,NimbusRomNo9L-Regu,False,157.2550048828125,465.2492980957031,0.02702702702702703,37,H3
sample_9.pdf,3,= 6,9.962599754333496,CMR10,False,329.3619079589844,465.09393310546875,0.0,3,H3
sample_9.pdf,3,identical layers. Each layer has two,10.061732292175293,NimbusRomNo9L-Regu,False,351.44268798828125,465.2492980957031,0.027777777777777776,36,H3
sample_9.pdf,3,"sub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-",10.007330894470215,NimbusRomNo9L-Regu,False,108.0,476.1995544433594,0.01,100,H3
sample_9.pdf,3,wise fully connected feed-forward network. We employ a residual connection [,10.041984558105469,NimbusRomNo9L-Regu,False,107.64099884033203,487.082275390625,0.013157894736842105,76,H3
sample_9.pdf,3,] around each of,10.041984558105469,NimbusRomNo9L-Regu,False,438.0570068359375,487.082275390625,0.0,16,H3
sample_9.pdf,3,"the two sub-layers, followed by layer normalization [",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,497.9762878417969,0.0,53,H3
sample_9.pdf,3,"]. That is, the output of each sub-layer is",10.061732292175293,NimbusRomNo9L-Regu,False,333.0559997558594,497.9762878417969,0.023255813953488372,43,H3
sample_9.pdf,3,LayerNorm(,9.962599754333496,CMR10,False,108.0,508.72991943359375,0.2,10,H3
sample_9.pdf,3,+ Sublayer(,9.962599754333496,CMR10,False,166.4726104736328,508.72991943359375,0.09090909090909091,11,H3
sample_9.pdf,3,", where",10.061732292175293,NimbusRomNo9L-Regu,False,233.85800170898438,508.8852844238281,0.0,7,H3
sample_9.pdf,3,Sublayer(,9.962599754333496,CMR10,False,264.1403503417969,508.72991943359375,0.1111111111111111,9,H3
sample_9.pdf,3,is the function implemented by the sub-layer,10.061732292175293,NimbusRomNo9L-Regu,False,317.8104553222656,508.8852844238281,0.0,44,H3
sample_9.pdf,3,"itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,519.8694458007812,0.009708737864077669,103,H3
sample_9.pdf,3,"layers, produce outputs of dimension",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,530.7794189453125,0.0,36,H3
sample_9.pdf,3,model,6.973800182342529,NimbusRomNo9L-Regu,False,263.1620178222656,534.5401000976562,0.0,5,P
sample_9.pdf,3,= 512,9.962599754333496,CMR10,False,280.5965576171875,530.5488891601562,0.0,5,H3
sample_9.pdf,3,Decoder:,9.962599754333496,NimbusRomNo9L-Medi,False,108.00001525878906,560.4415283203125,0.125,8,H3
sample_9.pdf,3,The decoder is also composed of a stack of,9.862470626831055,NimbusRomNo9L-Regu,False,156.68699645996094,560.6083984375,0.023809523809523808,42,H3
sample_9.pdf,3,= 6,9.962599754333496,CMR10,False,334.13092041015625,560.3019409179688,0.0,3,H3
sample_9.pdf,3,identical layers. In addition to the two,9.862470626831055,NimbusRomNo9L-Regu,False,353.4808044433594,560.6083984375,0.025,40,H3
sample_9.pdf,3,"sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,571.3662719726562,0.0,98,H3
sample_9.pdf,3,"attention over the output of the encoder stack. Similar to the encoder, we employ residual connections",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,582.4263916015625,0.00980392156862745,102,H3
sample_9.pdf,3,"around each of the sub-layers, followed by layer normalization. We also modify the self-attention",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,593.1852416992188,0.010309278350515464,97,H3
sample_9.pdf,3,sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,604.09423828125,0.010416666666666666,96,H3
sample_9.pdf,3,"masking, combined with fact that the output embeddings are offset by one position, ensures that the",9.952631950378418,NimbusRomNo9L-Regu,False,108.0,615.0860595703125,0.0,99,H3
sample_9.pdf,3,predictions for position,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,625.9874267578125,0.0,24,H3
sample_9.pdf,3,can depend only on the known outputs at positions less than,9.962599754333496,NimbusRomNo9L-Regu,False,206.90811157226562,625.9874267578125,0.0,59,H3
sample_9.pdf,3,3.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,656.9954833984375,0.0,3,H3
sample_9.pdf,3,Attention,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,656.9954833984375,0.1111111111111111,9,H3
sample_9.pdf,3,"An attention function can be described as mapping a query and a set of key-value pairs to an output,",9.952631950378418,NimbusRomNo9L-Regu,False,107.64099884033203,679.7250366210938,0.01,100,H3
sample_9.pdf,3,"where the query, keys, values, and output are all vectors. The output is computed as a weighted sum",9.937662124633789,NimbusRomNo9L-Regu,False,107.64099884033203,690.6453857421875,0.010101010101010102,99,H3
sample_9.pdf,3,"of the values, where the weight assigned to each value is computed by a compatibility function of the",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,701.6076049804688,0.0,101,H3
sample_9.pdf,3,query with the corresponding key.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,712.4444580078125,0.0,33,H3
sample_9.pdf,4,Scaled Dot-Product Attention,9.962599754333496,NimbusRomNo9L-Regu,False,147.7830047607422,71.19947814941406,0.14285714285714285,28,H3
sample_9.pdf,4,Multi-Head Attention,9.962599754333496,NimbusRomNo9L-Regu,False,363.58599853515625,71.19947814941406,0.15,20,H3
sample_9.pdf,4,Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,274.3883056640625,0.08421052631578947,95,H3
sample_9.pdf,4,attention layers running in parallel.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,285.3724670410156,0.0,37,H3
sample_9.pdf,4,3.2.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,318.76751708984375,0.0,5,H3
sample_9.pdf,4,Scaled Dot-Product Attention,9.962599754333496,NimbusRomNo9L-Medi,False,137.88778686523438,318.76751708984375,0.14285714285714285,28,H3
sample_9.pdf,4,"We call our particular attention ""Scaled Dot-Product Attention"" (Figure 2). The input consists of",10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,338.061279296875,0.07216494845360824,97,H3
sample_9.pdf,4,queries and keys of dimension,9.972557067871094,NimbusRomNo9L-Regu,False,108.0,349.0379333496094,0.0,29,H3
sample_9.pdf,4,", and values of dimension",9.972557067871094,NimbusRomNo9L-Regu,False,241.74200439453125,349.0379333496094,0.0,25,H3
sample_9.pdf,4,. We compute the dot products of the,9.972557067871094,NimbusRomNo9L-Regu,False,356.1889953613281,349.0379333496094,0.027777777777777776,36,H3
sample_9.pdf,4,"query with all keys, divide each by",9.997407913208008,NimbusRomNo9L-Regu,False,108.0,359.9280700683594,0.0,35,H3
sample_9.pdf,4,", and apply a softmax function to obtain the weights on the",9.997407913208008,NimbusRomNo9L-Regu,False,268.43798828125,359.9280700683594,0.0,59,H3
sample_9.pdf,4,values.,9.962599754333496,NimbusRomNo9L-Regu,False,107.7509994506836,370.86346435546875,0.0,7,H3
sample_9.pdf,4,"In practice, we compute the attention function on a set of queries simultaneously, packed together",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,387.17730712890625,0.01020408163265306,98,H3
sample_9.pdf,4,into a matrix,9.977532386779785,NimbusRomNo9L-Regu,False,108.0,398.150146484375,0.0,13,H3
sample_9.pdf,4,. The keys and values are also packed together into matrices,9.977532386779785,NimbusRomNo9L-Regu,False,169.41400146484375,398.150146484375,0.016666666666666666,60,H3
sample_9.pdf,4,and,9.977532386779785,NimbusRomNo9L-Regu,False,420.2952575683594,398.150146484375,0.0,3,H3
sample_9.pdf,4,. We compute,9.977532386779785,NimbusRomNo9L-Regu,False,446.22320556640625,398.150146484375,0.08333333333333333,12,H3
sample_9.pdf,4,the matrix of outputs as:,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,409.0704650878906,0.0,25,H3
sample_9.pdf,4,Attention(,9.962599754333496,CMR10,False,219.97000122070312,443.50592041015625,0.1,10,H3
sample_9.pdf,4,"Q, K, V",9.962599754333496,CMMI10,False,265.6319885253906,443.50592041015625,0.42857142857142855,7,H3
sample_9.pdf,4,) = softmax(,9.962599754333496,CMR10,False,296.7949523925781,443.50592041015625,0.0,12,H3
sample_9.pdf,4,(1),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,443.7364501953125,0.0,3,H3
sample_9.pdf,4,The two most commonly used attention functions are additive attention [,9.987475395202637,NimbusRomNo9L-Regu,False,107.69100189208984,472.3586120605469,0.014084507042253521,71,H3
sample_9.pdf,4,"], and dot-product (multi-",9.987475395202637,NimbusRomNo9L-Regu,False,403.385986328125,472.3586120605469,0.0,26,H3
sample_9.pdf,4,"plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,483.2789306640625,0.009615384615384616,104,H3
sample_9.pdf,4,. Additive attention computes the compatibility function using a feed-forward network with,10.007330894470215,NimbusRomNo9L-Regu,False,134.52481079101562,494.16156005859375,0.011111111111111112,90,H3
sample_9.pdf,4,"a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,507.2903137207031,0.01,100,H3
sample_9.pdf,4,"much faster and more space-efﬁcient in practice, since it can be implemented using highly optimized",9.887598037719727,NimbusRomNo9L-Regu,False,108.0,518.3323364257812,0.0,99,H3
sample_9.pdf,4,matrix multiplication code.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,529.1844482421875,0.0,27,H3
sample_9.pdf,4,While for small values of,9.992443084716797,NimbusRomNo9L-Regu,False,107.53199768066406,545.5498046875,0.04,25,H3
sample_9.pdf,4,"the two mechanisms perform similarly, additive attention outperforms",9.992443084716797,NimbusRomNo9L-Regu,False,220.98008728027344,545.5498046875,0.0,68,H3
sample_9.pdf,4,dot product attention without scaling for larger values of,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,556.4625854492188,0.0,58,H3
sample_9.pdf,4,]. We suspect that for large values of,9.987475395202637,NimbusRomNo9L-Regu,False,357.2879943847656,556.4625854492188,0.02631578947368421,38,H3
sample_9.pdf,4,", the dot products grow large in magnitude, pushing the softmax function into regions where it has",9.89261531829834,NimbusRomNo9L-Regu,False,118.08699798583984,567.4435424804688,0.0,98,H3
sample_9.pdf,4,extremely small gradients,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,578.2994384765625,0.0,25,H3
sample_9.pdf,4,". To counteract this effect, we scale the dot products by",9.962599754333496,NimbusRomNo9L-Regu,False,217.25900268554688,578.2994384765625,0.017543859649122806,57,H3
sample_9.pdf,4,3.2.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,605.3135375976562,0.0,5,H3
sample_9.pdf,4,Multi-Head Attention,9.962599754333496,NimbusRomNo9L-Medi,False,137.88778686523438,605.3135375976562,0.15,20,H3
sample_9.pdf,4,Instead of performing a single attention function with,10.037040710449219,NimbusRomNo9L-Regu,False,108.0,624.6260375976562,0.018518518518518517,54,H3
sample_9.pdf,4,model,6.973800182342529,NimbusRomNo9L-Regu,False,331.85699462890625,628.4441528320312,0.0,5,P
sample_9.pdf,4,"-dimensional keys, values and queries,",10.037040710449219,NimbusRomNo9L-Regu,False,349.78900146484375,624.6260375976562,0.0,38,H3
sample_9.pdf,4,"we found it beneﬁcial to linearly project the queries, keys and values",9.95761775970459,NimbusRomNo9L-Regu,False,107.64099884033203,635.5962524414062,0.0,70,H3
sample_9.pdf,4,"times with different, learned",9.95761775970459,NimbusRomNo9L-Regu,False,388.99346923828125,635.5962524414062,0.0,29,H3
sample_9.pdf,4,linear projections to,9.982504844665527,NimbusRomNo9L-Regu,False,108.0,646.4863891601562,0.0,21,H3
sample_9.pdf,4,and,9.982504844665527,NimbusRomNo9L-Regu,False,214.9670867919922,646.4863891601562,0.0,3,H3
sample_9.pdf,4,"dimensions, respectively. On each of these projected versions of",9.982504844665527,NimbusRomNo9L-Regu,False,244.22303771972656,646.4863891601562,0.015625,64,H3
sample_9.pdf,4,"queries, keys and values we then perform the attention function in parallel, yielding",9.947644233703613,NimbusRomNo9L-Regu,False,108.0,657.4218139648438,0.0,85,H3
sample_9.pdf,4,-dimensional,9.947644233703613,NimbusRomNo9L-Regu,False,452.1319885253906,657.4218139648438,0.0,12,H3
sample_9.pdf,4,"output values. These are concatenated and once again projected, resulting in the ﬁnal values, as",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,668.2442626953125,0.010416666666666666,96,H3
sample_9.pdf,4,depicted in Figure 2.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,679.2284545898438,0.047619047619047616,21,H3
sample_9.pdf,4,"To illustrate why the dot products get large, assume that the components of",8.876283645629883,NimbusRomNo9L-Regu,False,124.13999938964844,701.9183349609375,0.013333333333333334,75,P
sample_9.pdf,4,and,8.876283645629883,NimbusRomNo9L-Regu,False,394.25958251953125,701.9183349609375,0.0,3,P
sample_9.pdf,4,are independent random,8.876283645629883,NimbusRomNo9L-Regu,False,416.5260314941406,701.9183349609375,0.0,22,P
sample_9.pdf,4,variables with mean,8.952940940856934,NimbusRomNo9L-Regu,False,107.7760009765625,713.210205078125,0.0,19,P
sample_9.pdf,4,and variance,8.952940940856934,NimbusRomNo9L-Regu,False,186.41273498535156,713.210205078125,0.0,12,P
sample_9.pdf,4,". Then their dot product,",8.952940940856934,NimbusRomNo9L-Regu,False,240.70599365234375,713.210205078125,0.04,25,P
sample_9.pdf,4,", has mean",8.952940940856934,NimbusRomNo9L-Regu,False,397.76300048828125,713.210205078125,0.0,10,P
sample_9.pdf,4,and variance,8.952940940856934,NimbusRomNo9L-Regu,False,442.6097412109375,713.210205078125,0.0,12,P
sample_9.pdf,5,Multi-head attention allows the model to jointly attend to information from different representation,9.982504844665527,NimbusRomNo9L-Regu,False,108.0,74.39238739013672,0.01,100,H3
sample_9.pdf,5,"subspaces at different positions. With a single attention head, averaging inhibits this.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,85.31648254394531,0.011363636363636364,88,H3
sample_9.pdf,5,MultiHead(,9.962599754333496,CMR10,False,186.94000244140625,115.34391784667969,0.2,10,H3
sample_9.pdf,5,"Q, K, V",9.962599754333496,CMMI10,False,237.3070068359375,115.34391784667969,0.42857142857142855,7,H3
sample_9.pdf,5,) = Concat(head,9.962599754333496,CMR10,False,268.4700012207031,115.34391784667969,0.06666666666666667,15,H3
sample_9.pdf,5,", ...,",9.962599754333496,CMMI10,False,347.6600036621094,115.34391784667969,0.0,6,H3
sample_9.pdf,5,head,9.962599754333496,CMR10,False,363.1717224121094,115.34391784667969,0.0,4,H3
sample_9.pdf,5,where,9.962599754333496,NimbusRomNo9L-Regu,False,224.4970245361328,132.38551330566406,0.0,5,H3
sample_9.pdf,5,head,9.962599754333496,CMR10,False,248.83566284179688,132.1549530029297,0.0,4,H3
sample_9.pdf,5,= Attention(,9.962599754333496,CMR10,False,274.05755615234375,132.1549530029297,0.08333333333333333,12,H3
sample_9.pdf,5,", KW",9.962599754333496,CMMI10,False,358.9450378417969,132.15501403808594,0.5,4,H3
sample_9.pdf,5,", V W",9.962599754333496,CMMI10,False,391.0210266113281,132.15501403808594,0.4,5,H3
sample_9.pdf,5,Where the projections are parameter matrices,9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,168.6223907470703,0.022727272727272728,44,H3
sample_9.pdf,5,model,4.981299877166748,NimbusRomNo9L-Regu,False,326.97900390625,169.70416259765625,0.0,5,P
sample_9.pdf,5,model,4.981299877166748,NimbusRomNo9L-Regu,False,401.822021484375,169.7041015625,0.0,5,P
sample_9.pdf,5,model,4.981299877166748,NimbusRomNo9L-Regu,False,475.9020080566406,169.7041015625,0.0,5,P
sample_9.pdf,5,and,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,180.77735900878906,0.0,3,H3
sample_9.pdf,5,model,4.981299877166748,NimbusRomNo9L-Regu,False,185.27398681640625,181.93609619140625,0.0,5,P
sample_9.pdf,5,In this work we employ,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,197.09127807617188,0.045454545454545456,22,H3
sample_9.pdf,5,= 8,9.962599754333496,CMR10,False,219.4334716796875,196.93589782714844,0.0,3,H3
sample_9.pdf,5,"parallel attention layers, or heads. For each of these we use",10.061732292175293,NimbusRomNo9L-Regu,False,242.9439697265625,197.09127807617188,0.01639344262295082,61,H3
sample_9.pdf,5,model,6.973800182342529,NimbusRomNo9L-Regu,False,159.77500915527344,211.83615112304688,0.0,5,P
sample_9.pdf,5,= 64,9.962599754333496,CMR10,False,188.4267578125,207.8448944091797,0.0,4,H3
sample_9.pdf,5,". Due to the reduced dimension of each head, the total computational cost",9.942654609680176,NimbusRomNo9L-Regu,False,211.68299865722656,208.090576171875,0.0136986301369863,73,H3
sample_9.pdf,5,is similar to that of single-head attention with full dimensionality.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,218.9844512939453,0.0,69,H3
sample_9.pdf,5,3.2.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,241.28448486328125,0.0,5,H3
sample_9.pdf,5,Applications of Attention in our Model,9.962599754333496,NimbusRomNo9L-Medi,False,137.88778686523438,241.28448486328125,0.07894736842105263,38,H3
sample_9.pdf,5,The Transformer uses multi-head attention in three different ways:,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,260.00543212890625,0.030303030303030304,66,H3
sample_9.pdf,5,"In ""encoder-decoder attention"" layers, the queries come from the previous decoder layer,",10.061732292175293,NimbusRomNo9L-Regu,False,138.88429260253906,278.6982727050781,0.011363636363636364,88,H3
sample_9.pdf,5,and the memory keys and values come from the output of the encoder. This allows every,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,289.6072998046875,0.011764705882352941,85,H3
sample_9.pdf,5,position in the decoder to attend over all positions in the input sequence. This mimics the,10.032095909118652,NimbusRomNo9L-Regu,False,143.86599731445312,300.5397644042969,0.01098901098901099,91,H3
sample_9.pdf,5,typical encoder-decoder attention mechanisms in sequence-to-sequence models such as,10.061732292175293,NimbusRomNo9L-Regu,False,143.86599731445312,311.4263000488281,0.0,83,H3
sample_9.pdf,5,"[38, 2, 9].",9.962599754333496,NimbusRomNo9L-Regu,False,143.86599731445312,322.41046142578125,0.0,11,H3
sample_9.pdf,5,"The encoder contains self-attention layers. In a self-attention layer all of the keys, values",10.061732292175293,NimbusRomNo9L-Regu,False,138.88429260253906,336.4263000488281,0.021505376344086023,93,H3
sample_9.pdf,5,"and queries come from the same place, in this case, the output of the previous layer in the",10.022196769714355,NimbusRomNo9L-Regu,False,143.86599731445312,347.3652648925781,0.0,91,H3
sample_9.pdf,5,encoder. Each position in the encoder can attend to all positions in the previous layer of the,9.90765380859375,NimbusRomNo9L-Regu,False,143.86599731445312,358.36114501953125,0.010638297872340425,94,H3
sample_9.pdf,5,encoder.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86599731445312,369.2294616699219,0.0,8,H3
sample_9.pdf,5,"Similarly, self-attention layers in the decoder allow each position in the decoder to attend to",9.887598037719727,NimbusRomNo9L-Regu,False,138.88429260253906,383.3773498535156,0.010526315789473684,95,H3
sample_9.pdf,5,all positions in the decoder up to and including that position. We need to prevent leftward,10.012289047241211,NimbusRomNo9L-Regu,False,143.86599731445312,394.1918029785156,0.01098901098901099,91,H3
sample_9.pdf,5,information ﬂow in the decoder to preserve the auto-regressive property. We implement this,9.877554893493652,NimbusRomNo9L-Regu,False,143.86599731445312,405.2029724121094,0.011111111111111112,90,H3
sample_9.pdf,5,inside of scaled dot-product attention by masking out (setting to,9.862470626831055,NimbusRomNo9L-Regu,False,143.86599731445312,416.1234130859375,0.0,65,H3
sample_9.pdf,5,) all values in the input,9.862470626831055,NimbusRomNo9L-Regu,False,414.2510070800781,416.1234130859375,0.0,25,H3
sample_9.pdf,5,of the softmax which correspond to illegal connections. See Figure 2.,9.962599754333496,NimbusRomNo9L-Regu,False,143.86599731445312,426.9564514160156,0.028985507246376812,69,H3
sample_9.pdf,5,3.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,450.60150146484375,0.0,3,H3
sample_9.pdf,5,Position-wise Feed-Forward Networks,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,450.60150146484375,0.11428571428571428,35,H3
sample_9.pdf,5,"In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,470.5932922363281,0.010101010101010102,99,H3
sample_9.pdf,5,"connected feed-forward network, which is applied to each position separately and identically. This",10.007330894470215,NimbusRomNo9L-Regu,False,108.0,481.5435485839844,0.01020408163265306,98,H3
sample_9.pdf,5,consists of two linear transformations with a ReLU activation in between.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,492.4864501953125,0.0410958904109589,73,H3
sample_9.pdf,5,FFN(,9.962599754333496,CMR10,False,226.9010009765625,519.5529174804688,0.75,4,H3
sample_9.pdf,5,) = max(0,9.962599754333496,CMR10,False,256.947998046875,519.5529174804688,0.0,9,H3
sample_9.pdf,5,", xW",9.962599754333496,CMMI10,False,301.50299072265625,519.5529174804688,0.25,4,H3
sample_9.pdf,5,(2),9.962599754333496,NimbusRomNo9L-Regu,False,492.3840026855469,519.783447265625,0.0,3,H3
sample_9.pdf,5,"While the linear transformations are the same across different positions, they use different parameters",9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,537.8253784179688,0.009708737864077669,103,H3
sample_9.pdf,5,from layer to layer. Another way of describing this is as two convolutions with kernel size 1.,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,548.583251953125,0.010638297872340425,94,H3
sample_9.pdf,5,The dimensionality of input and output is,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,559.4922485351562,0.024390243902439025,41,H3
sample_9.pdf,5,model,6.973800182342529,NimbusRomNo9L-Regu,False,289.6510009765625,563.3291015625,0.0,5,P
sample_9.pdf,5,= 512,9.962599754333496,CMR10,False,307.0855407714844,559.3369140625,0.0,5,H3
sample_9.pdf,5,", and the inner-layer has dimensionality",10.061732292175293,NimbusRomNo9L-Regu,False,339.1679992675781,559.4922485351562,0.0,40,H3
sample_9.pdf,5,= 2048,9.962599754333496,CMR10,False,121.73487854003906,570.2459106445312,0.0,6,H3
sample_9.pdf,5,3.4,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,594.1215209960938,0.0,3,H3
sample_9.pdf,5,Embeddings and Softmax,9.962599754333496,NimbusRomNo9L-Medi,False,130.41583251953125,594.1215209960938,0.09090909090909091,22,H3
sample_9.pdf,5,"Similarly to other sequence transduction models, we use learned embeddings to convert the input",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,614.11328125,0.010526315789473684,95,H3
sample_9.pdf,5,tokens and output tokens to vectors of dimension,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,625.1734008789062,0.0,48,H3
sample_9.pdf,5,model,6.973800182342529,NimbusRomNo9L-Regu,False,306.8500061035156,628.8580932617188,0.0,5,P
sample_9.pdf,5,. We also use the usual learned linear transfor-,9.862470626831055,NimbusRomNo9L-Regu,False,324.7829895019531,625.1734008789062,0.020833333333333332,48,H3
sample_9.pdf,5,mation and softmax function to convert the decoder output to predicted next-token probabilities. In,9.982504844665527,NimbusRomNo9L-Regu,False,108.0,635.9913940429688,0.010101010101010102,99,H3
sample_9.pdf,5,"our model, we share the same weight matrix between the two embedding layers and the pre-softmax",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,646.9495849609375,0.0,95,H3
sample_9.pdf,5,"linear transformation, similar to [",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,657.900390625,0.0,35,H3
sample_9.pdf,5,"]. In the embedding layers, we multiply those weights by",9.862470626831055,NimbusRomNo9L-Regu,False,247.5229949951172,657.900390625,0.017857142857142856,56,H3
sample_9.pdf,5,model,6.973800182342529,NimbusRomNo9L-Regu,False,485.3699951171875,661.5851440429688,0.0,5,P
sample_9.pdf,5,3.5,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,681.469482421875,0.0,3,H3
sample_9.pdf,5,Positional Encoding,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,681.469482421875,0.10526315789473684,19,H3
sample_9.pdf,5,"Since our model contains no recurrence and no convolution, in order for the model to make use of the",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,701.6113891601562,0.01,100,H3
sample_9.pdf,5,"order of the sequence, we must inject some information about the relative or absolute position of the",9.9126615524292,NimbusRomNo9L-Regu,False,108.0,712.4823608398438,0.0,101,H3
sample_9.pdf,6,"Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations",9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,71.2754135131836,0.021052631578947368,95,H3
sample_9.pdf,6,for different layer types.,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,82.08960723876953,0.0,26,H3
sample_9.pdf,6,"is the sequence length,",9.987475395202637,NimbusRomNo9L-Regu,False,214.091552734375,82.08960723876953,0.0,23,H3
sample_9.pdf,6,"is the representation dimension,",9.987475395202637,NimbusRomNo9L-Regu,False,314.8835144042969,82.08960723876953,0.0,32,H3
sample_9.pdf,6,is the kernel,9.987475395202637,NimbusRomNo9L-Regu,False,452.38250732421875,82.08960723876953,0.0,13,H3
sample_9.pdf,6,size of convolutions and,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,93.01747131347656,0.0,24,H3
sample_9.pdf,6,the size of the neighborhood in restricted self-attention.,9.962599754333496,NimbusRomNo9L-Regu,False,211.51113891601562,93.01747131347656,0.0,58,H3
sample_9.pdf,6,Layer Type,9.962599754333496,NimbusRomNo9L-Regu,False,124.5469970703125,116.51148986816406,0.2,10,H3
sample_9.pdf,6,Complexity per Layer,9.962599754333496,NimbusRomNo9L-Regu,False,239.70468139648438,116.51148986816406,0.1,20,H3
sample_9.pdf,6,Sequential,9.962599754333496,NimbusRomNo9L-Regu,False,340.326904296875,116.51148986816406,0.1,10,H3
sample_9.pdf,6,Maximum Path Length,9.962599754333496,NimbusRomNo9L-Regu,False,395.1709899902344,116.51148986816406,0.15789473684210525,19,H3
sample_9.pdf,6,Operations,9.962599754333496,NimbusRomNo9L-Regu,False,339.4989929199219,127.42048645019531,0.1,10,H3
sample_9.pdf,6,Self-Attention,9.962599754333496,NimbusRomNo9L-Regu,False,124.5469970703125,140.05848693847656,0.14285714285714285,14,H3
sample_9.pdf,6,(1),9.962599754333496,CMR10,False,358.9300231933594,139.8279266357422,0.0,3,H3
sample_9.pdf,6,(1),9.962599754333496,CMR10,False,438.884033203125,139.8279266357422,0.0,3,H3
sample_9.pdf,6,Recurrent,9.962599754333496,NimbusRomNo9L-Regu,False,124.54702758789062,151.4405059814453,0.1111111111111111,9,H3
sample_9.pdf,6,Convolutional,9.962599754333496,NimbusRomNo9L-Regu,False,124.54705810546875,162.82252502441406,0.07692307692307693,13,H3
sample_9.pdf,6,(1),9.962599754333496,CMR10,False,358.9300537109375,162.5919647216797,0.0,3,H3
sample_9.pdf,6,log,9.962599754333496,CMMI10,False,429.5590515136719,162.5919647216797,0.0,3,H3
sample_9.pdf,6,Self-Attention (restricted),9.962599754333496,NimbusRomNo9L-Regu,False,124.54705810546875,173.7315216064453,0.07407407407407407,27,H3
sample_9.pdf,6,(1),9.962599754333496,CMR10,False,358.9300537109375,173.50096130371094,0.0,3,H3
sample_9.pdf,6,n/r,9.962599754333496,CMMI10,False,437.383056640625,173.50096130371094,0.0,3,H3
sample_9.pdf,6,"tokens in the sequence. To this end, we add ""positional encodings"" to the input embeddings at the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,213.18630981445312,0.010309278350515464,97,H3
sample_9.pdf,6,bottoms of the encoder and decoder stacks. The positional encodings have the same dimension,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,224.2464141845703,0.01098901098901099,91,H3
sample_9.pdf,6,model,6.973800182342529,NimbusRomNo9L-Regu,False,486.0669860839844,227.93215942382812,0.0,5,P
sample_9.pdf,6,"as the embeddings, so that the two can be summed. There are many choices of positional encodings,",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,235.10597229003906,0.010309278350515464,97,H3
sample_9.pdf,6,learned and ﬁxed [9].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,245.9884796142578,0.0,21,H3
sample_9.pdf,6,"In this work, we use sine and cosine functions of different frequencies:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,262.37744140625,0.013888888888888888,72,H3
sample_9.pdf,6,"pos,",6.973800182342529,CMMI7,False,253.7570037841797,299.1477355957031,0.0,4,P
sample_9.pdf,6,sin,9.962599754333496,CMMI10,False,288.8418884277344,295.0129089355469,0.0,3,H3
sample_9.pdf,6,pos/,9.962599754333496,CMMI10,False,309.56396484375,295.0129089355469,0.0,4,H3
sample_9.pdf,6,10000,9.962599754333496,CMR10,False,329.0569763183594,295.0129089355469,0.0,5,H3
sample_9.pdf,6,i/d,6.973800182342529,CMMI7,False,357.9349670410156,293.2347106933594,0.0,3,P
sample_9.pdf,6,model,4.981299877166748,NimbusRomNo9L-Regu,False,368.98297119140625,295.9042053222656,0.0,5,P
sample_9.pdf,6,"pos,",6.973800182342529,CMMI7,False,243.94097900390625,316.01873779296875,0.0,4,P
sample_9.pdf,6,+1),6.973800182342529,CMR7,False,264.8970031738281,316.01873779296875,0.0,3,P
sample_9.pdf,6,cos,9.962599754333496,CMMI10,False,289.1139221191406,311.8839111328125,0.0,3,H3
sample_9.pdf,6,pos/,9.962599754333496,CMMI10,False,309.5639953613281,311.8839111328125,0.0,4,H3
sample_9.pdf,6,10000,9.962599754333496,CMR10,False,329.0570068359375,311.8839111328125,0.0,5,H3
sample_9.pdf,6,i/d,6.973800182342529,CMMI7,False,357.93499755859375,310.1067199707031,0.0,3,P
sample_9.pdf,6,model,4.981299877166748,NimbusRomNo9L-Regu,False,368.9830017089844,312.77520751953125,0.0,5,P
sample_9.pdf,6,where,9.95761775970459,NimbusRomNo9L-Regu,False,107.64099884033203,334.07525634765625,0.0,5,H3
sample_9.pdf,6,pos,9.962599754333496,CMMI10,False,131.95529174804688,333.8409423828125,0.0,3,H3
sample_9.pdf,6,is the position and,9.95761775970459,NimbusRomNo9L-Regu,False,148.95350646972656,334.07525634765625,0.0,19,H3
sample_9.pdf,6,"is the dimension. That is, each dimension of the positional encoding",9.95761775970459,NimbusRomNo9L-Regu,False,230.0511016845703,334.07525634765625,0.014705882352941176,68,H3
sample_9.pdf,6,corresponds to a sinusoid. The wavelengths form a geometric progression from,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,345.0564270019531,0.013157894736842105,76,H3
sample_9.pdf,6,10000,9.962599754333496,CMR10,False,440.7698974609375,344.74993896484375,0.0,5,H3
sample_9.pdf,6,. We,9.862470626831055,NimbusRomNo9L-Regu,False,485.74200439453125,345.0564270019531,0.25,4,H3
sample_9.pdf,6,chose this function because we hypothesized it would allow the model to easily learn to attend by,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,355.8143005371094,0.0,97,H3
sample_9.pdf,6,"relative positions, since for any ﬁxed offset",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,366.7232971191406,0.0,45,H3
sample_9.pdf,6,pos,6.973800182342529,CMMI7,False,311.52899169921875,370.39874267578125,0.0,3,P
sample_9.pdf,6,can be represented as a linear function of,10.061732292175293,NimbusRomNo9L-Regu,False,333.6770935058594,366.7232971191406,0.0,42,H3
sample_9.pdf,6,pos,6.973800182342529,CMMI7,False,123.13400268554688,381.3077392578125,0.0,3,P
sample_9.pdf,6,We also experimented with using learned positional embeddings [,9.96757984161377,NimbusRomNo9L-Regu,False,107.53199768066406,394.09271240234375,0.015873015873015872,63,H3
sample_9.pdf,6,"] instead, and found that the two",9.96757984161377,NimbusRomNo9L-Regu,False,375.2799987792969,394.09271240234375,0.0,33,H3
sample_9.pdf,6,versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version,10.061732292175293,NimbusRomNo9L-Regu,False,107.7509994506836,404.9302978515625,0.030927835051546393,97,H3
sample_9.pdf,6,because it may allow the model to extrapolate to sequence lengths longer than the ones encountered,9.947644233703613,NimbusRomNo9L-Regu,False,108.0,415.9258117675781,0.0,98,H3
sample_9.pdf,6,during training.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,426.8234558105469,0.0,16,H3
sample_9.pdf,6,Why Self-Attention,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,453.3441467285156,0.16666666666666666,18,H3
sample_9.pdf,6,In this section we compare various aspects of self-attention layers to the recurrent and convolu-,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,477.7492980957031,0.010309278350515464,97,H3
sample_9.pdf,6,tional layers commonly used for mapping one variable-length sequence of symbol representations,10.041984558105469,NimbusRomNo9L-Regu,False,108.0,488.67327880859375,0.0,94,H3
sample_9.pdf,6,", ..., x",9.962599754333496,CMMI10,False,120.87200164794922,499.41192626953125,0.0,8,H3
sample_9.pdf,6,to another sequence of equal length,10.061732292175293,NimbusRomNo9L-Regu,False,153.0224609375,499.5672912597656,0.0,35,H3
sample_9.pdf,6,", ..., z",9.962599754333496,CMMI10,False,321.1269836425781,499.41192626953125,0.0,8,H3
sample_9.pdf,6,", with",10.061732292175293,NimbusRomNo9L-Regu,False,352.2149963378906,499.5672912597656,0.0,6,H3
sample_9.pdf,6,", z",9.962599754333496,CMMI10,False,388.80499267578125,499.41192626953125,0.0,3,H3
sample_9.pdf,6,", such as a hidden",10.061732292175293,NimbusRomNo9L-Regu,False,428.4750061035156,499.5672912597656,0.0,18,H3
sample_9.pdf,6,layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we,9.952631950378418,NimbusRomNo9L-Regu,False,108.0,510.55902099609375,0.01,100,H3
sample_9.pdf,6,consider three desiderata.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,521.46044921875,0.0,26,H3
sample_9.pdf,6,One is the total computational complexity per layer. Another is the amount of computation that can,9.96757984161377,NimbusRomNo9L-Regu,False,108.0,537.845703125,0.02040816326530612,98,H3
sample_9.pdf,6,"be parallelized, as measured by the minimum number of sequential operations required.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,548.7584228515625,0.0,85,H3
sample_9.pdf,6,The third is the path length between long-range dependencies in the network. Learning long-range,10.017244338989258,NimbusRomNo9L-Regu,False,107.69100189208984,565.1050415039062,0.020833333333333332,96,H3
sample_9.pdf,6,dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the,10.022196769714355,NimbusRomNo9L-Regu,False,108.0,576.01025390625,0.010309278350515464,97,H3
sample_9.pdf,6,ability to learn such dependencies is the length of the paths forward and backward signals have to,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,586.8902587890625,0.0,98,H3
sample_9.pdf,6,traverse in the network. The shorter these paths between any combination of positions in the input,10.037040710449219,NimbusRomNo9L-Regu,False,108.0,597.8179931640625,0.01020408163265306,98,H3
sample_9.pdf,6,"and output sequences, the easier it is to learn long-range dependencies [",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,608.8175659179688,0.0,73,H3
sample_9.pdf,6,]. Hence we also compare,9.9176664352417,NimbusRomNo9L-Regu,False,401.0840148925781,608.8175659179688,0.041666666666666664,24,H3
sample_9.pdf,6,the maximum path length between any two input and output positions in networks composed of the,9.96757984161377,NimbusRomNo9L-Regu,False,108.0,619.6886596679688,0.0,94,H3
sample_9.pdf,6,different layer types.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,630.6014404296875,0.0,22,H3
sample_9.pdf,6,"As noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially",9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,647.0653686523438,0.01904761904761905,105,H3
sample_9.pdf,6,"executed operations, whereas a recurrent layer requires",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,657.8242797851562,0.0,55,H3
sample_9.pdf,6,sequential operations. In terms of,10.061732292175293,NimbusRomNo9L-Regu,False,360.39447021484375,657.8242797851562,0.029411764705882353,34,H3
sample_9.pdf,6,"computational complexity, self-attention layers are faster than recurrent layers when the sequence",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,668.7332763671875,0.0,98,H3
sample_9.pdf,6,length,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,679.6422729492188,0.0,6,H3
sample_9.pdf,6,is smaller than the representation dimensionality,10.061732292175293,NimbusRomNo9L-Regu,False,142.83755493164062,679.6422729492188,0.0,49,H3
sample_9.pdf,6,", which is most often the case with",10.061732292175293,NimbusRomNo9L-Regu,False,356.79901123046875,679.6422729492188,0.0,35,H3
sample_9.pdf,6,"sentence representations used by state-of-the-art models in machine translations, such as word-piece",9.9176664352417,NimbusRomNo9L-Regu,False,108.0,690.6605834960938,0.0,100,H3
sample_9.pdf,6,] and byte-pair [,9.992443084716797,NimbusRomNo9L-Regu,False,121.30000305175781,701.5128173828125,0.0,17,H3
sample_9.pdf,6,] representations. To improve computational performance for tasks involving,9.992443084716797,NimbusRomNo9L-Regu,False,196.03500366210938,701.5128173828125,0.013333333333333334,75,H3
sample_9.pdf,6,"very long sequences, self-attention could be restricted to considering only a neighborhood of size",9.862470626831055,NimbusRomNo9L-Regu,False,107.7509994506836,712.5203857421875,0.0,98,H3
sample_9.pdf,7,the input sequence centered around the respective output position. This would increase the maximum,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,74.4834213256836,0.01020408163265306,98,H3
sample_9.pdf,7,path length to,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,85.31648254394531,0.0,14,H3
sample_9.pdf,7,n/r,9.962599754333496,CMMI10,False,177.03500366210938,85.08592224121094,0.0,3,H3
sample_9.pdf,7,. We plan to investigate this approach further in future work.,9.962599754333496,NimbusRomNo9L-Regu,False,196.64199829101562,85.31648254394531,0.016129032258064516,62,H3
sample_9.pdf,7,A single convolutional layer with kernel width,9.987475395202637,NimbusRomNo9L-Regu,False,107.64099884033203,101.68561553955078,0.021739130434782608,46,H3
sample_9.pdf,7,k < n,9.962599754333496,CMMI10,False,293.6916809082031,101.47392272949219,0.0,5,H3
sample_9.pdf,7,does not connect all pairs of input and output,9.987475395202637,NimbusRomNo9L-Regu,False,320.9380187988281,101.68561553955078,0.0,46,H3
sample_9.pdf,7,positions. Doing so requires a stack of,9.862470626831055,NimbusRomNo9L-Regu,False,108.0,112.68941497802734,0.02564102564102564,39,H3
sample_9.pdf,7,n/k,9.962599754333496,CMMI10,False,271.7440185546875,112.38291931152344,0.0,3,H3
sample_9.pdf,7,"convolutional layers in the case of contiguous kernels,",9.862470626831055,NimbusRomNo9L-Regu,False,292.0804748535156,112.68941497802734,0.0,55,H3
sample_9.pdf,7,log,9.962599754333496,CMMI10,False,131.14999389648438,123.29191589355469,0.0,3,H3
sample_9.pdf,7,in the case of dilated convolutions [,10.061732292175293,NimbusRomNo9L-Regu,False,166.40689086914062,123.44729614257812,0.0,37,H3
sample_9.pdf,7,"], increasing the length of the longest paths",10.061732292175293,NimbusRomNo9L-Regu,False,326.1409912109375,123.44729614257812,0.0,45,H3
sample_9.pdf,7,between any two positions in the network. Convolutional layers are generally more expensive than,10.012289047241211,NimbusRomNo9L-Regu,False,108.0,134.39476013183594,0.010416666666666666,96,H3
sample_9.pdf,7,"recurrent layers, by a factor of",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,145.26626586914062,0.0,32,H3
sample_9.pdf,7,. Separable convolutions [,10.061732292175293,NimbusRomNo9L-Regu,False,242.38900756835938,145.26626586914062,0.038461538461538464,26,H3
sample_9.pdf,7,"], however, decrease the complexity",10.061732292175293,NimbusRomNo9L-Regu,False,356.322998046875,145.26626586914062,0.0,35,H3
sample_9.pdf,7,"considerably, to",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,156.17532348632812,0.0,16,H3
sample_9.pdf,7,. Even with,10.061732292175293,NimbusRomNo9L-Regu,False,259.9330139160156,156.17532348632812,0.09090909090909091,11,H3
sample_9.pdf,7,", however, the complexity of a separable",10.061732292175293,NimbusRomNo9L-Regu,False,337.8760070800781,156.17532348632812,0.0,40,H3
sample_9.pdf,7,"convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,",9.927669525146484,NimbusRomNo9L-Regu,False,108.0,167.1859893798828,0.0,102,H3
sample_9.pdf,7,the approach we take in our model.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,178.06849670410156,0.0,34,H3
sample_9.pdf,7,"As side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions",9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,194.5324249267578,0.019230769230769232,104,H3
sample_9.pdf,7,from our models and present and discuss examples in the appendix. Not only do individual attention,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,205.4043426513672,0.01020408163265306,98,H3
sample_9.pdf,7,"heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,216.3513946533203,0.0,104,H3
sample_9.pdf,7,and semantic structure of the sentences.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,227.18446350097656,0.0,40,H3
sample_9.pdf,7,Training,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,254.941162109375,0.125,8,H3
sample_9.pdf,7,This section describes the training regime for our models.,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,280.2654724121094,0.017241379310344827,58,H3
sample_9.pdf,7,5.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,305.61651611328125,0.0,3,H3
sample_9.pdf,7,Training Data and Batching,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,305.61651611328125,0.11538461538461539,26,H3
sample_9.pdf,7,We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million,10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,326.00030517578125,0.06666666666666667,90,H3
sample_9.pdf,7,sentence pairs. Sentences were encoded using byte-pair encoding [,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,336.9093017578125,0.015384615384615385,65,H3
sample_9.pdf,7,"], which has a shared source-",10.061732292175293,NimbusRomNo9L-Regu,False,386.7200012207031,336.9093017578125,0.0,29,H3
sample_9.pdf,7,"target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT",9.92266845703125,NimbusRomNo9L-Regu,False,108.0,347.92376708984375,0.0625,96,H3
sample_9.pdf,7,2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece,9.987475395202637,NimbusRomNo9L-Regu,False,108.0,358.7835998535156,0.03125,96,H3
sample_9.pdf,7,vocabulary [,9.862470626831055,NimbusRomNo9L-Regu,False,107.7509994506836,369.78741455078125,0.0,12,H3
sample_9.pdf,7,]. Sentence pairs were batched together by approximate sequence length. Each training,9.862470626831055,NimbusRomNo9L-Regu,False,166.1199951171875,369.78741455078125,0.023529411764705882,85,H3
sample_9.pdf,7,batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,380.5462951660156,0.0,94,H3
sample_9.pdf,7,target tokens.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,391.53045654296875,0.0,14,H3
sample_9.pdf,7,5.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,416.8815002441406,0.0,3,H3
sample_9.pdf,7,Hardware and Schedule,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,416.8815002441406,0.09523809523809523,21,H3
sample_9.pdf,7,We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using,10.061732292175293,NimbusRomNo9L-Regu,False,107.53199768066406,437.2652893066406,0.13793103448275862,87,H3
sample_9.pdf,7,"the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,448.234375,0.010309278350515464,97,H3
sample_9.pdf,7,"trained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,459.2344055175781,0.00980392156862745,102,H3
sample_9.pdf,7,"bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,469.9932861328125,0.010309278350515464,97,H3
sample_9.pdf,7,(3.5 days).,9.962599754333496,NimbusRomNo9L-Regu,False,107.6709976196289,480.9774475097656,0.0,11,H3
sample_9.pdf,7,5.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,506.3284912109375,0.0,3,H3
sample_9.pdf,7,Optimizer,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,506.3284912109375,0.1111111111111111,9,H3
sample_9.pdf,7,We used the Adam optimizer [,10.041984558105469,NimbusRomNo9L-Regu,False,107.53199768066406,526.727294921875,0.07142857142857142,28,H3
sample_9.pdf,7,] with,10.041984558105469,NimbusRomNo9L-Regu,False,240.97999572753906,526.727294921875,0.0,6,H3
sample_9.pdf,7,= 0,9.962599754333496,CMR10,False,276.9200744628906,526.5569458007812,0.0,3,H3
sample_9.pdf,7,= 0,9.962599754333496,CMR10,False,318.05108642578125,526.5569458007812,0.0,3,H3
sample_9.pdf,7,and,10.041984558105469,NimbusRomNo9L-Regu,False,349.5406188964844,526.727294921875,0.0,3,H3
sample_9.pdf,7,= 10,9.962599754333496,CMR10,False,373.163818359375,526.5569458007812,0.0,4,H3
sample_9.pdf,7,. We varied the learning,10.041984558105469,NimbusRomNo9L-Regu,False,407.1050109863281,526.727294921875,0.041666666666666664,24,H3
sample_9.pdf,7,"rate over the course of training, according to the formula:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,537.6964721679688,0.0,59,H3
sample_9.pdf,7,lrate,9.962599754333496,CMMI10,False,162.89199829101562,566.075927734375,0.0,5,H3
sample_9.pdf,7,model,6.973800182342529,NimbusRomNo9L-Regu,False,202.8040008544922,571.463134765625,0.0,5,P
sample_9.pdf,7,min(,9.962599754333496,CMR10,False,225.72061157226562,566.075927734375,0.0,4,H3
sample_9.pdf,7,step,9.962599754333496,CMMI10,False,248.4110107421875,566.075927734375,0.0,4,H3
sample_9.pdf,7,num,9.962599754333496,CMMI10,False,271.3110046386719,566.075927734375,0.0,3,H3
sample_9.pdf,7,", step",9.962599754333496,CMMI10,False,308.7749938964844,566.075927734375,0.0,6,H3
sample_9.pdf,7,num,9.962599754333496,CMMI10,False,336.1029968261719,566.075927734375,0.0,3,H3
sample_9.pdf,7,warmup,9.962599754333496,CMMI10,False,361.5166015625,566.075927734375,0.0,6,H3
sample_9.pdf,7,steps,9.962599754333496,CMMI10,False,405.6109924316406,566.075927734375,0.0,5,H3
sample_9.pdf,7,(3),9.962599754333496,NimbusRomNo9L-Regu,False,492.38397216796875,566.3064575195312,0.0,3,H3
sample_9.pdf,7,This corresponds to increasing the learning rate linearly for the ﬁrst,10.017244338989258,NimbusRomNo9L-Regu,False,107.69100189208984,587.9500122070312,0.014285714285714285,70,H3
sample_9.pdf,7,warmup,9.962599754333496,CMMI10,False,379.3075866699219,587.7609252929688,0.0,6,H3
sample_9.pdf,7,steps,9.962599754333496,CMMI10,False,423.67999267578125,587.7609252929688,0.0,5,H3
sample_9.pdf,7,"training steps,",10.017244338989258,NimbusRomNo9L-Regu,False,446.2751770019531,587.9500122070312,0.0,15,H3
sample_9.pdf,7,and decreasing it thereafter proportionally to the inverse square root of the step number. We used,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,598.8252563476562,0.01020408163265306,98,H3
sample_9.pdf,7,warmup,9.962599754333496,CMMI10,False,108.0,609.5789184570312,0.0,6,H3
sample_9.pdf,7,steps,9.962599754333496,CMMI10,False,149.8820037841797,609.5789184570312,0.0,5,H3
sample_9.pdf,7,= 4000,9.962599754333496,CMR10,False,172.4771728515625,609.5789184570312,0.0,6,H3
sample_9.pdf,7,5.4,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,635.1605224609375,0.0,3,H3
sample_9.pdf,7,Regularization,9.962599754333496,NimbusRomNo9L-Medi,False,130.41583251953125,635.1605224609375,0.07142857142857142,14,H3
sample_9.pdf,7,We employ three types of regularization during training:,9.962599754333496,NimbusRomNo9L-Regu,False,107.53199005126953,655.6204833984375,0.017857142857142856,56,H3
sample_9.pdf,7,Residual Dropout,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,679.6265258789062,0.125,16,H3
sample_9.pdf,7,We apply dropout [,9.927669525146484,NimbusRomNo9L-Regu,False,193.33700561523438,679.7439575195312,0.05555555555555555,18,H3
sample_9.pdf,7,"] to the output of each sub-layer, before it is added to the",9.927669525146484,NimbusRomNo9L-Regu,False,279.7510070800781,679.7439575195312,0.0,60,H3
sample_9.pdf,7,"sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,690.702392578125,0.010101010101010102,99,H3
sample_9.pdf,7,"positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,701.4602661132812,0.010309278350515464,97,H3
sample_9.pdf,7,drop,6.973800182342529,CMMI7,False,114.39599609375,716.0437622070312,0.0,4,P
sample_9.pdf,7,= 0,9.962599754333496,CMR10,False,130.49850463867188,712.2139282226562,0.0,3,H3
sample_9.pdf,8,Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the,9.962599754333496,NimbusRomNo9L-Regu,False,107.69100189208984,71.19947814941406,0.07216494845360824,97,H3
sample_9.pdf,8,English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,82.10847473144531,0.0425531914893617,94,H3
sample_9.pdf,8,Model,9.962599754333496,NimbusRomNo9L-Regu,False,136.67100524902344,106.07545471191406,0.2,5,H3
sample_9.pdf,8,BLEU,9.962599754333496,NimbusRomNo9L-Regu,False,311.02099609375,97.78645324707031,1.0,4,H3
sample_9.pdf,8,Training Cost (FLOPs),9.962599754333496,NimbusRomNo9L-Regu,False,383.2498474121094,97.78645324707031,0.2857142857142857,21,H3
sample_9.pdf,8,EN-DE,9.962599754333496,NimbusRomNo9L-Regu,False,288.7200012207031,113.49745178222656,0.8,5,H3
sample_9.pdf,8,EN-FR,9.962599754333496,NimbusRomNo9L-Regu,False,330.5529479980469,113.49745178222656,0.8,5,H3
sample_9.pdf,8,EN-DE,9.962599754333496,NimbusRomNo9L-Regu,False,387.4692687988281,113.49745178222656,0.8,5,H3
sample_9.pdf,8,EN-FR,9.962599754333496,NimbusRomNo9L-Regu,False,440.0419006347656,113.49745178222656,0.8,5,H3
sample_9.pdf,8,ByteNet [18],9.962599754333496,NimbusRomNo9L-Regu,False,136.67100524902344,124.80445861816406,0.16666666666666666,12,H3
sample_9.pdf,8,23.75,9.962599754333496,NimbusRomNo9L-Regu,False,292.44622802734375,124.80445861816406,0.0,5,H3
sample_9.pdf,8,Deep-Att + PosUnk [39],9.962599754333496,NimbusRomNo9L-Regu,False,136.67100524902344,136.1874542236328,0.18181818181818182,22,H3
sample_9.pdf,8,39.2,9.962599754333496,NimbusRomNo9L-Regu,False,336.22186279296875,136.1874542236328,0.0,4,H3
sample_9.pdf,8,GNMT + RL [38],9.962599754333496,NimbusRomNo9L-Regu,False,136.67098999023438,147.5694122314453,0.42857142857142855,14,H3
sample_9.pdf,8,24.6,9.962599754333496,NimbusRomNo9L-Regu,False,294.93682861328125,147.5694122314453,0.0,4,H3
sample_9.pdf,8,39.92,9.962599754333496,NimbusRomNo9L-Regu,False,333.7311706542969,147.5694122314453,0.0,5,H3
sample_9.pdf,8,ConvS2S [9],9.962599754333496,NimbusRomNo9L-Regu,False,136.6710205078125,158.95143127441406,0.2727272727272727,11,H3
sample_9.pdf,8,25.16,9.962599754333496,NimbusRomNo9L-Regu,False,292.4461975097656,158.95143127441406,0.0,5,H3
sample_9.pdf,8,40.46,9.962599754333496,NimbusRomNo9L-Regu,False,333.731201171875,158.95143127441406,0.0,5,H3
sample_9.pdf,8,MoE [32],9.962599754333496,NimbusRomNo9L-Regu,False,136.67105102539062,170.3344268798828,0.25,8,H3
sample_9.pdf,8,26.03,9.962599754333496,NimbusRomNo9L-Regu,False,292.4462585449219,170.3344268798828,0.0,5,H3
sample_9.pdf,8,40.56,9.962599754333496,NimbusRomNo9L-Regu,False,333.73126220703125,170.3344268798828,0.0,5,H3
sample_9.pdf,8,Deep-Att + PosUnk Ensemble [39],9.962599754333496,NimbusRomNo9L-Regu,False,136.67100524902344,182.97145080566406,0.16129032258064516,31,H3
sample_9.pdf,8,40.4,9.962599754333496,NimbusRomNo9L-Regu,False,336.2218322753906,182.97145080566406,0.0,4,H3
sample_9.pdf,8,GNMT + RL Ensemble [38],9.962599754333496,NimbusRomNo9L-Regu,False,136.67098999023438,194.3544464111328,0.30434782608695654,23,H3
sample_9.pdf,8,26.30,9.962599754333496,NimbusRomNo9L-Regu,False,292.4461669921875,194.3544464111328,0.0,5,H3
sample_9.pdf,8,41.16,9.962599754333496,NimbusRomNo9L-Regu,False,333.7311706542969,194.3544464111328,0.0,5,H3
sample_9.pdf,8,ConvS2S Ensemble [9],9.962599754333496,NimbusRomNo9L-Regu,False,136.6710205078125,205.7364044189453,0.2,20,H3
sample_9.pdf,8,26.36,9.962599754333496,NimbusRomNo9L-Regu,False,292.4461975097656,205.7364044189453,0.0,5,H3
sample_9.pdf,8,41.29,9.962599754333496,NimbusRomNo9L-Medi,False,333.73602294921875,205.64544677734375,0.0,5,H3
sample_9.pdf,8,Transformer (base model),9.962599754333496,NimbusRomNo9L-Regu,False,136.67100524902344,218.87245178222656,0.041666666666666664,24,H3
sample_9.pdf,8,27.3,9.962599754333496,NimbusRomNo9L-Regu,False,294.9368896484375,218.87245178222656,0.0,4,H3
sample_9.pdf,8,38.1,9.962599754333496,NimbusRomNo9L-Regu,False,336.2218933105469,218.87245178222656,0.0,4,H3
sample_9.pdf,8,Transformer (big),9.962599754333496,NimbusRomNo9L-Regu,False,136.67098999023438,230.25440979003906,0.058823529411764705,17,H3
sample_9.pdf,8,28.4,9.962599754333496,NimbusRomNo9L-Medi,False,294.94097900390625,230.1634521484375,0.0,4,H3
sample_9.pdf,8,41.8,9.962599754333496,NimbusRomNo9L-Medi,False,336.2259826660156,230.1634521484375,0.0,4,H3
sample_9.pdf,8,Label Smoothing,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,272.57452392578125,0.13333333333333333,15,H3
sample_9.pdf,8,"During training, we employed label smoothing of value",10.061732292175293,NimbusRomNo9L-Regu,False,191.10499572753906,272.5903015136719,0.018867924528301886,53,H3
sample_9.pdf,8,= 0,9.962599754333496,CMR10,False,431.9062805175781,272.4349365234375,0.0,3,H3
sample_9.pdf,8,]. This,10.061732292175293,NimbusRomNo9L-Regu,False,475.88299560546875,272.5903015136719,0.14285714285714285,7,H3
sample_9.pdf,8,"hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,283.574462890625,0.0425531914893617,94,H3
sample_9.pdf,8,Results,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,312.32415771484375,0.14285714285714285,7,H3
sample_9.pdf,8,6.1,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,338.15252685546875,0.0,3,H3
sample_9.pdf,8,Machine Translation,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,338.15252685546875,0.10526315789473684,19,H3
sample_9.pdf,8,"On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,359.0854187011719,0.07291666666666667,96,H3
sample_9.pdf,8,in Table 2) outperforms the best previously reported models (including ensembles) by more than,9.9126615524292,NimbusRomNo9L-Regu,False,108.0,369.9563293457031,0.010638297872340425,94,H3
sample_9.pdf,8,"BLEU, establishing a new state-of-the-art BLEU score of",10.051863670349121,NimbusRomNo9L-Regu,False,108.0,380.759765625,0.14545454545454545,55,H3
sample_9.pdf,8,. The conﬁguration of this model is,10.051863670349121,NimbusRomNo9L-Regu,False,360.84600830078125,380.759765625,0.02857142857142857,35,H3
sample_9.pdf,8,listed in the bottom line of Table 3. Training took,10.032095909118652,NimbusRomNo9L-Regu,False,108.0,391.6837463378906,0.0392156862745098,51,H3
sample_9.pdf,8,days on,10.032095909118652,NimbusRomNo9L-Regu,False,322.6922912597656,391.6837463378906,0.0,7,H3
sample_9.pdf,8,P100 GPUs. Even our base model,10.032095909118652,NimbusRomNo9L-Regu,False,363.75830078125,391.6837463378906,0.16666666666666666,30,H3
sample_9.pdf,8,"surpasses all previously published models and ensembles, at a fraction of the training cost of any of",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,402.64544677734375,0.0,101,H3
sample_9.pdf,8,the competitive models.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,413.554443359375,0.0,23,H3
sample_9.pdf,8,"On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of",9.867501258850098,NimbusRomNo9L-Regu,False,108.0,430.0155944824219,0.1111111111111111,90,H3
sample_9.pdf,8,"outperforming all of the previously published single models, at less than",9.942654609680176,NimbusRomNo9L-Regu,False,108.0,440.8675842285156,0.0,73,H3
sample_9.pdf,8,the training cost of the,9.942654609680176,NimbusRomNo9L-Regu,False,412.18328857421875,440.8675842285156,0.0,24,H3
sample_9.pdf,8,previous state-of-the-art model. The Transformer (big) model trained for English-to-French used,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,451.686279296875,0.042105263157894736,95,H3
sample_9.pdf,8,dropout rate,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,462.67047119140625,0.0,12,H3
sample_9.pdf,8,drop,6.973800182342529,CMMI7,False,165.30499267578125,466.270751953125,0.0,4,P
sample_9.pdf,8,= 0,9.962599754333496,CMR10,False,181.4075164794922,462.43994140625,0.0,3,H3
sample_9.pdf,8,", instead of",9.962599754333496,NimbusRomNo9L-Regu,False,207.91697692871094,462.67047119140625,0.0,12,H3
sample_9.pdf,8,"For the base models, we used a single model obtained by averaging the last 5 checkpoints, which",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,478.9842834472656,0.010526315789473684,95,H3
sample_9.pdf,8,"were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We",10.061732292175293,NimbusRomNo9L-Regu,False,107.64099884033203,489.8932800292969,0.020833333333333332,96,H3
sample_9.pdf,8,used beam search with a beam size of,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,500.80230712890625,0.0,36,H3
sample_9.pdf,8,and length penalty,10.061732292175293,NimbusRomNo9L-Regu,False,269.8952941894531,500.80230712890625,0.0,18,H3
sample_9.pdf,8,= 0,9.962599754333496,CMR10,False,356.9990539550781,500.6469421386719,0.0,3,H3
sample_9.pdf,8,]. These hyperparameters,10.061732292175293,NimbusRomNo9L-Regu,False,399.7909851074219,500.80230712890625,0.041666666666666664,24,H3
sample_9.pdf,8,were chosen after experimentation on the development set. We set the maximum output length during,9.862470626831055,NimbusRomNo9L-Regu,False,107.64099884033203,511.8624572753906,0.010309278350515464,97,H3
sample_9.pdf,8,inference to input length +,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,522.6954345703125,0.0,27,H3
sample_9.pdf,8,", but terminate early when possible [38].",9.962599754333496,NimbusRomNo9L-Regu,False,226.2360076904297,522.6954345703125,0.0,41,H3
sample_9.pdf,8,Table 2 summarizes our results and compares our translation quality and training costs to other model,9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,539.160400390625,0.009900990099009901,101,H3
sample_9.pdf,8,architectures from the literature. We estimate the number of ﬂoating point operations used to train a,9.947644233703613,NimbusRomNo9L-Regu,False,108.0,550.0048217773438,0.009900990099009901,101,H3
sample_9.pdf,8,"model by multiplying the training time, the number of GPUs used, and an estimate of the sustained",9.982504844665527,NimbusRomNo9L-Regu,False,108.0,560.8873901367188,0.030927835051546393,97,H3
sample_9.pdf,8,single-precision ﬂoating-point capacity of each GPU,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,571.8114624023438,0.058823529411764705,51,H3
sample_9.pdf,8,6.2,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,598.155517578125,0.0,3,H3
sample_9.pdf,8,Model Variations,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,598.155517578125,0.125,16,H3
sample_9.pdf,8,"To evaluate the importance of different components of the Transformer, we varied our base model",10.056798934936523,NimbusRomNo9L-Regu,False,107.69100189208984,618.9400634765625,0.021052631578947368,95,H3
sample_9.pdf,8,"in different ways, measuring the change in performance on English-to-German translation on the",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,629.8452758789062,0.02127659574468085,94,H3
sample_9.pdf,8,"development set, newstest2013. We used beam search as described in the previous section, but no",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,640.7542724609375,0.010526315789473684,95,H3
sample_9.pdf,8,checkpoint averaging. We present these results in Table 3.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,651.7394409179688,0.034482758620689655,58,H3
sample_9.pdf,8,"In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,668.203369140625,0.029411764705882353,102,H3
sample_9.pdf,8,"keeping the amount of computation constant, as described in Section 3.2.2. While single-head",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,678.9612426757812,0.021739130434782608,92,H3
sample_9.pdf,8,"attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,689.9454345703125,0.0425531914893617,94,H3
sample_9.pdf,8,"We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.",8.966400146484375,NimbusRomNo9L-Regu,False,124.13999938964844,713.199951171875,0.125,88,P
sample_9.pdf,9,Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base,9.882577896118164,NimbusRomNo9L-Regu,False,107.69100189208984,71.26016235351562,0.038834951456310676,103,H3
sample_9.pdf,9,"model. All metrics are on the English-to-German translation development set, newstest2013. Listed",9.942654609680176,NimbusRomNo9L-Regu,False,108.0,82.12359619140625,0.041237113402061855,97,H3
sample_9.pdf,9,"perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,93.01747131347656,0.0,98,H3
sample_9.pdf,9,per-word perplexities.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,103.92646789550781,0.0,22,H3
sample_9.pdf,9,model,6.973800182342529,NimbusRomNo9L-Regu,False,172.35800170898438,140.69815063476562,0.0,5,P
sample_9.pdf,9,drop,6.973800182342529,CMMI7,False,316.239013671875,140.53675842285156,0.0,4,P
sample_9.pdf,9,train,9.962599754333496,NimbusRomNo9L-Regu,False,371.1390075683594,131.4824981689453,0.0,5,H3
sample_9.pdf,9,PPL,9.962599754333496,NimbusRomNo9L-Regu,False,405.09600830078125,131.4824981689453,1.0,3,H3
sample_9.pdf,9,BLEU,9.962599754333496,NimbusRomNo9L-Regu,False,436.01995849609375,131.4824981689453,1.0,4,H3
sample_9.pdf,9,params,9.962599754333496,NimbusRomNo9L-Regu,False,473.9874267578125,131.4824981689453,0.0,6,H3
sample_9.pdf,9,steps,9.962599754333496,NimbusRomNo9L-Regu,False,370.3070068359375,142.8644561767578,0.0,5,H3
sample_9.pdf,9,(dev),9.962599754333496,NimbusRomNo9L-Regu,False,403.2929992675781,142.8644561767578,0.0,5,H3
sample_9.pdf,9,(dev),9.962599754333496,NimbusRomNo9L-Regu,False,438.6402893066406,142.8644561767578,0.0,5,H3
sample_9.pdf,9,base,9.962599754333496,NimbusRomNo9L-Regu,False,116.46800231933594,155.50245666503906,0.0,4,H3
sample_9.pdf,9,512,9.962599754333496,NimbusRomNo9L-Regu,False,171.25538635253906,155.50245666503906,0.0,3,H3
sample_9.pdf,9,2048,9.962599754333496,NimbusRomNo9L-Regu,False,202.24900817871094,155.50245666503906,0.0,4,H3
sample_9.pdf,9,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,315.115234375,155.50245666503906,0.0,3,H3
sample_9.pdf,9,0.1,9.962599754333496,NimbusRomNo9L-Regu,False,344.7938232421875,155.50245666503906,0.0,3,H3
sample_9.pdf,9,100K,9.962599754333496,NimbusRomNo9L-Regu,False,369.2021789550781,155.50245666503906,0.25,4,H3
sample_9.pdf,9,4.92,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,155.50245666503906,0.0,4,H3
sample_9.pdf,9,25.8,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,155.50245666503906,0.0,4,H3
sample_9.pdf,9,(A),9.962599754333496,NimbusRomNo9L-Regu,False,118.40599822998047,184.5034942626953,0.3333333333333333,3,H3
sample_9.pdf,9,512,9.962599754333496,NimbusRomNo9L-Regu,False,256.0440673828125,168.1394805908203,0.0,3,H3
sample_9.pdf,9,512,9.962599754333496,NimbusRomNo9L-Regu,False,282.94305419921875,168.1394805908203,0.0,3,H3
sample_9.pdf,9,5.29,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,168.1394805908203,0.0,4,H3
sample_9.pdf,9,24.9,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,168.1394805908203,0.0,4,H3
sample_9.pdf,9,128,9.962599754333496,NimbusRomNo9L-Regu,False,256.0440673828125,179.04945373535156,0.0,3,H3
sample_9.pdf,9,128,9.962599754333496,NimbusRomNo9L-Regu,False,282.94305419921875,179.04945373535156,0.0,3,H3
sample_9.pdf,9,5.00,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,179.04945373535156,0.0,4,H3
sample_9.pdf,9,25.5,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,179.04945373535156,0.0,4,H3
sample_9.pdf,9,4.91,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,189.9584503173828,0.0,4,H3
sample_9.pdf,9,25.8,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,189.9584503173828,0.0,4,H3
sample_9.pdf,9,5.01,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,200.86744689941406,0.0,4,H3
sample_9.pdf,9,25.4,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,200.86744689941406,0.0,4,H3
sample_9.pdf,9,(B),9.962599754333496,NimbusRomNo9L-Regu,False,118.68000030517578,218.95948791503906,0.3333333333333333,3,H3
sample_9.pdf,9,5.16,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,213.5044708251953,0.0,4,H3
sample_9.pdf,9,25.1,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,213.5044708251953,0.0,4,H3
sample_9.pdf,9,5.01,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,224.41346740722656,0.0,4,H3
sample_9.pdf,9,25.4,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,224.41346740722656,0.0,4,H3
sample_9.pdf,9,(C),9.962599754333496,NimbusRomNo9L-Regu,False,118.68000030517578,269.7784423828125,0.3333333333333333,3,H3
sample_9.pdf,9,6.11,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,237.0514678955078,0.0,4,H3
sample_9.pdf,9,23.7,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,237.0514678955078,0.0,4,H3
sample_9.pdf,9,5.19,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,247.96046447753906,0.0,4,H3
sample_9.pdf,9,25.3,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,247.96046447753906,0.0,4,H3
sample_9.pdf,9,4.88,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,258.86944580078125,0.0,4,H3
sample_9.pdf,9,25.5,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,258.86944580078125,0.0,4,H3
sample_9.pdf,9,256,9.962599754333496,NimbusRomNo9L-Regu,False,171.25999450683594,269.7784423828125,0.0,3,H3
sample_9.pdf,9,5.75,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,269.7784423828125,0.0,4,H3
sample_9.pdf,9,24.5,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,269.7784423828125,0.0,4,H3
sample_9.pdf,9,1024,9.962599754333496,NimbusRomNo9L-Regu,False,168.7689971923828,280.6874694824219,0.0,4,H3
sample_9.pdf,9,128,9.962599754333496,NimbusRomNo9L-Regu,False,256.0413513183594,280.6874694824219,0.0,3,H3
sample_9.pdf,9,128,9.962599754333496,NimbusRomNo9L-Regu,False,282.9403381347656,280.6874694824219,0.0,3,H3
sample_9.pdf,9,4.66,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,280.6874694824219,0.0,4,H3
sample_9.pdf,9,26.0,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,280.6874694824219,0.0,4,H3
sample_9.pdf,9,168,9.962599754333496,NimbusRomNo9L-Regu,False,480.89691162109375,280.6874694824219,0.0,3,H3
sample_9.pdf,9,1024,9.962599754333496,NimbusRomNo9L-Regu,False,202.24600219726562,291.5964660644531,0.0,4,H3
sample_9.pdf,9,5.12,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,291.5964660644531,0.0,4,H3
sample_9.pdf,9,25.4,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,291.5964660644531,0.0,4,H3
sample_9.pdf,9,4096,9.962599754333496,NimbusRomNo9L-Regu,False,202.24600219726562,302.5054626464844,0.0,4,H3
sample_9.pdf,9,4.75,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,302.5054626464844,0.0,4,H3
sample_9.pdf,9,26.2,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,302.5054626464844,0.0,4,H3
sample_9.pdf,9,(D),9.962599754333496,NimbusRomNo9L-Regu,False,118.40599822998047,331.5074462890625,0.3333333333333333,3,H3
sample_9.pdf,9,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,315.1130065917969,315.1434631347656,0.0,3,H3
sample_9.pdf,9,5.77,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,315.1434631347656,0.0,4,H3
sample_9.pdf,9,24.6,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,315.1434631347656,0.0,4,H3
sample_9.pdf,9,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,315.1130065917969,326.0524597167969,0.0,3,H3
sample_9.pdf,9,4.95,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,326.0524597167969,0.0,4,H3
sample_9.pdf,9,25.5,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,326.0524597167969,0.0,4,H3
sample_9.pdf,9,0.0,9.962599754333496,NimbusRomNo9L-Regu,False,344.7919921875,336.9614562988281,0.0,3,H3
sample_9.pdf,9,4.67,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,336.9614562988281,0.0,4,H3
sample_9.pdf,9,25.3,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,336.9614562988281,0.0,4,H3
sample_9.pdf,9,0.2,9.962599754333496,NimbusRomNo9L-Regu,False,344.7919921875,347.8704528808594,0.0,3,H3
sample_9.pdf,9,5.47,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,347.8704528808594,0.0,4,H3
sample_9.pdf,9,25.7,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,347.8704528808594,0.0,4,H3
sample_9.pdf,9,(E),9.962599754333496,NimbusRomNo9L-Regu,False,118.95899963378906,360.5084533691406,0.3333333333333333,3,H3
sample_9.pdf,9,positional embedding instead of sinusoids,9.962599754333496,NimbusRomNo9L-Regu,False,178.63400268554688,360.5084533691406,0.0,41,H3
sample_9.pdf,9,4.92,9.962599754333496,NimbusRomNo9L-Regu,False,404.9620056152344,360.5084533691406,0.0,4,H3
sample_9.pdf,9,25.7,9.962599754333496,NimbusRomNo9L-Regu,False,440.3092956542969,360.5084533691406,0.0,4,H3
sample_9.pdf,9,big,9.962599754333496,NimbusRomNo9L-Regu,False,118.9540023803711,373.14544677734375,0.0,3,H3
sample_9.pdf,9,1024,9.962599754333496,NimbusRomNo9L-Regu,False,168.76473999023438,373.14544677734375,0.0,4,H3
sample_9.pdf,9,4096,9.962599754333496,NimbusRomNo9L-Regu,False,202.24900817871094,373.14544677734375,0.0,4,H3
sample_9.pdf,9,0.3,9.962599754333496,NimbusRomNo9L-Regu,False,315.1152648925781,373.14544677734375,0.0,3,H3
sample_9.pdf,9,300K,9.962599754333496,NimbusRomNo9L-Regu,False,369.20220947265625,373.14544677734375,0.25,4,H3
sample_9.pdf,9,4.33,9.962599754333496,NimbusRomNo9L-Medi,False,404.9620056152344,373.05450439453125,0.0,4,H3
sample_9.pdf,9,26.4,9.962599754333496,NimbusRomNo9L-Medi,False,440.3092956542969,373.05450439453125,0.0,4,H3
sample_9.pdf,9,213,9.962599754333496,NimbusRomNo9L-Regu,False,480.9010009765625,373.14544677734375,0.0,3,H3
sample_9.pdf,9,Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23,9.862470626831055,NimbusRomNo9L-Regu,False,107.69100189208984,403.1494140625,0.06,100,H3
sample_9.pdf,9,of WSJ),9.962599754333496,NimbusRomNo9L-Regu,False,108.0,413.98345947265625,0.42857142857142855,7,H3
sample_9.pdf,9,Parser,9.962599754333496,NimbusRomNo9L-Medi,False,206.75799560546875,426.0105285644531,0.16666666666666666,6,H3
sample_9.pdf,9,Training,9.962599754333496,NimbusRomNo9L-Medi,False,334.0840148925781,426.0105285644531,0.125,8,H3
sample_9.pdf,9,WSJ 23 F1,9.962599754333496,NimbusRomNo9L-Medi,False,414.47698974609375,426.0105285644531,0.4444444444444444,9,H3
sample_9.pdf,9,Vinyals & Kaiser el al. (2014) [37],9.962599754333496,NimbusRomNo9L-Regu,False,151.02699279785156,437.4094543457031,0.05714285714285714,35,H3
sample_9.pdf,9,"WSJ only, discriminative",9.962599754333496,NimbusRomNo9L-Regu,False,302.5580139160156,437.4094543457031,0.125,24,H3
sample_9.pdf,9,88.3,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,437.4094543457031,0.0,4,H3
sample_9.pdf,9,Petrov et al. (2006) [29],9.962599754333496,NimbusRomNo9L-Regu,False,172.58599853515625,448.3184509277344,0.04,25,H3
sample_9.pdf,9,"WSJ only, discriminative",9.962599754333496,NimbusRomNo9L-Regu,False,302.5580139160156,448.3184509277344,0.125,24,H3
sample_9.pdf,9,90.4,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,448.3184509277344,0.0,4,H3
sample_9.pdf,9,Zhu et al. (2013) [40],9.962599754333496,NimbusRomNo9L-Regu,False,177.49298095703125,459.2274475097656,0.045454545454545456,22,H3
sample_9.pdf,9,"WSJ only, discriminative",9.962599754333496,NimbusRomNo9L-Regu,False,302.5580139160156,459.2274475097656,0.125,24,H3
sample_9.pdf,9,90.4,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,459.2274475097656,0.0,4,H3
sample_9.pdf,9,Dyer et al. (2016) [8],9.962599754333496,NimbusRomNo9L-Regu,False,178.05099487304688,470.1364440917969,0.045454545454545456,22,H3
sample_9.pdf,9,"WSJ only, discriminative",9.962599754333496,NimbusRomNo9L-Regu,False,302.5580139160156,470.1364440917969,0.125,24,H3
sample_9.pdf,9,91.7,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,470.1364440917969,0.0,4,H3
sample_9.pdf,9,Transformer (4 layers),9.962599754333496,NimbusRomNo9L-Regu,False,175.8990020751953,481.04547119140625,0.045454545454545456,22,H3
sample_9.pdf,9,"WSJ only, discriminative",9.962599754333496,NimbusRomNo9L-Regu,False,302.5580139160156,481.04547119140625,0.125,24,H3
sample_9.pdf,9,91.3,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,481.04547119140625,0.0,4,H3
sample_9.pdf,9,Zhu et al. (2013) [40],9.962599754333496,NimbusRomNo9L-Regu,False,177.4929962158203,491.9544677734375,0.045454545454545456,22,H3
sample_9.pdf,9,semi-supervised,9.962599754333496,NimbusRomNo9L-Regu,False,320.1669921875,491.9544677734375,0.0,15,H3
sample_9.pdf,9,91.3,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,491.9544677734375,0.0,4,H3
sample_9.pdf,9,Huang & Harper (2009) [14],9.962599754333496,NimbusRomNo9L-Regu,False,163.27099609375,502.86346435546875,0.07692307692307693,26,H3
sample_9.pdf,9,semi-supervised,9.962599754333496,NimbusRomNo9L-Regu,False,320.1669921875,502.86346435546875,0.0,15,H3
sample_9.pdf,9,91.3,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,502.86346435546875,0.0,4,H3
sample_9.pdf,9,McClosky et al. (2006) [26],9.962599754333496,NimbusRomNo9L-Regu,False,164.83499145507812,513.7734375,0.07407407407407407,27,H3
sample_9.pdf,9,semi-supervised,9.962599754333496,NimbusRomNo9L-Regu,False,320.1669921875,513.7734375,0.0,15,H3
sample_9.pdf,9,92.1,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,513.7734375,0.0,4,H3
sample_9.pdf,9,Vinyals & Kaiser el al. (2014) [37],9.962599754333496,NimbusRomNo9L-Regu,False,151.0269775390625,524.6824951171875,0.05714285714285714,35,H3
sample_9.pdf,9,semi-supervised,9.962599754333496,NimbusRomNo9L-Regu,False,320.1669921875,524.6824951171875,0.0,15,H3
sample_9.pdf,9,92.1,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,524.6824951171875,0.0,4,H3
sample_9.pdf,9,Transformer (4 layers),9.962599754333496,NimbusRomNo9L-Regu,False,175.8990020751953,535.5914306640625,0.045454545454545456,22,H3
sample_9.pdf,9,semi-supervised,9.962599754333496,NimbusRomNo9L-Regu,False,320.1669921875,535.5914306640625,0.0,15,H3
sample_9.pdf,9,92.7,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,535.5914306640625,0.0,4,H3
sample_9.pdf,9,Luong et al. (2015) [23],9.962599754333496,NimbusRomNo9L-Regu,False,172.51100158691406,546.50048828125,0.041666666666666664,24,H3
sample_9.pdf,9,multi-task,9.962599754333496,NimbusRomNo9L-Regu,False,332.33599853515625,546.50048828125,0.0,10,H3
sample_9.pdf,9,93.0,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,546.50048828125,0.0,4,H3
sample_9.pdf,9,Dyer et al. (2016) [8],9.962599754333496,NimbusRomNo9L-Regu,False,178.05099487304688,557.409423828125,0.045454545454545456,22,H3
sample_9.pdf,9,generative,9.962599754333496,NimbusRomNo9L-Regu,False,331.99200439453125,557.409423828125,0.0,10,H3
sample_9.pdf,9,93.3,9.962599754333496,NimbusRomNo9L-Regu,False,429.0069885253906,557.409423828125,0.0,4,H3
sample_9.pdf,9,"In Table 3 rows (B), we observe that reducing the attention key size",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,598.4402465820312,0.04411764705882353,68,H3
sample_9.pdf,9,hurts model quality. This,10.061732292175293,NimbusRomNo9L-Regu,False,397.1900939941406,598.4402465820312,0.04,25,H3
sample_9.pdf,9,suggests that determining compatibility is not easy and that a more sophisticated compatibility,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,609.3492431640625,0.0,95,H3
sample_9.pdf,9,"function than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,620.409423828125,0.0297029702970297,101,H3
sample_9.pdf,9,"bigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,631.318359375,0.019230769230769232,104,H3
sample_9.pdf,9,sinusoidal positional encoding with learned positional embeddings [,9.952631950378418,NimbusRomNo9L-Regu,False,108.0,642.1590576171875,0.0,67,H3
sample_9.pdf,9,"], and observe nearly identical",9.952631950378418,NimbusRomNo9L-Regu,False,383.99200439453125,642.1590576171875,0.0,31,H3
sample_9.pdf,9,results to the base model.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,653.0614624023438,0.0,26,H3
sample_9.pdf,9,6.3,9.962599754333496,NimbusRomNo9L-Medi,False,108.0,680.3145141601562,0.0,3,H3
sample_9.pdf,9,English Constituency Parsing,9.962599754333496,NimbusRomNo9L-Medi,False,130.4158477783203,680.3145141601562,0.10714285714285714,28,H3
sample_9.pdf,9,To evaluate if the Transformer can generalize to other tasks we performed experiments on English,10.041984558105469,NimbusRomNo9L-Regu,False,107.69100189208984,701.4752807617188,0.03125,96,H3
sample_9.pdf,9,constituency parsing. This task presents speciﬁc challenges: the output is subject to strong structural,9.90765380859375,NimbusRomNo9L-Regu,False,108.0,712.4861450195312,0.009708737864077669,103,H3
sample_9.pdf,10,"constraints and is signiﬁcantly longer than the input. Furthermore, RNN sequence-to-sequence",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,74.33230590820312,0.043478260869565216,92,H3
sample_9.pdf,10,models have not been able to attain state-of-the-art results in small-data regimes [37].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,85.31648254394531,0.0,88,H3
sample_9.pdf,10,We trained a 4-layer transformer with,9.862470626831055,NimbusRomNo9L-Regu,False,107.53199768066406,101.7804183959961,0.02702702702702703,37,H3
sample_9.pdf,10,model,6.973800182342529,CMMI7,False,262.1610107421875,105.30476379394531,0.0,5,P
sample_9.pdf,10,= 1024,9.962599754333496,CMR10,False,283.6124267578125,101.47392272949219,0.0,6,H3
sample_9.pdf,10,on the Wall Street Journal (WSJ) portion of the,9.862470626831055,NimbusRomNo9L-Regu,False,317.3606872558594,101.7804183959961,0.1276595744680851,47,H3
sample_9.pdf,10,Penn Treebank [,10.051863670349121,NimbusRomNo9L-Regu,False,108.0,112.54578399658203,0.13333333333333333,15,H3
sample_9.pdf,10,"], about 40K training sentences. We also trained it in a semi-supervised setting,",10.051863670349121,NimbusRomNo9L-Regu,False,184.55599975585938,112.54578399658203,0.024691358024691357,81,H3
sample_9.pdf,10,using the larger high-conﬁdence and BerkleyParser corpora from with approximately 17M sentences,9.89763069152832,NimbusRomNo9L-Regu,False,108.0,123.57174682617188,0.031578947368421054,95,H3
sample_9.pdf,10,]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens,9.95761775970459,NimbusRomNo9L-Regu,False,121.2770004272461,134.43621826171875,0.06451612903225806,93,H3
sample_9.pdf,10,for the semi-supervised setting.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,145.34144592285156,0.0,32,H3
sample_9.pdf,10,"We performed only a small number of experiments to select the dropout, both attention and residual",9.947644233703613,NimbusRomNo9L-Regu,False,107.53199768066406,161.74078369140625,0.01020408163265306,98,H3
sample_9.pdf,10,"(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters",10.041984558105469,NimbusRomNo9L-Regu,False,107.6709976196289,172.57823181152344,0.010101010101010102,99,H3
sample_9.pdf,10,"remained unchanged from the English-to-German base translation model. During inference, we",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,183.47232055664062,0.03333333333333333,90,H3
sample_9.pdf,10,increased the maximum output length to input length +,9.89763069152832,NimbusRomNo9L-Regu,False,108.0,194.50576782226562,0.0,53,H3
sample_9.pdf,10,300,9.962599754333496,CMR10,False,324.6917724609375,194.22593688964844,0.0,3,H3
sample_9.pdf,10,. We used a beam size of,9.89763069152832,NimbusRomNo9L-Regu,False,342.1260070800781,194.50576782226562,0.041666666666666664,24,H3
sample_9.pdf,10,and,9.89763069152832,NimbusRomNo9L-Regu,False,452.6275939941406,194.50576782226562,0.0,3,H3
sample_9.pdf,10,= 0,9.962599754333496,CMR10,False,478.1900634765625,194.22593688964844,0.0,3,H3
sample_9.pdf,10,for both WSJ only and the semi-supervised setting.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,205.36647033691406,0.06,50,H3
sample_9.pdf,10,Our results in Table 4 show that despite the lack of task-speciﬁc tuning our model performs sur-,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,221.67929077148438,0.020833333333333332,96,H3
sample_9.pdf,10,"prisingly well, yielding better results than all previously reported models with the exception of the",10.032095909118652,NimbusRomNo9L-Regu,False,108.0,232.6107635498047,0.0,101,H3
sample_9.pdf,10,Recurrent Neural Network Grammar [8].,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,243.5724639892578,0.10810810810810811,37,H3
sample_9.pdf,10,In contrast to RNN sequence-to-sequence models [,10.032095909118652,NimbusRomNo9L-Regu,False,108.0,259.9087829589844,0.08333333333333333,48,H3
sample_9.pdf,10,"], the Transformer outperforms the Berkeley-",10.032095909118652,NimbusRomNo9L-Regu,False,323.5870056152344,259.9087829589844,0.045454545454545456,44,H3
sample_9.pdf,10,Parser [29] even when training only on the WSJ training set of 40K sentences.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,270.8704833984375,0.06493506493506493,77,H3
sample_9.pdf,10,Conclusion,11.9552001953125,NimbusRomNo9L-Medi,False,125.93280029296875,297.14117431640625,0.1,10,H3
sample_9.pdf,10,"In this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on",9.972557067871094,NimbusRomNo9L-Regu,False,108.0,321.36492919921875,0.02040816326530612,98,H3
sample_9.pdf,10,"attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with",9.95761775970459,NimbusRomNo9L-Regu,False,108.0,332.2862548828125,0.0,98,H3
sample_9.pdf,10,multi-headed self-attention.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,343.19146728515625,0.0,28,H3
sample_9.pdf,10,"For translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,359.5043029785156,0.02040816326530612,98,H3
sample_9.pdf,10,on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,370.4132995605469,0.10588235294117647,85,H3
sample_9.pdf,10,"English-to-French translation tasks, we achieve a new state of the art. In the former task our best",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,381.3222961425781,0.030303030303030304,99,H3
sample_9.pdf,10,model outperforms even all previously reported ensembles.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,392.30645751953125,0.0,57,H3
sample_9.pdf,10,We are excited about the future of attention-based models and plan to apply them to other tasks. We,9.942654609680176,NimbusRomNo9L-Regu,False,107.53199768066406,408.7106018066406,0.020202020202020204,99,H3
sample_9.pdf,10,plan to extend the Transformer to problems involving input and output modalities other than text and,9.887598037719727,NimbusRomNo9L-Regu,False,108.0,419.6613464355469,0.01,100,H3
sample_9.pdf,10,"to investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs",10.061732292175293,NimbusRomNo9L-Regu,False,108.0,430.43829345703125,0.0,99,H3
sample_9.pdf,10,"such as images, audio and video. Making generation less sequential is another research goals of ours.",9.882577896118164,NimbusRomNo9L-Regu,False,108.0,441.483154296875,0.009900990099009901,101,H3
sample_9.pdf,10,The code we used to train and evaluate our models is available at,10.061732292175293,NimbusRomNo9L-Regu,False,107.69100189208984,457.7362976074219,0.015384615384615385,65,H3
sample_9.pdf,10,https://github.com/,9.962599754333496,SFTT1000,False,400.71820068359375,458.05950927734375,0.0,19,H3
sample_9.pdf,10,tensorflow/tensor2tensor,9.962599754333496,SFTT1000,False,108.0,468.968505859375,0.0,24,H3
sample_9.pdf,10,Acknowledgements,9.962599754333496,NimbusRomNo9L-Medi,False,107.99999237060547,491.2405090332031,0.0625,16,H3
sample_9.pdf,10,We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful,10.061732292175293,NimbusRomNo9L-Regu,False,200.322998046875,491.25628662109375,0.06944444444444445,72,H3
sample_9.pdf,10,"comments, corrections and inspiration.",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,502.2404479980469,0.0,38,H3
sample_9.pdf,10,References,11.9552001953125,NimbusRomNo9L-Medi,False,108.0,528.5121459960938,0.1,10,H3
sample_9.pdf,10,[1],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,547.263427734375,0.0,3,H3
sample_9.pdf,10,"Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization.",9.89261531829834,NimbusRomNo9L-Regu,False,124.5973892211914,547.3165283203125,0.13333333333333333,75,H3
sample_9.pdf,10,arXiv preprint,9.89261531829834,NimbusRomNo9L-ReguItal,False,444.2333679199219,547.1412963867188,0.07142857142857142,14,H3
sample_9.pdf,10,arXiv:1607.06450,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,557.9960327148438,0.0625,16,H3
sample_9.pdf,10,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,558.1724853515625,0.0,7,H3
sample_9.pdf,10,[2],9.962599754333496,NimbusRomNo9L-Regu,False,112.98098754882812,575.9364624023438,0.0,3,H3
sample_9.pdf,10,"Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly",9.862470626831055,NimbusRomNo9L-Regu,False,124.59737396240234,576.0123901367188,0.07865168539325842,89,H3
sample_9.pdf,10,learning to align and translate.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,586.845458984375,0.0,32,H3
sample_9.pdf,10,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,250.49508666992188,586.6690063476562,0.75,4,H3
sample_9.pdf,10,", abs/1409.0473, 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,277.8809814453125,586.845458984375,0.0,22,H3
sample_9.pdf,10,[3],9.962599754333496,NimbusRomNo9L-Regu,False,112.98098754882812,604.6084594726562,0.0,3,H3
sample_9.pdf,10,"Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural",9.867501258850098,NimbusRomNo9L-Regu,False,124.59737396240234,604.6806030273438,0.12359550561797752,89,H3
sample_9.pdf,10,machine translation architectures.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,615.5174560546875,0.0,34,H3
sample_9.pdf,10,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,263.76531982421875,615.3410034179688,0.75,4,H3
sample_9.pdf,10,", abs/1703.03906, 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,291.1509704589844,615.5174560546875,0.0,23,H3
sample_9.pdf,10,[4],9.962599754333496,NimbusRomNo9L-Regu,False,112.98097229003906,633.281494140625,0.0,3,H3
sample_9.pdf,10,"Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine",9.882577896118164,NimbusRomNo9L-Regu,False,124.59735870361328,633.3422241210938,0.07954545454545454,88,H3
sample_9.pdf,10,reading.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,644.1904296875,0.0,8,H3
sample_9.pdf,10,arXiv preprint arXiv:1601.06733,9.962599754333496,NimbusRomNo9L-ReguItal,False,161.94747924804688,644.0139770507812,0.06451612903225806,31,H3
sample_9.pdf,10,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,297.71697998046875,644.1904296875,0.0,7,H3
sample_9.pdf,10,[5],9.962599754333496,NimbusRomNo9L-Regu,False,112.98098754882812,661.9534912109375,0.0,3,H3
sample_9.pdf,10,"Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,",10.061732292175293,NimbusRomNo9L-Regu,False,124.59737396240234,661.8782958984375,0.11764705882352941,85,H3
sample_9.pdf,10,and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical,9.972557067871094,NimbusRomNo9L-Regu,False,129.57899475097656,672.8548583984375,0.03260869565217391,92,H3
sample_9.pdf,10,machine translation.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,683.771484375,0.0,20,H3
sample_9.pdf,10,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,210.37570190429688,683.5950317382812,0.75,4,H3
sample_9.pdf,10,", abs/1406.1078, 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,237.76199340820312,683.771484375,0.0,22,H3
sample_9.pdf,10,[6],9.962599754333496,NimbusRomNo9L-Regu,False,112.98099517822266,701.5354614257812,0.0,3,H3
sample_9.pdf,10,Francois Chollet. Xception: Deep learning with depthwise separable convolutions.,10.061732292175293,NimbusRomNo9L-Regu,False,124.59738159179688,701.4602661132812,0.05,80,H3
sample_9.pdf,10,arXiv,10.061732292175293,NimbusRomNo9L-ReguItal,False,475.1127014160156,701.2820434570312,0.2,5,H3
sample_9.pdf,10,preprint arXiv:1610.02357,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,712.2680053710938,0.04,25,H3
sample_9.pdf,10,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,237.13499450683594,712.4444580078125,0.0,7,H3
sample_9.pdf,11,[7],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,74.40748596191406,0.0,3,H3
sample_9.pdf,11,"Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation",9.877554893493652,NimbusRomNo9L-Regu,False,124.5973892211914,74.47198486328125,0.10344827586206896,87,H3
sample_9.pdf,11,of gated recurrent neural networks on sequence modeling.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,85.31648254394531,0.0,56,H3
sample_9.pdf,11,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,360.7212829589844,85.1400146484375,0.75,4,H3
sample_9.pdf,11,", abs/1412.3555, 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,388.10699462890625,85.31648254394531,0.0,22,H3
sample_9.pdf,11,[8],9.962599754333496,NimbusRomNo9L-Regu,False,112.98098754882812,105.11750793457031,0.0,3,H3
sample_9.pdf,11,"Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural",10.061732292175293,NimbusRomNo9L-Regu,False,124.59737396240234,105.04226684570312,0.11764705882352941,85,H3
sample_9.pdf,11,network grammars. In,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,116.02644348144531,0.05,20,H3
sample_9.pdf,11,Proc. of NAACL,9.962599754333496,NimbusRomNo9L-ReguItal,False,218.83392333984375,115.8499755859375,0.42857142857142855,14,H3
sample_9.pdf,11,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,285.9020080566406,116.02644348144531,0.0,7,H3
sample_9.pdf,11,[9],9.962599754333496,NimbusRomNo9L-Regu,False,112.98100280761719,135.8274688720703,0.0,3,H3
sample_9.pdf,11,"Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-",10.022196769714355,NimbusRomNo9L-Regu,False,124.5973892211914,135.7822723388672,0.13636363636363635,88,H3
sample_9.pdf,11,tional sequence to sequence learning.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,146.73646545410156,0.0,37,H3
sample_9.pdf,11,arXiv preprint arXiv:1705.03122v2,9.962599754333496,NimbusRomNo9L-ReguItal,False,278.1512451171875,146.55999755859375,0.06060606060606061,33,H3
sample_9.pdf,11,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,423.32501220703125,146.73646545410156,0.0,7,H3
sample_9.pdf,11,[10],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,166.53749084472656,0.0,4,H3
sample_9.pdf,11,Alex Graves.,10.061732292175293,NimbusRomNo9L-Regu,False,124.59768676757812,166.46231079101562,0.16666666666666666,12,H3
sample_9.pdf,11,Generating sequences with recurrent neural networks.,10.061732292175293,NimbusRomNo9L-Regu,False,197.99871826171875,166.46231079101562,0.019230769230769232,52,H3
sample_9.pdf,11,arXiv preprint,10.061732292175293,NimbusRomNo9L-ReguItal,False,443.18701171875,166.28408813476562,0.07142857142857142,14,H3
sample_9.pdf,11,arXiv:1308.0850,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,177.27001953125,0.06666666666666667,15,H3
sample_9.pdf,11,", 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,197.37399291992188,177.4464874267578,0.0,7,H3
sample_9.pdf,11,[11],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,197.2475128173828,0.0,4,H3
sample_9.pdf,11,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-",10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,197.17227172851562,0.10588235294117647,85,H3
sample_9.pdf,11,age recognition. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,208.08126831054688,0.05263157894736842,19,H3
sample_9.pdf,11,Proceedings of the IEEE Conference on Computer Vision and Pattern,10.061732292175293,NimbusRomNo9L-ReguItal,False,210.56898498535156,207.90304565429688,0.13846153846153847,65,H3
sample_9.pdf,11,Recognition,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.27000427246094,218.88897705078125,0.09090909090909091,11,H3
sample_9.pdf,11,", pages 770–778, 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,177.32000732421875,219.06544494628906,0.0,22,H3
sample_9.pdf,11,[12],9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,238.86647033691406,0.0,4,H3
sample_9.pdf,11,"Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in",10.041984558105469,NimbusRomNo9L-Regu,False,124.59769439697266,238.80625915527344,0.10344827586206896,87,H3
sample_9.pdf,11,"recurrent nets: the difﬁculty of learning long-term dependencies, 2001.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,249.7754669189453,0.0,71,H3
sample_9.pdf,11,[13],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,269.57647705078125,0.0,4,H3
sample_9.pdf,11,Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory.,10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,269.5013122558594,0.07936507936507936,63,H3
sample_9.pdf,11,Neural computation,10.061732292175293,NimbusRomNo9L-ReguItal,False,415.0662536621094,269.3230895996094,0.05555555555555555,18,H3
sample_9.pdf,11,"9(8):1735–1780, 1997.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,280.4854431152344,0.0,21,H3
sample_9.pdf,11,[14],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,300.28643798828125,0.0,4,H3
sample_9.pdf,11,Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations,10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,300.2112731933594,0.10588235294117647,85,H3
sample_9.pdf,11,across languages. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,311.1213073730469,0.05,20,H3
sample_9.pdf,11,Proceedings of the 2009 Conference on Empirical Methods in Natural,10.061732292175293,NimbusRomNo9L-ReguItal,False,213.80043029785156,310.9430847167969,0.07575757575757576,66,H3
sample_9.pdf,11,Language Processing,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.3000030517578,321.92901611328125,0.10526315789473684,19,H3
sample_9.pdf,11,", pages 832–841. ACL, August 2009.",9.962599754333496,NimbusRomNo9L-Regu,False,215.26699829101562,322.10546875,0.11764705882352941,34,H3
sample_9.pdf,11,[15],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,341.9064636230469,0.0,4,H3
sample_9.pdf,11,"Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring",10.022196769714355,NimbusRomNo9L-Regu,False,124.59768676757812,341.86126708984375,0.12643678160919541,87,H3
sample_9.pdf,11,the limits of language modeling.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,352.8154602050781,0.0,32,H3
sample_9.pdf,11,arXiv preprint arXiv:1602.02410,9.962599754333496,NimbusRomNo9L-ReguItal,False,258.8138427734375,352.6390075683594,0.06451612903225806,31,H3
sample_9.pdf,11,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,394.5830078125,352.8154602050781,0.0,7,H3
sample_9.pdf,11,[16],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,372.616455078125,0.0,4,H3
sample_9.pdf,11,Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In,9.872529029846191,NimbusRomNo9L-Regu,False,124.59768676757812,372.6847839355469,0.08571428571428572,70,H3
sample_9.pdf,11,Advances in Neural,9.872529029846191,NimbusRomNo9L-ReguItal,False,424.4176940917969,372.5099182128906,0.1111111111111111,18,H3
sample_9.pdf,11,"Information Processing Systems, (NIPS)",9.962599754333496,NimbusRomNo9L-ReguItal,False,129.41000366210938,383.3489990234375,0.18421052631578946,38,H3
sample_9.pdf,11,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,290.0059814453125,383.52545166015625,0.0,7,H3
sample_9.pdf,11,[17],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,403.3264465332031,0.0,4,H3
sample_9.pdf,11,Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In,9.92266845703125,NimbusRomNo9L-Regu,False,124.59767150878906,403.35675048828125,0.13636363636363635,66,H3
sample_9.pdf,11,International Conference,9.92266845703125,NimbusRomNo9L-ReguItal,False,401.6848449707031,403.1809997558594,0.08333333333333333,24,H3
sample_9.pdf,11,on Learning Representations (ICLR),9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,414.0589904785156,0.17647058823529413,34,H3
sample_9.pdf,11,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,275.5999755859375,414.2354431152344,0.0,7,H3
sample_9.pdf,11,[18],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,434.03643798828125,0.0,4,H3
sample_9.pdf,11,"Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-",9.862470626831055,NimbusRomNo9L-Regu,False,124.59765625,434.1123962402344,0.12222222222222222,90,H3
sample_9.pdf,11,ray Kavukcuoglu. Neural machine translation in linear time.,9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,445.02142333984375,0.03389830508474576,59,H3
sample_9.pdf,11,arXiv preprint arXiv:1610.10099v2,9.862470626831055,NimbusRomNo9L-ReguItal,False,362.239501953125,444.8467102050781,0.06060606060606061,33,H3
sample_9.pdf,11,2017.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,455.8544616699219,0.0,5,H3
sample_9.pdf,11,[19],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,475.65545654296875,0.0,4,H3
sample_9.pdf,11,"Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.",9.882577896118164,NimbusRomNo9L-Regu,False,124.5976791381836,475.7161560058594,0.11235955056179775,89,H3
sample_9.pdf,11,International Conference on Learning Representations,9.962599754333496,NimbusRomNo9L-ReguItal,False,137.87783813476562,486.38800048828125,0.07692307692307693,52,H3
sample_9.pdf,11,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,358.7969970703125,486.564453125,0.0,7,H3
sample_9.pdf,11,[20],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,506.365478515625,0.0,4,H3
sample_9.pdf,11,Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In,9.90765380859375,NimbusRomNo9L-Regu,False,124.59768676757812,506.40716552734375,0.09210526315789473,76,H3
sample_9.pdf,11,ICLR,9.90765380859375,NimbusRomNo9L-ReguItal,False,454.7776184082031,506.2316589355469,1.0,4,H3
sample_9.pdf,11,", 2015.",9.90765380859375,NimbusRomNo9L-Regu,False,478.6199951171875,506.40716552734375,0.0,7,H3
sample_9.pdf,11,[21],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,526.1664428710938,0.0,4,H3
sample_9.pdf,11,Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks.,9.9176664352417,NimbusRomNo9L-Regu,False,124.59768676757812,526.2005615234375,0.11842105263157894,76,H3
sample_9.pdf,11,arXiv preprint,9.9176664352417,NimbusRomNo9L-ReguItal,False,443.9432373046875,526.0248413085938,0.07142857142857142,14,H3
sample_9.pdf,11,arXiv:1703.10722,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,536.8989868164062,0.0625,16,H3
sample_9.pdf,11,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,537.075439453125,0.0,7,H3
sample_9.pdf,11,[22],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,556.87646484375,0.0,4,H3
sample_9.pdf,11,"Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen",10.061732292175293,NimbusRomNo9L-Regu,False,124.59767150878906,556.80126953125,0.15384615384615385,78,H3
sample_9.pdf,11,"Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding.",10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,567.7102661132812,0.05555555555555555,72,H3
sample_9.pdf,11,arXiv preprint,10.061732292175293,NimbusRomNo9L-ReguItal,False,440.1152038574219,567.5320434570312,0.07142857142857142,14,H3
sample_9.pdf,11,arXiv:1703.03130,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,578.5189819335938,0.0625,16,H3
sample_9.pdf,11,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,578.6954345703125,0.0,7,H3
sample_9.pdf,11,[23],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,598.4964599609375,0.0,4,H3
sample_9.pdf,11,"Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task",9.947644233703613,NimbusRomNo9L-Regu,False,124.59767150878906,598.5078125,0.14444444444444443,90,H3
sample_9.pdf,11,sequence to sequence learning.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,609.4054565429688,0.0,30,H3
sample_9.pdf,11,arXiv preprint arXiv:1511.06114,9.962599754333496,NimbusRomNo9L-ReguItal,False,252.96580505371094,609.22900390625,0.06451612903225806,31,H3
sample_9.pdf,11,", 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,388.7349853515625,609.4054565429688,0.0,7,H3
sample_9.pdf,11,[24],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,629.2064208984375,0.0,4,H3
sample_9.pdf,11,"Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-",9.862470626831055,NimbusRomNo9L-Regu,False,124.59768676757812,629.2823486328125,0.1,90,H3
sample_9.pdf,11,based neural machine translation.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,640.115478515625,0.0,33,H3
sample_9.pdf,11,arXiv preprint arXiv:1508.04025,9.962599754333496,NimbusRomNo9L-ReguItal,False,262.93841552734375,639.9390258789062,0.06451612903225806,31,H3
sample_9.pdf,11,", 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,398.70697021484375,640.115478515625,0.0,7,H3
sample_9.pdf,11,[25],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,659.9164428710938,0.0,4,H3
sample_9.pdf,11,"Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated",9.862470626831055,NimbusRomNo9L-Regu,False,124.59765625,659.9923706054688,0.0967741935483871,93,H3
sample_9.pdf,11,corpus of english: The penn treebank.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,670.825439453125,0.02702702702702703,37,H3
sample_9.pdf,11,Computational linguistics,9.962599754333496,NimbusRomNo9L-ReguItal,False,280.6916809082031,670.6489868164062,0.04,25,H3
sample_9.pdf,11,", 19(2):313–330, 1993.",9.962599754333496,NimbusRomNo9L-Regu,False,387.5190124511719,670.825439453125,0.0,22,H3
sample_9.pdf,11,[26],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,690.62646484375,0.0,4,H3
sample_9.pdf,11,"David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In",9.977532386779785,NimbusRomNo9L-Regu,False,124.59768676757812,690.6151733398438,0.1,90,H3
sample_9.pdf,11,"Proceedings of the Human Language Technology Conference of the NAACL, Main Conference",9.927669525146484,NimbusRomNo9L-ReguItal,False,129.27000427246094,701.3861083984375,0.1411764705882353,85,H3
sample_9.pdf,11,"pages 152–159. ACL, June 2006.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,712.4444580078125,0.13333333333333333,30,H3
sample_9.pdf,12,[27],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,74.40748596191406,0.0,4,H3
sample_9.pdf,12,"Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention",9.862470626831055,NimbusRomNo9L-Regu,False,124.59768676757812,74.4834213256836,0.1,90,H3
sample_9.pdf,12,model. In,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,85.31648254394531,0.1111111111111111,9,H3
sample_9.pdf,12,Empirical Methods in Natural Language Processing,9.962599754333496,NimbusRomNo9L-ReguItal,False,168.86151123046875,85.1400146484375,0.10416666666666667,48,H3
sample_9.pdf,12,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,380.0479736328125,85.31648254394531,0.0,7,H3
sample_9.pdf,12,[28],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,114.92945861816406,0.0,4,H3
sample_9.pdf,12,"Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive",9.95761775970459,NimbusRomNo9L-Regu,False,124.59765625,114.93323516845703,0.07865168539325842,89,H3
sample_9.pdf,12,summarization.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,125.83845520019531,0.0,14,H3
sample_9.pdf,12,arXiv preprint arXiv:1705.04304,9.962599754333496,NimbusRomNo9L-ReguItal,False,191.287353515625,125.6619873046875,0.06451612903225806,31,H3
sample_9.pdf,12,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,327.05596923828125,125.83845520019531,0.0,7,H3
sample_9.pdf,12,[29],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,155.45143127441406,0.0,4,H3
sample_9.pdf,12,"Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,",10.061732292175293,NimbusRomNo9L-Regu,False,124.59765625,155.37625122070312,0.10588235294117647,85,H3
sample_9.pdf,12,and interpretable tree annotation. In,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,166.28530883789062,0.02702702702702703,37,H3
sample_9.pdf,12,Proceedings of the 21st International Conference on,10.061732292175293,NimbusRomNo9L-ReguItal,False,281.8544006347656,166.10708618164062,0.058823529411764705,51,H3
sample_9.pdf,12,Computational Linguistics and 44th Annual Meeting of the ACL,10.061732292175293,NimbusRomNo9L-ReguItal,False,129.25,177.01608276367188,0.11666666666666667,60,H3
sample_9.pdf,12,", pages 433–440. ACL, July",10.061732292175293,NimbusRomNo9L-Regu,False,390.5950012207031,177.19430541992188,0.15384615384615385,26,H3
sample_9.pdf,12,2006.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,188.17848205566406,0.0,5,H3
sample_9.pdf,12,[30],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,217.79249572753906,0.0,4,H3
sample_9.pdf,12,Oﬁr Press and Lior Wolf. Using the output embedding to improve language models.,10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,217.71731567382812,0.06329113924050633,79,H3
sample_9.pdf,12,arXiv,10.061732292175293,NimbusRomNo9L-ReguItal,False,476.5859680175781,217.53909301757812,0.2,5,H3
sample_9.pdf,12,preprint arXiv:1608.05859,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,228.5250244140625,0.04,25,H3
sample_9.pdf,12,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,237.13499450683594,228.7014923095703,0.0,7,H3
sample_9.pdf,12,[31],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,258.314453125,0.0,4,H3
sample_9.pdf,12,"Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words",9.92266845703125,NimbusRomNo9L-Regu,False,124.59768676757812,258.3447570800781,0.07777777777777778,90,H3
sample_9.pdf,12,with subword units.,9.962599754333496,NimbusRomNo9L-Regu,False,129.22000122070312,269.22344970703125,0.0,19,H3
sample_9.pdf,12,arXiv preprint arXiv:1508.07909,9.962599754333496,NimbusRomNo9L-ReguItal,False,207.99424743652344,269.0469970703125,0.06451612903225806,31,H3
sample_9.pdf,12,", 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,343.76397705078125,269.22344970703125,0.0,7,H3
sample_9.pdf,12,[32],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,298.8364562988281,0.0,4,H3
sample_9.pdf,12,"Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,",9.902643203735352,NimbusRomNo9L-Regu,False,124.59765625,298.8819274902344,0.1348314606741573,89,H3
sample_9.pdf,12,and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts,10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,309.6702880859375,0.045454545454545456,88,H3
sample_9.pdf,12,layer.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,320.6544494628906,0.0,6,H3
sample_9.pdf,12,arXiv preprint arXiv:1701.06538,9.962599754333496,NimbusRomNo9L-ReguItal,False,151.43695068359375,320.4779968261719,0.06451612903225806,31,H3
sample_9.pdf,12,", 2017.",9.962599754333496,NimbusRomNo9L-Regu,False,287.2070007324219,320.6544494628906,0.0,7,H3
sample_9.pdf,12,[33],9.962599754333496,NimbusRomNo9L-Regu,False,108.0,350.2684631347656,0.0,4,H3
sample_9.pdf,12,"Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-",9.942654609680176,NimbusRomNo9L-Regu,False,124.59768676757812,350.2835998535156,0.11827956989247312,93,H3
sample_9.pdf,12,nov. Dropout: a simple way to prevent neural networks from overﬁtting.,10.02714729309082,NimbusRomNo9L-Regu,False,129.57899475097656,361.1285095214844,0.014285714285714285,70,H3
sample_9.pdf,12,Journal of Machine,10.02714729309082,NimbusRomNo9L-ReguItal,False,421.2914733886719,360.9508972167969,0.1111111111111111,18,H3
sample_9.pdf,12,Learning Research,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.3000030517578,371.9100036621094,0.11764705882352941,17,H3
sample_9.pdf,12,", 15(1):1929–1958, 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,204.87600708007812,372.0864562988281,0.0,24,H3
sample_9.pdf,12,[34],9.962599754333496,NimbusRomNo9L-Regu,False,108.00000762939453,401.699462890625,0.0,4,H3
sample_9.pdf,12,"Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory",10.061732292175293,NimbusRomNo9L-Regu,False,124.59769439697266,401.6242980957031,0.10843373493975904,83,H3
sample_9.pdf,12,"networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,",10.061732292175293,NimbusRomNo9L-Regu,False,129.57899475097656,412.5332946777344,0.14772727272727273,88,H3
sample_9.pdf,12,Advances in Neural Information Processing Systems 28,9.95761775970459,NimbusRomNo9L-ReguItal,False,128.9709930419922,423.3448791503906,0.09615384615384616,52,H3
sample_9.pdf,12,", pages 2440–2448. Curran Associates,",9.95761775970459,NimbusRomNo9L-Regu,False,350.1340026855469,423.521240234375,0.05405405405405406,37,H3
sample_9.pdf,12,"Inc., 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,434.42645263671875,0.09090909090909091,11,H3
sample_9.pdf,12,[35],9.962599754333496,NimbusRomNo9L-Regu,False,107.99999237060547,464.0394592285156,0.0,4,H3
sample_9.pdf,12,"Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural",10.061732292175293,NimbusRomNo9L-Regu,False,124.5976791381836,463.96429443359375,0.10227272727272728,88,H3
sample_9.pdf,12,networks. In,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,474.9484558105469,0.08333333333333333,12,H3
sample_9.pdf,12,Advances in Neural Information Processing Systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,180.37828063964844,474.7720031738281,0.10204081632653061,49,H3
sample_9.pdf,12,", pages 3104–3112, 2014.",9.962599754333496,NimbusRomNo9L-Regu,False,391.74298095703125,474.9484558105469,0.0,24,H3
sample_9.pdf,12,[36],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,504.5625,0.0,4,H3
sample_9.pdf,12,"Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.",10.061732292175293,NimbusRomNo9L-Regu,False,124.59765625,504.4873352050781,0.11363636363636363,88,H3
sample_9.pdf,12,Rethinking the inception architecture for computer vision.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,515.471435546875,0.017241379310344827,58,H3
sample_9.pdf,12,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,361.17950439453125,515.2949829101562,0.75,4,H3
sample_9.pdf,12,", abs/1512.00567, 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,388.5649719238281,515.471435546875,0.0,23,H3
sample_9.pdf,12,[37],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,545.08447265625,0.0,4,H3
sample_9.pdf,12,"Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In",10.061732292175293,NimbusRomNo9L-Regu,False,124.59765625,545.00927734375,0.09195402298850575,87,H3
sample_9.pdf,12,Advances in Neural Information Processing Systems,9.962599754333496,NimbusRomNo9L-ReguItal,False,128.9709930419922,555.8170166015625,0.10204081632653061,49,H3
sample_9.pdf,12,", 2015.",9.962599754333496,NimbusRomNo9L-Regu,False,337.84600830078125,555.9934692382812,0.0,7,H3
sample_9.pdf,12,[38],9.962599754333496,NimbusRomNo9L-Regu,False,108.00001525878906,585.6064453125,0.0,4,H3
sample_9.pdf,12,"Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang",10.061732292175293,NimbusRomNo9L-Regu,False,124.59770202636719,585.53125,0.15384615384615385,78,H3
sample_9.pdf,12,"Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine",9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,596.5913696289062,0.11235955056179775,89,H3
sample_9.pdf,12,translation system: Bridging the gap between human and machine translation.,10.012289047241211,NimbusRomNo9L-Regu,False,129.57899475097656,607.3867797851562,0.013333333333333334,75,H3
sample_9.pdf,12,arXiv preprint,10.012289047241211,NimbusRomNo9L-ReguItal,False,442.936767578125,607.2094116210938,0.07142857142857142,14,H3
sample_9.pdf,12,arXiv:1609.08144,9.962599754333496,NimbusRomNo9L-ReguItal,False,129.57899475097656,618.1580200195312,0.0625,16,H3
sample_9.pdf,12,", 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,202.35598754882812,618.33447265625,0.0,7,H3
sample_9.pdf,12,[39],9.962599754333496,NimbusRomNo9L-Regu,False,107.99998474121094,647.9474487304688,0.0,4,H3
sample_9.pdf,12,"Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with",10.061732292175293,NimbusRomNo9L-Regu,False,124.59767150878906,647.8722534179688,0.13580246913580246,81,H3
sample_9.pdf,12,fast-forward connections for neural machine translation.,9.962599754333496,NimbusRomNo9L-Regu,False,129.57899475097656,658.8564453125,0.0,56,H3
sample_9.pdf,12,CoRR,9.962599754333496,NimbusRomNo9L-ReguItal,False,353.47845458984375,658.6799926757812,0.75,4,H3
sample_9.pdf,12,", abs/1606.04199, 2016.",9.962599754333496,NimbusRomNo9L-Regu,False,380.8639831542969,658.8564453125,0.0,23,H3
sample_9.pdf,12,[40],9.962599754333496,NimbusRomNo9L-Regu,False,107.99996948242188,688.469482421875,0.0,4,H3
sample_9.pdf,12,"Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate",10.061732292175293,NimbusRomNo9L-Regu,False,124.59765625,688.394287109375,0.13580246913580246,81,H3
sample_9.pdf,12,shift-reduce constituent parsing. In,9.862470626831055,NimbusRomNo9L-Regu,False,129.57899475097656,699.4544067382812,0.027777777777777776,36,H3
sample_9.pdf,12,Proceedings of the 51st Annual Meeting of the ACL (Volume,9.862470626831055,NimbusRomNo9L-ReguItal,False,266.55877685546875,699.2797241210938,0.12280701754385964,57,H3
sample_9.pdf,12,1: Long Papers),9.962599754333496,NimbusRomNo9L-ReguItal,False,128.83200073242188,710.1110229492188,0.13333333333333333,15,H3
sample_9.pdf,12,", pages 434–443. ACL, August 2013.",9.962599754333496,NimbusRomNo9L-Regu,False,193.83799743652344,710.2874755859375,0.11764705882352941,34,H3
sample_9.pdf,13,Attention Visualizations,11.9552001953125,NimbusRomNo9L-Medi,False,108.0,72.78716278076172,0.08333333333333333,24,H3
sample_9.pdf,13,this,7.778810977935791,ArialMT,False,154.6262969970703,148.38047790527344,0.0,4,P
sample_9.pdf,13,spirit,7.778810977935791,ArialMT,False,166.2949676513672,144.0637664794922,0.0,6,P
sample_9.pdf,13,that,7.778810977935791,ArialMT,False,177.96324157714844,147.50924682617188,0.0,4,P
sample_9.pdf,13,majority,7.778810977935791,ArialMT,False,201.29957580566406,133.2584686279297,0.0,8,P
sample_9.pdf,13,American,7.778810977935791,ArialMT,False,224.6365203857422,127.6349105834961,0.125,8,P
sample_9.pdf,13,governments,7.778810977935791,ArialMT,False,236.30470275878906,115.52276611328125,0.0,11,P
sample_9.pdf,13,have,7.778810977935791,ArialMT,False,247.97296142578125,143.62037658691406,0.0,4,P
sample_9.pdf,13,passed,7.778810977935791,ArialMT,False,259.6411437988281,135.40542602539062,0.0,6,P
sample_9.pdf,13,new,7.778810977935791,ArialMT,False,271.3092956542969,146.21849060058594,0.0,3,P
sample_9.pdf,13,laws,7.778810977935791,ArialMT,False,282.9775695800781,144.92721557617188,0.0,4,P
sample_9.pdf,13,since,7.778810977935791,ArialMT,False,294.6462707519531,142.32858276367188,0.0,5,P
sample_9.pdf,13,2009,7.778810977935791,ArialMT,False,306.3144226074219,143.1847686767578,0.0,4,P
sample_9.pdf,13,making,7.778810977935791,ArialMT,False,317.9826965332031,135.4132080078125,0.0,6,P
sample_9.pdf,13,the,7.778810977935791,ArialMT,False,329.6508483886719,149.6722869873047,0.0,3,P
sample_9.pdf,13,registration,7.778810977935791,ArialMT,False,341.3191223144531,122.01134490966797,0.0,12,P
sample_9.pdf,13,voting,7.778810977935791,ArialMT,False,364.6559753417969,139.73004150390625,0.0,6,P
sample_9.pdf,13,process,7.778810977935791,ArialMT,False,376.3242492675781,133.2506866455078,0.0,7,P
sample_9.pdf,13,more,7.778810977935791,ArialMT,False,387.9924011230469,142.7646942138672,0.0,4,P
sample_9.pdf,13,difficult,7.778810977935791,ArialMT,False,399.6600646972656,136.41770935058594,0.0,9,P
sample_9.pdf,13,<EOS>,7.778810977935791,ArialMT,False,422.99749755859375,134.96939086914062,0.6,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,434.66619873046875,138.42359924316406,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,446.3339538574219,138.4241180419922,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,458.0016174316406,138.42465209960938,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,469.6702880859375,138.4241180419922,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,481.33905029296875,138.42318725585938,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,493.00775146484375,138.42359924316406,0.0,5,P
sample_9.pdf,13,this,7.778810977935791,ArialMT,False,154.62681579589844,241.3857421875,0.0,4,P
sample_9.pdf,13,spirit,7.778810977935791,ArialMT,False,166.2949676513672,241.38760375976562,0.0,6,P
sample_9.pdf,13,that,7.778810977935791,ArialMT,False,177.96324157714844,241.3844757080078,0.0,4,P
sample_9.pdf,13,majority,7.778810977935791,ArialMT,False,201.29957580566406,241.3892364501953,0.0,8,P
sample_9.pdf,13,American,7.778810977935791,ArialMT,False,224.6365203857422,241.38912963867188,0.125,8,P
sample_9.pdf,13,governments,7.778810977935791,ArialMT,False,236.30470275878906,241.390869140625,0.0,11,P
sample_9.pdf,13,have,7.778810977935791,ArialMT,False,247.97296142578125,241.38877868652344,0.0,4,P
sample_9.pdf,13,passed,7.778810977935791,ArialMT,False,259.6411437988281,241.39036560058594,0.0,6,P
sample_9.pdf,13,new,7.778810977935791,ArialMT,False,271.3098449707031,241.388427734375,0.0,3,P
sample_9.pdf,13,laws,7.778810977935791,ArialMT,False,282.97808837890625,241.38824462890625,0.0,4,P
sample_9.pdf,13,since,7.778810977935791,ArialMT,False,294.6462707519531,241.38818359375,0.0,5,P
sample_9.pdf,13,2009,7.778810977935791,ArialMT,False,306.3144226074219,241.3896484375,0.0,4,P
sample_9.pdf,13,making,7.778810977935791,ArialMT,False,317.9826965332031,241.39048767089844,0.0,6,P
sample_9.pdf,13,the,7.778810977935791,ArialMT,False,329.6508483886719,241.38583374023438,0.0,3,P
sample_9.pdf,13,registration,7.778810977935791,ArialMT,False,341.3191223144531,241.3905792236328,0.0,12,P
sample_9.pdf,13,voting,7.778810977935791,ArialMT,False,364.6559753417969,241.3886260986328,0.0,6,P
sample_9.pdf,13,process,7.778810977935791,ArialMT,False,376.3242492675781,241.38809204101562,0.0,7,P
sample_9.pdf,13,more,7.778810977935791,ArialMT,False,387.9924011230469,241.3873291015625,0.0,4,P
sample_9.pdf,13,difficult,7.778810977935791,ArialMT,False,399.6600646972656,241.38653564453125,0.0,9,P
sample_9.pdf,13,<EOS>,7.778810977935791,ArialMT,False,422.99749755859375,241.38356018066406,0.6,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,434.6651611328125,241.38819885253906,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,446.3339538574219,241.38819885253906,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,458.0016174316406,241.38768005371094,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,469.6702880859375,241.38819885253906,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,481.33905029296875,241.38861083984375,0.0,5,P
sample_9.pdf,13,<pad>,7.778810977935791,ArialMT,False,493.00775146484375,241.38819885253906,0.0,5,P
sample_9.pdf,13,Figure 3: An example of the attention mechanism following long-distance dependencies in the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,312.311279296875,0.02197802197802198,91,H3
sample_9.pdf,13,encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of,9.972557067871094,NimbusRomNo9L-Regu,False,108.0,323.2889099121094,0.009900990099009901,101,H3
sample_9.pdf,13,"the verb ‘making’, completing the phrase ‘making...more difﬁcult’. Attentions here shown only for",9.987475395202637,NimbusRomNo9L-Regu,False,108.0,334.18658447265625,0.010309278350515464,97,H3
sample_9.pdf,13,the word ‘making’. Different colors represent different heads. Best viewed in color.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,345.1144714355469,0.023809523809523808,84,H3
sample_9.pdf,14,The,9.317630767822266,ArialMT,False,121.92073059082031,199.1611328125,0.3333333333333333,3,H3
sample_9.pdf,14,Law,9.317630767822266,ArialMT,False,135.89710998535156,198.1262664794922,0.3333333333333333,3,H3
sample_9.pdf,14,will,9.317630767822266,ArialMT,False,149.87362670898438,202.28128051757812,0.0,4,H3
sample_9.pdf,14,never,9.317630767822266,ArialMT,False,163.85000610351562,191.91078186035156,0.0,5,H3
sample_9.pdf,14,perfect,9.317630767822266,ArialMT,False,191.80352783203125,186.7301788330078,0.0,7,H3
sample_9.pdf,14,but,9.317630767822266,ArialMT,False,219.75628662109375,202.26266479492188,0.0,3,H3
sample_9.pdf,14,its,9.317630767822266,ArialMT,False,233.73280334472656,205.89715576171875,0.0,3,H3
sample_9.pdf,14,application,9.317630767822266,ArialMT,False,247.70977783203125,170.67654418945312,0.0,11,H3
sample_9.pdf,14,should,9.317630767822266,ArialMT,False,261.6861877441406,187.76443481445312,0.0,6,H3
sample_9.pdf,14,just,9.317630767822266,ArialMT,False,289.6390686035156,200.71592712402344,0.0,4,H3
sample_9.pdf,14,this,9.317630767822266,ArialMT,False,317.59197998046875,200.716552734375,0.0,4,H3
sample_9.pdf,14,what,9.317630767822266,ArialMT,False,345.54534912109375,195.53594970703125,0.0,4,H3
sample_9.pdf,14,are,9.317630767822266,ArialMT,False,373.4982604980469,201.7508087158203,0.0,3,H3
sample_9.pdf,14,missing,9.317630767822266,ArialMT,False,387.4747619628906,183.63796997070312,0.0,7,H3
sample_9.pdf,14,opinion,9.317630767822266,ArialMT,False,443.3810119628906,185.1747589111328,0.0,7,H3
sample_9.pdf,14,<EOS>,9.317630767822266,ArialMT,False,471.33441162109375,184.65296936035156,0.6,5,H3
sample_9.pdf,14,<pad>,9.317630767822266,ArialMT,False,485.3109130859375,188.7887420654297,0.0,5,H3
sample_9.pdf,14,The,9.317630767822266,ArialMT,False,121.92073059082031,312.11932373046875,0.3333333333333333,3,H3
sample_9.pdf,14,Law,9.317630767822266,ArialMT,False,135.89710998535156,312.1227722167969,0.3333333333333333,3,H3
sample_9.pdf,14,will,9.317630767822266,ArialMT,False,149.87362670898438,312.1257629394531,0.0,4,H3
sample_9.pdf,14,never,9.317630767822266,ArialMT,False,163.85061645507812,312.1228332519531,0.0,5,H3
sample_9.pdf,14,perfect,9.317630767822266,ArialMT,False,191.80352783203125,312.1194763183594,0.0,7,H3
sample_9.pdf,14,but,9.317630767822266,ArialMT,False,219.75628662109375,312.1203918457031,0.0,3,H3
sample_9.pdf,14,its,9.317630767822266,ArialMT,False,233.73280334472656,312.11822509765625,0.0,3,H3
sample_9.pdf,14,application,9.317630767822266,ArialMT,False,247.70977783203125,312.1297912597656,0.0,11,H3
sample_9.pdf,14,should,9.317630767822266,ArialMT,False,261.6861877441406,312.1255798339844,0.0,6,H3
sample_9.pdf,14,just,9.317630767822266,ArialMT,False,289.6390686035156,312.1209411621094,0.0,4,H3
sample_9.pdf,14,this,9.317630767822266,ArialMT,False,317.59259033203125,312.11907958984375,0.0,4,H3
sample_9.pdf,14,what,9.317630767822266,ArialMT,False,345.54534912109375,312.12164306640625,0.0,4,H3
sample_9.pdf,14,are,9.317630767822266,ArialMT,False,373.4982604980469,312.1217041015625,0.0,3,H3
sample_9.pdf,14,missing,9.317630767822266,ArialMT,False,387.4747619628906,312.1240234375,0.0,7,H3
sample_9.pdf,14,opinion,9.317630767822266,ArialMT,False,443.3810119628906,312.1288146972656,0.0,7,H3
sample_9.pdf,14,<EOS>,9.317630767822266,ArialMT,False,471.33392333984375,312.116455078125,0.6,5,H3
sample_9.pdf,14,<pad>,9.317630767822266,ArialMT,False,485.3109130859375,312.1231384277344,0.0,5,H3
sample_9.pdf,14,The,9.422321319580078,ArialMT,False,122.07714080810547,416.2327575683594,0.3333333333333333,3,H3
sample_9.pdf,14,Law,9.422321319580078,ArialMT,False,136.21055603027344,415.18621826171875,0.3333333333333333,3,H3
sample_9.pdf,14,will,9.422321319580078,ArialMT,False,150.34410095214844,419.3879699707031,0.0,4,H3
sample_9.pdf,14,never,9.422321319580078,ArialMT,False,164.47752380371094,408.90087890625,0.0,5,H3
sample_9.pdf,14,perfect,9.422321319580078,ArialMT,False,192.7451171875,403.6620788574219,0.0,7,H3
sample_9.pdf,14,but,9.422321319580078,ArialMT,False,221.01194763183594,419.3691101074219,0.0,3,H3
sample_9.pdf,14,its,9.422321319580078,ArialMT,False,235.1455078125,423.04443359375,0.0,3,H3
sample_9.pdf,14,application,9.422321319580078,ArialMT,False,249.279541015625,387.4281005859375,0.0,11,H3
sample_9.pdf,14,should,9.422321319580078,ArialMT,False,263.4129638671875,404.7079772949219,0.0,6,H3
sample_9.pdf,14,just,9.422321319580078,ArialMT,False,291.6799011230469,417.80499267578125,0.0,4,H3
sample_9.pdf,14,this,9.422321319580078,ArialMT,False,319.9468688964844,417.8056335449219,0.0,4,H3
sample_9.pdf,14,what,9.422321319580078,ArialMT,False,348.21435546875,412.5668029785156,0.0,4,H3
sample_9.pdf,14,are,9.422321319580078,ArialMT,False,376.4813232421875,418.85150146484375,0.0,3,H3
sample_9.pdf,14,missing,9.422321319580078,ArialMT,False,390.6148681640625,400.53515625,0.0,7,H3
sample_9.pdf,14,opinion,9.422321319580078,ArialMT,False,447.1492919921875,402.0892028808594,0.0,7,H3
sample_9.pdf,14,<EOS>,9.422321319580078,ArialMT,False,475.416748046875,401.5615539550781,0.6,5,H3
sample_9.pdf,14,<pad>,9.422321319580078,ArialMT,False,489.55029296875,405.74395751953125,0.0,5,H3
sample_9.pdf,14,The,9.422321319580078,ArialMT,False,122.07714080810547,530.4600830078125,0.3333333333333333,3,H3
sample_9.pdf,14,Law,9.422321319580078,ArialMT,False,136.21055603027344,530.4636840820312,0.3333333333333333,3,H3
sample_9.pdf,14,will,9.422321319580078,ArialMT,False,150.34410095214844,530.4666137695312,0.0,4,H3
sample_9.pdf,14,never,9.422321319580078,ArialMT,False,164.4781494140625,530.4636840820312,0.0,5,H3
sample_9.pdf,14,perfect,9.422321319580078,ArialMT,False,192.7451171875,530.4602661132812,0.0,7,H3
sample_9.pdf,14,but,9.422321319580078,ArialMT,False,221.01194763183594,530.461181640625,0.0,3,H3
sample_9.pdf,14,its,9.422321319580078,ArialMT,False,235.1455078125,530.4590454101562,0.0,3,H3
sample_9.pdf,14,application,9.422321319580078,ArialMT,False,249.279541015625,530.4706420898438,0.0,11,H3
sample_9.pdf,14,should,9.422321319580078,ArialMT,False,263.4129638671875,530.4664916992188,0.0,6,H3
sample_9.pdf,14,just,9.422321319580078,ArialMT,False,291.6799011230469,530.4617309570312,0.0,4,H3
sample_9.pdf,14,this,9.422321319580078,ArialMT,False,319.9475402832031,530.4597778320312,0.0,4,H3
sample_9.pdf,14,what,9.422321319580078,ArialMT,False,348.21435546875,530.4625854492188,0.0,4,H3
sample_9.pdf,14,are,9.422321319580078,ArialMT,False,376.4813232421875,530.4624633789062,0.0,3,H3
sample_9.pdf,14,missing,9.422321319580078,ArialMT,False,390.6148681640625,530.4649047851562,0.0,7,H3
sample_9.pdf,14,opinion,9.422321319580078,ArialMT,False,447.1492919921875,530.4696655273438,0.0,7,H3
sample_9.pdf,14,<EOS>,9.422321319580078,ArialMT,False,475.416259765625,530.4572143554688,0.6,5,H3
sample_9.pdf,14,<pad>,9.422321319580078,ArialMT,False,489.55029296875,530.4639282226562,0.0,5,H3
sample_9.pdf,14,"Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:",9.962599754333496,NimbusRomNo9L-Regu,False,108.0,614.281494140625,0.0297029702970297,101,H3
sample_9.pdf,14,Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5,10.002370834350586,NimbusRomNo9L-Regu,False,108.0,625.1602783203125,0.029411764705882353,102,H3
sample_9.pdf,14,and 6. Note that the attentions are very sharp for this word.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,636.0994873046875,0.01639344262295082,61,H3
sample_9.pdf,15,The,9.342264175415039,ArialMT,False,120.93101501464844,213.67007446289062,0.3333333333333333,3,H3
sample_9.pdf,15,Law,9.342264175415039,ArialMT,False,134.94435119628906,212.63246154785156,0.3333333333333333,3,H3
sample_9.pdf,15,will,9.342264175415039,ArialMT,False,148.9578094482422,216.79847717285156,0.0,4,H3
sample_9.pdf,15,never,9.342264175415039,ArialMT,False,162.9711456298828,206.4005584716797,0.0,5,H3
sample_9.pdf,15,perfect,9.342264175415039,ArialMT,False,190.99855041503906,201.20623779296875,0.0,7,H3
sample_9.pdf,15,but,9.342264175415039,ArialMT,False,219.02523803710938,216.77980041503906,0.0,3,H3
sample_9.pdf,15,its,9.342264175415039,ArialMT,False,233.03868103027344,220.42391967773438,0.0,3,H3
sample_9.pdf,15,application,9.342264175415039,ArialMT,False,247.05264282226562,185.11016845703125,0.0,11,H3
sample_9.pdf,15,should,9.342264175415039,ArialMT,False,261.06597900390625,202.24325561523438,0.0,6,H3
sample_9.pdf,15,just,9.342264175415039,ArialMT,False,289.0927734375,215.22898864746094,0.0,4,H3
sample_9.pdf,15,this,9.342264175415039,ArialMT,False,317.11956787109375,215.2296142578125,0.0,4,H3
sample_9.pdf,15,what,9.342264175415039,ArialMT,False,345.1468505859375,210.03530883789062,0.0,4,H3
sample_9.pdf,15,are,9.342264175415039,ArialMT,False,373.17364501953125,216.2666015625,0.0,3,H3
sample_9.pdf,15,missing,9.342264175415039,ArialMT,False,387.1871032714844,198.10586547851562,0.0,7,H3
sample_9.pdf,15,opinion,9.342264175415039,ArialMT,False,443.2411804199219,199.646728515625,0.0,7,H3
sample_9.pdf,15,<EOS>,9.342264175415039,ArialMT,False,471.2685852050781,199.12355041503906,0.6,5,H3
sample_9.pdf,15,<pad>,9.342264175415039,ArialMT,False,485.28192138671875,203.27040100097656,0.0,5,H3
sample_9.pdf,15,The,9.342264175415039,ArialMT,False,120.93101501464844,326.9269104003906,0.3333333333333333,3,H3
sample_9.pdf,15,Law,9.342264175415039,ArialMT,False,134.94435119628906,326.93048095703125,0.3333333333333333,3,H3
sample_9.pdf,15,will,9.342264175415039,ArialMT,False,148.9578094482422,326.933349609375,0.0,4,H3
sample_9.pdf,15,never,9.342264175415039,ArialMT,False,162.97177124023438,326.9304504394531,0.0,5,H3
sample_9.pdf,15,perfect,9.342264175415039,ArialMT,False,190.99855041503906,326.9270935058594,0.0,7,H3
sample_9.pdf,15,but,9.342264175415039,ArialMT,False,219.02523803710938,326.9280090332031,0.0,3,H3
sample_9.pdf,15,its,9.342264175415039,ArialMT,False,233.03868103027344,326.9259033203125,0.0,3,H3
sample_9.pdf,15,application,9.342264175415039,ArialMT,False,247.05264282226562,326.9373779296875,0.0,11,H3
sample_9.pdf,15,should,9.342264175415039,ArialMT,False,261.06597900390625,326.9333190917969,0.0,6,H3
sample_9.pdf,15,just,9.342264175415039,ArialMT,False,289.0927734375,326.92852783203125,0.0,4,H3
sample_9.pdf,15,this,9.342264175415039,ArialMT,False,317.12017822265625,326.9266357421875,0.0,4,H3
sample_9.pdf,15,what,9.342264175415039,ArialMT,False,345.1468505859375,326.92938232421875,0.0,4,H3
sample_9.pdf,15,are,9.342264175415039,ArialMT,False,373.17364501953125,326.9292907714844,0.0,3,H3
sample_9.pdf,15,missing,9.342264175415039,ArialMT,False,387.1871032714844,326.9317321777344,0.0,7,H3
sample_9.pdf,15,opinion,9.342264175415039,ArialMT,False,443.2411804199219,326.9364013671875,0.0,7,H3
sample_9.pdf,15,<EOS>,9.342264175415039,ArialMT,False,471.2679748535156,326.9240417480469,0.6,5,H3
sample_9.pdf,15,<pad>,9.342264175415039,ArialMT,False,485.28192138671875,326.93072509765625,0.0,5,H3
sample_9.pdf,15,The,9.346844673156738,ArialMT,False,120.73013305664062,431.96942138671875,0.3333333333333333,3,H3
sample_9.pdf,15,Law,9.346844673156738,ArialMT,False,134.75033569335938,430.93133544921875,0.3333333333333333,3,H3
sample_9.pdf,15,will,9.346844673156738,ArialMT,False,148.7706756591797,435.099365234375,0.0,4,H3
sample_9.pdf,15,never,9.346844673156738,ArialMT,False,162.79087829589844,424.69635009765625,0.0,5,H3
sample_9.pdf,15,perfect,9.346844673156738,ArialMT,False,190.83203125,419.49951171875,0.0,7,H3
sample_9.pdf,15,but,9.346844673156738,ArialMT,False,218.8724365234375,435.0806884765625,0.0,3,H3
sample_9.pdf,15,its,9.346844673156738,ArialMT,False,232.8927764892578,438.7265625,0.0,3,H3
sample_9.pdf,15,application,9.346844673156738,ArialMT,False,246.91360473632812,403.3955383300781,0.0,11,H3
sample_9.pdf,15,should,9.346844673156738,ArialMT,False,260.9338073730469,420.5370178222656,0.0,6,H3
sample_9.pdf,15,just,9.346844673156738,ArialMT,False,288.9743347167969,433.52911376953125,0.0,4,H3
sample_9.pdf,15,this,9.346844673156738,ArialMT,False,317.0148620605469,433.52972412109375,0.0,4,H3
sample_9.pdf,15,what,9.346844673156738,ArialMT,False,345.055908203125,428.3328857421875,0.0,4,H3
sample_9.pdf,15,are,9.346844673156738,ArialMT,False,373.0964660644531,434.5672607421875,0.0,3,H3
sample_9.pdf,15,missing,9.346844673156738,ArialMT,False,387.1167907714844,416.3976135253906,0.0,7,H3
sample_9.pdf,15,opinion,9.346844673156738,ArialMT,False,443.1983337402344,417.939208984375,0.0,7,H3
sample_9.pdf,15,<EOS>,9.346844673156738,ArialMT,False,471.2388916015625,417.415771484375,0.6,5,H3
sample_9.pdf,15,<pad>,9.346844673156738,ArialMT,False,485.25970458984375,421.56451416015625,0.0,5,H3
sample_9.pdf,15,The,9.346844673156738,ArialMT,False,120.73013305664062,545.2817993164062,0.3333333333333333,3,H3
sample_9.pdf,15,Law,9.346844673156738,ArialMT,False,134.75033569335938,545.2852783203125,0.3333333333333333,3,H3
sample_9.pdf,15,will,9.346844673156738,ArialMT,False,148.7706756591797,545.2882690429688,0.0,4,H3
sample_9.pdf,15,never,9.346844673156738,ArialMT,False,162.79150390625,545.2853393554688,0.0,5,H3
sample_9.pdf,15,perfect,9.346844673156738,ArialMT,False,190.83203125,545.2819213867188,0.0,7,H3
sample_9.pdf,15,but,9.346844673156738,ArialMT,False,218.8724365234375,545.2828369140625,0.0,3,H3
sample_9.pdf,15,its,9.346844673156738,ArialMT,False,232.8927764892578,545.2808227539062,0.0,3,H3
sample_9.pdf,15,application,9.346844673156738,ArialMT,False,246.91360473632812,545.2922973632812,0.0,11,H3
sample_9.pdf,15,should,9.346844673156738,ArialMT,False,260.9338073730469,545.2882080078125,0.0,6,H3
sample_9.pdf,15,just,9.346844673156738,ArialMT,False,288.9743347167969,545.2833862304688,0.0,4,H3
sample_9.pdf,15,this,9.346844673156738,ArialMT,False,317.0155029296875,545.2815551757812,0.0,4,H3
sample_9.pdf,15,what,9.346844673156738,ArialMT,False,345.055908203125,545.2842407226562,0.0,4,H3
sample_9.pdf,15,are,9.346844673156738,ArialMT,False,373.0964660644531,545.2841796875,0.0,3,H3
sample_9.pdf,15,missing,9.346844673156738,ArialMT,False,387.1167907714844,545.2864990234375,0.0,7,H3
sample_9.pdf,15,opinion,9.346844673156738,ArialMT,False,443.1983337402344,545.2913208007812,0.0,7,H3
sample_9.pdf,15,<EOS>,9.346844673156738,ArialMT,False,471.2388916015625,545.2789306640625,0.6,5,H3
sample_9.pdf,15,<pad>,9.346844673156738,ArialMT,False,485.25970458984375,545.2855834960938,0.0,5,H3
sample_9.pdf,15,Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the,10.061732292175293,NimbusRomNo9L-Regu,False,108.0,602.3233032226562,0.02040816326530612,98,H3
sample_9.pdf,15,"sentence. We give two such examples above, from two different heads from the encoder self-attention",9.862470626831055,NimbusRomNo9L-Regu,False,108.0,613.3834228515625,0.010101010101010102,99,H3
sample_9.pdf,15,at layer 5 of 6. The heads clearly learned to perform different tasks.,9.962599754333496,NimbusRomNo9L-Regu,False,108.0,624.217529296875,0.014285714285714285,70,H3
